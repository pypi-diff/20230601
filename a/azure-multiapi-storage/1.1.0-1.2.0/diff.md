# Comparing `tmp/azure-multiapi-storage-1.1.0.tar.gz` & `tmp/azure-multiapi-storage-1.2.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "/mnt/vss/_work/1/a/azure-multiapi-storage-1.1.0.tar", last modified: Thu Apr 13 05:27:03 2023, max compression
+gzip compressed data, was "/mnt/vss/_work/1/a/azure-multiapi-storage-1.2.0.tar", last modified: Thu Jun  1 07:38:15 2023, max compression
```

## Comparing `azure-multiapi-storage-1.1.0.tar` & `azure-multiapi-storage-1.2.0.tar`

### file list

```diff
@@ -1,911 +1,914 @@
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1078 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/LICENSE
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       40 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/MANIFEST.in
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6058 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/PKG-INFO
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5138 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/README.rst
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       56 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1289 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4842 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_auth.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3663 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_common_conversion.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6707 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_connection.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1855 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12708 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9540 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7751 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_error.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2452 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4505 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/httpclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12244 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6465 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/cloudstorageaccount.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26207 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10013 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/retry.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15303 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/sharedaccesssignature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16244 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/storageclient.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1005 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11600 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12934 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3475 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7713 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_request.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8065 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7366 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9333 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/tablebatch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    53331 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/tableservice.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1142 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4398 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_auth.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2874 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_common_conversion.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5691 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_connection.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1681 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10544 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3167 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_error.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2555 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13919 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/batchclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8266 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/httpclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2926 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/requestsclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10972 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_serialization.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1324 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12377 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13817 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1537 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4377 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24350 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/appendblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   143392 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/baseblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38381 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/blockblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23327 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46296 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/pageblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8911 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/cloudstorageaccount.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/common/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1144 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/common/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       22 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/common/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       22 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/common/models.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1008 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9570 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6513 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2799 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    95690 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/fileservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14855 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22947 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/models.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      884 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4783 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1381 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2442 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8549 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    40604 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/queueservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35228 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/sharedaccesssignature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5095 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/storageclient.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1006 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8743 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3113 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4118 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_request.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8147 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7247 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8561 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/tablebatch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46676 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/tableservice.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      742 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1322 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/__init__.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)      997 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15754 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5225 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_download_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7596 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1537 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4423 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18312 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_upload_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27638 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/appendblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   165964 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/baseblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50536 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/blockblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26126 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    74008 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/pageblobservice.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    10060 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     1297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/__init__.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     4084 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_auth.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     3663 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_common_conversion.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     6590 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_connection.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     2086 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_constants.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    12791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_deserialization.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     9506 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_encryption.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     7751 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_error.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_http/
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     2452 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_http/__init__.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     4505 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_http/httpclient.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    12208 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_serialization.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     9450 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/cloudstorageaccount.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    25988 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/models.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    11481 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/retry.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    10477 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/sharedaccesssignature.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    16912 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/storageclient.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1026 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/__init__.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)      889 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7536 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4373 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_download_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2893 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5225 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_upload_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   112937 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/fileservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15903 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/models.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    10408 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      883 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/__init__.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)      889 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5357 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7143 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1449 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2595 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8501 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    47641 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/queueservice.py
--rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     4532 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      742 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      888 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      565 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16128 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_download_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7162 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1103 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3989 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18315 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_upload_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27474 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/appendblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   169237 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/baseblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50367 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/blockblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27183 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    74190 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/pageblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9626 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      935 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4381 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_auth.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3229 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_common_conversion.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6517 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_connection.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2187 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13348 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9072 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7444 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_error.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_http/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2018 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_http/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4235 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_http/httpclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12383 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9016 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/cloudstorageaccount.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27046 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12668 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/retry.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10043 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/sharedaccesssignature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17638 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/storageclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1833 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/tokencredential.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      592 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      457 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7102 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3939 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_download_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2459 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_upload_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   112555 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/fileservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15460 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9974 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      449 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      457 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4911 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6709 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1015 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2161 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8067 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    47646 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/queueservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4098 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      742 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      888 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      562 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20626 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7264 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_download_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7145 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1103 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5218 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18819 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_upload_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    41817 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/appendblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   177228 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/baseblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    61592 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/blockblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29575 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    82000 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/pageblobservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14986 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      992 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4688 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_auth.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3229 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_common_conversion.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6629 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_connection.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2305 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14315 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9072 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9025 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_error.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_http/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2018 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_http/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4235 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_http/httpclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13262 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9660 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/cloudstorageaccount.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28076 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12705 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/retry.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8207 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/sharedaccesssignature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20088 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/storageclient.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1833 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/tokencredential.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      592 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      454 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6685 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_download_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2459 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_upload_chunking.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   123033 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/fileservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17028 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11858 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      449 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      454 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4911 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_deserialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6692 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1015 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_error.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2161 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8067 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48303 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/queueservice.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5583 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/sharedaccesssignature.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8228 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   158646 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28784 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_service_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    66438 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_container_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3356 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22816 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_download.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      609 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3493 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_azure_blob_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2209 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_configuration.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      561 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3675 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_azure_blob_storage_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2256 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_configuration_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1087 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34281 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_append_blob_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   145141 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_blob_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48007 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_block_blob_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    73061 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_container_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42775 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79967 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_page_blob_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28466 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6645 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10047 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_azure_blob_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    63369 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    64150 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models_py3.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1045 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34229 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_append_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   144795 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    47925 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_block_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    72844 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_container_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42693 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_directory_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79825 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_page_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28315 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/version.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15900 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48762 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4342 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_serialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15991 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6499 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18701 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26709 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13192 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29353 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11008 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_upload_helpers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      330 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6542 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   110874 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27183 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_service_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57030 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_container_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19660 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_download_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15172 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10426 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10116 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_upload_helpers.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   215964 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_blob_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34604 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_blob_service_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    81125 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_container_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8060 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25503 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_download.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      779 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4907 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_azure_blob_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2821 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1197 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_vendor.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      779 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4767 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_azure_blob_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2653 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      957 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36933 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_append_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   163444 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    59370 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_block_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    92506 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_container_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    76370 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_page_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35307 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_service_operations.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8345 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12288 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_azure_blob_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   103782 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   110664 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_models_py3.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      957 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    59637 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_append_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   242157 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    96200 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_block_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   134896 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_container_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   121685 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_page_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50251 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16639 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11076 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_list_blobs_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57292 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6270 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_quick_query_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7864 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_serialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6701 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/authentication.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      310 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16446 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/avro_io.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16593 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/avro_io_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8563 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/datafile.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7334 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/datafile_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36373 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/schema.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17790 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7050 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      704 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20674 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28970 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10014 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8640 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10330 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22746 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15229 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31629 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12810 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_upload_helpers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      331 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7001 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   149107 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_blob_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32623 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_blob_service_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    64530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_container_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22338 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_download_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16327 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7905 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_list_blobs_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7685 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11914 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_upload_helpers.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9915 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   217473 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35330 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_service_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    82891 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_container_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8060 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31848 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_download.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    41056 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_encryption.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      843 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4829 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_azure_blob_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2646 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    77452 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1169 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_vendor.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      843 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4895 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_azure_blob_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2612 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1196 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38371 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_append_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   172848 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    62003 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_block_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97943 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_container_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79480 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_page_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37599 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_service_operations.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6318 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12935 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_azure_blob_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   109753 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_models_py3.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1196 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57060 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_append_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   238681 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    92591 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_block_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   134950 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_container_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   116882 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_page_blob_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50925 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16639 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11076 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_list_blobs_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57292 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6270 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_quick_query_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7882 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_serialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6701 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/authentication.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      310 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16446 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16593 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8563 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7334 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36373 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/schema.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18008 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7050 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      704 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20674 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29122 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10014 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8640 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10330 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22285 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15661 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31629 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13976 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_upload_helpers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      333 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7618 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   150123 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    33058 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_service_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    65681 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_container_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28946 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_download_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16327 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7905 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_list_blobs_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7684 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13231 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_upload_helpers.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2002 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    30652 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_directory_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28057 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_file_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13266 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19045 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_service_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4957 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34958 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_file_system_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      625 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2714 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_data_lake_storage_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      577 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2765 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_configuration_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2714 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_data_lake_storage_client_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      736 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25074 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_file_system_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    87573 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_path_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6192 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1992 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1089 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_data_lake_storage_client_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10554 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10775 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models_py3.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      718 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24992 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_file_system_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    87392 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_path_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6170 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/version.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22020 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35382 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_path_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3131 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_serialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15870 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6466 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18635 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27763 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13192 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18357 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      332 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      884 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29446 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_directory_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24363 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_file_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13249 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17153 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_service_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32965 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_file_system_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4643 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29374 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_path_client_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3048 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36179 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_directory_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46871 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_file_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13377 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28023 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_service_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9942 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2664 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_download.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    51904 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_file_system_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      878 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4790 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_azure_data_lake_storage_restapi.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3409 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    77452 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1169 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_vendor.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      878 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4844 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_azure_data_lake_storage_restapi.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3375 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      951 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31614 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_file_system_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   107271 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_path_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7290 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_service_operations.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2758 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2241 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_azure_data_lake_storage_restapi_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38715 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_models_py3.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      951 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42848 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_file_system_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   147178 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_path_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9134 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7371 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_list_paths_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50553 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    53977 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_path_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2499 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_quick_query_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4750 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_serialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5369 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18032 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6792 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      668 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20683 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1590 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27627 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9993 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9737 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8627 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10456 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22184 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15661 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21995 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4375 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_upload_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      332 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      967 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35406 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_directory_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35630 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_file_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13416 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25834 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_service_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2716 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_download_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    49315 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_file_system_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7564 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_list_paths_helper.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2011 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46852 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_path_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4443 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_upload_helper.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1796 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2054 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    30099 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_directory_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19599 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_download.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    59539 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_file_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      609 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2767 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_azure_file_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2562 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_configuration.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      561 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2901 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_azure_file_storage_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2609 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_configuration_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      808 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37857 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97891 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_file_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12118 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38425 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_share_operations_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3760 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4829 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_azure_file_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    33327 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    33666 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models_py3.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      784 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37730 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_directory_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97590 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_file_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12066 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38253 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_share_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/version.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7084 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    40637 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1745 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4779 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_serialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28414 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15925 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_service_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15959 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6466 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18718 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26709 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13213 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24437 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      330 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      701 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25762 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_directory_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18144 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_download_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    51846 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_file_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6890 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8418 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23508 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14123 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_service_client_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2749 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2795 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_deserialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    49793 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_directory_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19304 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_download.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    83598 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_file_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      835 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5492 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_azure_file_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4288 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    78824 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_serialization.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1302 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_vendor.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      835 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_azure_file_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4299 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1002 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    53512 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_directory_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   116468 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_file_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      674 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14252 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    86740 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_share_operations.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4059 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6510 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_azure_file_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    62679 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_models_py3.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      674 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1002 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    76437 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_directory_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   165586 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_file_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      674 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18995 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   118171 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_share_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12763 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_lease.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46513 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1790 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6962 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_serialize.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48728 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23360 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_service_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1477 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7148 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17824 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7019 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      620 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21044 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1590 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29100 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11530 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9968 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8897 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10032 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22114 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16818 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24380 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      333 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      701 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    44563 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_directory_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18624 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_download_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    74849 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_file_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12354 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_lease_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8596 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42026 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20967 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_service_client_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/__init__.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1592 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1514 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_deserialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      782 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4396 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_azure_queue_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2823 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_patch.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1197 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_vendor.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      782 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4248 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2781 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2655 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2258 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_patch.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9762 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_message_id_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17821 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_messages_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22941 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_queue_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18240 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_service_operations.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      821 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9320 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_message_id_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18033 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_messages_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21596 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_queue_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17341 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_service_operations_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2649 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3830 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_azure_queue_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    30089 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31633 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models_py3.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13587 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_message_id_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25428 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_messages_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32815 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_queue_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25992 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/version.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5354 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_message_encoding.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19635 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    39773 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19082 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_service_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      955 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_serialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5369 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17835 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6788 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      668 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22646 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20678 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27829 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9993 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9737 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8747 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9985 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22645 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15223 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12337 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      493 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      477 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4942 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34942 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17177 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_service_client_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1592 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1462 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_deserialize.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      612 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2647 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_azure_queue_storage.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2211 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_configuration.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      564 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2781 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_azure_queue_storage_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2258 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_configuration_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      821 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9320 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_message_id_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18033 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_messages_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21596 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_queue_operations_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17341 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2525 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3643 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_azure_queue_storage_enums.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23880 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23909 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models_py3.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      797 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9283 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_message_id_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17966 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_messages_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21499 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_queue_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17274 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_service_operations.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/version.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5312 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_message_encoding.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19115 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34860 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18504 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_service_client.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/authentication.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15870 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6466 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/constants.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/encryption.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17498 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/parser.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27763 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/request_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/response_handlers.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13192 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12432 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared_access_signature.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      493 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_version.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      477 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/__init__.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4349 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_models.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31263 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_client_async.py
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16980 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_service_client_async.py
-drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6058 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/PKG-INFO
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    54236 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/SOURCES.txt
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)        1 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/dependency_links.txt
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)        1 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/not-zip-safe
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      170 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/requires.txt
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)        6 2023-04-13 05:27:02.000000 azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/top_level.txt
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-04-13 05:27:03.000000 azure-multiapi-storage-1.1.0/setup.cfg
--rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2620 2023-04-13 05:26:52.000000 azure-multiapi-storage-1.1.0/setup.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1078 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/LICENSE
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       40 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/MANIFEST.in
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6132 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/PKG-INFO
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5212 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/README.rst
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       56 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1289 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4842 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_auth.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3663 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_common_conversion.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6707 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_connection.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1855 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12708 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9540 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7751 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_error.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2452 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4505 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/httpclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12244 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6465 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/cloudstorageaccount.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26207 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10013 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/retry.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15303 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/sharedaccesssignature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16244 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/storageclient.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1005 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11600 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12934 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3475 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7713 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_request.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8065 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7366 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9333 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/tablebatch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    53331 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/tableservice.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1142 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4398 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_auth.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2874 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_common_conversion.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5691 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_connection.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1681 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10544 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3167 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_error.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2555 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13919 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/batchclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8266 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/httpclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2926 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/requestsclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10972 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_serialization.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1324 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12377 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13817 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1537 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4377 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24350 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/appendblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   143392 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/baseblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38381 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/blockblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23327 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46296 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/pageblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8911 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/cloudstorageaccount.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/common/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1144 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/common/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       22 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/common/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       22 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/common/models.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1008 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9570 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6513 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2799 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    95690 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/fileservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14855 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22947 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/models.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      884 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4783 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1381 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2442 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8549 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    40604 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/queueservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35228 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/sharedaccesssignature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5095 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/storageclient.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1006 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8743 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3113 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4118 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_request.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8147 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7247 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8561 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/tablebatch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46676 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/tableservice.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      742 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1322 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/__init__.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)      997 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15754 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5225 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_download_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7596 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1537 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4423 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18312 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_upload_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27638 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/appendblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   165964 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/baseblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50536 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/blockblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26126 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    74008 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/pageblobservice.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    10060 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     1297 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/__init__.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     4084 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_auth.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     3663 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_common_conversion.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     6590 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_connection.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     2086 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_constants.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    12791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_deserialization.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     9506 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_encryption.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     7751 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_error.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_http/
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     2452 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_http/__init__.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     4505 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_http/httpclient.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    12208 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_serialization.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     9450 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/cloudstorageaccount.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    25988 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/models.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    11481 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/retry.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    10477 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/sharedaccesssignature.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    16912 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/storageclient.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1026 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/__init__.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)      889 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7536 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4373 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_download_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2893 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5225 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_upload_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   112937 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/fileservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15903 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/models.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)    10408 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      883 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/__init__.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)      889 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5357 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7143 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1449 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2595 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8501 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    47641 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/queueservice.py
+-rwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)     4532 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      742 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      888 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      565 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16128 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_download_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7162 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1103 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3989 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18315 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_upload_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27474 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/appendblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   169237 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/baseblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50367 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/blockblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27183 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    74190 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/pageblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9626 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      935 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4381 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_auth.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3229 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_common_conversion.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6517 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_connection.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2187 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13348 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9072 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7444 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_error.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_http/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2018 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_http/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4235 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_http/httpclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12383 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9016 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/cloudstorageaccount.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27046 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12668 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/retry.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10043 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/sharedaccesssignature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17638 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/storageclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1833 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/tokencredential.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      592 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      457 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7102 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3939 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_download_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2459 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_upload_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   112555 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/fileservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15460 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9974 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      449 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      457 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4911 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6709 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1015 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2161 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8067 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    47646 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/queueservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4098 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      742 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      888 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      562 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20626 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7264 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_download_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7145 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1103 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5218 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18819 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_upload_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    41817 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/appendblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   177228 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/baseblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    61592 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/blockblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29575 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    82000 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/pageblobservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14986 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      992 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4688 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_auth.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3229 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_common_conversion.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6629 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_connection.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2305 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14315 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9072 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9025 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_error.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_http/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2018 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_http/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4235 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_http/httpclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13262 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9660 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/cloudstorageaccount.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28076 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12705 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/retry.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8207 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/sharedaccesssignature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20088 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/storageclient.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1833 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/tokencredential.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      592 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      454 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9297 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6685 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_download_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2459 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_upload_chunking.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   123033 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/fileservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17028 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11858 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      449 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      454 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4911 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_deserialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6692 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1015 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_error.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2161 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8067 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48303 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/queueservice.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5583 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/sharedaccesssignature.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8228 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   158646 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28784 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_service_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    66438 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_container_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3356 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22816 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_download.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      609 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3493 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_azure_blob_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2209 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_configuration.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      561 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3675 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_azure_blob_storage_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2256 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_configuration_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1087 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34281 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_append_blob_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   145141 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_blob_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48007 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_block_blob_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    73061 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_container_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42775 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79967 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_page_blob_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28466 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6645 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10047 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_azure_blob_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    63369 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    64150 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models_py3.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1045 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34229 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_append_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   144795 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    47925 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_block_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    72844 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_container_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42693 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_directory_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79825 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_page_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28315 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/version.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15900 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48762 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4342 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_serialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15991 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6499 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18701 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26709 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13192 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29353 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11008 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_upload_helpers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      330 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6542 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   110874 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27183 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_service_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57030 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_container_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19660 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_download_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15172 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10426 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10116 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_upload_helpers.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9915 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   217473 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35330 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_service_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    82891 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_container_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8060 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31848 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_download.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    41056 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_encryption.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      843 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4829 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_azure_blob_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2646 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    77452 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1169 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_vendor.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      843 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4895 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_azure_blob_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2612 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1196 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38371 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_append_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   172848 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    62003 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_block_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97943 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_container_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79480 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_page_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37599 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_service_operations.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6318 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12935 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_azure_blob_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   109753 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_models_py3.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1196 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57060 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_append_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   238681 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    92591 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_block_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   134950 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_container_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   116882 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_page_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50925 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16639 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11076 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_list_blobs_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57292 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6270 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_quick_query_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7882 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_serialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6701 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/authentication.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      310 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16446 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16593 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8563 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7334 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36373 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/schema.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18008 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7050 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      704 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20674 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29122 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10014 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8640 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10330 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22285 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15661 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31629 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13976 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_upload_helpers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      333 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7618 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   150123 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    33058 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_service_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    65681 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_container_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28946 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_download_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16327 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7905 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_list_blobs_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7684 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13231 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_upload_helpers.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9915 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   233131 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_blob_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    39496 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_blob_service_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    92743 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_container_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8744 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32099 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_download.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    41014 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_encryption.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      843 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4829 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_azure_blob_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2646 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    77450 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1169 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_vendor.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      843 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4895 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_azure_blob_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2612 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1196 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38371 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_append_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   173195 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    62360 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_block_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97943 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_container_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    79480 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_page_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37599 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_service_operations.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6318 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12989 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_azure_blob_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   109769 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_models_py3.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1196 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57060 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_append_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   239028 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    93208 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_block_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   134950 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_container_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   116882 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_page_blob_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50925 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18749 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14741 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_list_blobs_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    57319 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6270 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_quick_query_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7918 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_serialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1477 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7148 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/authentication.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      310 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16446 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/avro_io.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16593 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/avro_io_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8563 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/datafile.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7334 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/datafile_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36374 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/schema.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17796 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6987 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      620 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21029 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1590 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29100 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9968 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8897 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10548 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22215 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16818 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32372 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13955 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_upload_helpers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      331 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7618 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   165641 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_blob_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37306 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_blob_service_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    75979 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_container_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29197 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_download_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18437 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11269 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_list_blobs_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7684 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13158 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_upload_helpers.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2002 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    30652 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_directory_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28057 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_file_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13266 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19045 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_service_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4957 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34958 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_file_system_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      625 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2714 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2608 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_data_lake_storage_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      577 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2765 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_configuration_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2714 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_data_lake_storage_client_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      736 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25074 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_file_system_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    87573 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_path_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6192 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1992 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1089 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_data_lake_storage_client_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10554 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10775 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models_py3.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      718 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24992 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_file_system_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    87392 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_path_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6170 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/version.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22020 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35382 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_path_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3131 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_serialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15870 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6466 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18635 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27763 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13192 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18357 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      332 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      884 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29446 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_directory_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24363 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_file_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13249 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17153 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_service_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32965 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_file_system_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4643 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29374 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_path_client_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3048 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    36179 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_directory_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46871 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_file_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13377 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28023 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_service_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9942 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2664 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_download.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    51904 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_file_system_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      878 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4790 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_azure_data_lake_storage_restapi.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3409 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    77452 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1169 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_vendor.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      878 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4844 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_azure_data_lake_storage_restapi.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3375 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      951 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31614 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_file_system_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   107271 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_path_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7290 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_service_operations.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2758 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2241 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_azure_data_lake_storage_restapi_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38715 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_models_py3.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      951 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42848 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_file_system_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   147178 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_path_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9134 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7371 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_list_paths_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    50553 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    53977 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_path_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2499 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_quick_query_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4750 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_serialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5369 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18032 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6792 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      668 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20683 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1590 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27627 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9993 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9737 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8627 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10456 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22184 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15661 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21995 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4375 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_upload_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      332 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      967 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35406 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_directory_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    35630 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_file_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13416 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25834 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_service_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2716 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_download_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    49315 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_file_system_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7564 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_list_paths_helper.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2011 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46852 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_path_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4443 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_upload_helper.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1796 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2054 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    30099 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_directory_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19599 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_download.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    59539 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_file_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      609 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2767 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_azure_file_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2562 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_configuration.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      561 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2901 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_azure_file_storage_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2609 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_configuration_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      808 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37857 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97891 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_file_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12118 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38425 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_share_operations_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3760 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4829 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_azure_file_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    33327 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    33666 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models_py3.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      784 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    37730 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_directory_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    97590 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_file_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12066 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    38253 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_share_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/version.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7084 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    40637 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1745 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4779 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_serialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    28414 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15925 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_service_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15959 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6466 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18718 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    26709 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13213 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24437 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      330 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      701 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25762 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_directory_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18144 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_download_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    51846 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_file_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6890 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8418 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23508 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14123 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_service_client_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2749 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2795 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_deserialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    49793 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_directory_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19304 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_download.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    83598 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_file_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      835 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5492 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_azure_file_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4288 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    78824 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_serialization.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1302 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_vendor.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      835 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5608 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_azure_file_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4299 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1002 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    53512 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_directory_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   116468 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_file_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      674 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    14252 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    86740 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_share_operations.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4059 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6510 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_azure_file_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    62679 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_models_py3.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      674 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1002 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    76437 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_directory_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   165586 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_file_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      674 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18995 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)   118171 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_share_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12763 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_lease.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    46513 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1790 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6962 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_serialize.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    48728 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23360 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_service_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1477 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7148 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17824 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     7019 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      620 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21044 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1590 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    29100 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    11530 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9968 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8897 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    10032 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22114 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16818 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    24380 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      333 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      701 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    44563 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_directory_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18624 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_download_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    74849 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_file_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12354 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_lease_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8596 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    42026 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20967 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_service_client_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       59 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/__init__.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1592 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1514 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_deserialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      782 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4396 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_azure_queue_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2823 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_patch.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1197 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_vendor.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      782 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4248 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2781 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2655 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2258 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_patch.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9762 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_message_id_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17821 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_messages_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22941 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_queue_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18240 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_service_operations.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      821 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9320 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_message_id_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18033 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_messages_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21596 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_queue_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17341 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_service_operations_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2649 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3830 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_azure_queue_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    30089 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31633 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models_py3.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      791 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13587 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_message_id_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25428 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_messages_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    32815 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_queue_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    25992 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/version.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5354 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_message_encoding.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19635 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    39773 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19082 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_service_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      955 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_serialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5369 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17835 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6788 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      668 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22646 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20678 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27829 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9993 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9737 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     8747 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9985 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22645 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15223 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12337 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      493 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      477 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4942 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34942 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17177 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_service_client_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1592 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1462 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_deserialize.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      612 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2647 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_azure_queue_storage.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2211 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_configuration.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      564 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2781 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_azure_queue_storage_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2258 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_configuration_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      821 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9320 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_message_id_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18033 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_messages_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21596 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_queue_operations_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17341 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2525 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     3643 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_azure_queue_storage_enums.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23880 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    23909 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models_py3.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      797 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9283 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_message_id_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17966 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_messages_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    21499 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_queue_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17274 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_service_operations.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      498 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/version.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5312 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_message_encoding.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    19115 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    34860 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    18504 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_service_client.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1529 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5176 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/authentication.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    15870 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6466 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     1007 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/constants.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    22608 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/encryption.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    17498 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      617 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/parser.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    27763 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9949 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     5297 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/request_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6675 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/response_handlers.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     9488 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    20016 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    13192 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    12432 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared_access_signature.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      493 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_version.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      477 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/__init__.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     4349 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_models.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    31263 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_client_async.py
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    16980 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_service_client_async.py
+drwxrwxr-x   0 cloudtest  (1000) cloudtest  (1000)        0 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     6132 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/PKG-INFO
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)    54451 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/SOURCES.txt
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)        1 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/dependency_links.txt
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)        1 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/not-zip-safe
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)      170 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/requires.txt
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)        6 2023-06-01 07:38:14.000000 azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/top_level.txt
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)       67 2023-06-01 07:38:15.000000 azure-multiapi-storage-1.2.0/setup.cfg
+-rw-rw-r--   0 cloudtest  (1000) cloudtest  (1000)     2620 2023-06-01 07:38:05.000000 azure-multiapi-storage-1.2.0/setup.py
```

### Comparing `azure-multiapi-storage-1.1.0/LICENSE` & `azure-multiapi-storage-1.2.0/LICENSE`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/PKG-INFO` & `azure-multiapi-storage-1.2.0/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: azure-multiapi-storage
-Version: 1.1.0
+Version: 1.2.0
 Summary: Microsoft Azure Storage Client Library for Python with multi API version support.
 Home-page: https://github.com/Azure/azure-multiapi-storage-python
 Author: Microsoft Corporation
 Author-email: azpycli@microsoft.com
 License: MIT
 Classifier: Development Status :: 4 - Beta
 Classifier: Programming Language :: Python
@@ -35,14 +35,18 @@
 
 - The official Azure CosmosDB Table SDK is at https://github.com/Azure/azure-cosmosdb-python/tree/master/azure-cosmosdb-table.
 
 - **Please file issues at the appropriate repository above.**
 
 Change Log
 ----------
+1.2.0
+++++++
+* blob: Support v2022-11-02(12.16.0) and remove v2021-06-08
+
 1.1.0
 ++++++
 * fileshare: Support v2022-11-02(12.12.0b1) and remove v2021-06-08
 
 1.0.0
 ++++++
 * storageV1:
```

### Comparing `azure-multiapi-storage-1.1.0/README.rst` & `azure-multiapi-storage-1.2.0/README.rst`

 * *Files 2% similar despite different names*

```diff
@@ -13,14 +13,18 @@
 
 - The official Azure CosmosDB Table SDK is at https://github.com/Azure/azure-cosmosdb-python/tree/master/azure-cosmosdb-table.
 
 - **Please file issues at the appropriate repository above.**
 
 Change Log
 ----------
+1.2.0
+++++++
+* blob: Support v2022-11-02(12.16.0) and remove v2021-06-08
+
 1.1.0
 ++++++
 * fileshare: Support v2022-11-02(12.12.0b1) and remove v2021-06-08
 
 1.0.0
 ++++++
 * storageV1:
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_auth.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_auth.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_common_conversion.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_common_conversion.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_connection.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_connection.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/httpclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_http/httpclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/cloudstorageaccount.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/cloudstorageaccount.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/retry.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/retry.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/common/storageclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/common/storageclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_request.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_request.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/tablebatch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/tablebatch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/cosmosdb/v2017_04_17/table/tableservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/cosmosdb/v2017_04_17/table/tableservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_auth.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_auth.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_common_conversion.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_common_conversion.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_connection.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_connection.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/batchclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/batchclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/httpclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/httpclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_http/requestsclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_http/requestsclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/appendblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/appendblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/baseblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/baseblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/blockblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/blockblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/blob/pageblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/blob/pageblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/cloudstorageaccount.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/cloudstorageaccount.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/common/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/common/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/fileservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/fileservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/file/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/file/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/queue/queueservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/queue/queueservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/storageclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/storageclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_request.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_request.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/tablebatch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/tablebatch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2015_04_05/table/tableservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2015_04_05/table/tableservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_download_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_download_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/_upload_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/_upload_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/appendblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/appendblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/baseblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/baseblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/blockblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/blockblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/pageblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/pageblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/blob/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/blob/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_auth.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_auth.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_common_conversion.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_common_conversion.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_connection.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_connection.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_http/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_http/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_http/httpclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_http/httpclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/cloudstorageaccount.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/cloudstorageaccount.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/retry.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/retry.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/common/storageclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/common/storageclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_download_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_download_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/_upload_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/_upload_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/fileservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/fileservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/file/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/file/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/queueservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/queueservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_04_17/queue/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_04_17/queue/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_download_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_download_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/_upload_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/_upload_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/appendblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/appendblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/baseblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/baseblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/blockblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/blockblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/pageblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/pageblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/blob/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/blob/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_auth.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_auth.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_common_conversion.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_common_conversion.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_connection.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_connection.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_http/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_http/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_http/httpclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_http/httpclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/cloudstorageaccount.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/cloudstorageaccount.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/retry.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/retry.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/storageclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/storageclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/common/tokencredential.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/common/tokencredential.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_download_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_download_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/_upload_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/_upload_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/fileservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/fileservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/file/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/file/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/queueservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/queueservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2017_11_09/queue/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2017_11_09/queue/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_download_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_download_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/_upload_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/_upload_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/appendblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/appendblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/baseblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/baseblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/blockblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/blockblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/pageblobservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/pageblobservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/blob/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/blob/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_auth.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_auth.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_common_conversion.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_common_conversion.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_connection.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_connection.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_http/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_http/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_http/httpclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_http/httpclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/cloudstorageaccount.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/cloudstorageaccount.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/retry.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/retry.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/storageclient.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/storageclient.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/common/tokencredential.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/common/tokencredential.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_download_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_download_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/_upload_chunking.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/_upload_chunking.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/fileservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/fileservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/file/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/file/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_deserialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_deserialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_error.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_error.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/queueservice.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/queueservice.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storage/v2018_11_09/queue/sharedaccesssignature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storage/v2018_11_09/queue/sharedaccesssignature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_blob_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_container_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_container_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_download.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_download.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_azure_blob_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_azure_blob_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_azure_blob_storage_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_azure_blob_storage_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_configuration_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/_configuration_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_append_blob_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_append_blob_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_blob_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_blob_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_block_blob_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_block_blob_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_container_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_container_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_page_blob_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_page_blob_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_azure_blob_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_azure_blob_storage_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_append_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_append_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_block_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_block_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_container_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_container_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_directory_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_directory_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_page_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_page_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_lease.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_serialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/response_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/_upload_helpers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/_upload_helpers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_container_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_container_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_download_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_download_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_lease_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_upload_helpers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2019_07_07/aio/_upload_helpers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -66,33 +66,35 @@
 
 __version__ = VERSION
 
 
 def upload_blob_to_url(
         blob_url,  # type: str
         data,  # type: Union[Iterable[AnyStr], IO[AnyStr]]
-        credential=None,  # type: Any
+        credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
         **kwargs):
     # type: (...) -> Dict[str, Any]
     """Upload data to a given URL
 
     The data will be uploaded as a block blob.
 
     :param str blob_url:
         The full URI to the blob. This can also include a SAS token.
     :param data:
         The data to upload. This can be bytes, text, an iterable or a file-like object.
     :type data: bytes or str or Iterable
     :param credential:
         The credentials with which to authenticate. This is optional if the
         blob URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword bool overwrite:
         Whether the blob to be uploaded should overwrite the current data.
         If True, upload_blob_to_url will overwrite any existing data. If set to False, the
         operation will fail with a ResourceExistsError.
     :keyword int max_concurrency:
         The number of parallel connections with which to download.
     :keyword int length:
@@ -123,32 +125,34 @@
     stream = client.download_blob(**kwargs)
     stream.readinto(handle)
 
 
 def download_blob_from_url(
         blob_url,  # type: str
         output,  # type: str
-        credential=None,  # type: Any
+        credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
         **kwargs):
     # type: (...) -> None
     """Download the contents of a blob to a local file or stream.
 
     :param str blob_url:
         The full URI to the blob. This can also include a SAS token.
     :param output:
         Where the data should be downloaded to. This could be either a file path to write to,
         or an open IO handle to write to.
     :type output: str or writable stream.
     :param credential:
         The credentials with which to authenticate. This is optional if the
         blob URL already has a SAS token or the blob is public. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials,
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
         an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword bool overwrite:
         Whether the local file should be overwritten if it already exists. The default value is
         `False` - in which case a ValueError will be raised if the file already exists. If set to
         `True`, an attempt will be made to write to the existing file. If a stream handle is passed
         in, this value is ignored.
     :keyword int max_concurrency:
         The number of parallel connections with which to download.
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_blob_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_client.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,42 +1,38 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-lines,no-self-use
+
 from functools import partial
 from io import BytesIO
-from typing import (  # pylint: disable=unused-import
-    Union, Optional, Any, IO, Iterable, AnyStr, Dict, List, Tuple,
-    TYPE_CHECKING,
-    TypeVar, Type)
+from typing import (
+    Any, AnyStr, Dict, IO, Iterable, List, Optional, overload, Tuple, Type, TypeVar, Union,
+    TYPE_CHECKING
+)
+from urllib.parse import urlparse, quote, unquote
 import warnings
 
-try:
-    from urllib.parse import urlparse, quote, unquote
-except ImportError:
-    from urlparse import urlparse  # type: ignore
-    from urllib2 import quote, unquote  # type: ignore
 import six
+from azure.core.exceptions import ResourceNotFoundError, HttpResponseError, ResourceExistsError
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import Pipeline
 from azure.core.tracing.decorator import distributed_trace
-from azure.core.exceptions import ResourceNotFoundError, HttpResponseError, ResourceExistsError
 
 from ._shared import encode_base64
 from ._shared.base_client import StorageAccountHostsMixin, parse_connection_str, parse_query, TransportWrapper
-from ._shared.encryption import generate_blob_encryption_data
 from ._shared.uploads import IterStreamer
 from ._shared.request_handlers import (
     add_metadata_headers, get_length, read_length,
     validate_and_format_range_headers)
 from ._shared.response_handlers import return_response_headers, process_storage_error, return_headers_and_deserialized
 from ._generated import AzureBlobStorage
-from ._generated.models import ( # pylint: disable=unused-import
+from ._generated.models import (
     DeleteSnapshotsOptionType,
     BlobHTTPHeaders,
     BlockLookupList,
     AppendPositionAccessConditions,
     SequenceNumberAccessConditions,
     QueryRequest,
     CpkInfo)
@@ -45,45 +41,53 @@
     get_source_conditions,
     get_cpk_scope_info,
     get_api_version,
     serialize_blob_tags_header,
     serialize_blob_tags,
     serialize_query_format, get_access_conditions
 )
-from ._deserialize import get_page_ranges_result, deserialize_blob_properties, deserialize_blob_stream, parse_tags, \
+from ._deserialize import (
+    get_page_ranges_result,
+    deserialize_blob_properties,
+    deserialize_blob_stream,
+    parse_tags,
     deserialize_pipeline_response_into_cls
+)
+from ._download import StorageStreamDownloader
+from ._encryption import StorageEncryptionMixin
+from ._lease import BlobLeaseClient
+from ._models import BlobType, BlobBlock, BlobProperties, BlobQueryError, QuickQueryDialect, \
+    DelimitedJsonDialect, DelimitedTextDialect, PageRangePaged, PageRange
 from ._quick_query_helper import BlobQueryReader
 from ._upload_helpers import (
     upload_block_blob,
     upload_append_blob,
-    upload_page_blob, _any_conditions)
-from ._models import BlobType, BlobBlock, BlobProperties, BlobQueryError, QuickQueryDialect, \
-    DelimitedJsonDialect, DelimitedTextDialect, PageRangePaged, PageRange
-from ._download import StorageStreamDownloader
-from ._lease import BlobLeaseClient
+    upload_page_blob,
+    _any_conditions
+)
 
 if TYPE_CHECKING:
     from datetime import datetime
     from ._generated.models import BlockList
-    from ._models import (  # pylint: disable=unused-import
+    from ._models import (
         ContentSettings,
         ImmutabilityPolicy,
         PremiumPageBlobTier,
         StandardBlobTier,
         SequenceNumberAction
     )
 
 _ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION = (
     'The require_encryption flag is set, but encryption is not supported'
     ' for this method.')
 
 ClassType = TypeVar("ClassType")
 
 
-class BlobClient(StorageAccountHostsMixin):  # pylint: disable=too-many-public-methods
+class BlobClient(StorageAccountHostsMixin, StorageEncryptionMixin):  # pylint: disable=too-many-public-methods
     """A client to interact with a specific blob, although that blob may not yet exist.
 
     For more optional configuration, please click
     `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
     #optional-configuration>`_.
 
     :param str account_url:
@@ -96,18 +100,20 @@
     :type blob_name: str
     :param str snapshot:
         The optional blob snapshot on which to operate. This can be the snapshot ID string
         or the response returned from :func:`create_snapshot`.
     :param credential:
         The credentials with which to authenticate. This is optional if the
         account URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword str api_version:
         The Storage API version to use for requests. Default value is the most recent service version that is
         compatible with the current SDK. Setting to an older version may result in reduced feature compatibility.
 
         .. versionadded:: 12.2.0
 
     :keyword str secondary_hostname:
@@ -143,15 +149,15 @@
             :caption: Creating the BlobClient from a SAS URL to a blob.
     """
     def __init__(
             self, account_url,  # type: str
             container_name,  # type: str
             blob_name,  # type: str
             snapshot=None,  # type: Optional[Union[str, Dict[str, Any]]]
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):
         # type: (...) -> None
         try:
             if not account_url.lower().startswith('http'):
                 account_url = "https://" + account_url
         except AttributeError:
@@ -177,14 +183,15 @@
 
         # This parameter is used for the hierarchy traversal. Give precedence to credential.
         self._raw_credential = credential if credential else sas_token
         self._query_str, credential = self._format_query_string(sas_token, credential, snapshot=self.snapshot)
         super(BlobClient, self).__init__(parsed_url, service='blob', credential=credential, **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
+        self._configure_encryption(kwargs)
 
     def _format_url(self, hostname):
         container_name = self.container_name
         if isinstance(container_name, six.text_type):
             container_name = container_name.encode('UTF-8')
         return "{}://{}/{}/{}{}".format(
             self.scheme,
@@ -201,30 +208,37 @@
         source_query = parsed_source_url.query
         result = ["{}://{}{}".format(source_scheme, source_hostname, quote(source_path, safe='~/'))]
         if source_query:
             result.append(source_query)
         return '?'.join(result)
 
     @classmethod
-    def from_blob_url(cls, blob_url, credential=None, snapshot=None, **kwargs):
-        # type: (Type[ClassType], str, Optional[Any], Optional[Union[str, Dict[str, Any]]], Any) -> ClassType
+    def from_blob_url(
+            cls,  # type: Type[ClassType]
+            blob_url,  # type: str
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
+            snapshot=None,  # type: Optional[Union[str, Dict[str, Any]]]
+            **kwargs  # type: Any
+        ):  # type: (...) -> ClassType
         """Create BlobClient from a blob url. This doesn't support customized blob url with '/' in blob name.
 
         :param str blob_url:
             The full endpoint URL to the Blob, including SAS token and snapshot if used. This could be
             either the primary endpoint, or the secondary endpoint depending on the current `location_mode`.
         :type blob_url: str
         :param credential:
             The credentials with which to authenticate. This is optional if the
             account URL already has a SAS token, or the connection string already has shared
             access key values. The value can be a SAS token string,
-            an instance of a AzureSasCredential from azure.core.credentials, an account shared access
-            key, or an instance of a TokenCredentials class from azure.identity.
+            an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+            an account shared access key, or an instance of a TokenCredentials class from azure.identity.
             If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
             - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+            If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+            should be the storage account key.
         :param str snapshot:
             The optional blob snapshot on which to operate. This can be the snapshot ID string
             or the response returned from :func:`create_snapshot`. If specified, this will override
             the snapshot in the url.
         :returns: A Blob client.
         :rtype: ~azure.storage.blob.BlobClient
         """
@@ -282,15 +296,15 @@
     @classmethod
     def from_connection_string(
             cls,  # type: Type[ClassType]
             conn_str,  # type: str
             container_name,  # type: str
             blob_name,  # type: str
             snapshot=None,  # type: Optional[str]
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):  # type: (...) -> ClassType
         """Create BlobClient from a Connection String.
 
         :param str conn_str:
             A connection string to an Azure Storage account.
         :param container_name: The container name for the blob.
@@ -300,17 +314,19 @@
         :param str snapshot:
             The optional blob snapshot on which to operate. This can be the snapshot ID string
             or the response returned from :func:`create_snapshot`.
         :param credential:
             The credentials with which to authenticate. This is optional if the
             account URL already has a SAS token, or the connection string already has shared
             access key values. The value can be a SAS token string,
-            an instance of a AzureSasCredential from azure.core.credentials, an account shared access
-            key, or an instance of a TokenCredentials class from azure.identity.
+            an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+            an account shared access key, or an instance of a TokenCredentials class from azure.identity.
             Credentials provided here will take precedence over those in the connection string.
+            If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+            should be the storage account key.
         :returns: A Blob client.
         :rtype: ~azure.storage.blob.BlobClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_authentication.py
                 :start-after: [START auth_from_connection_string_blob]
@@ -340,47 +356,43 @@
         """
         try:
             return self._client.blob.get_account_info(cls=return_response_headers, **kwargs) # type: ignore
         except HttpResponseError as error:
             process_storage_error(error)
 
     def _upload_blob_options(  # pylint:disable=too-many-statements
-            self, data,  # type: Union[AnyStr, Iterable[AnyStr], IO[AnyStr]]
+            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
             blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
             length=None,  # type: Optional[int]
             metadata=None,  # type: Optional[Dict[str, str]]
             **kwargs
         ):
         # type: (...) -> Dict[str, Any]
         if self.require_encryption and not self.key_encryption_key:
             raise ValueError("Encryption required but no key was provided.")
         encryption_options = {
             'required': self.require_encryption,
+            'version': self.encryption_version,
             'key': self.key_encryption_key,
             'resolver': self.key_resolver_function,
         }
-        if self.key_encryption_key is not None:
-            cek, iv, encryption_data = generate_blob_encryption_data(self.key_encryption_key)
-            encryption_options['cek'] = cek
-            encryption_options['vector'] = iv
-            encryption_options['data'] = encryption_data
 
         encoding = kwargs.pop('encoding', 'UTF-8')
         if isinstance(data, six.text_type):
             data = data.encode(encoding) # type: ignore
         if length is None:
             length = get_length(data)
         if isinstance(data, bytes):
             data = data[:length]
 
         if isinstance(data, bytes):
             stream = BytesIO(data)
         elif hasattr(data, 'read'):
             stream = data
-        elif hasattr(data, '__iter__'):
+        elif hasattr(data, '__iter__') and not isinstance(data, (list, tuple, set, dict)):
             stream = IterStreamer(data, encoding=encoding)
         else:
             raise TypeError("Unsupported data type: {}".format(type(data)))
 
         validate_content = kwargs.pop('validate_content', False)
         content_settings = kwargs.pop('content_settings', None)
         overwrite = kwargs.pop('overwrite', False)
@@ -418,14 +430,16 @@
         kwargs['max_concurrency'] = max_concurrency
         kwargs['encryption_options'] = encryption_options
 
         if blob_type == BlobType.BlockBlob:
             kwargs['client'] = self._client.block_blob
             kwargs['data'] = data
         elif blob_type == BlobType.PageBlob:
+            if self.encryption_version == '2.0' and (self.require_encryption or self.key_encryption_key is not None):
+                raise ValueError("Encryption version 2.0 does not currently support page blobs.")
             kwargs['client'] = self._client.page_blob
         elif blob_type == BlobType.AppendBlob:
             if self.require_encryption or (self.key_encryption_key is not None):
                 raise ValueError(_ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION)
             kwargs['client'] = self._client.append_blob
         else:
             raise ValueError("Unsupported BlobType: {}".format(blob_type))
@@ -574,15 +588,15 @@
         try:
             return self._client.block_blob.put_blob_from_url(**options)
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace
     def upload_blob(  # pylint: disable=too-many-locals
-            self, data,  # type: Union[AnyStr, Iterable[AnyStr], IO[AnyStr]]
+            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
             blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
             length=None,  # type: Optional[int]
             metadata=None,  # type: Optional[Dict[str, str]]
             **kwargs
         ):
         # type: (...) -> Any
         """Creates a new blob from a data source with automatic chunking.
@@ -726,16 +740,16 @@
             **kwargs)
         if blob_type == BlobType.BlockBlob:
             return upload_block_blob(**options)
         if blob_type == BlobType.PageBlob:
             return upload_page_blob(**options)
         return upload_append_blob(**options)
 
-    def _download_blob_options(self, offset=None, length=None, **kwargs):
-        # type: (Optional[int], Optional[int], **Any) -> Dict[str, Any]
+    def _download_blob_options(self, offset=None, length=None, encoding=None, **kwargs):
+        # type: (Optional[int], Optional[int], Optional[str], **Any) -> Dict[str, Any]
         if self.require_encryption and not self.key_encryption_key:
             raise ValueError("Encryption required but no key was provided.")
         if length is not None and offset is None:
             raise ValueError("Offset value must not be None if length is set.")
         if length is not None:
             length = offset + length - 1  # Service actually uses an end-range inclusive index
 
@@ -761,26 +775,48 @@
             'encryption_options': {
                 'required': self.require_encryption,
                 'key': self.key_encryption_key,
                 'resolver': self.key_resolver_function},
             'lease_access_conditions': access_conditions,
             'modified_access_conditions': mod_conditions,
             'cpk_info': cpk_info,
-            'cls': kwargs.pop('cls', None) or deserialize_blob_stream,
+            'download_cls': kwargs.pop('cls', None) or deserialize_blob_stream,
             'max_concurrency':kwargs.pop('max_concurrency', 1),
-            'encoding': kwargs.pop('encoding', None),
+            'encoding': encoding,
             'timeout': kwargs.pop('timeout', None),
             'name': self.blob_name,
             'container': self.container_name}
         options.update(kwargs)
         return options
 
+    @overload
+    def download_blob(
+            self, offset: int = None,
+            length: int = None,
+            *,
+            encoding: str,
+            **kwargs) -> StorageStreamDownloader[str]:
+        ...
+
+    @overload
+    def download_blob(
+            self, offset: int = None,
+            length: int = None,
+            *,
+            encoding: None = None,
+            **kwargs) -> StorageStreamDownloader[bytes]:
+        ...
+
     @distributed_trace
-    def download_blob(self, offset=None, length=None, **kwargs):
-        # type: (Optional[int], Optional[int], **Any) -> StorageStreamDownloader
+    def download_blob(
+            self, offset: int = None,
+            length: int = None,
+            *,
+            encoding: Optional[str] = None,
+            **kwargs) -> StorageStreamDownloader:
         """Downloads a blob to the StorageStreamDownloader. The readall() method must
         be used to read all the content or readinto() must be used to download the blob into
         a stream. Using chunks() returns an iterator which allows the user to iterate over the content in chunks.
 
         :param int offset:
             Start of byte range to use for downloading a section of the blob.
             Must be set if length is provided.
@@ -860,14 +896,15 @@
                 :language: python
                 :dedent: 12
                 :caption: Download a blob.
         """
         options = self._download_blob_options(
             offset=offset,
             length=length,
+            encoding=encoding,
             **kwargs)
         return StorageStreamDownloader(**options)
 
     def _quick_query_options(self, query_expression,
                              **kwargs):
         # type: (str, **Any) -> Dict[str, Any]
         delimiter = '\n'
@@ -1517,19 +1554,20 @@
                                encryption_algorithm=cpk.algorithm)
 
         immutability_policy = kwargs.pop('immutability_policy', None)
         if immutability_policy:
             kwargs['immutability_policy_expiry'] = immutability_policy.expiry_time
             kwargs['immutability_policy_mode'] = immutability_policy.policy_mode
 
+        tier = None
         if premium_page_blob_tier:
             try:
-                headers['x-ms-access-tier'] = premium_page_blob_tier.value  # type: ignore
+                tier = premium_page_blob_tier.value  # type: ignore
             except AttributeError:
-                headers['x-ms-access-tier'] = premium_page_blob_tier  # type: ignore
+                tier = premium_page_blob_tier  # type: ignore
 
         blob_tags_string = serialize_blob_tags_header(kwargs.pop('tags', None))
 
         options = {
             'content_length': 0,
             'blob_content_length': size,
             'blob_sequence_number': sequence_number,
@@ -1537,14 +1575,15 @@
             'timeout': kwargs.pop('timeout', None),
             'lease_access_conditions': access_conditions,
             'modified_access_conditions': mod_conditions,
             'cpk_scope_info': cpk_scope_info,
             'cpk_info': cpk_info,
             'blob_tags_string': blob_tags_string,
             'cls': return_response_headers,
+            "tier": tier,
             'headers': headers}
         options.update(kwargs)
         return options
 
     @distributed_trace
     def create_page_blob(  # type: ignore
             self, size,  # type: int
@@ -3712,15 +3751,15 @@
         options = self._clear_page_options(offset, length, **kwargs)
         try:
             return self._client.page_blob.clear_pages(**options)  # type: ignore
         except HttpResponseError as error:
             process_storage_error(error)
 
     def _append_block_options( # type: ignore
-            self, data,  # type: Union[AnyStr, Iterable[AnyStr], IO[AnyStr]]
+            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
             length=None,  # type: Optional[int]
             **kwargs
         ):
         # type: (...) -> Dict[str, Any]
         if self.require_encryption or (self.key_encryption_key is not None):
             raise ValueError(_ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION)
 
@@ -3767,15 +3806,15 @@
             'cpk_info': cpk_info,
             'cls': return_response_headers}
         options.update(kwargs)
         return options
 
     @distributed_trace
     def append_block( # type: ignore
-            self, data,  # type: Union[AnyStr, Iterable[AnyStr], IO[AnyStr]]
+            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
             length=None,  # type: Optional[int]
             **kwargs
         ):
         # type: (...) -> Dict[str, Union[str, datetime, int]]
         """Commits a new block of data to the end of the existing append blob.
 
         :param data:
@@ -4120,9 +4159,9 @@
             )
         else:
             _pipeline = self._pipeline   # pylint: disable = protected-access
         return ContainerClient(
             "{}://{}".format(self.scheme, self.primary_hostname), container_name=self.container_name,
             credential=self._raw_credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_blob_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_service_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,42 +3,41 @@
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
 import functools
 import warnings
 from typing import (  # pylint: disable=unused-import
-    Union, Optional, Any, Iterable, Dict, List,
-    TYPE_CHECKING,
-    TypeVar)
+    Any, Dict, List, Optional, TypeVar, Union,
+    TYPE_CHECKING
+)
+from urllib.parse import urlparse
 
-
-try:
-    from urllib.parse import urlparse
-except ImportError:
-    from urlparse import urlparse # type: ignore
-
-from azure.core.paging import ItemPaged
 from azure.core.exceptions import HttpResponseError
+from azure.core.paging import ItemPaged
 from azure.core.pipeline import Pipeline
 from azure.core.tracing.decorator import distributed_trace
 
-from ._shared.models import LocationMode
 from ._shared.base_client import StorageAccountHostsMixin, TransportWrapper, parse_connection_str, parse_query
+from ._shared.models import LocationMode
 from ._shared.parser import _to_utc_datetime
-from ._shared.response_handlers import return_response_headers, process_storage_error, \
+from ._shared.response_handlers import (
+    return_response_headers,
+    process_storage_error,
     parse_to_internal_user_delegation_key
+)
 from ._generated import AzureBlobStorage
 from ._generated.models import StorageServiceProperties, KeyInfo
 from ._container_client import ContainerClient
 from ._blob_client import BlobClient
-from ._models import ContainerPropertiesPaged
+from ._deserialize import service_stats_deserialize, service_properties_deserialize
+from ._encryption import StorageEncryptionMixin
 from ._list_blobs_helper import FilteredBlobPaged
+from ._models import ContainerPropertiesPaged
 from ._serialize import get_api_version
-from ._deserialize import service_stats_deserialize, service_properties_deserialize
 
 if TYPE_CHECKING:
     from datetime import datetime
     from ._shared.models import UserDelegationKey
     from ._lease import BlobLeaseClient
     from ._models import (
         ContainerProperties,
@@ -51,15 +50,15 @@
         StaticWebsite,
         FilteredBlob
     )
 
 ClassType = TypeVar("ClassType")
 
 
-class BlobServiceClient(StorageAccountHostsMixin):
+class BlobServiceClient(StorageAccountHostsMixin, StorageEncryptionMixin):
     """A client to interact with the Blob Service at the account level.
 
     This client provides operations to retrieve and configure the account properties
     as well as list, create and delete containers within the account.
     For operations relating to a specific container or blob, clients for those entities
     can also be retrieved using the `get_client` functions.
 
@@ -70,18 +69,20 @@
     :param str account_url:
         The URL to the blob storage account. Any other entities included
         in the URL path (e.g. container or blob) will be discarded. This URL can be optionally
         authenticated with a SAS token.
     :param credential:
         The credentials with which to authenticate. This is optional if the
         account URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword str api_version:
         The Storage API version to use for requests. Default value is the most recent service version that is
         compatible with the current SDK. Setting to an older version may result in reduced feature compatibility.
 
         .. versionadded:: 12.2.0
 
     :keyword str secondary_hostname:
@@ -115,15 +116,15 @@
             :language: python
             :dedent: 8
             :caption: Creating the BlobServiceClient with Azure Identity credentials.
     """
 
     def __init__(
             self, account_url,  # type: str
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):
         # type: (...) -> None
         try:
             if not account_url.lower().startswith('http'):
                 account_url = "https://" + account_url
         except AttributeError:
@@ -133,39 +134,42 @@
             raise ValueError("Invalid URL: {}".format(account_url))
 
         _, sas_token = parse_query(parsed_url.query)
         self._query_str, credential = self._format_query_string(sas_token, credential)
         super(BlobServiceClient, self).__init__(parsed_url, service='blob', credential=credential, **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
+        self._configure_encryption(kwargs)
 
     def _format_url(self, hostname):
         """Format the endpoint URL according to the current location
         mode hostname.
         """
         return "{}://{}/{}".format(self.scheme, hostname, self._query_str)
 
     @classmethod
     def from_connection_string(
             cls,  # type: Type[ClassType]
             conn_str,  # type: str
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):  # type: (...) -> ClassType
         """Create BlobServiceClient from a Connection String.
 
         :param str conn_str:
             A connection string to an Azure Storage account.
         :param credential:
             The credentials with which to authenticate. This is optional if the
             account URL already has a SAS token, or the connection string already has shared
             access key values. The value can be a SAS token string,
-            an instance of a AzureSasCredential from azure.core.credentials, an account shared access
-            key, or an instance of a TokenCredentials class from azure.identity.
+            an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+            an account shared access key, or an instance of a TokenCredentials class from azure.identity.
             Credentials provided here will take precedence over those in the connection string.
+            If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+            should be the storage account key.
         :returns: A Blob service client.
         :rtype: ~azure.storage.blob.BlobServiceClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_authentication.py
                 :start-after: [START auth_from_connection_string]
@@ -679,16 +683,16 @@
             transport=TransportWrapper(self._pipeline._transport), # pylint: disable = protected-access
             policies=self._pipeline._impl_policies # pylint: disable = protected-access
         )
         return ContainerClient(
             self.url, container_name=container_name,
             credential=self.credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
 
     def get_blob_client(
             self, container,  # type: Union[ContainerProperties, str]
             blob,  # type: Union[BlobProperties, str]
             snapshot=None  # type: Optional[Union[Dict[str, Any], str]]
         ):
         # type: (...) -> BlobClient
@@ -732,9 +736,9 @@
             transport=TransportWrapper(self._pipeline._transport), # pylint: disable = protected-access
             policies=self._pipeline._impl_policies # pylint: disable = protected-access
         )
         return BlobClient( # type: ignore
             self.url, container_name=container_name, blob_name=blob_name, snapshot=snapshot,
             credential=self.credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_container_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_container_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,61 +3,55 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
 import functools
 from typing import (  # pylint: disable=unused-import
-    Union, Optional, Any, Iterable, AnyStr, Dict, List, Tuple, IO, Iterator,
-    TYPE_CHECKING,
-    TypeVar)
-
-
-try:
-    from urllib.parse import urlparse, quote, unquote
-except ImportError:
-    from urlparse import urlparse # type: ignore
-    from urllib2 import quote, unquote # type: ignore
+    Any, AnyStr, Dict, List, IO, Iterable, Iterator, Optional, overload, TypeVar, Union,
+    TYPE_CHECKING
+)
+from urllib.parse import urlparse, quote, unquote
 
 import six
-
 from azure.core import MatchConditions
 from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
 from azure.core.paging import ItemPaged
-from azure.core.tracing.decorator import distributed_trace
 from azure.core.pipeline import Pipeline
-from azure.core.pipeline.transport import HttpRequest
+from azure.core.pipeline.transport import HttpRequest, HttpResponse
+from azure.core.tracing.decorator import distributed_trace
 
 from ._shared.base_client import StorageAccountHostsMixin, TransportWrapper, parse_connection_str, parse_query
 from ._shared.request_handlers import add_metadata_headers, serialize_iso
 from ._shared.response_handlers import (
     process_storage_error,
     return_response_headers,
-    return_headers_and_deserialized)
+    return_headers_and_deserialized
+)
 from ._generated import AzureBlobStorage
 from ._generated.models import SignedIdentifier
+from ._blob_client import BlobClient
 from ._deserialize import deserialize_container_properties
-from ._serialize import get_modify_conditions, get_container_cpk_scope_info, get_api_version, get_access_conditions
-from ._models import ( # pylint: disable=unused-import
+from ._download import StorageStreamDownloader
+from ._encryption import StorageEncryptionMixin
+from ._lease import BlobLeaseClient
+from ._list_blobs_helper import BlobPrefix, BlobPropertiesPaged, FilteredBlobPaged
+from ._models import (
     ContainerProperties,
     BlobProperties,
     BlobType,
-    FilteredBlob)
-from ._list_blobs_helper import BlobPrefix, BlobPropertiesPaged, FilteredBlobPaged
-from ._lease import BlobLeaseClient
-from ._blob_client import BlobClient
+    FilteredBlob
+)
+from ._serialize import get_modify_conditions, get_container_cpk_scope_info, get_api_version, get_access_conditions
 
 if TYPE_CHECKING:
-    from azure.core.pipeline.transport import HttpTransport, HttpResponse  # pylint: disable=ungrouped-imports
-    from azure.core.pipeline.policies import HTTPPolicy # pylint: disable=ungrouped-imports
     from datetime import datetime
     from ._models import (  # pylint: disable=unused-import
         PublicAccess,
         AccessPolicy,
-        ContentSettings,
         StandardBlobTier,
         PremiumPageBlobTier)
 
 
 def _get_blob_name(blob):
     """Return the blob name.
 
@@ -69,15 +63,15 @@
     except AttributeError:
         return blob
 
 
 ClassType = TypeVar("ClassType")
 
 
-class ContainerClient(StorageAccountHostsMixin):    # pylint: disable=too-many-public-methods
+class ContainerClient(StorageAccountHostsMixin, StorageEncryptionMixin):    # pylint: disable=too-many-public-methods
     """A client to interact with a specific container, although that container
     may not yet exist.
 
     For operations relating to a specific blob within this container, a blob client can be
     retrieved using the :func:`~get_blob_client` function.
 
     For more optional configuration, please click
@@ -89,18 +83,20 @@
         use the :func:`from_container_url` classmethod.
     :param container_name:
         The name of the container for the blob.
     :type container_name: str
     :param credential:
         The credentials with which to authenticate. This is optional if the
         account URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword str api_version:
         The Storage API version to use for requests. Default value is the most recent service version that is
         compatible with the current SDK. Setting to an older version may result in reduced feature compatibility.
 
         .. versionadded:: 12.2.0
 
     :keyword str secondary_hostname:
@@ -134,15 +130,15 @@
             :language: python
             :dedent: 8
             :caption: Creating the container client directly.
     """
     def __init__(
             self, account_url,  # type: str
             container_name,  # type: str
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):
         # type: (...) -> None
         try:
             if not account_url.lower().startswith('http'):
                 account_url = "https://" + account_url
         except AttributeError:
@@ -157,42 +153,49 @@
         self.container_name = container_name
         # This parameter is used for the hierarchy traversal. Give precedence to credential.
         self._raw_credential = credential if credential else sas_token
         self._query_str, credential = self._format_query_string(sas_token, credential)
         super(ContainerClient, self).__init__(parsed_url, service='blob', credential=credential, **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs) # pylint: disable=protected-access
+        self._configure_encryption(kwargs)
 
     def _format_url(self, hostname):
         container_name = self.container_name
         if isinstance(container_name, six.text_type):
             container_name = container_name.encode('UTF-8')
         return "{}://{}/{}{}".format(
             self.scheme,
             hostname,
             quote(container_name),
             self._query_str)
 
     @classmethod
-    def from_container_url(cls, container_url, credential=None, **kwargs):
-        # type: (Type[ClassType], str, Optional[Any], Any) -> ClassType
+    def from_container_url(
+            cls,  # type: Type[ClassType]
+            container_url,  # type: str
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
+            **kwargs  # type: Any
+        ):  # type: (...) -> ClassType
         """Create ContainerClient from a container url.
 
         :param str container_url:
             The full endpoint URL to the Container, including SAS token if used. This could be
             either the primary endpoint, or the secondary endpoint depending on the current `location_mode`.
         :type container_url: str
         :param credential:
             The credentials with which to authenticate. This is optional if the
             account URL already has a SAS token, or the connection string already has shared
             access key values. The value can be a SAS token string,
-            an instance of a AzureSasCredential from azure.core.credentials, an account shared access
-            key, or an instance of a TokenCredentials class from azure.identity.
+            an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+            an account shared access key, or an instance of a TokenCredentials class from azure.identity.
             If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
             - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+            If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+            should be the storage account key.
         :returns: A container client.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         try:
             if not container_url.lower().startswith('http'):
                 container_url = "https://" + container_url
         except AttributeError:
@@ -216,31 +219,33 @@
         return cls(account_url, container_name=container_name, credential=credential, **kwargs)
 
     @classmethod
     def from_connection_string(
             cls,  # type: Type[ClassType]
             conn_str,  # type: str
             container_name,  # type: str
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):  # type: (...) -> ClassType
         """Create ContainerClient from a Connection String.
 
         :param str conn_str:
             A connection string to an Azure Storage account.
         :param container_name:
             The container name for the blob.
         :type container_name: str
         :param credential:
             The credentials with which to authenticate. This is optional if the
             account URL already has a SAS token, or the connection string already has shared
             access key values. The value can be a SAS token string,
-            an instance of a AzureSasCredential from azure.core.credentials, an account shared access
-            key, or an instance of a TokenCredentials class from azure.identity.
+            an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+            an account shared access key, or an instance of a TokenCredentials class from azure.identity.
             Credentials provided here will take precedence over those in the connection string.
+            If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+            should be the storage account key.
         :returns: A container client.
         :rtype: ~azure.storage.blob.ContainerClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_authentication.py
                 :start-after: [START auth_from_connection_string_container]
@@ -319,24 +324,24 @@
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
             The timeout parameter is expressed in seconds.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         lease = kwargs.pop('lease', None)
         try:
-            kwargs['source_lease_id'] = lease.id  # type: str
+            kwargs['source_lease_id'] = lease.id
         except AttributeError:
             kwargs['source_lease_id'] = lease
         try:
             renamed_container = ContainerClient(
                 "{}://{}".format(self.scheme, self.primary_hostname), container_name=new_name,
                 credential=self.credential, api_version=self.api_version, _configuration=self._config,
                 _pipeline=self._pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-                require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-                key_resolver_function=self.key_resolver_function)
+                require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+                key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
             renamed_container._client.container.rename(self.container_name, **kwargs)   # pylint: disable = protected-access
             return renamed_container
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace
     def delete_container(
@@ -615,16 +620,16 @@
             )
         else:
             _pipeline = self._pipeline   # pylint: disable = protected-access
         return BlobServiceClient(
             "{}://{}".format(self.scheme, self.primary_hostname),
             credential=self._raw_credential, api_version=self.api_version, _configuration=self._config,
             _location_mode=self._location_mode, _hosts=self._hosts, require_encryption=self.require_encryption,
-            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function,
-            _pipeline=_pipeline)
+            encryption_version=self.encryption_version, key_encryption_key=self.key_encryption_key,
+            key_resolver_function=self.key_resolver_function, _pipeline=_pipeline)
 
     @distributed_trace
     def get_container_access_policy(self, **kwargs):
         # type: (Any) -> Dict[str, Any]
         """Gets the permissions for the specified container.
         The permissions indicate whether container data may be accessed publicly.
 
@@ -742,18 +747,19 @@
         """Returns a generator to list the blobs under the specified container.
         The generator will lazily follow the continuation tokens returned by
         the service.
 
         :param str name_starts_with:
             Filters the results to return only blobs whose names
             begin with the specified prefix.
-        :param list[str] or str include:
+        :param include:
             Specifies one or more additional datasets to include in the response.
             Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted', 'deletedwithversions',
             'tags', 'versions', 'immutabilitypolicy', 'legalhold'.
+        :paramtype include: list[str] or str
         :keyword int timeout:
             The timeout parameter is expressed in seconds.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.BlobProperties]
 
         .. admonition:: Example:
 
@@ -1006,15 +1012,15 @@
         snapshots. You can delete both at the same time with the delete_blob
         operation.
 
         If a delete retention policy is enabled for the service, then this operation soft deletes the blob or snapshot
         and retains the blob or snapshot for specified number of days.
         After specified number of days, blob's data is removed from the service during garbage collection.
         Soft deleted blob or snapshot is accessible through :func:`list_blobs()` specifying `include=["deleted"]`
-        option. Soft-deleted blob or snapshot can be restored using :func:`~BlobClient.undelete()`
+        option. Soft-deleted blob or snapshot can be restored using :func:`~azure.storage.blob.BlobClient.undelete()`
 
         :param blob: The blob with which to interact. If specified, this value will override
             a blob value specified in the blob URL.
         :type blob: str or ~azure.storage.blob.BlobProperties
         :param str delete_snapshots:
             Required if the blob has associated snapshots. Values include:
              - "only": Deletes only the blobs snapshots.
@@ -1061,17 +1067,42 @@
         kwargs.setdefault('merge_span', True)
         timeout = kwargs.pop('timeout', None)
         blob_client.delete_blob( # type: ignore
             delete_snapshots=delete_snapshots,
             timeout=timeout,
             **kwargs)
 
+    @overload
+    def download_blob(
+            self, blob: Union[str, BlobProperties],
+            offset: int = None,
+            length: int = None,
+            *,
+            encoding: str,
+            **kwargs) -> StorageStreamDownloader[str]:
+        ...
+
+    @overload
+    def download_blob(
+            self, blob: Union[str, BlobProperties],
+            offset: int = None,
+            length: int = None,
+            *,
+            encoding: None = None,
+            **kwargs) -> StorageStreamDownloader[bytes]:
+        ...
+
     @distributed_trace
-    def download_blob(self, blob, offset=None, length=None, **kwargs):
-        # type: (Union[str, BlobProperties], Optional[int], Optional[int], **Any) -> StorageStreamDownloader
+    def download_blob(
+            self, blob: Union[str, BlobProperties],
+            offset: int = None,
+            length: int = None,
+            *,
+            encoding: Optional[str] = None,
+            **kwargs) -> StorageStreamDownloader:
         """Downloads a blob to the StorageStreamDownloader. The readall() method must
         be used to read all the content or readinto() must be used to download the blob into
         a stream. Using chunks() returns an iterator which allows the user to iterate over the content in chunks.
 
         :param blob: The blob with which to interact. If specified, this value will override
             a blob value specified in the blob URL.
         :type blob: str or ~azure.storage.blob.BlobProperties
@@ -1144,18 +1175,23 @@
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :returns: A streaming object (StorageStreamDownloader)
         :rtype: ~azure.storage.blob.StorageStreamDownloader
         """
         blob_client = self.get_blob_client(blob) # type: ignore
         kwargs.setdefault('merge_span', True)
-        return blob_client.download_blob(offset=offset, length=length, **kwargs)
+        return blob_client.download_blob(
+            offset=offset,
+            length=length,
+            encoding=encoding,
+            **kwargs)
 
     def _generate_delete_blobs_subrequest_options(
         self, snapshot=None,
+        version_id=None,
         delete_snapshots=None,
         lease_access_conditions=None,
         modified_access_conditions=None,
         **kwargs
     ):
         """This code is a copy from _generated.
 
@@ -1181,14 +1217,16 @@
             if_tags = modified_access_conditions.if_tags
 
         # Construct parameters
         timeout = kwargs.pop('timeout', None)
         query_parameters = {}
         if snapshot is not None:
             query_parameters['snapshot'] = self._client._serialize.query("snapshot", snapshot, 'str')  # pylint: disable=protected-access
+        if version_id is not None:
+            query_parameters['versionid'] = self._client._serialize.query("version_id", version_id, 'str')  # pylint: disable=protected-access
         if timeout is not None:
             query_parameters['timeout'] = self._client._serialize.query("timeout", timeout, 'int', minimum=0)  # pylint: disable=protected-access
 
         # Construct headers
         header_parameters = {}
         if delete_snapshots is not None:
             header_parameters['x-ms-delete-snapshots'] = self._client._serialize.header(  # pylint: disable=protected-access
@@ -1209,18 +1247,18 @@
             header_parameters['If-None-Match'] = self._client._serialize.header(  # pylint: disable=protected-access
                 "if_none_match", if_none_match, 'str')
         if if_tags is not None:
             header_parameters['x-ms-if-tags'] = self._client._serialize.header("if_tags", if_tags, 'str')  # pylint: disable=protected-access
 
         return query_parameters, header_parameters
 
-    def _generate_delete_blobs_options(self,
-                                       *blobs,  # type: List[Union[str, BlobProperties, dict]]
-                                       **kwargs
-                                       ):
+    def _generate_delete_blobs_options(
+            self, *blobs: Union[str, Dict[str, Any], BlobProperties],
+            **kwargs: Any
+        ):
         timeout = kwargs.pop('timeout', None)
         raise_on_any_failure = kwargs.pop('raise_on_any_failure', True)
         delete_snapshots = kwargs.pop('delete_snapshots', None)
         if_modified_since = kwargs.pop('if_modified_since', None)
         if_unmodified_since = kwargs.pop('if_unmodified_since', None)
         if_tags_match_condition = kwargs.pop('if_tags_match_condition', None)
         kwargs.update({'raise_on_any_failure': raise_on_any_failure,
@@ -1234,14 +1272,15 @@
         for blob in blobs:
             blob_name = _get_blob_name(blob)
             container_name = self.container_name
 
             try:
                 options = BlobClient._generic_delete_blob_options(  # pylint: disable=protected-access
                     snapshot=blob.get('snapshot'),
+                    version_id=blob.get('version_id'),
                     delete_snapshots=delete_snapshots or blob.get('delete_snapshots'),
                     lease=blob.get('lease_id'),
                     if_modified_since=if_modified_since or blob.get('if_modified_since'),
                     if_unmodified_since=if_unmodified_since or blob.get('if_unmodified_since'),
                     etag=blob.get('etag'),
                     if_tags_match_condition=if_tags_match_condition or blob.get('if_tags_match_condition'),
                     match_condition=blob.get('match_condition') or MatchConditions.IfNotModified if blob.get('etag')
@@ -1265,57 +1304,61 @@
             )
             req.format_parameters(query_parameters)
             reqs.append(req)
 
         return reqs, kwargs
 
     @distributed_trace
-    def delete_blobs(self, *blobs, **kwargs):
-        # type: (...) -> Iterator[HttpResponse]
+    def delete_blobs(
+            self, *blobs: Union[str, Dict[str, Any], BlobProperties],
+            **kwargs: Any
+        ) -> Iterator[HttpResponse]:
         """Marks the specified blobs or snapshots for deletion.
 
         The blobs are later deleted during garbage collection.
         Note that in order to delete blobs, you must delete all of their
         snapshots. You can delete both at the same time with the delete_blobs operation.
 
         If a delete retention policy is enabled for the service, then this operation soft deletes the blobs or snapshots
         and retains the blobs or snapshots for specified number of days.
         After specified number of days, blobs' data is removed from the service during garbage collection.
         Soft deleted blobs or snapshots are accessible through :func:`list_blobs()` specifying `include=["deleted"]`
-        Soft-deleted blobs or snapshots can be restored using :func:`~BlobClient.undelete()`
+        Soft-deleted blobs or snapshots can be restored using :func:`~azure.storage.blob.BlobClient.undelete()`
 
         The maximum number of blobs that can be deleted in a single request is 256.
 
         :param blobs:
             The blobs to delete. This can be a single blob, or multiple values can
             be supplied, where each value is either the name of the blob (str) or BlobProperties.
 
             .. note::
                 When the blob type is dict, here's a list of keys, value rules.
 
                 blob name:
                     key: 'name', value type: str
                 snapshot you want to delete:
                     key: 'snapshot', value type: str
-                whether to delete snapthots when deleting blob:
+                version id:
+                    key: 'version_id', value type: str
+                whether to delete snapshots when deleting blob:
                     key: 'delete_snapshots', value: 'include' or 'only'
                 if the blob modified or not:
                     key: 'if_modified_since', 'if_unmodified_since', value type: datetime
                 etag:
                     key: 'etag', value type: str
                 match the etag or not:
                     key: 'match_condition', value type: MatchConditions
                 tags match condition:
                     key: 'if_tags_match_condition', value type: str
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
-        :type blobs: list[str], list[dict], or list[~azure.storage.blob.BlobProperties]
+        :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword str delete_snapshots:
             Required if a blob has associated snapshots. Values include:
              - "only": Deletes only the blobs snapshots.
              - "include": Deletes the blob along with all snapshots.
         :keyword ~datetime.datetime if_modified_since:
             A DateTime value. Azure expects the date value passed in to be UTC.
             If timezone is included, any non-UTC datetimes will be converted to UTC.
@@ -1396,19 +1439,19 @@
         if lease_id is not None:
             header_parameters['x-ms-lease-id'] = self._client._serialize.header("lease_id", lease_id, 'str')  # pylint: disable=protected-access
         if if_tags is not None:
             header_parameters['x-ms-if-tags'] = self._client._serialize.header("if_tags", if_tags, 'str')  # pylint: disable=protected-access
 
         return query_parameters, header_parameters
 
-    def _generate_set_tiers_options(self,
-                                    blob_tier,  # type: Optional[Union[str, StandardBlobTier, PremiumPageBlobTier]]
-                                    *blobs,  # type: List[Union[str, BlobProperties, dict]]
-                                    **kwargs
-                                    ):
+    def _generate_set_tiers_options(
+            self, blob_tier: Optional[Union[str, 'StandardBlobTier', 'PremiumPageBlobTier']],
+            *blobs: Union[str, Dict[str, Any], BlobProperties],
+            **kwargs: Any
+        ):
         timeout = kwargs.pop('timeout', None)
         raise_on_any_failure = kwargs.pop('raise_on_any_failure', True)
         rehydrate_priority = kwargs.pop('rehydrate_priority', None)
         if_tags = kwargs.pop('if_tags_match_condition', None)
         kwargs.update({'raise_on_any_failure': raise_on_any_failure,
                        'sas': self._query_str.replace('?', '&'),
                        'timeout': '&timeout=' + str(timeout) if timeout else "",
@@ -1444,20 +1487,18 @@
             req.format_parameters(query_parameters)
             reqs.append(req)
 
         return reqs, kwargs
 
     @distributed_trace
     def set_standard_blob_tier_blobs(
-        self,
-        standard_blob_tier,  # type: Optional[Union[str, StandardBlobTier]]
-        *blobs,  # type: List[Union[str, BlobProperties, dict]]
-        **kwargs
-    ):
-        # type: (...) -> Iterator[HttpResponse]
+        self, standard_blob_tier: Optional[Union[str, 'StandardBlobTier']],
+        *blobs: Union[str, Dict[str, Any], BlobProperties],
+        **kwargs: Any
+    ) -> Iterator[HttpResponse]:
         """This operation sets the tier on block blobs.
 
         A block blob's tier determines Hot/Cool/Archive storage type.
         This operation does not update the blob's ETag.
 
         The maximum number of blobs that can be updated in a single request is 256.
 
@@ -1486,23 +1527,23 @@
                 standard blob tier:
                     key: 'blob_tier', value type: StandardBlobTier
                 rehydrate priority:
                     key: 'rehydrate_priority', value type: RehydratePriority
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 snapshot:
-                    key: "snapshost", value type: str
+                    key: "snapshot", value type: str
                 version id:
                     key: "version_id", value type: str
                 tags match condition:
                     key: 'if_tags_match_condition', value type: str
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
-        :type blobs: list[str], list[dict], or list[~azure.storage.blob.BlobProperties]
+        :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword ~azure.storage.blob.RehydratePriority rehydrate_priority:
             Indicates the priority with which to rehydrate an archived blob
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
@@ -1517,20 +1558,18 @@
         """
         reqs, options = self._generate_set_tiers_options(standard_blob_tier, *blobs, **kwargs)
 
         return self._batch_send(*reqs, **options)
 
     @distributed_trace
     def set_premium_page_blob_tier_blobs(
-        self,
-        premium_page_blob_tier,  # type: Optional[Union[str, PremiumPageBlobTier]]
-        *blobs,  # type: List[Union[str, BlobProperties, dict]]
-        **kwargs
-    ):
-        # type: (...) -> Iterator[HttpResponse]
+        self, premium_page_blob_tier: Optional[Union[str, 'PremiumPageBlobTier']],
+        *blobs: Union[str, Dict[str, Any], BlobProperties],
+        **kwargs: Any
+    ) -> Iterator[HttpResponse]:
         """Sets the page blob tiers on all blobs. This API is only supported for page blobs on premium accounts.
 
         The maximum number of blobs that can be updated in a single request is 256.
 
         :param premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
@@ -1553,15 +1592,15 @@
                 premium blob tier:
                     key: 'blob_tier', value type: PremiumPageBlobTier
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
-        :type blobs: list[str], list[dict], or list[~azure.storage.blob.BlobProperties]
+        :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword int timeout:
             The timeout parameter is expressed in seconds. This method may make
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure.
@@ -1604,9 +1643,9 @@
             transport=TransportWrapper(self._pipeline._transport), # pylint: disable = protected-access
             policies=self._pipeline._impl_policies # pylint: disable = protected-access
         )
         return BlobClient(
             self.url, container_name=self.container_name, blob_name=blob_name, snapshot=snapshot,
             credential=self.credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_download.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_download.py`

 * *Files 12% similar despite different names*

```diff
@@ -2,28 +2,22 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
 import sys
 import threading
-import time
-
 import warnings
 from io import BytesIO
-from typing import Iterator, Union
-
-import requests
-from azure.core.exceptions import HttpResponseError, ServiceResponseError
 
+from azure.core.exceptions import HttpResponseError
 from azure.core.tracing.common import with_current_context
 from ._shared.encryption import decrypt_blob
 from ._shared.request_handlers import validate_and_format_range_headers
 from ._shared.response_handlers import process_storage_error, parse_length_from_content_range
-from ._deserialize import get_page_ranges_result
 
 
 def process_range_and_offset(start_range, end_range, length, encryption):
     start_offset, end_offset = 0, 0
     if encryption.get("key") is not None or encryption.get("resolver") is not None:
         if start_range is not None:
             # Align the start of the range along a 16 byte block
@@ -44,17 +38,18 @@
 
     return (start_range, end_range), (start_offset, end_offset)
 
 
 def process_content(data, start_offset, end_offset, encryption):
     if data is None:
         raise ValueError("Response cannot be None.")
-
-    content = b"".join(list(data))
-
+    try:
+        content = b"".join(list(data))
+    except Exception as error:
+        raise HttpResponseError(message="Download stream interrupted.", response=data.response, error=error)
     if content and encryption.get("key") is not None or encryption.get("resolver") is not None:
         try:
             return decrypt_blob(
                 encryption.get("required"),
                 encryption.get("key"),
                 encryption.get("resolver"),
                 content,
@@ -67,41 +62,37 @@
     return content
 
 
 class _ChunkDownloader(object):  # pylint: disable=too-many-instance-attributes
     def __init__(
         self,
         client=None,
-        non_empty_ranges=None,
         total_size=None,
         chunk_size=None,
         current_progress=None,
         start_range=None,
         end_range=None,
         stream=None,
         parallel=None,
         validate_content=None,
         encryption_options=None,
-        progress_hook=None,
         **kwargs
     ):
         self.client = client
-        self.non_empty_ranges = non_empty_ranges
 
         # Information on the download range/chunk size
         self.chunk_size = chunk_size
         self.total_size = total_size
         self.start_index = start_range
         self.end_index = end_range
 
         # The destination that we will write to
         self.stream = stream
         self.stream_lock = threading.Lock() if parallel else None
         self.progress_lock = threading.Lock() if parallel else None
-        self.progress_hook = progress_hook
 
         # For a parallel download, the stream is always seekable, so we note down the current position
         # in order to seek to the right place when out-of-order chunks come in
         self.stream_start = stream.tell() if parallel else None
 
         # Download progress so far
         self.progress_total = current_progress
@@ -141,104 +132,51 @@
     def _update_progress(self, length):
         if self.progress_lock:
             with self.progress_lock:  # pylint: disable=not-context-manager
                 self.progress_total += length
         else:
             self.progress_total += length
 
-        if self.progress_hook:
-            self.progress_hook(self.progress_total, self.total_size)
-
     def _write_to_stream(self, chunk_data, chunk_start):
         if self.stream_lock:
             with self.stream_lock:  # pylint: disable=not-context-manager
                 self.stream.seek(self.stream_start + (chunk_start - self.start_index))
                 self.stream.write(chunk_data)
         else:
             self.stream.write(chunk_data)
 
-    def _do_optimize(self, given_range_start, given_range_end):
-        # If we have no page range list stored, then assume there's data everywhere for that page blob
-        # or it's a block blob or append blob
-        if self.non_empty_ranges is None:
-            return False
-
-        for source_range in self.non_empty_ranges:
-            # Case 1: As the range list is sorted, if we've reached such a source_range
-            # we've checked all the appropriate source_range already and haven't found any overlapping.
-            # so the given range doesn't have any data and download optimization could be applied.
-            # given range:		|   |
-            # source range:			       |   |
-            if given_range_end < source_range['start']:  # pylint:disable=no-else-return
-                return True
-            # Case 2: the given range comes after source_range, continue checking.
-            # given range:				|   |
-            # source range:	|   |
-            elif source_range['end'] < given_range_start:
-                pass
-            # Case 3: source_range and given range overlap somehow, no need to optimize.
-            else:
-                return False
-        # Went through all src_ranges, but nothing overlapped. Optimization will be applied.
-        return True
-
     def _download_chunk(self, chunk_start, chunk_end):
         download_range, offset = process_range_and_offset(
             chunk_start, chunk_end, chunk_end, self.encryption_options
         )
+        range_header, range_validation = validate_and_format_range_headers(
+            download_range[0], download_range[1], check_content_md5=self.validate_content
+        )
 
-        # No need to download the empty chunk from server if there's no data in the chunk to be downloaded.
-        # Do optimize and create empty chunk locally if condition is met.
-        if self._do_optimize(download_range[0], download_range[1]):
-            chunk_data = b"\x00" * self.chunk_size
-        else:
-            range_header, range_validation = validate_and_format_range_headers(
-                download_range[0],
-                download_range[1],
-                check_content_md5=self.validate_content
+        try:
+            _, response = self.client.download(
+                range=range_header,
+                range_get_content_md5=range_validation,
+                validate_content=self.validate_content,
+                data_stream_total=self.total_size,
+                download_stream_current=self.progress_total,
+                **self.request_options
             )
+        except HttpResponseError as error:
+            process_storage_error(error)
 
-            retry_active = True
-            retry_total = 3
-            while retry_active:
-                try:
-                    _, response = self.client.download(
-                        range=range_header,
-                        range_get_content_md5=range_validation,
-                        validate_content=self.validate_content,
-                        data_stream_total=self.total_size,
-                        download_stream_current=self.progress_total,
-                        **self.request_options
-                    )
-                except HttpResponseError as error:
-                    process_storage_error(error)
-
-                try:
-                    chunk_data = process_content(response, offset[0], offset[1], self.encryption_options)
-                    retry_active = False
-                except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError) as error:
-                    retry_total -= 1
-                    if retry_total <= 0:
-                        raise ServiceResponseError(error, error=error)
-                    time.sleep(1)
-
-            # This makes sure that if_match is set so that we can validate
-            # that subsequent downloads are to an unmodified blob
-            if self.request_options.get("modified_access_conditions"):
-                self.request_options["modified_access_conditions"].if_match = response.properties.etag
-
+        chunk_data = process_content(response, offset[0], offset[1], self.encryption_options)
         return chunk_data
 
 
 class _ChunkIterator(object):
     """Async iterator for chunks in blob download stream."""
 
-    def __init__(self, size, content, downloader, chunk_size):
+    def __init__(self, size, content, downloader):
         self.size = size
-        self._chunk_size = chunk_size
         self._current_content = content
         self._iter_downloader = downloader
         self._iter_chunks = None
         self._complete = (size == 0)
 
     def __len__(self):
         return self.size
@@ -247,97 +185,81 @@
         return self
 
     def __next__(self):
         """Iterate through responses."""
         if self._complete:
             raise StopIteration("Download complete")
         if not self._iter_downloader:
-            # cut the data obtained from initial GET into chunks
-            if len(self._current_content) > self._chunk_size:
-                return self._get_chunk_data()
+            # If no iterator was supplied, the download completed with
+            # the initial GET, so we just return that data
             self._complete = True
             return self._current_content
 
         if not self._iter_chunks:
             self._iter_chunks = self._iter_downloader.get_chunk_offsets()
-
-        # initial GET result still has more than _chunk_size bytes of data
-        if len(self._current_content) >= self._chunk_size:
-            return self._get_chunk_data()
-
-        try:
+        else:
             chunk = next(self._iter_chunks)
-            self._current_content += self._iter_downloader.yield_chunk(chunk)
-        except StopIteration as e:
-            self._complete = True
-            if self._current_content:
-                return self._current_content
-            raise e
-
-        # the current content from the first get is still there but smaller than chunk size
-        # therefore we want to make sure its also included
-        return self._get_chunk_data()
+            self._current_content = self._iter_downloader.yield_chunk(chunk)
 
-    next = __next__  # Python 2 compatibility.
+        return self._current_content
 
-    def _get_chunk_data(self):
-        chunk_data = self._current_content[: self._chunk_size]
-        self._current_content = self._current_content[self._chunk_size:]
-        return chunk_data
+    next = __next__  # Python 2 compatibility.
 
 
 class StorageStreamDownloader(object):  # pylint: disable=too-many-instance-attributes
     """A streaming object to download from Azure Storage.
 
     :ivar str name:
-        The name of the blob being downloaded.
-    :ivar str container:
-        The name of the container where the blob is.
-    :ivar ~azure.storage.blob.BlobProperties properties:
-        The properties of the blob being downloaded. If only a range of the data is being
+        The name of the file being downloaded.
+    :ivar: str path:
+        The full path of the file.
+    :ivar str share:
+        The name of the share where the file is.
+    :ivar ~azure.storage.fileshare.FileProperties properties:
+        The properties of the file being downloaded. If only a range of the data is being
         downloaded, this will be reflected in the properties.
     :ivar int size:
-        The size of the total data in the stream. This will be the byte range if specified,
-        otherwise the total size of the blob.
+        The size of the total data in the stream. This will be the byte range if speficied,
+        otherwise the total size of the file.
     """
 
     def __init__(
         self,
-        clients=None,
+        client=None,
         config=None,
         start_range=None,
         end_range=None,
         validate_content=None,
         encryption_options=None,
         max_concurrency=1,
         name=None,
-        container=None,
+        path=None,
+        share=None,
         encoding=None,
         **kwargs
     ):
         self.name = name
-        self.container = container
+        self.path = path
+        self.share = share
         self.properties = None
         self.size = None
 
-        self._clients = clients
+        self._client = client
         self._config = config
         self._start_range = start_range
         self._end_range = end_range
         self._max_concurrency = max_concurrency
         self._encoding = encoding
         self._validate_content = validate_content
         self._encryption_options = encryption_options or {}
-        self._progress_hook = kwargs.pop('progress_hook', None)
         self._request_options = kwargs
         self._location_mode = None
         self._download_complete = False
         self._current_content = None
         self._file_size = None
-        self._non_empty_ranges = None
         self._response = None
 
         # The service only provides transactional MD5s for chunks under 4MB.
         # If validate_content is on, get only self.MAX_CHUNK_GET_SIZE for the first
         # chunk so a transactional MD5 can be retrieved.
         self._first_get_size = (
             self._config.max_single_get_size if not self._validate_content else self._config.max_chunk_get_size
@@ -351,15 +273,16 @@
         self._initial_range, self._initial_offset = process_range_and_offset(
             initial_request_start, initial_request_end, self._end_range, self._encryption_options
         )
 
         self._response = self._initial_request()
         self.properties = self._response.properties
         self.properties.name = self.name
-        self.properties.container = self.container
+        self.properties.path = self.path
+        self.properties.share = self.share
 
         # Set the content length to the download size instead of the size of
         # the last range
         self.properties.size = self.size
 
         # Overwrite the content range to the user requested range
         self.properties.content_range = "bytes {0}-{1}/{2}".format(
@@ -369,138 +292,98 @@
         )
 
         # Overwrite the content MD5 as it is the MD5 for the last range instead
         # of the stored MD5
         # TODO: Set to the stored MD5 when the service returns this
         self.properties.content_md5 = None
 
+        if self.size == 0:
+            self._current_content = b""
+        else:
+            self._current_content = process_content(
+                self._response,
+                self._initial_offset[0],
+                self._initial_offset[1],
+                self._encryption_options
+            )
+
     def __len__(self):
         return self.size
 
     def _initial_request(self):
         range_header, range_validation = validate_and_format_range_headers(
             self._initial_range[0],
             self._initial_range[1],
             start_range_required=False,
             end_range_required=False,
             check_content_md5=self._validate_content
         )
 
-        retry_active = True
-        retry_total = 3
-        while retry_active:
-            try:
-                location_mode, response = self._clients.blob.download(
-                    range=range_header,
-                    range_get_content_md5=range_validation,
-                    validate_content=self._validate_content,
-                    data_stream_total=None,
-                    download_stream_current=0,
-                    **self._request_options
-                )
-
-                # Check the location we read from to ensure we use the same one
-                # for subsequent requests.
-                self._location_mode = location_mode
-
-                # Parse the total file size and adjust the download size if ranges
-                # were specified
-                self._file_size = parse_length_from_content_range(response.properties.content_range)
-                if self._end_range is not None:
-                    # Use the end range index unless it is over the end of the file
-                    self.size = min(self._file_size, self._end_range - self._start_range + 1)
-                elif self._start_range is not None:
-                    self.size = self._file_size - self._start_range
-                else:
-                    self.size = self._file_size
-
-            except HttpResponseError as error:
-                if self._start_range is None and error.response.status_code == 416:
-                    # Get range will fail on an empty file. If the user did not
-                    # request a range, do a regular get request in order to get
-                    # any properties.
-                    try:
-                        _, response = self._clients.blob.download(
-                            validate_content=self._validate_content,
-                            data_stream_total=0,
-                            download_stream_current=0,
-                            **self._request_options
-                        )
-                    except HttpResponseError as error:
-                        process_storage_error(error)
-
-                    # Set the download size to empty
-                    self.size = 0
-                    self._file_size = 0
-                else:
-                    process_storage_error(error)
+        try:
+            location_mode, response = self._client.download(
+                range=range_header,
+                range_get_content_md5=range_validation,
+                validate_content=self._validate_content,
+                data_stream_total=None,
+                download_stream_current=0,
+                **self._request_options
+            )
 
-            try:
-                if self.size == 0:
-                    self._current_content = b""
-                else:
-                    self._current_content = process_content(
-                        response,
-                        self._initial_offset[0],
-                        self._initial_offset[1],
-                        self._encryption_options
+            # Check the location we read from to ensure we use the same one
+            # for subsequent requests.
+            self._location_mode = location_mode
+
+            # Parse the total file size and adjust the download size if ranges
+            # were specified
+            self._file_size = parse_length_from_content_range(response.properties.content_range)
+            if self._end_range is not None:
+                # Use the end range index unless it is over the end of the file
+                self.size = min(self._file_size, self._end_range - self._start_range + 1)
+            elif self._start_range is not None:
+                self.size = self._file_size - self._start_range
+            else:
+                self.size = self._file_size
+
+        except HttpResponseError as error:
+            if self._start_range is None and error.response.status_code == 416:
+                # Get range will fail on an empty file. If the user did not
+                # request a range, do a regular get request in order to get
+                # any properties.
+                try:
+                    _, response = self._client.download(
+                        validate_content=self._validate_content,
+                        data_stream_total=0,
+                        download_stream_current=0,
+                        **self._request_options
                     )
-                retry_active = False
-            except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError) as error:
-                retry_total -= 1
-                if retry_total <= 0:
-                    raise ServiceResponseError(error, error=error)
-                time.sleep(1)
+                except HttpResponseError as error:
+                    process_storage_error(error)
 
-        # get page ranges to optimize downloading sparse page blob
-        if response.properties.blob_type == 'PageBlob':
-            try:
-                page_ranges = self._clients.page_blob.get_page_ranges()
-                self._non_empty_ranges = get_page_ranges_result(page_ranges)[0]
-            # according to the REST API documentation:
-            # in a highly fragmented page blob with a large number of writes,
-            # a Get Page Ranges request can fail due to an internal server timeout.
-            # thus, if the page blob is not sparse, it's ok for it to fail
-            except HttpResponseError:
-                pass
+                # Set the download size to empty
+                self.size = 0
+                self._file_size = 0
+            else:
+                process_storage_error(error)
 
         # If the file is small, the download is complete at this point.
         # If file size is large, download the rest of the file in chunks.
-        if response.properties.size != self.size:
-            if self._request_options.get("modified_access_conditions"):
-                self._request_options["modified_access_conditions"].if_match = response.properties.etag
-        else:
+        if response.properties.size == self.size:
             self._download_complete = True
         return response
 
     def chunks(self):
-        # type: () -> Iterator[bytes]
-        """Iterate over chunks in the download stream.
-
-        :rtype: Iterator[bytes]
-
-        .. admonition:: Example:
-
-            .. literalinclude:: ../samples/blob_samples_hello_world.py
-                :start-after: [START download_a_blob_in_chunk]
-                :end-before: [END download_a_blob_in_chunk]
-                :language: python
-                :dedent: 12
-                :caption: Download a blob using chunks().
-        """
         if self.size == 0 or self._download_complete:
             iter_downloader = None
         else:
             data_end = self._file_size
             if self._end_range is not None:
                 # Use the end range index unless it is over the end of the file
                 data_end = min(self._file_size, self._end_range + 1)
             iter_downloader = _ChunkDownloader(
-                client=self._clients.blob,
-                non_empty_ranges=self._non_empty_ranges,
+                client=self._client,
                 total_size=self.size,
                 chunk_size=self._config.max_chunk_get_size,
                 current_progress=self._first_get_size,
                 start_range=self._initial_range[1] + 1,  # start where the first download ended
                 end_range=data_end,
                 stream=None,
                 parallel=False,
@@ -508,20 +391,18 @@
                 encryption_options=self._encryption_options,
                 use_location=self._location_mode,
                 **self._request_options
             )
         return _ChunkIterator(
             size=self.size,
             content=self._current_content,
-            downloader=iter_downloader,
-            chunk_size=self._config.max_chunk_get_size)
+            downloader=iter_downloader)
 
     def readall(self):
-        # type: () -> Union[bytes, str]
-        """Download the contents of this blob.
+        """Download the contents of this file.
 
         This operation is blocking until all data is downloaded.
         :rtype: bytes or str
         """
         stream = BytesIO()
         self.readinto(stream)
         data = stream.getvalue()
@@ -542,15 +423,15 @@
             "content_as_bytes is deprecated, use readall instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
         return self.readall()
 
     def content_as_text(self, max_concurrency=1, encoding="UTF-8"):
-        """Download the contents of this blob, and decode as text.
+        """Download the contents of this file, and decode as text.
 
         This operation is blocking until all data is downloaded.
 
         :keyword int max_concurrency:
             The number of parallel connections with which to download.
         :param str encoding:
             Test encoding to decode the downloaded bytes. Default is UTF-8.
@@ -584,61 +465,56 @@
             try:
                 stream.seek(stream.tell())
             except (NotImplementedError, AttributeError):
                 raise ValueError(error_message)
 
         # Write the content to the user stream
         stream.write(self._current_content)
-        if self._progress_hook:
-            self._progress_hook(len(self._current_content), self.size)
-
         if self._download_complete:
             return self.size
 
         data_end = self._file_size
         if self._end_range is not None:
             # Use the length unless it is over the end of the file
             data_end = min(self._file_size, self._end_range + 1)
 
         downloader = _ChunkDownloader(
-            client=self._clients.blob,
-            non_empty_ranges=self._non_empty_ranges,
+            client=self._client,
             total_size=self.size,
             chunk_size=self._config.max_chunk_get_size,
             current_progress=self._first_get_size,
             start_range=self._initial_range[1] + 1,  # Start where the first download ended
             end_range=data_end,
             stream=stream,
             parallel=parallel,
             validate_content=self._validate_content,
             encryption_options=self._encryption_options,
             use_location=self._location_mode,
-            progress_hook=self._progress_hook,
             **self._request_options
         )
         if parallel:
             import concurrent.futures
-            with concurrent.futures.ThreadPoolExecutor(self._max_concurrency) as executor:
-                list(executor.map(
-                        with_current_context(downloader.process_chunk),
-                        downloader.get_chunk_offsets()
-                    ))
+            executor = concurrent.futures.ThreadPoolExecutor(self._max_concurrency)
+            list(executor.map(
+                    with_current_context(downloader.process_chunk),
+                    downloader.get_chunk_offsets()
+                ))
         else:
             for chunk in downloader.get_chunk_offsets():
                 downloader.process_chunk(chunk)
         return self.size
 
     def download_to_stream(self, stream, max_concurrency=1):
-        """Download the contents of this blob to a stream.
+        """Download the contents of this file to a stream.
 
         :param stream:
             The stream to download to. This can be an open file-handle,
             or any writable stream. The stream must be seekable if the download
             uses more than one parallel connection.
-        :returns: The properties of the downloaded blob.
+        :returns: The properties of the downloaded file.
         :rtype: Any
         """
         warnings.warn(
             "download_to_stream is deprecated, use readinto instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,14 +2,14 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from ._azure_blob_storage import AzureBlobStorage
-__all__ = ['AzureBlobStorage']
+from ._azure_queue_storage import AzureQueueStorage
+__all__ = ['AzureQueueStorage']
 
 # `._patch.py` is used for handwritten extensions to the generated code
 # Example: https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/customize_code/how-to-patch-sdk-code.md
 from ._patch import patch_sdk
 patch_sdk()
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_azure_blob_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_azure_blob_storage.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,109 +3,98 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from copy import deepcopy
-from typing import TYPE_CHECKING
+from typing import Any, Awaitable
 
-from msrest import Deserializer, Serializer
+from azure.core import AsyncPipelineClient
+from azure.core.rest import AsyncHttpResponse, HttpRequest
 
-from azure.core import PipelineClient
-
-from . import models
+from .. import models
+from .._serialization import Deserializer, Serializer
 from ._configuration import AzureBlobStorageConfiguration
-from .operations import AppendBlobOperations, BlobOperations, BlockBlobOperations, ContainerOperations, PageBlobOperations, ServiceOperations
-
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any
+from .operations import (
+    AppendBlobOperations,
+    BlobOperations,
+    BlockBlobOperations,
+    ContainerOperations,
+    PageBlobOperations,
+    ServiceOperations,
+)
 
-    from azure.core.rest import HttpRequest, HttpResponse
 
-class AzureBlobStorage(object):
+class AzureBlobStorage:  # pylint: disable=client-accepts-api-version-keyword
     """AzureBlobStorage.
 
     :ivar service: ServiceOperations operations
-    :vartype service: azure.storage.blob.operations.ServiceOperations
+    :vartype service: azure.storage.blob.aio.operations.ServiceOperations
     :ivar container: ContainerOperations operations
-    :vartype container: azure.storage.blob.operations.ContainerOperations
+    :vartype container: azure.storage.blob.aio.operations.ContainerOperations
     :ivar blob: BlobOperations operations
-    :vartype blob: azure.storage.blob.operations.BlobOperations
+    :vartype blob: azure.storage.blob.aio.operations.BlobOperations
     :ivar page_blob: PageBlobOperations operations
-    :vartype page_blob: azure.storage.blob.operations.PageBlobOperations
+    :vartype page_blob: azure.storage.blob.aio.operations.PageBlobOperations
     :ivar append_blob: AppendBlobOperations operations
-    :vartype append_blob: azure.storage.blob.operations.AppendBlobOperations
+    :vartype append_blob: azure.storage.blob.aio.operations.AppendBlobOperations
     :ivar block_blob: BlockBlobOperations operations
-    :vartype block_blob: azure.storage.blob.operations.BlockBlobOperations
+    :vartype block_blob: azure.storage.blob.aio.operations.BlockBlobOperations
     :param url: The URL of the service account, container, or blob that is the target of the
-     desired operation.
+     desired operation. Required.
     :type url: str
-    :param base_url: Service URL. Default value is "".
+    :param base_url: Service URL. Required. Default value is "".
     :type base_url: str
     :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2021-04-10". Note that overriding this default value may result in unsupported behavior.
+     is "2021-08-06". Note that overriding this default value may result in unsupported behavior.
     :paramtype version: str
     """
 
-    def __init__(
-        self,
-        url,  # type: str
-        base_url="",  # type: str
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+    def __init__(  # pylint: disable=missing-client-constructor-parameter-credential
+        self, url: str, base_url: str = "", **kwargs: Any
+    ) -> None:
         self._config = AzureBlobStorageConfiguration(url=url, **kwargs)
-        self._client = PipelineClient(base_url=base_url, config=self._config, **kwargs)
+        self._client = AsyncPipelineClient(base_url=base_url, config=self._config, **kwargs)
 
         client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
         self._serialize = Serializer(client_models)
         self._deserialize = Deserializer(client_models)
         self._serialize.client_side_validation = False
         self.service = ServiceOperations(self._client, self._config, self._serialize, self._deserialize)
         self.container = ContainerOperations(self._client, self._config, self._serialize, self._deserialize)
         self.blob = BlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.page_blob = PageBlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.append_blob = AppendBlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.block_blob = BlockBlobOperations(self._client, self._config, self._serialize, self._deserialize)
 
-
-    def _send_request(
-        self,
-        request,  # type: HttpRequest
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> HttpResponse
+    def _send_request(self, request: HttpRequest, **kwargs: Any) -> Awaitable[AsyncHttpResponse]:
         """Runs the network request through the client's chained policies.
 
         >>> from azure.core.rest import HttpRequest
         >>> request = HttpRequest("GET", "https://www.example.org/")
         <HttpRequest [GET], url: 'https://www.example.org/'>
-        >>> response = client._send_request(request)
-        <HttpResponse: 200 OK>
+        >>> response = await client._send_request(request)
+        <AsyncHttpResponse: 200 OK>
 
-        For more information on this code flow, see https://aka.ms/azsdk/python/protocol/quickstart
+        For more information on this code flow, see https://aka.ms/azsdk/dpcodegen/python/send_request
 
         :param request: The network request you want to make. Required.
         :type request: ~azure.core.rest.HttpRequest
         :keyword bool stream: Whether the response payload will be streamed. Defaults to False.
         :return: The response of your network call. Does not do error handling on your response.
-        :rtype: ~azure.core.rest.HttpResponse
+        :rtype: ~azure.core.rest.AsyncHttpResponse
         """
 
         request_copy = deepcopy(request)
         request_copy.url = self._client.format_url(request_copy.url)
         return self._client.send_request(request_copy, **kwargs)
 
-    def close(self):
-        # type: () -> None
-        self._client.close()
-
-    def __enter__(self):
-        # type: () -> AzureBlobStorage
-        self._client.__enter__()
+    async def close(self) -> None:
+        await self._client.close()
+
+    async def __aenter__(self) -> "AzureBlobStorage":
+        await self._client.__aenter__()
         return self
 
-    def __exit__(self, *exc_details):
-        # type: (Any) -> None
-        self._client.__exit__(*exc_details)
+    async def __aexit__(self, *exc_details) -> None:
+        await self._client.__aexit__(*exc_details)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,63 +2,57 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from typing import TYPE_CHECKING
+from typing import Any
 
 from azure.core.configuration import Configuration
 from azure.core.pipeline import policies
 
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any
-
 VERSION = "unknown"
 
-class AzureBlobStorageConfiguration(Configuration):  # pylint: disable=too-many-instance-attributes
-    """Configuration for AzureBlobStorage.
+class AzureQueueStorageConfiguration(Configuration):  # pylint: disable=too-many-instance-attributes
+    """Configuration for AzureQueueStorage.
 
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
-    :param url: The URL of the service account, container, or blob that is the target of the
-     desired operation.
+    :param url: The URL of the service account, queue or message that is the target of the desired
+     operation.
     :type url: str
     :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2021-04-10". Note that overriding this default value may result in unsupported behavior.
+     is "2018-03-28". Note that overriding this default value may result in unsupported behavior.
     :paramtype version: str
     """
 
     def __init__(
         self,
-        url,  # type: str
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        super(AzureBlobStorageConfiguration, self).__init__(**kwargs)
-        version = kwargs.pop('version', "2021-04-10")  # type: str
+        url: str,
+        **kwargs: Any
+    ) -> None:
+        super(AzureQueueStorageConfiguration, self).__init__(**kwargs)
+        version = kwargs.pop('version', "2018-03-28")  # type: str
 
         if url is None:
             raise ValueError("Parameter 'url' must not be None.")
 
         self.url = url
         self.version = version
-        kwargs.setdefault('sdk_moniker', 'azureblobstorage/{}'.format(VERSION))
+        kwargs.setdefault('sdk_moniker', 'azurequeuestorage/{}'.format(VERSION))
         self._configure(**kwargs)
 
     def _configure(
         self,
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        **kwargs: Any
+    ) -> None:
         self.user_agent_policy = kwargs.get('user_agent_policy') or policies.UserAgentPolicy(**kwargs)
         self.headers_policy = kwargs.get('headers_policy') or policies.HeadersPolicy(**kwargs)
         self.proxy_policy = kwargs.get('proxy_policy') or policies.ProxyPolicy(**kwargs)
         self.logging_policy = kwargs.get('logging_policy') or policies.NetworkTraceLoggingPolicy(**kwargs)
         self.http_logging_policy = kwargs.get('http_logging_policy') or policies.HttpLoggingPolicy(**kwargs)
-        self.retry_policy = kwargs.get('retry_policy') or policies.RetryPolicy(**kwargs)
+        self.retry_policy = kwargs.get('retry_policy') or policies.AsyncRetryPolicy(**kwargs)
         self.custom_hook_policy = kwargs.get('custom_hook_policy') or policies.CustomHookPolicy(**kwargs)
-        self.redirect_policy = kwargs.get('redirect_policy') or policies.RedirectPolicy(**kwargs)
+        self.redirect_policy = kwargs.get('redirect_policy') or policies.AsyncRedirectPolicy(**kwargs)
         self.authentication_policy = kwargs.get('authentication_policy')
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/_vendor.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_vendor.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,14 +2,14 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from ._azure_blob_storage import AzureBlobStorage
-__all__ = ['AzureBlobStorage']
+from ._azure_queue_storage import AzureQueueStorage
+__all__ = ['AzureQueueStorage']
 
 # `._patch.py` is used for handwritten extensions to the generated code
 # Example: https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/customize_code/how-to-patch-sdk-code.md
 from ._patch import patch_sdk
 patch_sdk()
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_azure_blob_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_azure_blob_storage.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,24 +5,31 @@
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from copy import deepcopy
 from typing import Any, Awaitable
 
-from msrest import Deserializer, Serializer
-
 from azure.core import AsyncPipelineClient
 from azure.core.rest import AsyncHttpResponse, HttpRequest
 
 from .. import models
+from .._serialization import Deserializer, Serializer
 from ._configuration import AzureBlobStorageConfiguration
-from .operations import AppendBlobOperations, BlobOperations, BlockBlobOperations, ContainerOperations, PageBlobOperations, ServiceOperations
+from .operations import (
+    AppendBlobOperations,
+    BlobOperations,
+    BlockBlobOperations,
+    ContainerOperations,
+    PageBlobOperations,
+    ServiceOperations,
+)
+
 
-class AzureBlobStorage:
+class AzureBlobStorage:  # pylint: disable=client-accepts-api-version-keyword
     """AzureBlobStorage.
 
     :ivar service: ServiceOperations operations
     :vartype service: azure.storage.blob.aio.operations.ServiceOperations
     :ivar container: ContainerOperations operations
     :vartype container: azure.storage.blob.aio.operations.ContainerOperations
     :ivar blob: BlobOperations operations
@@ -30,28 +37,25 @@
     :ivar page_blob: PageBlobOperations operations
     :vartype page_blob: azure.storage.blob.aio.operations.PageBlobOperations
     :ivar append_blob: AppendBlobOperations operations
     :vartype append_blob: azure.storage.blob.aio.operations.AppendBlobOperations
     :ivar block_blob: BlockBlobOperations operations
     :vartype block_blob: azure.storage.blob.aio.operations.BlockBlobOperations
     :param url: The URL of the service account, container, or blob that is the target of the
-     desired operation.
+     desired operation. Required.
     :type url: str
-    :param base_url: Service URL. Default value is "".
+    :param base_url: Service URL. Required. Default value is "".
     :type base_url: str
     :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2021-04-10". Note that overriding this default value may result in unsupported behavior.
+     is "2021-12-02". Note that overriding this default value may result in unsupported behavior.
     :paramtype version: str
     """
 
-    def __init__(
-        self,
-        url: str,
-        base_url: str = "",
-        **kwargs: Any
+    def __init__(  # pylint: disable=missing-client-constructor-parameter-credential
+        self, url: str, base_url: str = "", **kwargs: Any
     ) -> None:
         self._config = AzureBlobStorageConfiguration(url=url, **kwargs)
         self._client = AsyncPipelineClient(base_url=base_url, config=self._config, **kwargs)
 
         client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
         self._serialize = Serializer(client_models)
         self._deserialize = Deserializer(client_models)
@@ -59,29 +63,24 @@
         self.service = ServiceOperations(self._client, self._config, self._serialize, self._deserialize)
         self.container = ContainerOperations(self._client, self._config, self._serialize, self._deserialize)
         self.blob = BlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.page_blob = PageBlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.append_blob = AppendBlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.block_blob = BlockBlobOperations(self._client, self._config, self._serialize, self._deserialize)
 
-
-    def _send_request(
-        self,
-        request: HttpRequest,
-        **kwargs: Any
-    ) -> Awaitable[AsyncHttpResponse]:
+    def _send_request(self, request: HttpRequest, **kwargs: Any) -> Awaitable[AsyncHttpResponse]:
         """Runs the network request through the client's chained policies.
 
         >>> from azure.core.rest import HttpRequest
         >>> request = HttpRequest("GET", "https://www.example.org/")
         <HttpRequest [GET], url: 'https://www.example.org/'>
         >>> response = await client._send_request(request)
         <AsyncHttpResponse: 200 OK>
 
-        For more information on this code flow, see https://aka.ms/azsdk/python/protocol/quickstart
+        For more information on this code flow, see https://aka.ms/azsdk/dpcodegen/python/send_request
 
         :param request: The network request you want to make. Required.
         :type request: ~azure.core.rest.HttpRequest
         :keyword bool stream: Whether the response payload will be streamed. Defaults to False.
         :return: The response of your network call. Does not do error handling on your response.
         :rtype: ~azure.core.rest.AsyncHttpResponse
         """
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_configuration.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,50 +9,44 @@
 from typing import Any
 
 from azure.core.configuration import Configuration
 from azure.core.pipeline import policies
 
 VERSION = "unknown"
 
+
 class AzureBlobStorageConfiguration(Configuration):  # pylint: disable=too-many-instance-attributes
     """Configuration for AzureBlobStorage.
 
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
     :param url: The URL of the service account, container, or blob that is the target of the
-     desired operation.
+     desired operation. Required.
     :type url: str
     :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2021-04-10". Note that overriding this default value may result in unsupported behavior.
+     is "2021-08-06". Note that overriding this default value may result in unsupported behavior.
     :paramtype version: str
     """
 
-    def __init__(
-        self,
-        url: str,
-        **kwargs: Any
-    ) -> None:
+    def __init__(self, url: str, **kwargs: Any) -> None:
         super(AzureBlobStorageConfiguration, self).__init__(**kwargs)
-        version = kwargs.pop('version', "2021-04-10")  # type: str
+        version = kwargs.pop("version", "2021-08-06")  # type: str
 
         if url is None:
             raise ValueError("Parameter 'url' must not be None.")
 
         self.url = url
         self.version = version
-        kwargs.setdefault('sdk_moniker', 'azureblobstorage/{}'.format(VERSION))
+        kwargs.setdefault("sdk_moniker", "azureblobstorage/{}".format(VERSION))
         self._configure(**kwargs)
 
-    def _configure(
-        self,
-        **kwargs: Any
-    ) -> None:
-        self.user_agent_policy = kwargs.get('user_agent_policy') or policies.UserAgentPolicy(**kwargs)
-        self.headers_policy = kwargs.get('headers_policy') or policies.HeadersPolicy(**kwargs)
-        self.proxy_policy = kwargs.get('proxy_policy') or policies.ProxyPolicy(**kwargs)
-        self.logging_policy = kwargs.get('logging_policy') or policies.NetworkTraceLoggingPolicy(**kwargs)
-        self.http_logging_policy = kwargs.get('http_logging_policy') or policies.HttpLoggingPolicy(**kwargs)
-        self.retry_policy = kwargs.get('retry_policy') or policies.AsyncRetryPolicy(**kwargs)
-        self.custom_hook_policy = kwargs.get('custom_hook_policy') or policies.CustomHookPolicy(**kwargs)
-        self.redirect_policy = kwargs.get('redirect_policy') or policies.AsyncRedirectPolicy(**kwargs)
-        self.authentication_policy = kwargs.get('authentication_policy')
+    def _configure(self, **kwargs: Any) -> None:
+        self.user_agent_policy = kwargs.get("user_agent_policy") or policies.UserAgentPolicy(**kwargs)
+        self.headers_policy = kwargs.get("headers_policy") or policies.HeadersPolicy(**kwargs)
+        self.proxy_policy = kwargs.get("proxy_policy") or policies.ProxyPolicy(**kwargs)
+        self.logging_policy = kwargs.get("logging_policy") or policies.NetworkTraceLoggingPolicy(**kwargs)
+        self.http_logging_policy = kwargs.get("http_logging_policy") or policies.HttpLoggingPolicy(**kwargs)
+        self.retry_policy = kwargs.get("retry_policy") or policies.AsyncRetryPolicy(**kwargs)
+        self.custom_hook_policy = kwargs.get("custom_hook_policy") or policies.CustomHookPolicy(**kwargs)
+        self.redirect_policy = kwargs.get("redirect_policy") or policies.AsyncRedirectPolicy(**kwargs)
+        self.authentication_policy = kwargs.get("authentication_policy")
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -3,21 +3,17 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from ._service_operations import ServiceOperations
-from ._container_operations import ContainerOperations
-from ._blob_operations import BlobOperations
-from ._page_blob_operations import PageBlobOperations
-from ._append_blob_operations import AppendBlobOperations
-from ._block_blob_operations import BlockBlobOperations
+from ._queue_operations import QueueOperations
+from ._messages_operations import MessagesOperations
+from ._message_id_operations import MessageIdOperations
 
 __all__ = [
     'ServiceOperations',
-    'ContainerOperations',
-    'BlobOperations',
-    'PageBlobOperations',
-    'AppendBlobOperations',
-    'BlockBlobOperations',
+    'QueueOperations',
+    'MessagesOperations',
+    'MessageIdOperations',
 ]
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_append_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_append_blob_operations.py`

 * *Files 11% similar despite different names*

```diff
@@ -5,68 +5,81 @@
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
 from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
+from azure.core.utils import case_insensitive_dict
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._append_blob_operations import build_append_block_from_url_request, build_append_block_request, build_create_request, build_seal_request
-T = TypeVar('T')
+from ...operations._append_blob_operations import (
+    build_append_block_from_url_request,
+    build_append_block_request,
+    build_create_request,
+    build_seal_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class AppendBlobOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.aio.AzureBlobStorage`'s
         :attr:`append_blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs) -> None:
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace_async
     async def create(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
         request_id_parameter: Optional[str] = None,
         blob_tags_string: Optional[str] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
-        blob_http_headers: Optional["_models.BlobHTTPHeaders"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Create Append Blob operation creates a new append blob.
 
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
@@ -83,15 +96,15 @@
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
@@ -102,25 +115,26 @@
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
          blob. Default value is "AppendBlob". Note that overriding this default value may result in
          unsupported behavior.
         :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        blob_type = kwargs.pop('blob_type', "AppendBlob")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
+
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "AppendBlob"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _blob_cache_control = None
         _lease_id = None
@@ -131,40 +145,37 @@
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_create_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
             content_length=content_length,
             timeout=timeout,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             blob_content_md5=_blob_content_md5,
             blob_cache_control=_blob_cache_control,
@@ -181,86 +192,95 @@
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.create.metadata['url'],
+            blob_type=blob_type,
+            version=self._config.version,
+            template_url=self.create.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    create.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def append_block(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         body: IO,
         timeout: Optional[int] = None,
-        transactional_content_md5: Optional[bytearray] = None,
-        transactional_content_crc64: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        append_position_access_conditions: Optional["_models.AppendPositionAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        append_position_access_conditions: Optional[_models.AppendPositionAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Append Block operation commits a new block of data to the end of an existing append blob.
         The Append Block operation is permitted only if the blob was created with x-ms-blob-type set to
         AppendBlob. Append Block is supported only on version 2015-02-21 version or later.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param append_position_access_conditions: Parameter group. Default value is None.
@@ -272,26 +292,27 @@
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "appendblock". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "appendblock")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        comp = kwargs.pop("comp", _params.pop("comp", "appendblock"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _max_size = None
         _append_position = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
@@ -300,36 +321,32 @@
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if append_position_access_conditions is not None:
-            _max_size = append_position_access_conditions.max_size
             _append_position = append_position_access_conditions.append_position
+            _max_size = append_position_access_conditions.max_size
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         _content = body
 
         request = build_append_block_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             content_length=content_length,
             timeout=timeout,
             transactional_content_md5=transactional_content_md5,
             transactional_content_crc64=transactional_content_crc64,
             lease_id=_lease_id,
             max_size=_max_size,
             append_position=_append_position,
@@ -339,98 +356,115 @@
             encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.append_block.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.append_block.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-blob-append-offset']=self._deserialize('str', response.headers.get('x-ms-blob-append-offset'))
-        response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-blob-append-offset"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-append-offset")
+        )
+        response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-committed-block-count")
+        )
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    append_block.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    append_block.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def append_block_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         source_url: str,
         content_length: int,
         source_range: Optional[str] = None,
-        source_content_md5: Optional[bytearray] = None,
-        source_contentcrc64: Optional[bytearray] = None,
+        source_content_md5: Optional[bytes] = None,
+        source_contentcrc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
-        transactional_content_md5: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
         request_id_parameter: Optional[str] = None,
         copy_source_authorization: Optional[str] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        append_position_access_conditions: Optional["_models.AppendPositionAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        source_modified_access_conditions: Optional["_models.SourceModifiedAccessConditions"] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        append_position_access_conditions: Optional[_models.AppendPositionAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Append Block operation commits a new block of data to the end of an existing append blob
         where the contents are read from a source url. The Append Block operation is permitted only if
         the blob was created with x-ms-blob-type set to AppendBlob. Append Block is supported only on
         version 2015-02-21 version or later.
 
-        :param source_url: Specify a URL to the copy source.
+        :param source_url: Specify a URL to the copy source. Required.
         :type source_url: str
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param source_range: Bytes of source data in the specified range. Default value is None.
         :type source_range: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param source_contentcrc64: Specify the crc64 calculated for the range of bytes that must be
          read from the copy source. Default value is None.
-        :type source_contentcrc64: bytearray
+        :type source_contentcrc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
          OAuth access token to copy source. Default value is None.
         :type copy_source_authorization: str
@@ -448,25 +482,26 @@
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :keyword comp: comp. Default value is "appendblock". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "appendblock")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "appendblock"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _lease_id = None
         _max_size = None
@@ -477,40 +512,38 @@
         _if_none_match = None
         _if_tags = None
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if append_position_access_conditions is not None:
-            _max_size = append_position_access_conditions.max_size
             _append_position = append_position_access_conditions.append_position
+            _max_size = append_position_access_conditions.max_size
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
         request = build_append_block_from_url_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             source_url=source_url,
             content_length=content_length,
             source_range=source_range,
             source_content_md5=source_content_md5,
             source_contentcrc64=source_contentcrc64,
             timeout=timeout,
             transactional_content_md5=transactional_content_md5,
@@ -528,60 +561,73 @@
             if_tags=_if_tags,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
             source_if_match=_source_if_match,
             source_if_none_match=_source_if_none_match,
             request_id_parameter=request_id_parameter,
             copy_source_authorization=copy_source_authorization,
-            template_url=self.append_block_from_url.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.append_block_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-blob-append-offset']=self._deserialize('str', response.headers.get('x-ms-blob-append-offset'))
-        response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-blob-append-offset"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-append-offset")
+        )
+        response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-committed-block-count")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    append_block_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    append_block_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def seal(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        append_position_access_conditions: Optional["_models.AppendPositionAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        append_position_access_conditions: Optional[_models.AppendPositionAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Seal operation seals the Append Blob to make it read-only. Seal is supported only on
         version 2019-12-12 version or later.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -599,79 +645,81 @@
         :param append_position_access_conditions: Parameter group. Default value is None.
         :type append_position_access_conditions:
          ~azure.storage.blob.models.AppendPositionAccessConditions
         :keyword comp: comp. Default value is "seal". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "seal")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "seal"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _append_position = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if append_position_access_conditions is not None:
             _append_position = append_position_access_conditions.append_position
 
         request = build_seal_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             append_position=_append_position,
-            template_url=self.seal.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.seal.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    seal.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    seal.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_blob_operations.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,63 +3,96 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
-from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
+from typing import Any, AsyncIterator, Callable, Dict, Optional, TypeVar, Union
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
+from azure.core.utils import case_insensitive_dict
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._blob_operations import build_abort_copy_from_url_request, build_acquire_lease_request, build_break_lease_request, build_change_lease_request, build_copy_from_url_request, build_create_snapshot_request, build_delete_immutability_policy_request, build_delete_request, build_download_request, build_get_account_info_request, build_get_properties_request, build_get_tags_request, build_query_request, build_release_lease_request, build_renew_lease_request, build_set_expiry_request, build_set_http_headers_request, build_set_immutability_policy_request, build_set_legal_hold_request, build_set_metadata_request, build_set_tags_request, build_set_tier_request, build_start_copy_from_url_request, build_undelete_request
-T = TypeVar('T')
+from ...operations._blob_operations import (
+    build_abort_copy_from_url_request,
+    build_acquire_lease_request,
+    build_break_lease_request,
+    build_change_lease_request,
+    build_copy_from_url_request,
+    build_create_snapshot_request,
+    build_delete_immutability_policy_request,
+    build_delete_request,
+    build_download_request,
+    build_get_account_info_request,
+    build_get_properties_request,
+    build_get_tags_request,
+    build_query_request,
+    build_release_lease_request,
+    build_renew_lease_request,
+    build_set_expiry_request,
+    build_set_http_headers_request,
+    build_set_immutability_policy_request,
+    build_set_legal_hold_request,
+    build_set_metadata_request,
+    build_set_tags_request,
+    build_set_tier_request,
+    build_start_copy_from_url_request,
+    build_undelete_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class BlobOperations:  # pylint: disable=too-many-public-methods
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.aio.AzureBlobStorage`'s
         :attr:`blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs) -> None:
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace_async
     async def download(
         self,
         snapshot: Optional[str] = None,
         version_id: Optional[str] = None,
         timeout: Optional[int] = None,
         range: Optional[str] = None,
         range_get_content_md5: Optional[bool] = None,
         range_get_content_crc64: Optional[bool] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> IO:
+    ) -> AsyncIterator[bytes]:
         """The Download operation reads or downloads a blob from the system, including its metadata and
         properties. You can also call Download to read a snapshot.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -91,49 +124,50 @@
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        :return: Async iterator of the response bytes or the result of cls(response)
+        :rtype: AsyncIterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[AsyncIterator[bytes]]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_download_request(
             url=self._config.url,
-            version=self._config.version,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             range=range,
             lease_id=_lease_id,
             range_get_content_md5=range_get_content_md5,
             range_get_content_crc64=range_get_content_crc64,
@@ -142,143 +176,210 @@
             encryption_algorithm=_encryption_algorithm,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.download.metadata['url'],
+            version=self._config.version,
+            template_url=self.download.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 206]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['x-ms-or-policy-id']=self._deserialize('str', response.headers.get('x-ms-or-policy-id'))
-            response_headers['x-ms-or']=self._deserialize('{str}', response.headers.get('x-ms-or'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-            response_headers['x-ms-is-current-version']=self._deserialize('bool', response.headers.get('x-ms-is-current-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            response_headers['x-ms-tag-count']=self._deserialize('long', response.headers.get('x-ms-tag-count'))
-            response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-            response_headers['x-ms-last-access-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-last-access-time'))
-            response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-            response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-            response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
+            response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+            response_headers["x-ms-is-current-version"] = self._deserialize(
+                "bool", response.headers.get("x-ms-is-current-version")
+            )
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+            response_headers["x-ms-tag-count"] = self._deserialize("int", response.headers.get("x-ms-tag-count"))
+            response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
+            response_headers["x-ms-last-access-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-last-access-time")
+            )
+            response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+            )
+            response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+                "str", response.headers.get("x-ms-immutability-policy-mode")
+            )
+            response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if response.status_code == 206:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['x-ms-or-policy-id']=self._deserialize('str', response.headers.get('x-ms-or-policy-id'))
-            response_headers['x-ms-or']=self._deserialize('{str}', response.headers.get('x-ms-or'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-            response_headers['x-ms-is-current-version']=self._deserialize('bool', response.headers.get('x-ms-is-current-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            response_headers['x-ms-tag-count']=self._deserialize('long', response.headers.get('x-ms-tag-count'))
-            response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-            response_headers['x-ms-last-access-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-last-access-time'))
-            response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-            response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-            response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
+            response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-content-crc64"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-content-crc64")
+            )
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+            response_headers["x-ms-is-current-version"] = self._deserialize(
+                "bool", response.headers.get("x-ms-is-current-version")
+            )
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+            response_headers["x-ms-tag-count"] = self._deserialize("int", response.headers.get("x-ms-tag-count"))
+            response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
+            response_headers["x-ms-last-access-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-last-access-time")
+            )
+            response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+            )
+            response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+                "str", response.headers.get("x-ms-immutability-policy-mode")
+            )
+            response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    download.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    download.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
         snapshot: Optional[str] = None,
         version_id: Optional[str] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Get Properties operation returns all user-defined metadata, standard HTTP properties, and
         system properties for the blob. It does not return the content of the blob.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
@@ -302,148 +403,185 @@
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_get_properties_request(
             url=self._config.url,
-            version=self._config.version,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_properties.metadata['url'],
+            version=self._config.version,
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-creation-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-creation-time'))
-        response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-        response_headers['x-ms-or-policy-id']=self._deserialize('str', response.headers.get('x-ms-or-policy-id'))
-        response_headers['x-ms-or']=self._deserialize('{str}', response.headers.get('x-ms-or'))
-        response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-        response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-        response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-        response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-        response_headers['x-ms-incremental-copy']=self._deserialize('bool', response.headers.get('x-ms-incremental-copy'))
-        response_headers['x-ms-copy-destination-snapshot']=self._deserialize('str', response.headers.get('x-ms-copy-destination-snapshot'))
-        response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-        response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-        response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-        response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-        response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-        response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-        response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-        response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-        response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-        response_headers['x-ms-access-tier']=self._deserialize('str', response.headers.get('x-ms-access-tier'))
-        response_headers['x-ms-access-tier-inferred']=self._deserialize('bool', response.headers.get('x-ms-access-tier-inferred'))
-        response_headers['x-ms-archive-status']=self._deserialize('str', response.headers.get('x-ms-archive-status'))
-        response_headers['x-ms-access-tier-change-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-access-tier-change-time'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['x-ms-is-current-version']=self._deserialize('bool', response.headers.get('x-ms-is-current-version'))
-        response_headers['x-ms-tag-count']=self._deserialize('long', response.headers.get('x-ms-tag-count'))
-        response_headers['x-ms-expiry-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-expiry-time'))
-        response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-        response_headers['x-ms-rehydrate-priority']=self._deserialize('str', response.headers.get('x-ms-rehydrate-priority'))
-        response_headers['x-ms-last-access-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-last-access-time'))
-        response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-        response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-        response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-creation-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-creation-time")
+        )
+        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
+        response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
+        response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+        response_headers["x-ms-copy-completion-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+        )
+        response_headers["x-ms-copy-status-description"] = self._deserialize(
+            "str", response.headers.get("x-ms-copy-status-description")
+        )
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-progress"] = self._deserialize("str", response.headers.get("x-ms-copy-progress"))
+        response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+        response_headers["x-ms-incremental-copy"] = self._deserialize(
+            "bool", response.headers.get("x-ms-incremental-copy")
+        )
+        response_headers["x-ms-copy-destination-snapshot"] = self._deserialize(
+            "str", response.headers.get("x-ms-copy-destination-snapshot")
+        )
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+        response_headers["Content-Disposition"] = self._deserialize("str", response.headers.get("Content-Disposition"))
+        response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+        response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+        response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-committed-block-count")
+        )
+        response_headers["x-ms-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
+        response_headers["x-ms-access-tier"] = self._deserialize("str", response.headers.get("x-ms-access-tier"))
+        response_headers["x-ms-access-tier-inferred"] = self._deserialize(
+            "bool", response.headers.get("x-ms-access-tier-inferred")
+        )
+        response_headers["x-ms-archive-status"] = self._deserialize("str", response.headers.get("x-ms-archive-status"))
+        response_headers["x-ms-access-tier-change-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-access-tier-change-time")
+        )
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["x-ms-is-current-version"] = self._deserialize(
+            "bool", response.headers.get("x-ms-is-current-version")
+        )
+        response_headers["x-ms-tag-count"] = self._deserialize("int", response.headers.get("x-ms-tag-count"))
+        response_headers["x-ms-expiry-time"] = self._deserialize("rfc-1123", response.headers.get("x-ms-expiry-time"))
+        response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
+        response_headers["x-ms-rehydrate-priority"] = self._deserialize(
+            "str", response.headers.get("x-ms-rehydrate-priority")
+        )
+        response_headers["x-ms-last-access-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-last-access-time")
+        )
+        response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+        )
+        response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+            "str", response.headers.get("x-ms-immutability-policy-mode")
+        )
+        response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def delete(  # pylint: disable=inconsistent-return-statements
         self,
         snapshot: Optional[str] = None,
         version_id: Optional[str] = None,
         timeout: Optional[int] = None,
         delete_snapshots: Optional[Union[str, "_models.DeleteSnapshotsOptionType"]] = None,
         request_id_parameter: Optional[str] = None,
-        blob_delete_type: Optional[str] = "Permanent",
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        blob_delete_type: str = "Permanent",
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """If the storage account's soft delete feature is disabled then, when a blob is deleted, it is
         permanently removed from the storage account. If the storage account's soft delete feature is
         enabled, then, when a blob is deleted, it is marked for deletion and becomes inaccessible
         immediately. However, the blob service retains the blob or snapshot for the number of days
         specified by the DeleteRetentionPolicy section of [Storage service properties]
@@ -468,105 +606,106 @@
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param delete_snapshots: Required if the blob has associated snapshots. Specify one of the
          following two options: include: Delete the base blob and all of its snapshots. only: Delete
-         only the blob's snapshots and not the blob itself. Default value is None.
+         only the blob's snapshots and not the blob itself. Known values are: "include" and "only".
+         Default value is None.
         :type delete_snapshots: str or ~azure.storage.blob.models.DeleteSnapshotsOptionType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_delete_type: Optional.  Only possible value is 'permanent', which specifies to
-         permanently delete a blob if blob soft delete is enabled. Possible values are "Permanent" or
+         permanently delete a blob if blob soft delete is enabled. Known values are "Permanent" and
          None. Default value is "Permanent".
         :type blob_delete_type: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_delete_request(
             url=self._config.url,
-            version=self._config.version,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             lease_id=_lease_id,
             delete_snapshots=delete_snapshots,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_delete_type=blob_delete_type,
-            template_url=self.delete.metadata['url'],
+            version=self._config.version,
+            template_url=self.delete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    delete.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def undelete(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
     ) -> None:
         """Undelete a blob that was previously soft deleted.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -575,75 +714,77 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "undelete")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_undelete_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.undelete.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.undelete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    undelete.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    undelete.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_expiry(  # pylint: disable=inconsistent-return-statements
         self,
         expiry_options: Union[str, "_models.BlobExpiryOptions"],
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         expires_on: Optional[str] = None,
         **kwargs: Any
     ) -> None:
         """Sets the time a blob will expire and be deleted.
 
-        :param expiry_options: Required. Indicates mode of the expiry time.
+        :param expiry_options: Required. Indicates mode of the expiry time. Known values are:
+         "NeverExpire", "RelativeToCreation", "RelativeToNow", and "Absolute". Required.
         :type expiry_options: str or ~azure.storage.blob.models.BlobExpiryOptions
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -652,75 +793,76 @@
         :type request_id_parameter: str
         :param expires_on: The time to set the blob to expiry. Default value is None.
         :type expires_on: str
         :keyword comp: comp. Default value is "expiry". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "expiry")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_set_expiry_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             expiry_options=expiry_options,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             expires_on=expires_on,
-            template_url=self.set_expiry.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_expiry.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_expiry.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_expiry.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_http_headers(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        blob_http_headers: Optional["_models.BlobHTTPHeaders"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Set HTTP Headers operation sets system properties on the blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -736,25 +878,26 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "properties")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_cache_control = None
         _blob_content_type = None
         _blob_content_md5 = None
         _blob_content_encoding = None
         _blob_content_language = None
         _lease_id = None
@@ -762,88 +905,90 @@
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _blob_content_disposition = None
         if blob_http_headers is not None:
             _blob_cache_control = blob_http_headers.blob_cache_control
-            _blob_content_type = blob_http_headers.blob_content_type
-            _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
+            _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_set_http_headers_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             blob_cache_control=_blob_cache_control,
             blob_content_type=_blob_content_type,
             blob_content_md5=_blob_content_md5,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             blob_content_disposition=_blob_content_disposition,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_http_headers.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_http_headers.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_http_headers.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_http_headers.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_immutability_policy(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Set Immutability Policy operation sets the immutability policy on the blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -853,85 +998,88 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "immutabilityPolicies". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "immutabilityPolicies")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_set_immutability_policy_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             if_unmodified_since=_if_unmodified_since,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
-            template_url=self.set_immutability_policy.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_immutability_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-        response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+        )
+        response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+            "str", response.headers.get("x-ms-immutability-policy-mode")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_immutability_policy.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_immutability_policy.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def delete_immutability_policy(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
     ) -> None:
         """The Delete Immutability Policy operation deletes the immutability policy on the blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -940,149 +1088,147 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "immutabilityPolicies". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "immutabilityPolicies")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_delete_immutability_policy_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.delete_immutability_policy.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.delete_immutability_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete_immutability_policy.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    delete_immutability_policy.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_legal_hold(  # pylint: disable=inconsistent-return-statements
-        self,
-        legal_hold: bool,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
+        self, legal_hold: bool, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
     ) -> None:
         """The Set Legal Hold operation sets a legal hold on the blob.
 
-        :param legal_hold: Specified if a legal hold should be set on the blob.
+        :param legal_hold: Specified if a legal hold should be set on the blob. Required.
         :type legal_hold: bool
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "legalhold". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "legalhold")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "legalhold"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_set_legal_hold_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             legal_hold=legal_hold,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_legal_hold.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_legal_hold.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_legal_hold.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_legal_hold.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Set Blob Metadata operation sets user-defined metadata for the specified blob as one or
         more name-value pairs.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -1109,112 +1255,120 @@
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "metadata")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_set_metadata_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             metadata=metadata,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_metadata.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_metadata.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_metadata.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_metadata.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         duration: Optional[int] = None,
         proposed_lease_id: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -1238,99 +1392,101 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "acquire". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "acquire")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_acquire_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             duration=duration,
             proposed_lease_id=proposed_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.acquire_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.acquire_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    acquire_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    acquire_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def release_lease(  # pylint: disable=inconsistent-return-statements
         self,
         lease_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1342,97 +1498,99 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "release". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "release")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_release_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.release_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.release_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    release_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    release_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def renew_lease(  # pylint: disable=inconsistent-return-statements
         self,
         lease_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1444,103 +1602,105 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "renew". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "renew")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_renew_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.renew_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.renew_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    renew_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    renew_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def change_lease(  # pylint: disable=inconsistent-return-statements
         self,
         lease_id: str,
         proposed_lease_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
          400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats.
+         Constructor (String) for a list of valid GUID string formats. Required.
         :type proposed_lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1552,93 +1712,95 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "change". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "change")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_change_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             proposed_lease_id=proposed_lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.change_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.change_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    change_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         break_period: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -1662,95 +1824,97 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "break". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "break")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_break_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             break_period=break_period,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.break_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.break_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-time']=self._deserialize('int', response.headers.get('x-ms-lease-time'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    break_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    break_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def create_snapshot(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
         request_id_parameter: Optional[str] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Create Snapshot operation creates a read-only snapshot of a blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -1776,102 +1940,106 @@
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword comp: comp. Default value is "snapshot". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "snapshot")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "snapshot"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _lease_id = None
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_create_snapshot_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             metadata=metadata,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.create_snapshot.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.create_snapshot.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-snapshot']=self._deserialize('str', response.headers.get('x-ms-snapshot'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-
+        response_headers["x-ms-snapshot"] = self._deserialize("str", response.headers.get("x-ms-snapshot"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create_snapshot.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    create_snapshot.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def start_copy_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         copy_source: str,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
@@ -1879,43 +2047,45 @@
         rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
         request_id_parameter: Optional[str] = None,
         blob_tags_string: Optional[str] = None,
         seal_blob: Optional[bool] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
-        source_modified_access_conditions: Optional["_models.SourceModifiedAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Start Copy From URL operation copies a blob or an internet resource to a new blob.
 
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
+         Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param rehydrate_priority: Optional: Indicates the priority with which to rehydrate an archived
-         blob. Default value is None.
+         blob. Known values are: "High" and "Standard". Default value is None.
         :type rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
@@ -1923,65 +2093,66 @@
         :param seal_blob: Overrides the sealed state of the destination blob.  Service version
          2019-12-12 and newer. Default value is None.
         :type seal_blob: bool
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         _source_if_tags = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _lease_id = None
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
             _source_if_tags = source_modified_access_conditions.source_if_tags
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_start_copy_from_url_request(
             url=self._config.url,
-            version=self._config.version,
             copy_source=copy_source,
             timeout=timeout,
             metadata=metadata,
             tier=tier,
             rehydrate_priority=rehydrate_priority,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
@@ -1996,116 +2167,121 @@
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             seal_blob=seal_blob,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.start_copy_from_url.metadata['url'],
+            version=self._config.version,
+            template_url=self.start_copy_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    start_copy_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    start_copy_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def copy_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         copy_source: str,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
         tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
         request_id_parameter: Optional[str] = None,
-        source_content_md5: Optional[bytearray] = None,
+        source_content_md5: Optional[bytes] = None,
         blob_tags_string: Optional[str] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
         copy_source_authorization: Optional[str] = None,
         copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
-        source_modified_access_conditions: Optional["_models.SourceModifiedAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
         **kwargs: Any
     ) -> None:
         """The Copy From URL operation copies a blob or an internet resource to a new blob. It will not
         return a response until the copy is complete.
 
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
+         Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
          OAuth access token to copy source. Default value is None.
         :type copy_source_authorization: str
         :param copy_source_tags: Optional, default 'replace'.  Indicates if source tags should be
-         copied or replaced with the tags specified by x-ms-tags. Default value is None.
+         copied or replaced with the tags specified by x-ms-tags. Known values are: "REPLACE" and
+         "COPY". Default value is None.
         :type copy_source_tags: str or ~azure.storage.blob.models.BlobCopySourceTags
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
@@ -2113,57 +2289,56 @@
         :param cpk_scope_info: Parameter group. Default value is None.
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :keyword x_ms_requires_sync: This header indicates that this is a synchronous Copy Blob From
          URL instead of a Asynchronous Copy Blob. Default value is "true". Note that overriding this
          default value may result in unsupported behavior.
         :paramtype x_ms_requires_sync: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        x_ms_requires_sync = kwargs.pop('x_ms_requires_sync', "true")  # type: str
+        x_ms_requires_sync = kwargs.pop("x_ms_requires_sync", _headers.pop("x-ms-requires-sync", "true"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _lease_id = None
         _encryption_scope = None
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
 
         request = build_copy_from_url_request(
             url=self._config.url,
-            x_ms_requires_sync=x_ms_requires_sync,
-            version=self._config.version,
             copy_source=copy_source,
             timeout=timeout,
             metadata=metadata,
             tier=tier,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
             source_if_match=_source_if_match,
@@ -2179,66 +2354,73 @@
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
             copy_source_authorization=copy_source_authorization,
             encryption_scope=_encryption_scope,
             copy_source_tags=copy_source_tags,
-            template_url=self.copy_from_url.metadata['url'],
+            x_ms_requires_sync=x_ms_requires_sync,
+            version=self._config.version,
+            template_url=self.copy_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    copy_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    copy_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def abort_copy_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         copy_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Abort Copy From URL operation aborts a pending Copy From URL operation, and leaves a
         destination blob with zero length and full metadata.
 
         :param copy_id: The copy identifier provided in the x-ms-copy-id header of the original Copy
-         Blob operation.
+         Blob operation. Required.
         :type copy_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2250,90 +2432,95 @@
         :keyword comp: comp. Default value is "copy". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword copy_action_abort_constant: Copy action. Default value is "abort". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype copy_action_abort_constant: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "copy")  # type: str
-        copy_action_abort_constant = kwargs.pop('copy_action_abort_constant', "abort")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "copy"))  # type: str
+        copy_action_abort_constant = kwargs.pop(
+            "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_abort_copy_from_url_request(
             url=self._config.url,
-            comp=comp,
-            copy_action_abort_constant=copy_action_abort_constant,
-            version=self._config.version,
             copy_id=copy_id,
             timeout=timeout,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.abort_copy_from_url.metadata['url'],
+            comp=comp,
+            copy_action_abort_constant=copy_action_abort_constant,
+            version=self._config.version,
+            template_url=self.abort_copy_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    abort_copy_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    abort_copy_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_tier(  # pylint: disable=inconsistent-return-statements
         self,
         tier: Union[str, "_models.AccessTierRequired"],
         snapshot: Optional[str] = None,
         version_id: Optional[str] = None,
         timeout: Optional[int] = None,
         rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Set Tier operation sets the tier on a blob. The operation is allowed on a page blob in a
         premium storage account and on a block blob in a blob storage account (locally redundant
         storage only). A premium page blob's tier determines the allowed size, IOPS, and bandwidth of
         the blob. A block blob's tier determines Hot/Cool/Archive storage type. This operation does not
         update the blob's ETag.
 
-        :param tier: Indicates the tier to be set on the blob.
+        :param tier: Indicates the tier to be set on the blob. Known values are: "P4", "P6", "P10",
+         "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive". Required.
         :type tier: str or ~azure.storage.blob.models.AccessTierRequired
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
          a Snapshot of a Blob.</a>`. Default value is None.
         :type snapshot: str
@@ -2343,172 +2530,173 @@
         :type version_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param rehydrate_priority: Optional: Indicates the priority with which to rehydrate an archived
-         blob. Default value is None.
+         blob. Known values are: "High" and "Standard". Default value is None.
         :type rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "tier". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "tier")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "tier"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
 
         request = build_set_tier_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             tier=tier,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             rehydrate_priority=rehydrate_priority,
             request_id_parameter=request_id_parameter,
             lease_id=_lease_id,
             if_tags=_if_tags,
-            template_url=self.set_tier.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_tier.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if response.status_code == 202:
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_tier.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_tier.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
-    async def get_account_info(  # pylint: disable=inconsistent-return-statements
-        self,
-        **kwargs: Any
-    ) -> None:
+    async def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
         """Returns the sku name and account kind.
 
         :keyword restype: restype. Default value is "account". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "account")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_get_account_info_request(
             url=self._config.url,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata['url'],
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-sku-name']=self._deserialize('str', response.headers.get('x-ms-sku-name'))
-        response_headers['x-ms-account-kind']=self._deserialize('str', response.headers.get('x-ms-account-kind'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_account_info.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def query(
         self,
         snapshot: Optional[str] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        query_request: Optional["_models.QueryRequest"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        query_request: Optional[_models.QueryRequest] = None,
         **kwargs: Any
-    ) -> IO:
+    ) -> AsyncIterator[bytes]:
         """The Query operation enables users to select/project on blob data by providing simple query
         expressions.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -2519,193 +2707,244 @@
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param query_request: the query request. Default value is None.
-        :type query_request: ~azure.storage.blob.models.QueryRequest
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :param query_request: the query request. Default value is None.
+        :type query_request: ~azure.storage.blob.models.QueryRequest
         :keyword comp: comp. Default value is "query". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
-        """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "query")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        :return: Async iterator of the response bytes or the result of cls(response)
+        :rtype: AsyncIterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "query"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[AsyncIterator[bytes]]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if query_request is not None:
-            _content = self._serialize.body(query_request, 'QueryRequest', is_xml=True)
+            _content = self._serialize.body(query_request, "QueryRequest", is_xml=True)
         else:
             _content = None
 
         request = build_query_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             snapshot=snapshot,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.query.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.query.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 206]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if response.status_code == 206:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-content-crc64"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-content-crc64")
+            )
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    query.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    query.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def get_tags(
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         snapshot: Optional[str] = None,
         version_id: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
-    ) -> "_models.BlobTags":
+    ) -> _models.BlobTags:
         """The Get Tags operation enables users to get the tags associated with a blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -2727,87 +2966,90 @@
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword comp: comp. Default value is "tags". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: BlobTags, or the result of cls(response)
+        :return: BlobTags or the result of cls(response)
         :rtype: ~azure.storage.blob.models.BlobTags
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.BlobTags"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "tags")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.BlobTags]
 
         _if_tags = None
         _lease_id = None
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_tags_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             snapshot=snapshot,
             version_id=version_id,
             if_tags=_if_tags,
             lease_id=_lease_id,
-            template_url=self.get_tags.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_tags.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('BlobTags', pipeline_response)
+        deserialized = self._deserialize("BlobTags", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_tags.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_tags.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def set_tags(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         version_id: Optional[str] = None,
-        transactional_content_md5: Optional[bytearray] = None,
-        transactional_content_crc64: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         request_id_parameter: Optional[str] = None,
-        tags: Optional["_models.BlobTags"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        tags: Optional[_models.BlobTags] = None,
         **kwargs: Any
     ) -> None:
         """The Set Tags operation enables users to set tags on a blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -2815,91 +3057,93 @@
         :type timeout: int
         :param version_id: The version id parameter is an opaque DateTime value that, when present,
          specifies the version of the blob to operate on. It's for service version 2019-10-10 and newer.
          Default value is None.
         :type version_id: str
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param tags: Blob tags. Default value is None.
-        :type tags: ~azure.storage.blob.models.BlobTags
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param tags: Blob tags. Default value is None.
+        :type tags: ~azure.storage.blob.models.BlobTags
         :keyword comp: comp. Default value is "tags". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "tags")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_tags = None
         _lease_id = None
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if tags is not None:
-            _content = self._serialize.body(tags, 'BlobTags', is_xml=True)
+            _content = self._serialize.body(tags, "BlobTags", is_xml=True)
         else:
             _content = None
 
         request = build_set_tags_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             timeout=timeout,
             version_id=version_id,
             transactional_content_md5=transactional_content_md5,
             transactional_content_crc64=transactional_content_crc64,
             request_id_parameter=request_id_parameter,
             if_tags=_if_tags,
             lease_id=_lease_id,
-            template_url=self.set_tags.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.set_tags.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_tags.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_tags.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_block_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_block_blob_operations.py`

 * *Files 12% similar despite different names*

```diff
@@ -5,110 +5,131 @@
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
 from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
+from azure.core.utils import case_insensitive_dict
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._block_blob_operations import build_commit_block_list_request, build_get_block_list_request, build_put_blob_from_url_request, build_stage_block_from_url_request, build_stage_block_request, build_upload_request
-T = TypeVar('T')
+from ...operations._block_blob_operations import (
+    build_commit_block_list_request,
+    build_get_block_list_request,
+    build_put_blob_from_url_request,
+    build_stage_block_from_url_request,
+    build_stage_block_request,
+    build_upload_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class BlockBlobOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.aio.AzureBlobStorage`'s
         :attr:`block_blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs) -> None:
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace_async
     async def upload(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         body: IO,
         timeout: Optional[int] = None,
-        transactional_content_md5: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
         metadata: Optional[Dict[str, str]] = None,
         tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
         request_id_parameter: Optional[str] = None,
         blob_tags_string: Optional[str] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
-        blob_http_headers: Optional["_models.BlobHTTPHeaders"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        transactional_content_crc64: Optional[bytes] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Upload Block Blob operation updates the content of an existing block blob. Updating an
         existing block blob overwrites any existing metadata on the blob. Partial updates are not
         supported with Put Blob; the content of the existing blob is overwritten with the content of
         the new blob. To perform a partial update of the content of a block blob, use the Put Block
         List operation.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
+        :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
+         validated by the service. Default value is None.
+        :type transactional_content_crc64: bytes
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param cpk_scope_info: Parameter group. Default value is None.
@@ -116,26 +137,27 @@
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
          blob. Default value is "BlockBlob". Note that overriding this default value may result in
          unsupported behavior.
         :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        blob_type = kwargs.pop('blob_type', "BlockBlob")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
+
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "BlockBlob"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _blob_cache_control = None
         _lease_id = None
@@ -146,43 +168,38 @@
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         _content = body
 
         request = build_upload_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             content_length=content_length,
             timeout=timeout,
             transactional_content_md5=transactional_content_md5,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             blob_content_md5=_blob_content_md5,
@@ -201,123 +218,138 @@
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.upload.metadata['url'],
+            transactional_content_crc64=transactional_content_crc64,
+            blob_type=blob_type,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.upload.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    upload.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def put_blob_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         copy_source: str,
         timeout: Optional[int] = None,
-        transactional_content_md5: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
         metadata: Optional[Dict[str, str]] = None,
         tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
         request_id_parameter: Optional[str] = None,
-        source_content_md5: Optional[bytearray] = None,
+        source_content_md5: Optional[bytes] = None,
         blob_tags_string: Optional[str] = None,
         copy_source_blob_properties: Optional[bool] = None,
         copy_source_authorization: Optional[str] = None,
         copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
-        blob_http_headers: Optional["_models.BlobHTTPHeaders"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        source_modified_access_conditions: Optional["_models.SourceModifiedAccessConditions"] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Put Blob from URL operation creates a new Block Blob where the contents of the blob are
         read from a given URL.  This API is supported beginning with the 2020-04-08 version. Partial
         updates are not supported with Put Blob from URL; the content of an existing blob is
         overwritten with the content of the new blob.  To perform partial updates to a block blobs
         contents using a source URL, use the Put Block from URL API in conjunction with Put Block List.
 
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param copy_source_blob_properties: Optional, default is true.  Indicates if properties from
-         the source blob should be copied.
+         the source blob should be copied. Default value is None.
         :type copy_source_blob_properties: bool
         :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
          OAuth access token to copy source. Default value is None.
         :type copy_source_authorization: str
         :param copy_source_tags: Optional, default 'replace'.  Indicates if source tags should be
-         copied or replaced with the tags specified by x-ms-tags. Default value is None.
+         copied or replaced with the tags specified by x-ms-tags. Known values are: "REPLACE" and
+         "COPY". Default value is None.
         :type copy_source_tags: str or ~azure.storage.blob.models.BlobCopySourceTags
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
@@ -329,25 +361,26 @@
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
          blob. Default value is "BlockBlob". Note that overriding this default value may result in
          unsupported behavior.
         :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        blob_type = kwargs.pop('blob_type', "BlockBlob")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
+
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "BlockBlob"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _blob_cache_control = None
         _lease_id = None
@@ -363,46 +396,43 @@
         _if_tags = None
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         _source_if_tags = None
         if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
             _source_if_tags = source_modified_access_conditions.source_if_tags
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
         request = build_put_blob_from_url_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
             content_length=content_length,
             copy_source=copy_source,
             timeout=timeout,
             transactional_content_md5=transactional_content_md5,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
@@ -428,82 +458,91 @@
             source_if_tags=_source_if_tags,
             request_id_parameter=request_id_parameter,
             source_content_md5=source_content_md5,
             blob_tags_string=blob_tags_string,
             copy_source_blob_properties=copy_source_blob_properties,
             copy_source_authorization=copy_source_authorization,
             copy_source_tags=copy_source_tags,
-            template_url=self.put_blob_from_url.metadata['url'],
+            blob_type=blob_type,
+            version=self._config.version,
+            template_url=self.put_blob_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    put_blob_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    put_blob_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def stage_block(  # pylint: disable=inconsistent-return-statements
         self,
         block_id: str,
         content_length: int,
         body: IO,
-        transactional_content_md5: Optional[bytearray] = None,
-        transactional_content_crc64: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
         **kwargs: Any
     ) -> None:
         """The Stage Block operation creates a new block to be committed as part of a blob.
 
         :param block_id: A valid Base64 string value that identifies the block. Prior to encoding, the
          string must be less than or equal to 64 bytes in size. For a given blob, the length of the
-         value specified for the blockid parameter must be the same size for each block.
+         value specified for the blockid parameter must be the same size for each block. Required.
         :type block_id: str
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
@@ -515,131 +554,141 @@
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param cpk_scope_info: Parameter group. Default value is None.
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :keyword comp: comp. Default value is "block". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "block")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "block"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         _content = body
 
         request = build_stage_block_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             block_id=block_id,
             content_length=content_length,
             transactional_content_md5=transactional_content_md5,
             transactional_content_crc64=transactional_content_crc64,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             request_id_parameter=request_id_parameter,
-            template_url=self.stage_block.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.stage_block.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    stage_block.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    stage_block.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def stage_block_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         block_id: str,
         content_length: int,
         source_url: str,
         source_range: Optional[str] = None,
-        source_content_md5: Optional[bytearray] = None,
-        source_contentcrc64: Optional[bytearray] = None,
+        source_content_md5: Optional[bytes] = None,
+        source_contentcrc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         copy_source_authorization: Optional[str] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        source_modified_access_conditions: Optional["_models.SourceModifiedAccessConditions"] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Stage Block operation creates a new block to be committed as part of a blob where the
         contents are read from a URL.
 
         :param block_id: A valid Base64 string value that identifies the block. Prior to encoding, the
          string must be less than or equal to 64 bytes in size. For a given blob, the length of the
-         value specified for the blockid parameter must be the same size for each block.
+         value specified for the blockid parameter must be the same size for each block. Required.
         :type block_id: str
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param source_url: Specify a URL to the copy source.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param source_url: Specify a URL to the copy source. Required.
         :type source_url: str
         :param source_range: Bytes of source data in the specified range. Default value is None.
         :type source_range: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param source_contentcrc64: Specify the crc64 calculated for the range of bytes that must be
          read from the copy source. Default value is None.
-        :type source_contentcrc64: bytearray
+        :type source_contentcrc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
@@ -657,53 +706,52 @@
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :keyword comp: comp. Default value is "block". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "block")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "block"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _lease_id = None
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
         request = build_stage_block_from_url_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             block_id=block_id,
             content_length=content_length,
             source_url=source_url,
             source_range=source_range,
             source_content_md5=source_content_md5,
             source_contentcrc64=source_contentcrc64,
             timeout=timeout,
@@ -714,113 +762,126 @@
             lease_id=_lease_id,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
             source_if_match=_source_if_match,
             source_if_none_match=_source_if_none_match,
             request_id_parameter=request_id_parameter,
             copy_source_authorization=copy_source_authorization,
-            template_url=self.stage_block_from_url.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.stage_block_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    stage_block_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    stage_block_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def commit_block_list(  # pylint: disable=inconsistent-return-statements
         self,
-        blocks: "_models.BlockLookupList",
+        blocks: _models.BlockLookupList,
         timeout: Optional[int] = None,
-        transactional_content_md5: Optional[bytearray] = None,
-        transactional_content_crc64: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         metadata: Optional[Dict[str, str]] = None,
         tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
         request_id_parameter: Optional[str] = None,
         blob_tags_string: Optional[str] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
-        blob_http_headers: Optional["_models.BlobHTTPHeaders"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Commit Block List operation writes a blob by specifying the list of block IDs that make up
         the blob. In order to be written as part of a blob, a block must have been successfully written
         to the server in a prior Put Block operation. You can call Put Block List to update a blob by
         uploading only those blocks that have changed, then committing the new and existing blocks
         together. You can do this by specifying whether to commit a block from the committed block list
         or from the uncommitted block list, or to commit the most recently uploaded version of the
         block, whichever list it may belong to.
 
-        :param blocks: Blob Blocks.
+        :param blocks: Blob Blocks. Required.
         :type blocks: ~azure.storage.blob.models.BlockLookupList
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
@@ -830,26 +891,27 @@
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "blocklist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "blocklist")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        comp = kwargs.pop("comp", _params.pop("comp", "blocklist"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_cache_control = None
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _lease_id = None
@@ -861,42 +923,37 @@
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if blob_http_headers is not None:
             _blob_cache_control = blob_http_headers.blob_cache_control
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
-        _content = self._serialize.body(blocks, 'BlockLookupList', is_xml=True)
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        _content = self._serialize.body(blocks, "BlockLookupList", is_xml=True)
 
         request = build_commit_block_list_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             timeout=timeout,
             blob_cache_control=_blob_cache_control,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             blob_content_md5=_blob_content_md5,
             transactional_content_md5=transactional_content_md5,
@@ -915,74 +972,88 @@
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.commit_block_list.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.commit_block_list.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    commit_block_list.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    commit_block_list.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def get_block_list(
         self,
         snapshot: Optional[str] = None,
         list_type: Union[str, "_models.BlockListType"] = "committed",
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> "_models.BlockList":
+    ) -> _models.BlockList:
         """The Get Block List operation retrieves the list of blocks that have been uploaded as part of a
         block blob.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
          a Snapshot of a Blob.</a>`. Default value is None.
         :type snapshot: str
         :param list_type: Specifies whether to return the list of committed blocks, the list of
-         uncommitted blocks, or both lists together. Default value is "committed".
+         uncommitted blocks, or both lists together. Known values are: "committed", "uncommitted", and
+         "all". Default value is "committed".
         :type list_type: str or ~azure.storage.blob.models.BlockListType
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -993,72 +1064,77 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "blocklist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: BlockList, or the result of cls(response)
+        :return: BlockList or the result of cls(response)
         :rtype: ~azure.storage.blob.models.BlockList
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.BlockList"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "blocklist")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blocklist"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.BlockList]
 
         _lease_id = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
 
         request = build_get_block_list_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             snapshot=snapshot,
             list_type=list_type,
             timeout=timeout,
             lease_id=_lease_id,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_block_list.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_block_list.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-blob-content-length']=self._deserialize('long', response.headers.get('x-ms-blob-content-length'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-blob-content-length"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-content-length")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('BlockList', pipeline_response)
+        deserialized = self._deserialize("BlockList", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_block_list.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_block_list.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_container_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_container_operations.py`

 * *Files 10% similar despite different names*

```diff
@@ -2,56 +2,83 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union
+from typing import Any, AsyncIterator, Callable, Dict, IO, List, Optional, TypeVar, Union
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
+from azure.core.utils import case_insensitive_dict
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._container_operations import build_acquire_lease_request, build_break_lease_request, build_change_lease_request, build_create_request, build_delete_request, build_filter_blobs_request, build_get_access_policy_request, build_get_account_info_request, build_get_properties_request, build_list_blob_flat_segment_request, build_list_blob_hierarchy_segment_request, build_release_lease_request, build_rename_request, build_renew_lease_request, build_restore_request, build_set_access_policy_request, build_set_metadata_request, build_submit_batch_request
-T = TypeVar('T')
+from ...operations._container_operations import (
+    build_acquire_lease_request,
+    build_break_lease_request,
+    build_change_lease_request,
+    build_create_request,
+    build_delete_request,
+    build_filter_blobs_request,
+    build_get_access_policy_request,
+    build_get_account_info_request,
+    build_get_properties_request,
+    build_list_blob_flat_segment_request,
+    build_list_blob_hierarchy_segment_request,
+    build_release_lease_request,
+    build_rename_request,
+    build_renew_lease_request,
+    build_restore_request,
+    build_set_access_policy_request,
+    build_set_metadata_request,
+    build_submit_batch_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class ContainerOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.aio.AzureBlobStorage`'s
         :attr:`container` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs) -> None:
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace_async
     async def create(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
         access: Optional[Union[str, "_models.PublicAccessType"]] = None,
         request_id_parameter: Optional[str] = None,
-        container_cpk_scope_info: Optional["_models.ContainerCpkScopeInfo"] = None,
+        container_cpk_scope_info: Optional[_models.ContainerCpkScopeInfo] = None,
         **kwargs: Any
     ) -> None:
         """creates a new container under the specified account. If the container with the same name
         already exists, the operation fails.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -63,92 +90,94 @@
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param access: Specifies whether data in the container may be accessed publicly and the level
-         of access. Default value is None.
+         of access. Known values are: "container" and "blob". Default value is None.
         :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param container_cpk_scope_info: Parameter group. Default value is None.
         :type container_cpk_scope_info: ~azure.storage.blob.models.ContainerCpkScopeInfo
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _default_encryption_scope = None
         _prevent_encryption_scope_override = None
         if container_cpk_scope_info is not None:
             _default_encryption_scope = container_cpk_scope_info.default_encryption_scope
             _prevent_encryption_scope_override = container_cpk_scope_info.prevent_encryption_scope_override
 
         request = build_create_request(
             url=self._config.url,
-            restype=restype,
-            version=self._config.version,
             timeout=timeout,
             metadata=metadata,
             access=access,
             request_id_parameter=request_id_parameter,
             default_encryption_scope=_default_encryption_scope,
             prevent_encryption_scope_override=_prevent_encryption_scope_override,
-            template_url=self.create.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.create.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    create.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """returns all user-defined metadata and system properties for the specified container. The data
         returned does not include the container's list of blobs.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -161,86 +190,98 @@
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_properties_request(
             url=self._config.url,
-            restype=restype,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_properties.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-        response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-        response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-blob-public-access']=self._deserialize('str', response.headers.get('x-ms-blob-public-access'))
-        response_headers['x-ms-has-immutability-policy']=self._deserialize('bool', response.headers.get('x-ms-has-immutability-policy'))
-        response_headers['x-ms-has-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-has-legal-hold'))
-        response_headers['x-ms-default-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-default-encryption-scope'))
-        response_headers['x-ms-deny-encryption-scope-override']=self._deserialize('bool', response.headers.get('x-ms-deny-encryption-scope-override'))
-        response_headers['x-ms-immutable-storage-with-versioning-enabled']=self._deserialize('bool', response.headers.get('x-ms-immutable-storage-with-versioning-enabled'))
-
+        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-blob-public-access"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-public-access")
+        )
+        response_headers["x-ms-has-immutability-policy"] = self._deserialize(
+            "bool", response.headers.get("x-ms-has-immutability-policy")
+        )
+        response_headers["x-ms-has-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-has-legal-hold"))
+        response_headers["x-ms-default-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-default-encryption-scope")
+        )
+        response_headers["x-ms-deny-encryption-scope-override"] = self._deserialize(
+            "bool", response.headers.get("x-ms-deny-encryption-scope-override")
+        )
+        response_headers["x-ms-immutable-storage-with-versioning-enabled"] = self._deserialize(
+            "bool", response.headers.get("x-ms-immutable-storage-with-versioning-enabled")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def delete(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """operation marks the specified container for deletion. The container and any blobs contained
         within it are later deleted during garbage collection.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -255,82 +296,84 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_delete_request(
             url=self._config.url,
-            restype=restype,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.delete.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.delete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    delete.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """operation sets one or more user-defined name-value pairs for the specified container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -355,84 +398,86 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "metadata")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
 
         request = build_set_metadata_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             metadata=metadata,
             if_modified_since=_if_modified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_metadata.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_metadata.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_metadata.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    set_metadata.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def get_access_policy(
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
-    ) -> List["_models.SignedIdentifier"]:
+    ) -> List[_models.SignedIdentifier]:
         """gets the permissions for the specified container. The permissions indicate whether container
         data may be accessed publicly.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -446,186 +491,195 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
          in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: list of SignedIdentifier, or the result of cls(response)
+        :return: list of SignedIdentifier or the result of cls(response)
         :rtype: list[~azure.storage.blob.models.SignedIdentifier]
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.SignedIdentifier"]]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "acl")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[List[_models.SignedIdentifier]]
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_access_policy_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_access_policy.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_access_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-blob-public-access']=self._deserialize('str', response.headers.get('x-ms-blob-public-access'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-blob-public-access"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-public-access")
+        )
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('[SignedIdentifier]', pipeline_response)
+        deserialized = self._deserialize("[SignedIdentifier]", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_access_policy.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    get_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def set_access_policy(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         access: Optional[Union[str, "_models.PublicAccessType"]] = None,
         request_id_parameter: Optional[str] = None,
-        container_acl: Optional[List["_models.SignedIdentifier"]] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        container_acl: Optional[List[_models.SignedIdentifier]] = None,
         **kwargs: Any
     ) -> None:
         """sets the permissions for the specified container. The permissions indicate whether blobs in a
         container may be accessed publicly.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param access: Specifies whether data in the container may be accessed publicly and the level
-         of access. Default value is None.
+         of access. Known values are: "container" and "blob". Default value is None.
         :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param container_acl: the acls for the container. Default value is None.
-        :type container_acl: list[~azure.storage.blob.models.SignedIdentifier]
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :param container_acl: the acls for the container. Default value is None.
+        :type container_acl: list[~azure.storage.blob.models.SignedIdentifier]
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
          in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "acl")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        serialization_ctxt = {"xml": {'name': 'SignedIdentifiers', 'wrapped': True, 'itemsName': 'SignedIdentifier'}}
+        serialization_ctxt = {"xml": {"name": "SignedIdentifiers", "wrapped": True, "itemsName": "SignedIdentifier"}}
         if container_acl is not None:
-            _content = self._serialize.body(container_acl, '[SignedIdentifier]', is_xml=True, serialization_ctxt=serialization_ctxt)
+            _content = self._serialize.body(
+                container_acl, "[SignedIdentifier]", is_xml=True, serialization_ctxt=serialization_ctxt
+            )
         else:
             _content = None
 
         request = build_set_access_policy_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             timeout=timeout,
             lease_id=_lease_id,
             access=access,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_access_policy.metadata['url'],
+            restype=restype,
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.set_access_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_access_policy.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    set_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def restore(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         deleted_container_name: Optional[str] = None,
@@ -652,79 +706,81 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "undelete")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_restore_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             deleted_container_name=deleted_container_name,
             deleted_container_version=deleted_container_version,
-            template_url=self.restore.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.restore.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    restore.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    restore.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def rename(  # pylint: disable=inconsistent-return-statements
         self,
         source_container_name: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         source_lease_id: Optional[str] = None,
         **kwargs: Any
     ) -> None:
         """Renames an existing container.
 
         :param source_container_name: Required.  Specifies the name of the container to rename.
+         Required.
         :type source_container_name: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -737,169 +793,171 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "rename". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "rename")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_rename_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             source_container_name=source_container_name,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             source_lease_id=source_lease_id,
-            template_url=self.rename.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.rename.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    rename.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    rename.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def submit_batch(
         self,
         content_length: int,
         body: IO,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> IO:
+    ) -> AsyncIterator[bytes]:
         """The Batch operation allows multiple API calls to be embedded into a single HTTP request.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword multipart_content_type: Required. The value of this header must be multipart/mixed
-         with a batch boundary. Example header value: multipart/mixed; boundary=batch_:code:`<GUID>`.
-        :paramtype multipart_content_type: str
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "batch". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: Async iterator of the response bytes or the result of cls(response)
+        :rtype: AsyncIterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        multipart_content_type = kwargs.pop('multipart_content_type')  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "batch")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        _content = self._serialize.body(body, 'IO')
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+        multipart_content_type = kwargs.pop(
+            "multipart_content_type", _headers.pop("Content-Type", "application/xml")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[AsyncIterator[bytes]]
+
+        _content = body
 
         request = build_submit_batch_request(
             url=self._config.url,
-            multipart_content_type=multipart_content_type,
+            content_length=content_length,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
+            multipart_content_type=multipart_content_type,
             version=self._config.version,
             content=_content,
-            content_length=content_length,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.submit_batch.metadata['url'],
+            template_url=self.submit_batch.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    submit_batch.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    submit_batch.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def filter_blobs(
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         where: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
         **kwargs: Any
-    ) -> "_models.FilterBlobSegment":
+    ) -> _models.FilterBlobSegment:
         """The Filter Blobs operation enables callers to list blobs in a container whose tags match a
         given search expression.  Filter blobs searches within the given container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -921,86 +979,92 @@
         :param maxresults: Specifies the maximum number of containers to return. If the request does
          not specify maxresults, or specifies a value greater than 5000, the server will return up to
          5000 items. Note that if the listing operation crosses a partition boundary, then the service
          will return a continuation token for retrieving the remainder of the results. For this reason,
          it is possible that the service will return fewer results than specified by maxresults, or than
          the default of 5000. Default value is None.
         :type maxresults: int
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.FilterBlobsIncludeItem]
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "blobs". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: FilterBlobSegment, or the result of cls(response)
+        :return: FilterBlobSegment or the result of cls(response)
         :rtype: ~azure.storage.blob.models.FilterBlobSegment
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.FilterBlobSegment"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "blobs")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.FilterBlobSegment]
 
-        
         request = build_filter_blobs_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             where=where,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.filter_blobs.metadata['url'],
+            include=include,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.filter_blobs.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('FilterBlobSegment', pipeline_response)
+        deserialized = self._deserialize("FilterBlobSegment", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    filter_blobs.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    filter_blobs.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         duration: Optional[int] = None,
         proposed_lease_id: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -1027,92 +1091,94 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "acquire". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "acquire")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_acquire_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             duration=duration,
             proposed_lease_id=proposed_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.acquire_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.acquire_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    acquire_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    acquire_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def release_lease(  # pylint: disable=inconsistent-return-statements
         self,
         lease_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1127,90 +1193,92 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "release". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "release")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_release_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.release_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.release_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    release_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    release_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def renew_lease(  # pylint: disable=inconsistent-return-statements
         self,
         lease_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1225,85 +1293,87 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "renew". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "renew")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_renew_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.renew_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.renew_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    renew_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    renew_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
         break_period: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
@@ -1330,96 +1400,98 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "break". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "break")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_break_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             break_period=break_period,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.break_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.break_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-time']=self._deserialize('int', response.headers.get('x-ms-lease-time'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    break_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    break_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def change_lease(  # pylint: disable=inconsistent-return-statements
         self,
         lease_id: str,
         proposed_lease_id: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
          400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats.
+         Constructor (String) for a list of valid GUID string formats. Required.
         :type proposed_lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1434,90 +1506,92 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "change". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "change")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_change_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             proposed_lease_id=proposed_lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.change_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.change_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    change_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def list_blob_flat_segment(
         self,
         prefix: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
         include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> "_models.ListBlobsFlatSegmentResponse":
+    ) -> _models.ListBlobsFlatSegmentResponse:
         """[Update] The List Blobs operation returns a list of the blobs under the specified container.
 
         :param prefix: Filters the results to return only containers whose name begins with the
          specified prefix. Default value is None.
         :type prefix: str
         :param marker: A string value that identifies the portion of the list of containers to be
          returned with the next listing operation. The operation returns the NextMarker value within the
@@ -1548,91 +1622,93 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "list". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListBlobsFlatSegmentResponse, or the result of cls(response)
+        :return: ListBlobsFlatSegmentResponse or the result of cls(response)
         :rtype: ~azure.storage.blob.models.ListBlobsFlatSegmentResponse
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ListBlobsFlatSegmentResponse"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "list")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsFlatSegmentResponse]
 
-        
         request = build_list_blob_flat_segment_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             prefix=prefix,
             marker=marker,
             maxresults=maxresults,
             include=include,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.list_blob_flat_segment.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_blob_flat_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('ListBlobsFlatSegmentResponse', pipeline_response)
+        deserialized = self._deserialize("ListBlobsFlatSegmentResponse", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    list_blob_flat_segment.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    list_blob_flat_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
     async def list_blob_hierarchy_segment(
         self,
         delimiter: str,
         prefix: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
         include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> "_models.ListBlobsHierarchySegmentResponse":
+    ) -> _models.ListBlobsHierarchySegmentResponse:
         """[Update] The List Blobs operation returns a list of the blobs under the specified container.
 
         :param delimiter: When the request includes this parameter, the operation returns a BlobPrefix
          element in the response body that acts as a placeholder for all blobs whose names begin with
          the same substring up to the appearance of the delimiter character. The delimiter may be a
-         single character or a string.
+         single character or a string. Required.
         :type delimiter: str
         :param prefix: Filters the results to return only containers whose name begins with the
          specified prefix. Default value is None.
         :type prefix: str
         :param marker: A string value that identifies the portion of the list of containers to be
          returned with the next listing operation. The operation returns the NextMarker value within the
          response body if the listing operation did not return all containers remaining to be listed
@@ -1662,131 +1738,131 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "list". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListBlobsHierarchySegmentResponse, or the result of cls(response)
+        :return: ListBlobsHierarchySegmentResponse or the result of cls(response)
         :rtype: ~azure.storage.blob.models.ListBlobsHierarchySegmentResponse
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ListBlobsHierarchySegmentResponse"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "list")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsHierarchySegmentResponse]
 
-        
         request = build_list_blob_hierarchy_segment_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             delimiter=delimiter,
             prefix=prefix,
             marker=marker,
             maxresults=maxresults,
             include=include,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.list_blob_hierarchy_segment.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_blob_hierarchy_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('ListBlobsHierarchySegmentResponse', pipeline_response)
+        deserialized = self._deserialize("ListBlobsHierarchySegmentResponse", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    list_blob_hierarchy_segment.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    list_blob_hierarchy_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace_async
-    async def get_account_info(  # pylint: disable=inconsistent-return-statements
-        self,
-        **kwargs: Any
-    ) -> None:
+    async def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
         """Returns the sku name and account kind.
 
         :keyword restype: restype. Default value is "account". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "account")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_get_account_info_request(
             url=self._config.url,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata['url'],
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-sku-name']=self._deserialize('str', response.headers.get('x-ms-sku-name'))
-        response_headers['x-ms-account-kind']=self._deserialize('str', response.headers.get('x-ms-account-kind'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    get_account_info.metadata = {"url": "{url}/{containerName}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_page_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_page_blob_operations.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,105 +5,124 @@
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
 from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
+from azure.core.utils import case_insensitive_dict
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._page_blob_operations import build_clear_pages_request, build_copy_incremental_request, build_create_request, build_get_page_ranges_diff_request, build_get_page_ranges_request, build_resize_request, build_update_sequence_number_request, build_upload_pages_from_url_request, build_upload_pages_request
-T = TypeVar('T')
+from ...operations._page_blob_operations import (
+    build_clear_pages_request,
+    build_copy_incremental_request,
+    build_create_request,
+    build_get_page_ranges_diff_request,
+    build_get_page_ranges_request,
+    build_resize_request,
+    build_update_sequence_number_request,
+    build_upload_pages_from_url_request,
+    build_upload_pages_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class PageBlobOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.aio.AzureBlobStorage`'s
         :attr:`page_blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs) -> None:
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace_async
     async def create(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         blob_content_length: int,
         timeout: Optional[int] = None,
         tier: Optional[Union[str, "_models.PremiumPageBlobAccessTier"]] = None,
         metadata: Optional[Dict[str, str]] = None,
-        blob_sequence_number: Optional[int] = 0,
+        blob_sequence_number: int = 0,
         request_id_parameter: Optional[str] = None,
         blob_tags_string: Optional[str] = None,
         immutability_policy_expiry: Optional[datetime.datetime] = None,
         immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
-        blob_http_headers: Optional["_models.BlobHTTPHeaders"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Create operation creates a new page blob.
 
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param blob_content_length: This header specifies the maximum size for the page blob, up to 1
-         TB. The page blob size must be aligned to a 512-byte boundary.
-        :type blob_content_length: long
+         TB. The page blob size must be aligned to a 512-byte boundary. Required.
+        :type blob_content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param tier: Optional. Indicates the tier to be set on the page blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the page blob. Known values are: "P4",
+         "P6", "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", and "P80". Default value is None.
         :type tier: str or ~azure.storage.blob.models.PremiumPageBlobAccessTier
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param blob_sequence_number: Set for page blobs only. The sequence number is a user-controlled
          value that you can use to track requests. The value of the sequence number must be between 0
          and 2^63 - 1. Default value is 0.
-        :type blob_sequence_number: long
+        :type blob_sequence_number: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
@@ -114,25 +133,26 @@
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
          blob. Default value is "PageBlob". Note that overriding this default value may result in
          unsupported behavior.
         :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        blob_type = kwargs.pop('blob_type', "PageBlob")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
+
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "PageBlob"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _blob_cache_control = None
         _lease_id = None
@@ -143,40 +163,37 @@
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_create_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
             content_length=content_length,
             blob_content_length=blob_content_length,
             timeout=timeout,
             tier=tier,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
@@ -196,80 +213,89 @@
             if_tags=_if_tags,
             blob_sequence_number=blob_sequence_number,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.create.metadata['url'],
+            blob_type=blob_type,
+            version=self._config.version,
+            template_url=self.create.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    create.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def upload_pages(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         body: IO,
-        transactional_content_md5: Optional[bytearray] = None,
-        transactional_content_crc64: Optional[bytearray] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
         range: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        sequence_number_access_conditions: Optional["_models.SequenceNumberAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        sequence_number_access_conditions: Optional[_models.SequenceNumberAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Upload Pages operation writes a range of pages to a page blob.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param range: Return only the bytes of the blob in the specified range. Default value is None.
         :type range: str
@@ -298,27 +324,28 @@
          and Content-Length headers must match to perform the update.
          * Clear: Clears the specified range and releases the space used in storage for that range. To
          clear a range, set the Content-Length header to zero, and the Range header to a value that
          indicates the range to clear, up to maximum blob size. Default value is "update". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "page")  # type: str
-        page_write = kwargs.pop('page_write', "update")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+        page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "update"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_sequence_number_less_than_or_equal_to = None
@@ -328,38 +355,35 @@
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if sequence_number_access_conditions is not None:
-            _if_sequence_number_less_than_or_equal_to = sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
-            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
             _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
+            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
+            _if_sequence_number_less_than_or_equal_to = (
+                sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
+            )
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         _content = body
 
         request = build_upload_pages_request(
             url=self._config.url,
-            comp=comp,
-            page_write=page_write,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             content_length=content_length,
             transactional_content_md5=transactional_content_md5,
             transactional_content_crc64=transactional_content_crc64,
             timeout=timeout,
             range=range,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
@@ -371,70 +395,86 @@
             if_sequence_number_equal_to=_if_sequence_number_equal_to,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.upload_pages.metadata['url'],
+            comp=comp,
+            page_write=page_write,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.upload_pages.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload_pages.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    upload_pages.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def clear_pages(  # pylint: disable=inconsistent-return-statements
         self,
         content_length: int,
         timeout: Optional[int] = None,
         range: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        sequence_number_access_conditions: Optional["_models.SequenceNumberAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        sequence_number_access_conditions: Optional[_models.SequenceNumberAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Clear Pages operation clears a set of pages from a page blob.
 
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param range: Return only the bytes of the blob in the specified range. Default value is None.
         :type range: str
@@ -463,26 +503,27 @@
          and Content-Length headers must match to perform the update.
          * Clear: Clears the specified range and releases the space used in storage for that range. To
          clear a range, set the Content-Length header to zero, and the Range header to a value that
          indicates the range to clear, up to maximum blob size. Default value is "clear". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "page")  # type: str
-        page_write = kwargs.pop('page_write', "clear")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+        page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "clear"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_sequence_number_less_than_or_equal_to = None
@@ -492,35 +533,34 @@
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if sequence_number_access_conditions is not None:
-            _if_sequence_number_less_than_or_equal_to = sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
-            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
             _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
+            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
+            _if_sequence_number_less_than_or_equal_to = (
+                sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
+            )
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_clear_pages_request(
             url=self._config.url,
-            comp=comp,
-            page_write=page_write,
-            version=self._config.version,
             content_length=content_length,
             timeout=timeout,
             range=range,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
@@ -530,88 +570,96 @@
             if_sequence_number_equal_to=_if_sequence_number_equal_to,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.clear_pages.metadata['url'],
+            comp=comp,
+            page_write=page_write,
+            version=self._config.version,
+            template_url=self.clear_pages.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    clear_pages.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    clear_pages.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def upload_pages_from_url(  # pylint: disable=inconsistent-return-statements
         self,
         source_url: str,
         source_range: str,
         content_length: int,
         range: str,
-        source_content_md5: Optional[bytearray] = None,
-        source_contentcrc64: Optional[bytearray] = None,
+        source_content_md5: Optional[bytes] = None,
+        source_contentcrc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         copy_source_authorization: Optional[str] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        sequence_number_access_conditions: Optional["_models.SequenceNumberAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
-        source_modified_access_conditions: Optional["_models.SourceModifiedAccessConditions"] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        sequence_number_access_conditions: Optional[_models.SequenceNumberAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Upload Pages operation writes a range of pages to a page blob where the contents are read
         from a URL.
 
-        :param source_url: Specify a URL to the copy source.
+        :param source_url: Specify a URL to the copy source. Required.
         :type source_url: str
         :param source_range: Bytes of source data in the specified range. The length of this range
-         should match the ContentLength header and x-ms-range/Range destination range header.
+         should match the ContentLength header and x-ms-range/Range destination range header. Required.
         :type source_range: str
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param range: The range of bytes to which the source range would be written. The range should
-         be 512 aligned and range-end is required.
+         be 512 aligned and range-end is required. Required.
         :type range: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param source_contentcrc64: Specify the crc64 calculated for the range of bytes that must be
          read from the copy source. Default value is None.
-        :type source_contentcrc64: bytearray
+        :type source_contentcrc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
@@ -644,26 +692,27 @@
          and Content-Length headers must match to perform the update.
          * Clear: Clears the specified range and releases the space used in storage for that range. To
          clear a range, set the Content-Length header to zero, and the Range header to a value that
          indicates the range to clear, up to maximum blob size. Default value is "update". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "page")  # type: str
-        page_write = kwargs.pop('page_write', "update")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+        page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "update"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _lease_id = None
         _if_sequence_number_less_than_or_equal_to = None
@@ -675,42 +724,41 @@
         _if_none_match = None
         _if_tags = None
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if sequence_number_access_conditions is not None:
-            _if_sequence_number_less_than_or_equal_to = sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
-            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
             _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
+            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
+            _if_sequence_number_less_than_or_equal_to = (
+                sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
+            )
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
         request = build_upload_pages_from_url_request(
             url=self._config.url,
-            comp=comp,
-            page_write=page_write,
-            version=self._config.version,
             source_url=source_url,
             source_range=source_range,
             content_length=content_length,
             range=range,
             source_content_md5=source_content_md5,
             source_contentcrc64=source_contentcrc64,
             timeout=timeout,
@@ -729,64 +777,76 @@
             if_tags=_if_tags,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
             source_if_match=_source_if_match,
             source_if_none_match=_source_if_none_match,
             request_id_parameter=request_id_parameter,
             copy_source_authorization=copy_source_authorization,
-            template_url=self.upload_pages_from_url.metadata['url'],
+            comp=comp,
+            page_write=page_write,
+            version=self._config.version,
+            template_url=self.upload_pages_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload_pages_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    upload_pages_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def get_page_ranges(
         self,
         snapshot: Optional[str] = None,
         timeout: Optional[int] = None,
         range: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> "_models.PageList":
+    ) -> _models.PageList:
         """The Get Page Ranges operation returns the list of valid page ranges for a page blob or snapshot
         of a page blob.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -821,108 +881,113 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "pagelist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: PageList, or the result of cls(response)
+        :return: PageList or the result of cls(response)
         :rtype: ~azure.storage.blob.models.PageList
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.PageList"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "pagelist")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "pagelist"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.PageList]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_get_page_ranges_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             snapshot=snapshot,
             timeout=timeout,
             range=range,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.get_page_ranges.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_page_ranges.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['x-ms-blob-content-length']=self._deserialize('long', response.headers.get('x-ms-blob-content-length'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["x-ms-blob-content-length"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-content-length")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('PageList', pipeline_response)
+        deserialized = self._deserialize("PageList", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_page_ranges.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_page_ranges.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def get_page_ranges_diff(
         self,
         snapshot: Optional[str] = None,
         timeout: Optional[int] = None,
         prevsnapshot: Optional[str] = None,
         prev_snapshot_url: Optional[str] = None,
         range: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> "_models.PageList":
+    ) -> _models.PageList:
         """The Get Page Ranges Diff operation returns the list of valid page ranges for a page blob that
         were changed between target blob and previous snapshot.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -969,112 +1034,117 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "pagelist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: PageList, or the result of cls(response)
+        :return: PageList or the result of cls(response)
         :rtype: ~azure.storage.blob.models.PageList
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.PageList"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "pagelist")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "pagelist"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.PageList]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_get_page_ranges_diff_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             snapshot=snapshot,
             timeout=timeout,
             prevsnapshot=prevsnapshot,
             prev_snapshot_url=prev_snapshot_url,
             range=range,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.get_page_ranges_diff.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_page_ranges_diff.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['x-ms-blob-content-length']=self._deserialize('long', response.headers.get('x-ms-blob-content-length'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["x-ms-blob-content-length"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-content-length")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('PageList', pipeline_response)
+        deserialized = self._deserialize("PageList", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_page_ranges_diff.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_page_ranges_diff.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def resize(  # pylint: disable=inconsistent-return-statements
         self,
         blob_content_length: int,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        cpk_info: Optional["_models.CpkInfo"] = None,
-        cpk_scope_info: Optional["_models.CpkScopeInfo"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """Resize the Blob.
 
         :param blob_content_length: This header specifies the maximum size for the page blob, up to 1
-         TB. The page blob size must be aligned to a 512-byte boundary.
-        :type blob_content_length: long
+         TB. The page blob size must be aligned to a 512-byte boundary. Required.
+        :type blob_content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
@@ -1088,232 +1158,241 @@
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "properties")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_resize_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             blob_content_length=blob_content_length,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.resize.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.resize.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    resize.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    resize.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def update_sequence_number(  # pylint: disable=inconsistent-return-statements
         self,
         sequence_number_action: Union[str, "_models.SequenceNumberActionType"],
         timeout: Optional[int] = None,
-        blob_sequence_number: Optional[int] = 0,
+        blob_sequence_number: int = 0,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional["_models.LeaseAccessConditions"] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """Update the sequence number of the blob.
 
         :param sequence_number_action: Required if the x-ms-blob-sequence-number header is set for the
          request. This property applies to page blobs only. This property indicates how the service
-         should modify the blob's sequence number.
+         should modify the blob's sequence number. Known values are: "max", "update", and "increment".
+         Required.
         :type sequence_number_action: str or ~azure.storage.blob.models.SequenceNumberActionType
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param blob_sequence_number: Set for page blobs only. The sequence number is a user-controlled
          value that you can use to track requests. The value of the sequence number must be between 0
          and 2^63 - 1. Default value is 0.
-        :type blob_sequence_number: long
+        :type blob_sequence_number: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "properties")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_update_sequence_number_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             sequence_number_action=sequence_number_action,
             timeout=timeout,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             blob_sequence_number=blob_sequence_number,
             request_id_parameter=request_id_parameter,
-            template_url=self.update_sequence_number.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.update_sequence_number.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    update_sequence_number.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    update_sequence_number.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace_async
     async def copy_incremental(  # pylint: disable=inconsistent-return-statements
         self,
         copy_source: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional["_models.ModifiedAccessConditions"] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
         """The Copy Incremental operation copies a snapshot of the source page blob to a destination page
         blob. The snapshot is copied such that only the differential changes between the previously
         copied snapshot are transferred to the destination. The copied snapshots are complete copies of
         the original snapshot and can be read or copied from as usual. This API is supported since REST
         version 2016-05-31.
 
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1322,76 +1401,78 @@
         :type request_id_parameter: str
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "incrementalcopy". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "incrementalcopy")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "incrementalcopy"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_copy_incremental_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             copy_source=copy_source,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.copy_incremental.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.copy_incremental.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    copy_incremental.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    copy_incremental.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_service_operations.py`

 * *Files 14% similar despite different names*

```diff
@@ -2,60 +2,77 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union
+from typing import Any, AsyncIterator, Callable, Dict, IO, List, Optional, TypeVar, Union
 
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import AsyncHttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator_async import distributed_trace_async
+from azure.core.utils import case_insensitive_dict
 
 from ... import models as _models
 from ..._vendor import _convert_request
-from ...operations._service_operations import build_filter_blobs_request, build_get_account_info_request, build_get_properties_request, build_get_statistics_request, build_get_user_delegation_key_request, build_list_containers_segment_request, build_set_properties_request, build_submit_batch_request
-T = TypeVar('T')
+from ...operations._service_operations import (
+    build_filter_blobs_request,
+    build_get_account_info_request,
+    build_get_properties_request,
+    build_get_statistics_request,
+    build_get_user_delegation_key_request,
+    build_list_containers_segment_request,
+    build_set_properties_request,
+    build_submit_batch_request,
+)
+
+T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]
 
+
 class ServiceOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.aio.AzureBlobStorage`'s
         :attr:`service` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs) -> None:
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace_async
     async def set_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        storage_service_properties: "_models.StorageServiceProperties",
+        storage_service_properties: _models.StorageServiceProperties,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
     ) -> None:
         """Sets properties for a storage account's Blob service endpoint, including properties for Storage
         Analytics and CORS (Cross-Origin Resource Sharing) rules.
 
-        :param storage_service_properties: The StorageService properties.
+        :param storage_service_properties: The StorageService properties. Required.
         :type storage_service_properties: ~azure.storage.blob.models.StorageServiceProperties
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -65,75 +82,74 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _content = self._serialize.body(storage_service_properties, 'StorageServiceProperties', is_xml=True)
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        _content = self._serialize.body(storage_service_properties, "StorageServiceProperties", is_xml=True)
 
         request = build_set_properties_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
-            version=self._config.version,
             content_type=content_type,
+            version=self._config.version,
             content=_content,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.set_properties.metadata['url'],
+            template_url=self.set_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_properties.metadata = {'url': "{url}"}  # type: ignore
-
+    set_properties.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
     async def get_properties(
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
-    ) -> "_models.StorageServiceProperties":
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> _models.StorageServiceProperties:
         """gets the properties of a storage account's Blob service, including properties for Storage
         Analytics and CORS (Cross-Origin Resource Sharing) rules.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -145,74 +161,73 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: StorageServiceProperties, or the result of cls(response)
+        :return: StorageServiceProperties or the result of cls(response)
         :rtype: ~azure.storage.blob.models.StorageServiceProperties
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.StorageServiceProperties"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.StorageServiceProperties]
 
-        
         request = build_get_properties_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.get_properties.metadata['url'],
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
-        deserialized = self._deserialize('StorageServiceProperties', pipeline_response)
+        deserialized = self._deserialize("StorageServiceProperties", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_properties.metadata = {'url': "{url}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
     async def get_statistics(
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
-    ) -> "_models.StorageServiceStats":
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> _models.StorageServiceStats:
         """Retrieves statistics related to replication for the Blob service. It is only available on the
         secondary location endpoint when read-access geo-redundant replication is enabled for the
         storage account.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -225,79 +240,81 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "stats". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: StorageServiceStats, or the result of cls(response)
+        :return: StorageServiceStats or the result of cls(response)
         :rtype: ~azure.storage.blob.models.StorageServiceStats
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.StorageServiceStats"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "stats")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "stats"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.StorageServiceStats]
 
-        
         request = build_get_statistics_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.get_statistics.metadata['url'],
+            template_url=self.get_statistics.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('StorageServiceStats', pipeline_response)
+        deserialized = self._deserialize("StorageServiceStats", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_statistics.metadata = {'url': "{url}"}  # type: ignore
-
+    get_statistics.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
     async def list_containers_segment(
         self,
         prefix: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
         include: Optional[List[Union[str, "_models.ListContainersIncludeType"]]] = None,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> "_models.ListContainersSegmentResponse":
+    ) -> _models.ListContainersSegmentResponse:
         """The List Containers Segment operation returns a list of the containers under the specified
         account.
 
         :param prefix: Filters the results to return only containers whose name begins with the
          specified prefix. Default value is None.
         :type prefix: str
         :param marker: A string value that identifies the portion of the list of containers to be
@@ -326,81 +343,83 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "list". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListContainersSegmentResponse, or the result of cls(response)
+        :return: ListContainersSegmentResponse or the result of cls(response)
         :rtype: ~azure.storage.blob.models.ListContainersSegmentResponse
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ListContainersSegmentResponse"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "list")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListContainersSegmentResponse]
 
-        
         request = build_list_containers_segment_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             prefix=prefix,
             marker=marker,
             maxresults=maxresults,
             include=include,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.list_containers_segment.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_containers_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
-        deserialized = self._deserialize('ListContainersSegmentResponse', pipeline_response)
+        deserialized = self._deserialize("ListContainersSegmentResponse", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    list_containers_segment.metadata = {'url': "{url}"}  # type: ignore
-
+    list_containers_segment.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
     async def get_user_delegation_key(
         self,
-        key_info: "_models.KeyInfo",
+        key_info: _models.KeyInfo,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> "_models.UserDelegationKey":
+    ) -> _models.UserDelegationKey:
         """Retrieves a user delegation key for the Blob service. This is only a valid operation when using
         bearer token authentication.
 
-        :param key_info: Key information.
+        :param key_info: Key information. Required.
         :type key_info: ~azure.storage.blob.models.KeyInfo
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -410,235 +429,237 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "userdelegationkey". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: UserDelegationKey, or the result of cls(response)
+        :return: UserDelegationKey or the result of cls(response)
         :rtype: ~azure.storage.blob.models.UserDelegationKey
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.UserDelegationKey"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "userdelegationkey")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "userdelegationkey"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.UserDelegationKey]
 
-        _content = self._serialize.body(key_info, 'KeyInfo', is_xml=True)
+        _content = self._serialize.body(key_info, "KeyInfo", is_xml=True)
 
         request = build_get_user_delegation_key_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
-            version=self._config.version,
             content_type=content_type,
+            version=self._config.version,
             content=_content,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.get_user_delegation_key.metadata['url'],
+            template_url=self.get_user_delegation_key.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('UserDelegationKey', pipeline_response)
+        deserialized = self._deserialize("UserDelegationKey", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_user_delegation_key.metadata = {'url': "{url}"}  # type: ignore
-
+    get_user_delegation_key.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
-    async def get_account_info(  # pylint: disable=inconsistent-return-statements
-        self,
-        **kwargs: Any
-    ) -> None:
+    async def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
         """Returns the sku name and account kind.
 
         :keyword restype: restype. Default value is "account". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "account")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_get_account_info_request(
             url=self._config.url,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata['url'],
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-sku-name']=self._deserialize('str', response.headers.get('x-ms-sku-name'))
-        response_headers['x-ms-account-kind']=self._deserialize('str', response.headers.get('x-ms-account-kind'))
-        response_headers['x-ms-is-hns-enabled']=self._deserialize('bool', response.headers.get('x-ms-is-hns-enabled'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
+        response_headers["x-ms-is-hns-enabled"] = self._deserialize("bool", response.headers.get("x-ms-is-hns-enabled"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {'url': "{url}"}  # type: ignore
-
+    get_account_info.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
     async def submit_batch(
         self,
         content_length: int,
         body: IO,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> IO:
+    ) -> AsyncIterator[bytes]:
         """The Batch operation allows multiple API calls to be embedded into a single HTTP request.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword multipart_content_type: Required. The value of this header must be multipart/mixed
-         with a batch boundary. Example header value: multipart/mixed; boundary=batch_:code:`<GUID>`.
-        :paramtype multipart_content_type: str
         :keyword comp: comp. Default value is "batch". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: Async iterator of the response bytes or the result of cls(response)
+        :rtype: AsyncIterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        multipart_content_type = kwargs.pop('multipart_content_type')  # type: str
-        comp = kwargs.pop('comp', "batch")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+        multipart_content_type = kwargs.pop(
+            "multipart_content_type", _headers.pop("Content-Type", "application/xml")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[AsyncIterator[bytes]]
 
-        _content = self._serialize.body(body, 'IO')
+        _content = body
 
         request = build_submit_batch_request(
             url=self._config.url,
-            multipart_content_type=multipart_content_type,
-            comp=comp,
-            version=self._config.version,
-            content=_content,
             content_length=content_length,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.submit_batch.metadata['url'],
+            comp=comp,
+            multipart_content_type=multipart_content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.submit_batch.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    submit_batch.metadata = {'url': "{url}"}  # type: ignore
-
+    submit_batch.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace_async
     async def filter_blobs(
         self,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
         where: Optional[str] = None,
         marker: Optional[str] = None,
         maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
         **kwargs: Any
-    ) -> "_models.FilterBlobSegment":
+    ) -> _models.FilterBlobSegment:
         """The Filter Blobs operation enables callers to list blobs across all containers whose tags match
         a given search expression.  Filter blobs searches across all containers within a storage
         account but can be scoped within the expression to a single container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -661,65 +682,71 @@
         :param maxresults: Specifies the maximum number of containers to return. If the request does
          not specify maxresults, or specifies a value greater than 5000, the server will return up to
          5000 items. Note that if the listing operation crosses a partition boundary, then the service
          will return a continuation token for retrieving the remainder of the results. For this reason,
          it is possible that the service will return fewer results than specified by maxresults, or than
          the default of 5000. Default value is None.
         :type maxresults: int
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.FilterBlobsIncludeItem]
         :keyword comp: comp. Default value is "blobs". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: FilterBlobSegment, or the result of cls(response)
+        :return: FilterBlobSegment or the result of cls(response)
         :rtype: ~azure.storage.blob.models.FilterBlobSegment
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.FilterBlobSegment"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "blobs")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.FilterBlobSegment]
 
-        
         request = build_filter_blobs_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             where=where,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.filter_blobs.metadata['url'],
+            include=include,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.filter_blobs.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('FilterBlobSegment', pipeline_response)
+        deserialized = self._deserialize("FilterBlobSegment", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    filter_blobs.metadata = {'url': "{url}"}  # type: ignore
-
+    filter_blobs.metadata = {"url": "{url}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_azure_blob_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_azure_blob_storage_enums.py`

 * *Files 11% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from enum import Enum
-from six import with_metaclass
 from azure.core import CaseInsensitiveEnumMeta
 
 
-class AccessTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+class AccessTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """AccessTier."""
 
     P4 = "P4"
     P6 = "P6"
     P10 = "P10"
     P15 = "P15"
     P20 = "P20"
     P30 = "P30"
@@ -23,16 +23,19 @@
     P50 = "P50"
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
     HOT = "Hot"
     COOL = "Cool"
     ARCHIVE = "Archive"
+    PREMIUM = "Premium"
 
-class AccessTierOptional(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class AccessTierOptional(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """AccessTierOptional."""
 
     P4 = "P4"
     P6 = "P6"
     P10 = "P10"
     P15 = "P15"
     P20 = "P20"
     P30 = "P30"
@@ -41,15 +44,17 @@
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
     HOT = "Hot"
     COOL = "Cool"
     ARCHIVE = "Archive"
 
-class AccessTierRequired(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class AccessTierRequired(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """AccessTierRequired."""
 
     P4 = "P4"
     P6 = "P6"
     P10 = "P10"
     P15 = "P15"
     P20 = "P20"
     P30 = "P30"
@@ -58,172 +63,218 @@
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
     HOT = "Hot"
     COOL = "Cool"
     ARCHIVE = "Archive"
 
-class AccountKind(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class AccountKind(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """AccountKind."""
 
     STORAGE = "Storage"
     BLOB_STORAGE = "BlobStorage"
     STORAGE_V2 = "StorageV2"
     FILE_STORAGE = "FileStorage"
     BLOCK_BLOB_STORAGE = "BlockBlobStorage"
 
-class ArchiveStatus(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class ArchiveStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """ArchiveStatus."""
 
     REHYDRATE_PENDING_TO_HOT = "rehydrate-pending-to-hot"
     REHYDRATE_PENDING_TO_COOL = "rehydrate-pending-to-cool"
 
-class BlobCopySourceTags(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class BlobCopySourceTags(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """BlobCopySourceTags."""
 
     REPLACE = "REPLACE"
     COPY = "COPY"
 
-class BlobExpiryOptions(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class BlobExpiryOptions(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """BlobExpiryOptions."""
 
     NEVER_EXPIRE = "NeverExpire"
     RELATIVE_TO_CREATION = "RelativeToCreation"
     RELATIVE_TO_NOW = "RelativeToNow"
     ABSOLUTE = "Absolute"
 
-class BlobImmutabilityPolicyMode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class BlobImmutabilityPolicyMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """BlobImmutabilityPolicyMode."""
 
     MUTABLE = "Mutable"
     UNLOCKED = "Unlocked"
     LOCKED = "Locked"
 
-class BlobType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class BlobType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """BlobType."""
 
     BLOCK_BLOB = "BlockBlob"
     PAGE_BLOB = "PageBlob"
     APPEND_BLOB = "AppendBlob"
 
-class BlockListType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class BlockListType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """BlockListType."""
 
     COMMITTED = "committed"
     UNCOMMITTED = "uncommitted"
     ALL = "all"
 
-class CopyStatusType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class CopyStatusType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """CopyStatusType."""
 
     PENDING = "pending"
     SUCCESS = "success"
     ABORTED = "aborted"
     FAILED = "failed"
 
-class DeleteSnapshotsOptionType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class DeleteSnapshotsOptionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """DeleteSnapshotsOptionType."""
 
     INCLUDE = "include"
     ONLY = "only"
 
-class EncryptionAlgorithmType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class EncryptionAlgorithmType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """EncryptionAlgorithmType."""
 
     NONE = "None"
     AES256 = "AES256"
 
-class GeoReplicationStatusType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """The status of the secondary location
-    """
+
+class FilterBlobsIncludeItem(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """FilterBlobsIncludeItem."""
+
+    NONE = "none"
+    VERSIONS = "versions"
+
+
+class GeoReplicationStatusType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """The status of the secondary location."""
 
     LIVE = "live"
     BOOTSTRAP = "bootstrap"
     UNAVAILABLE = "unavailable"
 
-class LeaseDurationType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class LeaseDurationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """LeaseDurationType."""
 
     INFINITE = "infinite"
     FIXED = "fixed"
 
-class LeaseStateType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class LeaseStateType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """LeaseStateType."""
 
     AVAILABLE = "available"
     LEASED = "leased"
     EXPIRED = "expired"
     BREAKING = "breaking"
     BROKEN = "broken"
 
-class LeaseStatusType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class LeaseStatusType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """LeaseStatusType."""
 
     LOCKED = "locked"
     UNLOCKED = "unlocked"
 
-class ListBlobsIncludeItem(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class ListBlobsIncludeItem(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """ListBlobsIncludeItem."""
 
     COPY = "copy"
     DELETED = "deleted"
     METADATA = "metadata"
     SNAPSHOTS = "snapshots"
     UNCOMMITTEDBLOBS = "uncommittedblobs"
     VERSIONS = "versions"
     TAGS = "tags"
     IMMUTABILITYPOLICY = "immutabilitypolicy"
     LEGALHOLD = "legalhold"
     DELETEDWITHVERSIONS = "deletedwithversions"
 
-class ListContainersIncludeType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class ListContainersIncludeType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """ListContainersIncludeType."""
 
     METADATA = "metadata"
     DELETED = "deleted"
     SYSTEM = "system"
 
-class PremiumPageBlobAccessTier(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class PremiumPageBlobAccessTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """PremiumPageBlobAccessTier."""
 
     P4 = "P4"
     P6 = "P6"
     P10 = "P10"
     P15 = "P15"
     P20 = "P20"
     P30 = "P30"
     P40 = "P40"
     P50 = "P50"
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
 
-class PublicAccessType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class PublicAccessType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """PublicAccessType."""
 
     CONTAINER = "container"
     BLOB = "blob"
 
-class QueryFormatType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """The quick query format type.
-    """
+
+class QueryFormatType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """The quick query format type."""
 
     DELIMITED = "delimited"
     JSON = "json"
     ARROW = "arrow"
     PARQUET = "parquet"
 
-class RehydratePriority(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class RehydratePriority(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """If an object is in rehydrate pending state then this header is returned with priority of
     rehydrate. Valid values are High and Standard.
     """
 
     HIGH = "High"
     STANDARD = "Standard"
 
-class SequenceNumberActionType(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class SequenceNumberActionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """SequenceNumberActionType."""
 
     MAX = "max"
     UPDATE = "update"
     INCREMENT = "increment"
 
-class SkuName(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
+
+class SkuName(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """SkuName."""
 
     STANDARD_LRS = "Standard_LRS"
     STANDARD_GRS = "Standard_GRS"
     STANDARD_RAGRS = "Standard_RAGRS"
     STANDARD_ZRS = "Standard_ZRS"
     PREMIUM_LRS = "Premium_LRS"
 
-class StorageErrorCode(with_metaclass(CaseInsensitiveEnumMeta, str, Enum)):
-    """Error codes returned by the service
-    """
+
+class StorageErrorCode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
+    """Error codes returned by the service."""
 
     ACCOUNT_ALREADY_EXISTS = "AccountAlreadyExists"
     ACCOUNT_BEING_CREATED = "AccountBeingCreated"
     ACCOUNT_IS_DISABLED = "AccountIsDisabled"
     AUTHENTICATION_FAILED = "AuthenticationFailed"
     AUTHORIZATION_FAILURE = "AuthorizationFailure"
     CONDITION_HEADERS_NOT_SUPPORTED = "ConditionHeadersNotSupported"
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_models_py3.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,128 +1,136 @@
 # coding=utf-8
+# pylint: disable=too-many-lines
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from azure.core.exceptions import HttpResponseError
-import msrest.serialization
+import datetime
+import sys
+from typing import Any, Dict, List, Optional, TYPE_CHECKING, Union
+
+from .. import _serialization
+
+if TYPE_CHECKING:
+    # pylint: disable=unused-import,ungrouped-imports
+    from .. import models as _models
+if sys.version_info >= (3, 9):
+    from collections.abc import MutableMapping
+else:
+    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
+JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
 
 
-class AccessPolicy(msrest.serialization.Model):
+class AccessPolicy(_serialization.Model):
     """An Access policy.
 
     :ivar start: the date-time the policy is active.
     :vartype start: str
     :ivar expiry: the date-time the policy expires.
     :vartype expiry: str
     :ivar permission: the permissions for the acl policy.
     :vartype permission: str
     """
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'str'},
-        'expiry': {'key': 'Expiry', 'type': 'str'},
-        'permission': {'key': 'Permission', 'type': 'str'},
+        "start": {"key": "Start", "type": "str"},
+        "expiry": {"key": "Expiry", "type": "str"},
+        "permission": {"key": "Permission", "type": "str"},
     }
 
     def __init__(
-        self,
-        **kwargs
+        self, *, start: Optional[str] = None, expiry: Optional[str] = None, permission: Optional[str] = None, **kwargs
     ):
         """
         :keyword start: the date-time the policy is active.
         :paramtype start: str
         :keyword expiry: the date-time the policy expires.
         :paramtype expiry: str
         :keyword permission: the permissions for the acl policy.
         :paramtype permission: str
         """
-        super(AccessPolicy, self).__init__(**kwargs)
-        self.start = kwargs.get('start', None)
-        self.expiry = kwargs.get('expiry', None)
-        self.permission = kwargs.get('permission', None)
+        super().__init__(**kwargs)
+        self.start = start
+        self.expiry = expiry
+        self.permission = permission
 
 
-class AppendPositionAccessConditions(msrest.serialization.Model):
+class AppendPositionAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar max_size: Optional conditional header. The max length in bytes permitted for the append
      blob. If the Append Block operation would cause the blob to exceed that limit or if the blob
      size is already greater than the value specified in this header, the request will fail with
      MaxBlobSizeConditionNotMet error (HTTP status code 412 - Precondition Failed).
-    :vartype max_size: long
+    :vartype max_size: int
     :ivar append_position: Optional conditional header, used only for the Append Block operation. A
      number indicating the byte offset to compare. Append Block will succeed only if the append
      position is equal to this number. If it is not, the request will fail with the
      AppendPositionConditionNotMet error (HTTP status code 412 - Precondition Failed).
-    :vartype append_position: long
+    :vartype append_position: int
     """
 
     _attribute_map = {
-        'max_size': {'key': 'maxSize', 'type': 'long'},
-        'append_position': {'key': 'appendPosition', 'type': 'long'},
+        "max_size": {"key": "maxSize", "type": "int"},
+        "append_position": {"key": "appendPosition", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, max_size: Optional[int] = None, append_position: Optional[int] = None, **kwargs):
         """
         :keyword max_size: Optional conditional header. The max length in bytes permitted for the
          append blob. If the Append Block operation would cause the blob to exceed that limit or if the
          blob size is already greater than the value specified in this header, the request will fail
          with MaxBlobSizeConditionNotMet error (HTTP status code 412 - Precondition Failed).
-        :paramtype max_size: long
+        :paramtype max_size: int
         :keyword append_position: Optional conditional header, used only for the Append Block
          operation. A number indicating the byte offset to compare. Append Block will succeed only if
          the append position is equal to this number. If it is not, the request will fail with the
          AppendPositionConditionNotMet error (HTTP status code 412 - Precondition Failed).
-        :paramtype append_position: long
+        :paramtype append_position: int
         """
-        super(AppendPositionAccessConditions, self).__init__(**kwargs)
-        self.max_size = kwargs.get('max_size', None)
-        self.append_position = kwargs.get('append_position', None)
+        super().__init__(**kwargs)
+        self.max_size = max_size
+        self.append_position = append_position
 
 
-class ArrowConfiguration(msrest.serialization.Model):
+class ArrowConfiguration(_serialization.Model):
     """Groups the settings used for formatting the response if the response should be Arrow formatted.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar schema: Required.
     :vartype schema: list[~azure.storage.blob.models.ArrowField]
     """
 
     _validation = {
-        'schema': {'required': True},
+        "schema": {"required": True},
     }
 
     _attribute_map = {
-        'schema': {'key': 'Schema', 'type': '[ArrowField]', 'xml': {'name': 'Schema', 'wrapped': True, 'itemsName': 'Field'}},
-    }
-    _xml_map = {
-        'name': 'ArrowConfiguration'
+        "schema": {
+            "key": "Schema",
+            "type": "[ArrowField]",
+            "xml": {"name": "Schema", "wrapped": True, "itemsName": "Field"},
+        },
     }
+    _xml_map = {"name": "ArrowConfiguration"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, schema: List["_models.ArrowField"], **kwargs):
         """
         :keyword schema: Required.
         :paramtype schema: list[~azure.storage.blob.models.ArrowField]
         """
-        super(ArrowConfiguration, self).__init__(**kwargs)
-        self.schema = kwargs['schema']
+        super().__init__(**kwargs)
+        self.schema = schema
 
 
-class ArrowField(msrest.serialization.Model):
+class ArrowField(_serialization.Model):
     """Groups settings regarding specific field of an arrow schema.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar type: Required.
     :vartype type: str
     :ivar name:
@@ -130,401 +138,407 @@
     :ivar precision:
     :vartype precision: int
     :ivar scale:
     :vartype scale: int
     """
 
     _validation = {
-        'type': {'required': True},
+        "type": {"required": True},
     }
 
     _attribute_map = {
-        'type': {'key': 'Type', 'type': 'str'},
-        'name': {'key': 'Name', 'type': 'str'},
-        'precision': {'key': 'Precision', 'type': 'int'},
-        'scale': {'key': 'Scale', 'type': 'int'},
-    }
-    _xml_map = {
-        'name': 'Field'
+        "type": {"key": "Type", "type": "str"},
+        "name": {"key": "Name", "type": "str"},
+        "precision": {"key": "Precision", "type": "int"},
+        "scale": {"key": "Scale", "type": "int"},
     }
+    _xml_map = {"name": "Field"}
 
     def __init__(
         self,
+        *,
+        type: str,
+        name: Optional[str] = None,
+        precision: Optional[int] = None,
+        scale: Optional[int] = None,
         **kwargs
     ):
         """
         :keyword type: Required.
         :paramtype type: str
         :keyword name:
         :paramtype name: str
         :keyword precision:
         :paramtype precision: int
         :keyword scale:
         :paramtype scale: int
         """
-        super(ArrowField, self).__init__(**kwargs)
-        self.type = kwargs['type']
-        self.name = kwargs.get('name', None)
-        self.precision = kwargs.get('precision', None)
-        self.scale = kwargs.get('scale', None)
+        super().__init__(**kwargs)
+        self.type = type
+        self.name = name
+        self.precision = precision
+        self.scale = scale
 
 
-class BlobFlatListSegment(msrest.serialization.Model):
+class BlobFlatListSegment(_serialization.Model):
     """BlobFlatListSegment.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar blob_items: Required.
     :vartype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
     """
 
     _validation = {
-        'blob_items': {'required': True},
+        "blob_items": {"required": True},
     }
 
     _attribute_map = {
-        'blob_items': {'key': 'BlobItems', 'type': '[BlobItemInternal]'},
-    }
-    _xml_map = {
-        'name': 'Blobs'
+        "blob_items": {"key": "BlobItems", "type": "[BlobItemInternal]", "xml": {"itemsName": "Blob"}},
     }
+    _xml_map = {"name": "Blobs"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, blob_items: List["_models.BlobItemInternal"], **kwargs):
         """
         :keyword blob_items: Required.
         :paramtype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
         """
-        super(BlobFlatListSegment, self).__init__(**kwargs)
-        self.blob_items = kwargs['blob_items']
+        super().__init__(**kwargs)
+        self.blob_items = blob_items
 
 
-class BlobHierarchyListSegment(msrest.serialization.Model):
+class BlobHierarchyListSegment(_serialization.Model):
     """BlobHierarchyListSegment.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar blob_prefixes:
     :vartype blob_prefixes: list[~azure.storage.blob.models.BlobPrefix]
     :ivar blob_items: Required.
     :vartype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
     """
 
     _validation = {
-        'blob_items': {'required': True},
+        "blob_items": {"required": True},
     }
 
     _attribute_map = {
-        'blob_prefixes': {'key': 'BlobPrefixes', 'type': '[BlobPrefix]', 'xml': {'name': 'BlobPrefix'}},
-        'blob_items': {'key': 'BlobItems', 'type': '[BlobItemInternal]', 'xml': {'name': 'Blob', 'itemsName': 'Blob'}},
-    }
-    _xml_map = {
-        'name': 'Blobs'
+        "blob_prefixes": {"key": "BlobPrefixes", "type": "[BlobPrefix]", "xml": {"name": "BlobPrefix"}},
+        "blob_items": {"key": "BlobItems", "type": "[BlobItemInternal]", "xml": {"name": "Blob", "itemsName": "Blob"}},
     }
+    _xml_map = {"name": "Blobs"}
 
     def __init__(
         self,
+        *,
+        blob_items: List["_models.BlobItemInternal"],
+        blob_prefixes: Optional[List["_models.BlobPrefix"]] = None,
         **kwargs
     ):
         """
         :keyword blob_prefixes:
         :paramtype blob_prefixes: list[~azure.storage.blob.models.BlobPrefix]
         :keyword blob_items: Required.
         :paramtype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
         """
-        super(BlobHierarchyListSegment, self).__init__(**kwargs)
-        self.blob_prefixes = kwargs.get('blob_prefixes', None)
-        self.blob_items = kwargs['blob_items']
+        super().__init__(**kwargs)
+        self.blob_prefixes = blob_prefixes
+        self.blob_items = blob_items
 
 
-class BlobHTTPHeaders(msrest.serialization.Model):
+class BlobHTTPHeaders(_serialization.Model):
     """Parameter group.
 
     :ivar blob_cache_control: Optional. Sets the blob's cache control. If specified, this property
      is stored with the blob and returned with a read request.
     :vartype blob_cache_control: str
     :ivar blob_content_type: Optional. Sets the blob's content type. If specified, this property is
      stored with the blob and returned with a read request.
     :vartype blob_content_type: str
     :ivar blob_content_md5: Optional. An MD5 hash of the blob content. Note that this hash is not
      validated, as the hashes for the individual blocks were validated when each was uploaded.
-    :vartype blob_content_md5: bytearray
+    :vartype blob_content_md5: bytes
     :ivar blob_content_encoding: Optional. Sets the blob's content encoding. If specified, this
      property is stored with the blob and returned with a read request.
     :vartype blob_content_encoding: str
     :ivar blob_content_language: Optional. Set the blob's content language. If specified, this
      property is stored with the blob and returned with a read request.
     :vartype blob_content_language: str
     :ivar blob_content_disposition: Optional. Sets the blob's Content-Disposition header.
     :vartype blob_content_disposition: str
     """
 
     _attribute_map = {
-        'blob_cache_control': {'key': 'blobCacheControl', 'type': 'str'},
-        'blob_content_type': {'key': 'blobContentType', 'type': 'str'},
-        'blob_content_md5': {'key': 'blobContentMD5', 'type': 'bytearray'},
-        'blob_content_encoding': {'key': 'blobContentEncoding', 'type': 'str'},
-        'blob_content_language': {'key': 'blobContentLanguage', 'type': 'str'},
-        'blob_content_disposition': {'key': 'blobContentDisposition', 'type': 'str'},
+        "blob_cache_control": {"key": "blobCacheControl", "type": "str"},
+        "blob_content_type": {"key": "blobContentType", "type": "str"},
+        "blob_content_md5": {"key": "blobContentMD5", "type": "bytearray"},
+        "blob_content_encoding": {"key": "blobContentEncoding", "type": "str"},
+        "blob_content_language": {"key": "blobContentLanguage", "type": "str"},
+        "blob_content_disposition": {"key": "blobContentDisposition", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        blob_cache_control: Optional[str] = None,
+        blob_content_type: Optional[str] = None,
+        blob_content_md5: Optional[bytes] = None,
+        blob_content_encoding: Optional[str] = None,
+        blob_content_language: Optional[str] = None,
+        blob_content_disposition: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword blob_cache_control: Optional. Sets the blob's cache control. If specified, this
          property is stored with the blob and returned with a read request.
         :paramtype blob_cache_control: str
         :keyword blob_content_type: Optional. Sets the blob's content type. If specified, this property
          is stored with the blob and returned with a read request.
         :paramtype blob_content_type: str
         :keyword blob_content_md5: Optional. An MD5 hash of the blob content. Note that this hash is
          not validated, as the hashes for the individual blocks were validated when each was uploaded.
-        :paramtype blob_content_md5: bytearray
+        :paramtype blob_content_md5: bytes
         :keyword blob_content_encoding: Optional. Sets the blob's content encoding. If specified, this
          property is stored with the blob and returned with a read request.
         :paramtype blob_content_encoding: str
         :keyword blob_content_language: Optional. Set the blob's content language. If specified, this
          property is stored with the blob and returned with a read request.
         :paramtype blob_content_language: str
         :keyword blob_content_disposition: Optional. Sets the blob's Content-Disposition header.
         :paramtype blob_content_disposition: str
         """
-        super(BlobHTTPHeaders, self).__init__(**kwargs)
-        self.blob_cache_control = kwargs.get('blob_cache_control', None)
-        self.blob_content_type = kwargs.get('blob_content_type', None)
-        self.blob_content_md5 = kwargs.get('blob_content_md5', None)
-        self.blob_content_encoding = kwargs.get('blob_content_encoding', None)
-        self.blob_content_language = kwargs.get('blob_content_language', None)
-        self.blob_content_disposition = kwargs.get('blob_content_disposition', None)
+        super().__init__(**kwargs)
+        self.blob_cache_control = blob_cache_control
+        self.blob_content_type = blob_content_type
+        self.blob_content_md5 = blob_content_md5
+        self.blob_content_encoding = blob_content_encoding
+        self.blob_content_language = blob_content_language
+        self.blob_content_disposition = blob_content_disposition
 
 
-class BlobItemInternal(msrest.serialization.Model):
+class BlobItemInternal(_serialization.Model):
     """An Azure Storage blob.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: ~azure.storage.blob.models.BlobName
     :ivar deleted: Required.
     :vartype deleted: bool
     :ivar snapshot: Required.
     :vartype snapshot: str
     :ivar version_id:
     :vartype version_id: str
     :ivar is_current_version:
     :vartype is_current_version: bool
-    :ivar properties: Required. Properties of a blob.
+    :ivar properties: Properties of a blob. Required.
     :vartype properties: ~azure.storage.blob.models.BlobPropertiesInternal
     :ivar metadata:
     :vartype metadata: ~azure.storage.blob.models.BlobMetadata
     :ivar blob_tags: Blob tags.
     :vartype blob_tags: ~azure.storage.blob.models.BlobTags
     :ivar has_versions_only:
     :vartype has_versions_only: bool
     :ivar object_replication_metadata: Dictionary of :code:`<string>`.
     :vartype object_replication_metadata: dict[str, str]
     """
 
     _validation = {
-        'name': {'required': True},
-        'deleted': {'required': True},
-        'snapshot': {'required': True},
-        'properties': {'required': True},
+        "name": {"required": True},
+        "deleted": {"required": True},
+        "snapshot": {"required": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'BlobName'},
-        'deleted': {'key': 'Deleted', 'type': 'bool'},
-        'snapshot': {'key': 'Snapshot', 'type': 'str'},
-        'version_id': {'key': 'VersionId', 'type': 'str'},
-        'is_current_version': {'key': 'IsCurrentVersion', 'type': 'bool'},
-        'properties': {'key': 'Properties', 'type': 'BlobPropertiesInternal'},
-        'metadata': {'key': 'Metadata', 'type': 'BlobMetadata'},
-        'blob_tags': {'key': 'BlobTags', 'type': 'BlobTags'},
-        'has_versions_only': {'key': 'HasVersionsOnly', 'type': 'bool'},
-        'object_replication_metadata': {'key': 'OrMetadata', 'type': '{str}'},
-    }
-    _xml_map = {
-        'name': 'Blob'
-    }
+        "name": {"key": "Name", "type": "BlobName"},
+        "deleted": {"key": "Deleted", "type": "bool"},
+        "snapshot": {"key": "Snapshot", "type": "str"},
+        "version_id": {"key": "VersionId", "type": "str"},
+        "is_current_version": {"key": "IsCurrentVersion", "type": "bool"},
+        "properties": {"key": "Properties", "type": "BlobPropertiesInternal"},
+        "metadata": {"key": "Metadata", "type": "BlobMetadata"},
+        "blob_tags": {"key": "BlobTags", "type": "BlobTags"},
+        "has_versions_only": {"key": "HasVersionsOnly", "type": "bool"},
+        "object_replication_metadata": {"key": "OrMetadata", "type": "{str}"},
+    }
+    _xml_map = {"name": "Blob"}
 
     def __init__(
         self,
+        *,
+        name: "_models.BlobName",
+        deleted: bool,
+        snapshot: str,
+        properties: "_models.BlobPropertiesInternal",
+        version_id: Optional[str] = None,
+        is_current_version: Optional[bool] = None,
+        metadata: Optional["_models.BlobMetadata"] = None,
+        blob_tags: Optional["_models.BlobTags"] = None,
+        has_versions_only: Optional[bool] = None,
+        object_replication_metadata: Optional[Dict[str, str]] = None,
         **kwargs
     ):
         """
         :keyword name: Required.
         :paramtype name: ~azure.storage.blob.models.BlobName
         :keyword deleted: Required.
         :paramtype deleted: bool
         :keyword snapshot: Required.
         :paramtype snapshot: str
         :keyword version_id:
         :paramtype version_id: str
         :keyword is_current_version:
         :paramtype is_current_version: bool
-        :keyword properties: Required. Properties of a blob.
+        :keyword properties: Properties of a blob. Required.
         :paramtype properties: ~azure.storage.blob.models.BlobPropertiesInternal
         :keyword metadata:
         :paramtype metadata: ~azure.storage.blob.models.BlobMetadata
         :keyword blob_tags: Blob tags.
         :paramtype blob_tags: ~azure.storage.blob.models.BlobTags
         :keyword has_versions_only:
         :paramtype has_versions_only: bool
         :keyword object_replication_metadata: Dictionary of :code:`<string>`.
         :paramtype object_replication_metadata: dict[str, str]
         """
-        super(BlobItemInternal, self).__init__(**kwargs)
-        self.name = kwargs['name']
-        self.deleted = kwargs['deleted']
-        self.snapshot = kwargs['snapshot']
-        self.version_id = kwargs.get('version_id', None)
-        self.is_current_version = kwargs.get('is_current_version', None)
-        self.properties = kwargs['properties']
-        self.metadata = kwargs.get('metadata', None)
-        self.blob_tags = kwargs.get('blob_tags', None)
-        self.has_versions_only = kwargs.get('has_versions_only', None)
-        self.object_replication_metadata = kwargs.get('object_replication_metadata', None)
+        super().__init__(**kwargs)
+        self.name = name
+        self.deleted = deleted
+        self.snapshot = snapshot
+        self.version_id = version_id
+        self.is_current_version = is_current_version
+        self.properties = properties
+        self.metadata = metadata
+        self.blob_tags = blob_tags
+        self.has_versions_only = has_versions_only
+        self.object_replication_metadata = object_replication_metadata
 
 
-class BlobMetadata(msrest.serialization.Model):
+class BlobMetadata(_serialization.Model):
     """BlobMetadata.
 
     :ivar additional_properties: Unmatched properties from the message are deserialized to this
      collection.
     :vartype additional_properties: dict[str, str]
     :ivar encrypted:
     :vartype encrypted: str
     """
 
     _attribute_map = {
-        'additional_properties': {'key': '', 'type': '{str}'},
-        'encrypted': {'key': 'Encrypted', 'type': 'str', 'xml': {'attr': True}},
-    }
-    _xml_map = {
-        'name': 'Metadata'
+        "additional_properties": {"key": "", "type": "{str}"},
+        "encrypted": {"key": "Encrypted", "type": "str", "xml": {"attr": True}},
     }
+    _xml_map = {"name": "Metadata"}
 
     def __init__(
-        self,
-        **kwargs
+        self, *, additional_properties: Optional[Dict[str, str]] = None, encrypted: Optional[str] = None, **kwargs
     ):
         """
         :keyword additional_properties: Unmatched properties from the message are deserialized to this
          collection.
         :paramtype additional_properties: dict[str, str]
         :keyword encrypted:
         :paramtype encrypted: str
         """
-        super(BlobMetadata, self).__init__(**kwargs)
-        self.additional_properties = kwargs.get('additional_properties', None)
-        self.encrypted = kwargs.get('encrypted', None)
+        super().__init__(**kwargs)
+        self.additional_properties = additional_properties
+        self.encrypted = encrypted
 
 
-class BlobName(msrest.serialization.Model):
+class BlobName(_serialization.Model):
     """BlobName.
 
     :ivar encoded: Indicates if the blob name is encoded.
     :vartype encoded: bool
     :ivar content: The name of the blob.
     :vartype content: str
     """
 
     _attribute_map = {
-        'encoded': {'key': 'Encoded', 'type': 'bool', 'xml': {'name': 'Encoded', 'attr': True}},
-        'content': {'key': 'content', 'type': 'str', 'xml': {'text': True}},
+        "encoded": {"key": "Encoded", "type": "bool", "xml": {"name": "Encoded", "attr": True}},
+        "content": {"key": "content", "type": "str", "xml": {"text": True}},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, encoded: Optional[bool] = None, content: Optional[str] = None, **kwargs):
         """
         :keyword encoded: Indicates if the blob name is encoded.
         :paramtype encoded: bool
         :keyword content: The name of the blob.
         :paramtype content: str
         """
-        super(BlobName, self).__init__(**kwargs)
-        self.encoded = kwargs.get('encoded', None)
-        self.content = kwargs.get('content', None)
+        super().__init__(**kwargs)
+        self.encoded = encoded
+        self.content = content
 
 
-class BlobPrefix(msrest.serialization.Model):
+class BlobPrefix(_serialization.Model):
     """BlobPrefix.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: ~azure.storage.blob.models.BlobName
     """
 
     _validation = {
-        'name': {'required': True},
+        "name": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'BlobName'},
+        "name": {"key": "Name", "type": "BlobName"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, name: "_models.BlobName", **kwargs):
         """
         :keyword name: Required.
         :paramtype name: ~azure.storage.blob.models.BlobName
         """
-        super(BlobPrefix, self).__init__(**kwargs)
-        self.name = kwargs['name']
+        super().__init__(**kwargs)
+        self.name = name
 
 
-class BlobPropertiesInternal(msrest.serialization.Model):
+class BlobPropertiesInternal(_serialization.Model):  # pylint: disable=too-many-instance-attributes
     """Properties of a blob.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar creation_time:
     :vartype creation_time: ~datetime.datetime
     :ivar last_modified: Required.
     :vartype last_modified: ~datetime.datetime
     :ivar etag: Required.
     :vartype etag: str
     :ivar content_length: Size in bytes.
-    :vartype content_length: long
+    :vartype content_length: int
     :ivar content_type:
     :vartype content_type: str
     :ivar content_encoding:
     :vartype content_encoding: str
     :ivar content_language:
     :vartype content_language: str
     :ivar content_md5:
-    :vartype content_md5: bytearray
+    :vartype content_md5: bytes
     :ivar content_disposition:
     :vartype content_disposition: str
     :ivar cache_control:
     :vartype cache_control: str
     :ivar blob_sequence_number:
-    :vartype blob_sequence_number: long
-    :ivar blob_type: Possible values include: "BlockBlob", "PageBlob", "AppendBlob".
+    :vartype blob_sequence_number: int
+    :ivar blob_type: Known values are: "BlockBlob", "PageBlob", and "AppendBlob".
     :vartype blob_type: str or ~azure.storage.blob.models.BlobType
-    :ivar lease_status: Possible values include: "locked", "unlocked".
+    :ivar lease_status: Known values are: "locked" and "unlocked".
     :vartype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-    :ivar lease_state: Possible values include: "available", "leased", "expired", "breaking",
+    :ivar lease_state: Known values are: "available", "leased", "expired", "breaking", and
      "broken".
     :vartype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-    :ivar lease_duration: Possible values include: "infinite", "fixed".
+    :ivar lease_duration: Known values are: "infinite" and "fixed".
     :vartype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
     :ivar copy_id:
     :vartype copy_id: str
-    :ivar copy_status: Possible values include: "pending", "success", "aborted", "failed".
+    :ivar copy_status: Known values are: "pending", "success", "aborted", and "failed".
     :vartype copy_status: str or ~azure.storage.blob.models.CopyStatusType
     :ivar copy_source:
     :vartype copy_source: str
     :ivar copy_progress:
     :vartype copy_progress: str
     :ivar copy_completion_time:
     :vartype copy_completion_time: ~datetime.datetime
@@ -536,20 +550,20 @@
     :vartype incremental_copy: bool
     :ivar destination_snapshot:
     :vartype destination_snapshot: str
     :ivar deleted_time:
     :vartype deleted_time: ~datetime.datetime
     :ivar remaining_retention_days:
     :vartype remaining_retention_days: int
-    :ivar access_tier: Possible values include: "P4", "P6", "P10", "P15", "P20", "P30", "P40",
-     "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive".
+    :ivar access_tier: Known values are: "P4", "P6", "P10", "P15", "P20", "P30", "P40", "P50",
+     "P60", "P70", "P80", "Hot", "Cool", "Archive", and "Premium".
     :vartype access_tier: str or ~azure.storage.blob.models.AccessTier
     :ivar access_tier_inferred:
     :vartype access_tier_inferred: bool
-    :ivar archive_status: Possible values include: "rehydrate-pending-to-hot",
+    :ivar archive_status: Known values are: "rehydrate-pending-to-hot" and
      "rehydrate-pending-to-cool".
     :vartype archive_status: str or ~azure.storage.blob.models.ArchiveStatus
     :ivar customer_provided_key_sha256:
     :vartype customer_provided_key_sha256: str
     :ivar encryption_scope: The name of the encryption scope under which the blob is encrypted.
     :vartype encryption_scope: str
     :ivar access_tier_change_time:
@@ -557,117 +571,156 @@
     :ivar tag_count:
     :vartype tag_count: int
     :ivar expires_on:
     :vartype expires_on: ~datetime.datetime
     :ivar is_sealed:
     :vartype is_sealed: bool
     :ivar rehydrate_priority: If an object is in rehydrate pending state then this header is
-     returned with priority of rehydrate. Valid values are High and Standard. Possible values
-     include: "High", "Standard".
+     returned with priority of rehydrate. Valid values are High and Standard. Known values are:
+     "High" and "Standard".
     :vartype rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
     :ivar last_accessed_on:
     :vartype last_accessed_on: ~datetime.datetime
     :ivar immutability_policy_expires_on:
     :vartype immutability_policy_expires_on: ~datetime.datetime
-    :ivar immutability_policy_mode: Possible values include: "Mutable", "Unlocked", "Locked".
+    :ivar immutability_policy_mode: Known values are: "Mutable", "Unlocked", and "Locked".
     :vartype immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
     :ivar legal_hold:
     :vartype legal_hold: bool
     """
 
     _validation = {
-        'last_modified': {'required': True},
-        'etag': {'required': True},
+        "last_modified": {"required": True},
+        "etag": {"required": True},
     }
 
     _attribute_map = {
-        'creation_time': {'key': 'Creation-Time', 'type': 'rfc-1123'},
-        'last_modified': {'key': 'Last-Modified', 'type': 'rfc-1123'},
-        'etag': {'key': 'Etag', 'type': 'str'},
-        'content_length': {'key': 'Content-Length', 'type': 'long'},
-        'content_type': {'key': 'Content-Type', 'type': 'str'},
-        'content_encoding': {'key': 'Content-Encoding', 'type': 'str'},
-        'content_language': {'key': 'Content-Language', 'type': 'str'},
-        'content_md5': {'key': 'Content-MD5', 'type': 'bytearray'},
-        'content_disposition': {'key': 'Content-Disposition', 'type': 'str'},
-        'cache_control': {'key': 'Cache-Control', 'type': 'str'},
-        'blob_sequence_number': {'key': 'x-ms-blob-sequence-number', 'type': 'long'},
-        'blob_type': {'key': 'BlobType', 'type': 'str'},
-        'lease_status': {'key': 'LeaseStatus', 'type': 'str'},
-        'lease_state': {'key': 'LeaseState', 'type': 'str'},
-        'lease_duration': {'key': 'LeaseDuration', 'type': 'str'},
-        'copy_id': {'key': 'CopyId', 'type': 'str'},
-        'copy_status': {'key': 'CopyStatus', 'type': 'str'},
-        'copy_source': {'key': 'CopySource', 'type': 'str'},
-        'copy_progress': {'key': 'CopyProgress', 'type': 'str'},
-        'copy_completion_time': {'key': 'CopyCompletionTime', 'type': 'rfc-1123'},
-        'copy_status_description': {'key': 'CopyStatusDescription', 'type': 'str'},
-        'server_encrypted': {'key': 'ServerEncrypted', 'type': 'bool'},
-        'incremental_copy': {'key': 'IncrementalCopy', 'type': 'bool'},
-        'destination_snapshot': {'key': 'DestinationSnapshot', 'type': 'str'},
-        'deleted_time': {'key': 'DeletedTime', 'type': 'rfc-1123'},
-        'remaining_retention_days': {'key': 'RemainingRetentionDays', 'type': 'int'},
-        'access_tier': {'key': 'AccessTier', 'type': 'str'},
-        'access_tier_inferred': {'key': 'AccessTierInferred', 'type': 'bool'},
-        'archive_status': {'key': 'ArchiveStatus', 'type': 'str'},
-        'customer_provided_key_sha256': {'key': 'CustomerProvidedKeySha256', 'type': 'str'},
-        'encryption_scope': {'key': 'EncryptionScope', 'type': 'str'},
-        'access_tier_change_time': {'key': 'AccessTierChangeTime', 'type': 'rfc-1123'},
-        'tag_count': {'key': 'TagCount', 'type': 'int'},
-        'expires_on': {'key': 'Expiry-Time', 'type': 'rfc-1123'},
-        'is_sealed': {'key': 'Sealed', 'type': 'bool'},
-        'rehydrate_priority': {'key': 'RehydratePriority', 'type': 'str'},
-        'last_accessed_on': {'key': 'LastAccessTime', 'type': 'rfc-1123'},
-        'immutability_policy_expires_on': {'key': 'ImmutabilityPolicyUntilDate', 'type': 'rfc-1123'},
-        'immutability_policy_mode': {'key': 'ImmutabilityPolicyMode', 'type': 'str'},
-        'legal_hold': {'key': 'LegalHold', 'type': 'bool'},
-    }
-    _xml_map = {
-        'name': 'Properties'
-    }
-
-    def __init__(
-        self,
+        "creation_time": {"key": "Creation-Time", "type": "rfc-1123"},
+        "last_modified": {"key": "Last-Modified", "type": "rfc-1123"},
+        "etag": {"key": "Etag", "type": "str"},
+        "content_length": {"key": "Content-Length", "type": "int"},
+        "content_type": {"key": "Content-Type", "type": "str"},
+        "content_encoding": {"key": "Content-Encoding", "type": "str"},
+        "content_language": {"key": "Content-Language", "type": "str"},
+        "content_md5": {"key": "Content-MD5", "type": "bytearray"},
+        "content_disposition": {"key": "Content-Disposition", "type": "str"},
+        "cache_control": {"key": "Cache-Control", "type": "str"},
+        "blob_sequence_number": {"key": "x-ms-blob-sequence-number", "type": "int"},
+        "blob_type": {"key": "BlobType", "type": "str"},
+        "lease_status": {"key": "LeaseStatus", "type": "str"},
+        "lease_state": {"key": "LeaseState", "type": "str"},
+        "lease_duration": {"key": "LeaseDuration", "type": "str"},
+        "copy_id": {"key": "CopyId", "type": "str"},
+        "copy_status": {"key": "CopyStatus", "type": "str"},
+        "copy_source": {"key": "CopySource", "type": "str"},
+        "copy_progress": {"key": "CopyProgress", "type": "str"},
+        "copy_completion_time": {"key": "CopyCompletionTime", "type": "rfc-1123"},
+        "copy_status_description": {"key": "CopyStatusDescription", "type": "str"},
+        "server_encrypted": {"key": "ServerEncrypted", "type": "bool"},
+        "incremental_copy": {"key": "IncrementalCopy", "type": "bool"},
+        "destination_snapshot": {"key": "DestinationSnapshot", "type": "str"},
+        "deleted_time": {"key": "DeletedTime", "type": "rfc-1123"},
+        "remaining_retention_days": {"key": "RemainingRetentionDays", "type": "int"},
+        "access_tier": {"key": "AccessTier", "type": "str"},
+        "access_tier_inferred": {"key": "AccessTierInferred", "type": "bool"},
+        "archive_status": {"key": "ArchiveStatus", "type": "str"},
+        "customer_provided_key_sha256": {"key": "CustomerProvidedKeySha256", "type": "str"},
+        "encryption_scope": {"key": "EncryptionScope", "type": "str"},
+        "access_tier_change_time": {"key": "AccessTierChangeTime", "type": "rfc-1123"},
+        "tag_count": {"key": "TagCount", "type": "int"},
+        "expires_on": {"key": "Expiry-Time", "type": "rfc-1123"},
+        "is_sealed": {"key": "Sealed", "type": "bool"},
+        "rehydrate_priority": {"key": "RehydratePriority", "type": "str"},
+        "last_accessed_on": {"key": "LastAccessTime", "type": "rfc-1123"},
+        "immutability_policy_expires_on": {"key": "ImmutabilityPolicyUntilDate", "type": "rfc-1123"},
+        "immutability_policy_mode": {"key": "ImmutabilityPolicyMode", "type": "str"},
+        "legal_hold": {"key": "LegalHold", "type": "bool"},
+    }
+    _xml_map = {"name": "Properties"}
+
+    def __init__(  # pylint: disable=too-many-locals
+        self,
+        *,
+        last_modified: datetime.datetime,
+        etag: str,
+        creation_time: Optional[datetime.datetime] = None,
+        content_length: Optional[int] = None,
+        content_type: Optional[str] = None,
+        content_encoding: Optional[str] = None,
+        content_language: Optional[str] = None,
+        content_md5: Optional[bytes] = None,
+        content_disposition: Optional[str] = None,
+        cache_control: Optional[str] = None,
+        blob_sequence_number: Optional[int] = None,
+        blob_type: Optional[Union[str, "_models.BlobType"]] = None,
+        lease_status: Optional[Union[str, "_models.LeaseStatusType"]] = None,
+        lease_state: Optional[Union[str, "_models.LeaseStateType"]] = None,
+        lease_duration: Optional[Union[str, "_models.LeaseDurationType"]] = None,
+        copy_id: Optional[str] = None,
+        copy_status: Optional[Union[str, "_models.CopyStatusType"]] = None,
+        copy_source: Optional[str] = None,
+        copy_progress: Optional[str] = None,
+        copy_completion_time: Optional[datetime.datetime] = None,
+        copy_status_description: Optional[str] = None,
+        server_encrypted: Optional[bool] = None,
+        incremental_copy: Optional[bool] = None,
+        destination_snapshot: Optional[str] = None,
+        deleted_time: Optional[datetime.datetime] = None,
+        remaining_retention_days: Optional[int] = None,
+        access_tier: Optional[Union[str, "_models.AccessTier"]] = None,
+        access_tier_inferred: Optional[bool] = None,
+        archive_status: Optional[Union[str, "_models.ArchiveStatus"]] = None,
+        customer_provided_key_sha256: Optional[str] = None,
+        encryption_scope: Optional[str] = None,
+        access_tier_change_time: Optional[datetime.datetime] = None,
+        tag_count: Optional[int] = None,
+        expires_on: Optional[datetime.datetime] = None,
+        is_sealed: Optional[bool] = None,
+        rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
+        last_accessed_on: Optional[datetime.datetime] = None,
+        immutability_policy_expires_on: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        legal_hold: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword creation_time:
         :paramtype creation_time: ~datetime.datetime
         :keyword last_modified: Required.
         :paramtype last_modified: ~datetime.datetime
         :keyword etag: Required.
         :paramtype etag: str
         :keyword content_length: Size in bytes.
-        :paramtype content_length: long
+        :paramtype content_length: int
         :keyword content_type:
         :paramtype content_type: str
         :keyword content_encoding:
         :paramtype content_encoding: str
         :keyword content_language:
         :paramtype content_language: str
         :keyword content_md5:
-        :paramtype content_md5: bytearray
+        :paramtype content_md5: bytes
         :keyword content_disposition:
         :paramtype content_disposition: str
         :keyword cache_control:
         :paramtype cache_control: str
         :keyword blob_sequence_number:
-        :paramtype blob_sequence_number: long
-        :keyword blob_type: Possible values include: "BlockBlob", "PageBlob", "AppendBlob".
+        :paramtype blob_sequence_number: int
+        :keyword blob_type: Known values are: "BlockBlob", "PageBlob", and "AppendBlob".
         :paramtype blob_type: str or ~azure.storage.blob.models.BlobType
-        :keyword lease_status: Possible values include: "locked", "unlocked".
+        :keyword lease_status: Known values are: "locked" and "unlocked".
         :paramtype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-        :keyword lease_state: Possible values include: "available", "leased", "expired", "breaking",
+        :keyword lease_state: Known values are: "available", "leased", "expired", "breaking", and
          "broken".
         :paramtype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-        :keyword lease_duration: Possible values include: "infinite", "fixed".
+        :keyword lease_duration: Known values are: "infinite" and "fixed".
         :paramtype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
         :keyword copy_id:
         :paramtype copy_id: str
-        :keyword copy_status: Possible values include: "pending", "success", "aborted", "failed".
+        :keyword copy_status: Known values are: "pending", "success", "aborted", and "failed".
         :paramtype copy_status: str or ~azure.storage.blob.models.CopyStatusType
         :keyword copy_source:
         :paramtype copy_source: str
         :keyword copy_progress:
         :paramtype copy_progress: str
         :keyword copy_completion_time:
         :paramtype copy_completion_time: ~datetime.datetime
@@ -679,20 +732,20 @@
         :paramtype incremental_copy: bool
         :keyword destination_snapshot:
         :paramtype destination_snapshot: str
         :keyword deleted_time:
         :paramtype deleted_time: ~datetime.datetime
         :keyword remaining_retention_days:
         :paramtype remaining_retention_days: int
-        :keyword access_tier: Possible values include: "P4", "P6", "P10", "P15", "P20", "P30", "P40",
-         "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive".
+        :keyword access_tier: Known values are: "P4", "P6", "P10", "P15", "P20", "P30", "P40", "P50",
+         "P60", "P70", "P80", "Hot", "Cool", "Archive", and "Premium".
         :paramtype access_tier: str or ~azure.storage.blob.models.AccessTier
         :keyword access_tier_inferred:
         :paramtype access_tier_inferred: bool
-        :keyword archive_status: Possible values include: "rehydrate-pending-to-hot",
+        :keyword archive_status: Known values are: "rehydrate-pending-to-hot" and
          "rehydrate-pending-to-cool".
         :paramtype archive_status: str or ~azure.storage.blob.models.ArchiveStatus
         :keyword customer_provided_key_sha256:
         :paramtype customer_provided_key_sha256: str
         :keyword encryption_scope: The name of the encryption scope under which the blob is encrypted.
         :paramtype encryption_scope: str
         :keyword access_tier_change_time:
@@ -700,392 +753,390 @@
         :keyword tag_count:
         :paramtype tag_count: int
         :keyword expires_on:
         :paramtype expires_on: ~datetime.datetime
         :keyword is_sealed:
         :paramtype is_sealed: bool
         :keyword rehydrate_priority: If an object is in rehydrate pending state then this header is
-         returned with priority of rehydrate. Valid values are High and Standard. Possible values
-         include: "High", "Standard".
+         returned with priority of rehydrate. Valid values are High and Standard. Known values are:
+         "High" and "Standard".
         :paramtype rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :keyword last_accessed_on:
         :paramtype last_accessed_on: ~datetime.datetime
         :keyword immutability_policy_expires_on:
         :paramtype immutability_policy_expires_on: ~datetime.datetime
-        :keyword immutability_policy_mode: Possible values include: "Mutable", "Unlocked", "Locked".
+        :keyword immutability_policy_mode: Known values are: "Mutable", "Unlocked", and "Locked".
         :paramtype immutability_policy_mode: str or
          ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :keyword legal_hold:
         :paramtype legal_hold: bool
         """
-        super(BlobPropertiesInternal, self).__init__(**kwargs)
-        self.creation_time = kwargs.get('creation_time', None)
-        self.last_modified = kwargs['last_modified']
-        self.etag = kwargs['etag']
-        self.content_length = kwargs.get('content_length', None)
-        self.content_type = kwargs.get('content_type', None)
-        self.content_encoding = kwargs.get('content_encoding', None)
-        self.content_language = kwargs.get('content_language', None)
-        self.content_md5 = kwargs.get('content_md5', None)
-        self.content_disposition = kwargs.get('content_disposition', None)
-        self.cache_control = kwargs.get('cache_control', None)
-        self.blob_sequence_number = kwargs.get('blob_sequence_number', None)
-        self.blob_type = kwargs.get('blob_type', None)
-        self.lease_status = kwargs.get('lease_status', None)
-        self.lease_state = kwargs.get('lease_state', None)
-        self.lease_duration = kwargs.get('lease_duration', None)
-        self.copy_id = kwargs.get('copy_id', None)
-        self.copy_status = kwargs.get('copy_status', None)
-        self.copy_source = kwargs.get('copy_source', None)
-        self.copy_progress = kwargs.get('copy_progress', None)
-        self.copy_completion_time = kwargs.get('copy_completion_time', None)
-        self.copy_status_description = kwargs.get('copy_status_description', None)
-        self.server_encrypted = kwargs.get('server_encrypted', None)
-        self.incremental_copy = kwargs.get('incremental_copy', None)
-        self.destination_snapshot = kwargs.get('destination_snapshot', None)
-        self.deleted_time = kwargs.get('deleted_time', None)
-        self.remaining_retention_days = kwargs.get('remaining_retention_days', None)
-        self.access_tier = kwargs.get('access_tier', None)
-        self.access_tier_inferred = kwargs.get('access_tier_inferred', None)
-        self.archive_status = kwargs.get('archive_status', None)
-        self.customer_provided_key_sha256 = kwargs.get('customer_provided_key_sha256', None)
-        self.encryption_scope = kwargs.get('encryption_scope', None)
-        self.access_tier_change_time = kwargs.get('access_tier_change_time', None)
-        self.tag_count = kwargs.get('tag_count', None)
-        self.expires_on = kwargs.get('expires_on', None)
-        self.is_sealed = kwargs.get('is_sealed', None)
-        self.rehydrate_priority = kwargs.get('rehydrate_priority', None)
-        self.last_accessed_on = kwargs.get('last_accessed_on', None)
-        self.immutability_policy_expires_on = kwargs.get('immutability_policy_expires_on', None)
-        self.immutability_policy_mode = kwargs.get('immutability_policy_mode', None)
-        self.legal_hold = kwargs.get('legal_hold', None)
+        super().__init__(**kwargs)
+        self.creation_time = creation_time
+        self.last_modified = last_modified
+        self.etag = etag
+        self.content_length = content_length
+        self.content_type = content_type
+        self.content_encoding = content_encoding
+        self.content_language = content_language
+        self.content_md5 = content_md5
+        self.content_disposition = content_disposition
+        self.cache_control = cache_control
+        self.blob_sequence_number = blob_sequence_number
+        self.blob_type = blob_type
+        self.lease_status = lease_status
+        self.lease_state = lease_state
+        self.lease_duration = lease_duration
+        self.copy_id = copy_id
+        self.copy_status = copy_status
+        self.copy_source = copy_source
+        self.copy_progress = copy_progress
+        self.copy_completion_time = copy_completion_time
+        self.copy_status_description = copy_status_description
+        self.server_encrypted = server_encrypted
+        self.incremental_copy = incremental_copy
+        self.destination_snapshot = destination_snapshot
+        self.deleted_time = deleted_time
+        self.remaining_retention_days = remaining_retention_days
+        self.access_tier = access_tier
+        self.access_tier_inferred = access_tier_inferred
+        self.archive_status = archive_status
+        self.customer_provided_key_sha256 = customer_provided_key_sha256
+        self.encryption_scope = encryption_scope
+        self.access_tier_change_time = access_tier_change_time
+        self.tag_count = tag_count
+        self.expires_on = expires_on
+        self.is_sealed = is_sealed
+        self.rehydrate_priority = rehydrate_priority
+        self.last_accessed_on = last_accessed_on
+        self.immutability_policy_expires_on = immutability_policy_expires_on
+        self.immutability_policy_mode = immutability_policy_mode
+        self.legal_hold = legal_hold
 
 
-class BlobTag(msrest.serialization.Model):
+class BlobTag(_serialization.Model):
     """BlobTag.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar key: Required.
     :vartype key: str
     :ivar value: Required.
     :vartype value: str
     """
 
     _validation = {
-        'key': {'required': True},
-        'value': {'required': True},
+        "key": {"required": True},
+        "value": {"required": True},
     }
 
     _attribute_map = {
-        'key': {'key': 'Key', 'type': 'str'},
-        'value': {'key': 'Value', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'Tag'
+        "key": {"key": "Key", "type": "str"},
+        "value": {"key": "Value", "type": "str"},
     }
+    _xml_map = {"name": "Tag"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, key: str, value: str, **kwargs):
         """
         :keyword key: Required.
         :paramtype key: str
         :keyword value: Required.
         :paramtype value: str
         """
-        super(BlobTag, self).__init__(**kwargs)
-        self.key = kwargs['key']
-        self.value = kwargs['value']
+        super().__init__(**kwargs)
+        self.key = key
+        self.value = value
 
 
-class BlobTags(msrest.serialization.Model):
+class BlobTags(_serialization.Model):
     """Blob tags.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar blob_tag_set: Required.
     :vartype blob_tag_set: list[~azure.storage.blob.models.BlobTag]
     """
 
     _validation = {
-        'blob_tag_set': {'required': True},
+        "blob_tag_set": {"required": True},
     }
 
     _attribute_map = {
-        'blob_tag_set': {'key': 'BlobTagSet', 'type': '[BlobTag]', 'xml': {'name': 'TagSet', 'wrapped': True, 'itemsName': 'Tag'}},
-    }
-    _xml_map = {
-        'name': 'Tags'
+        "blob_tag_set": {
+            "key": "BlobTagSet",
+            "type": "[BlobTag]",
+            "xml": {"name": "TagSet", "wrapped": True, "itemsName": "Tag"},
+        },
     }
+    _xml_map = {"name": "Tags"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, blob_tag_set: List["_models.BlobTag"], **kwargs):
         """
         :keyword blob_tag_set: Required.
         :paramtype blob_tag_set: list[~azure.storage.blob.models.BlobTag]
         """
-        super(BlobTags, self).__init__(**kwargs)
-        self.blob_tag_set = kwargs['blob_tag_set']
+        super().__init__(**kwargs)
+        self.blob_tag_set = blob_tag_set
 
 
-class Block(msrest.serialization.Model):
+class Block(_serialization.Model):
     """Represents a single block in a block blob.  It describes the block's ID and size.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar name: Required. The base64 encoded block ID.
+    :ivar name: The base64 encoded block ID. Required.
     :vartype name: str
-    :ivar size: Required. The block size in bytes.
-    :vartype size: long
+    :ivar size: The block size in bytes. Required.
+    :vartype size: int
     """
 
     _validation = {
-        'name': {'required': True},
-        'size': {'required': True},
+        "name": {"required": True},
+        "size": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'str'},
-        'size': {'key': 'Size', 'type': 'long'},
+        "name": {"key": "Name", "type": "str"},
+        "size": {"key": "Size", "type": "int"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, name: str, size: int, **kwargs):
         """
-        :keyword name: Required. The base64 encoded block ID.
+        :keyword name: The base64 encoded block ID. Required.
         :paramtype name: str
-        :keyword size: Required. The block size in bytes.
-        :paramtype size: long
+        :keyword size: The block size in bytes. Required.
+        :paramtype size: int
         """
-        super(Block, self).__init__(**kwargs)
-        self.name = kwargs['name']
-        self.size = kwargs['size']
+        super().__init__(**kwargs)
+        self.name = name
+        self.size = size
 
 
-class BlockList(msrest.serialization.Model):
+class BlockList(_serialization.Model):
     """BlockList.
 
     :ivar committed_blocks:
     :vartype committed_blocks: list[~azure.storage.blob.models.Block]
     :ivar uncommitted_blocks:
     :vartype uncommitted_blocks: list[~azure.storage.blob.models.Block]
     """
 
     _attribute_map = {
-        'committed_blocks': {'key': 'CommittedBlocks', 'type': '[Block]', 'xml': {'wrapped': True}},
-        'uncommitted_blocks': {'key': 'UncommittedBlocks', 'type': '[Block]', 'xml': {'wrapped': True}},
+        "committed_blocks": {"key": "CommittedBlocks", "type": "[Block]", "xml": {"wrapped": True}},
+        "uncommitted_blocks": {"key": "UncommittedBlocks", "type": "[Block]", "xml": {"wrapped": True}},
     }
 
     def __init__(
         self,
+        *,
+        committed_blocks: Optional[List["_models.Block"]] = None,
+        uncommitted_blocks: Optional[List["_models.Block"]] = None,
         **kwargs
     ):
         """
         :keyword committed_blocks:
         :paramtype committed_blocks: list[~azure.storage.blob.models.Block]
         :keyword uncommitted_blocks:
         :paramtype uncommitted_blocks: list[~azure.storage.blob.models.Block]
         """
-        super(BlockList, self).__init__(**kwargs)
-        self.committed_blocks = kwargs.get('committed_blocks', None)
-        self.uncommitted_blocks = kwargs.get('uncommitted_blocks', None)
+        super().__init__(**kwargs)
+        self.committed_blocks = committed_blocks
+        self.uncommitted_blocks = uncommitted_blocks
 
 
-class BlockLookupList(msrest.serialization.Model):
+class BlockLookupList(_serialization.Model):
     """BlockLookupList.
 
     :ivar committed:
     :vartype committed: list[str]
     :ivar uncommitted:
     :vartype uncommitted: list[str]
     :ivar latest:
     :vartype latest: list[str]
     """
 
     _attribute_map = {
-        'committed': {'key': 'Committed', 'type': '[str]', 'xml': {'itemsName': 'Committed'}},
-        'uncommitted': {'key': 'Uncommitted', 'type': '[str]', 'xml': {'itemsName': 'Uncommitted'}},
-        'latest': {'key': 'Latest', 'type': '[str]', 'xml': {'itemsName': 'Latest'}},
-    }
-    _xml_map = {
-        'name': 'BlockList'
+        "committed": {"key": "Committed", "type": "[str]", "xml": {"itemsName": "Committed"}},
+        "uncommitted": {"key": "Uncommitted", "type": "[str]", "xml": {"itemsName": "Uncommitted"}},
+        "latest": {"key": "Latest", "type": "[str]", "xml": {"itemsName": "Latest"}},
     }
+    _xml_map = {"name": "BlockList"}
 
     def __init__(
         self,
+        *,
+        committed: Optional[List[str]] = None,
+        uncommitted: Optional[List[str]] = None,
+        latest: Optional[List[str]] = None,
         **kwargs
     ):
         """
         :keyword committed:
         :paramtype committed: list[str]
         :keyword uncommitted:
         :paramtype uncommitted: list[str]
         :keyword latest:
         :paramtype latest: list[str]
         """
-        super(BlockLookupList, self).__init__(**kwargs)
-        self.committed = kwargs.get('committed', None)
-        self.uncommitted = kwargs.get('uncommitted', None)
-        self.latest = kwargs.get('latest', None)
+        super().__init__(**kwargs)
+        self.committed = committed
+        self.uncommitted = uncommitted
+        self.latest = latest
 
 
-class ClearRange(msrest.serialization.Model):
+class ClearRange(_serialization.Model):
     """ClearRange.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar start: Required.
-    :vartype start: long
+    :vartype start: int
     :ivar end: Required.
-    :vartype end: long
+    :vartype end: int
     """
 
     _validation = {
-        'start': {'required': True},
-        'end': {'required': True},
+        "start": {"required": True},
+        "end": {"required": True},
     }
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'long', 'xml': {'name': 'Start'}},
-        'end': {'key': 'End', 'type': 'long', 'xml': {'name': 'End'}},
-    }
-    _xml_map = {
-        'name': 'ClearRange'
+        "start": {"key": "Start", "type": "int", "xml": {"name": "Start"}},
+        "end": {"key": "End", "type": "int", "xml": {"name": "End"}},
     }
+    _xml_map = {"name": "ClearRange"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, start: int, end: int, **kwargs):
         """
         :keyword start: Required.
-        :paramtype start: long
+        :paramtype start: int
         :keyword end: Required.
-        :paramtype end: long
+        :paramtype end: int
         """
-        super(ClearRange, self).__init__(**kwargs)
-        self.start = kwargs['start']
-        self.end = kwargs['end']
+        super().__init__(**kwargs)
+        self.start = start
+        self.end = end
 
 
-class ContainerCpkScopeInfo(msrest.serialization.Model):
+class ContainerCpkScopeInfo(_serialization.Model):
     """Parameter group.
 
     :ivar default_encryption_scope: Optional.  Version 2019-07-07 and later.  Specifies the default
      encryption scope to set on the container and use for all future writes.
     :vartype default_encryption_scope: str
     :ivar prevent_encryption_scope_override: Optional.  Version 2019-07-07 and newer.  If true,
      prevents any request from specifying a different encryption scope than the scope set on the
      container.
     :vartype prevent_encryption_scope_override: bool
     """
 
     _attribute_map = {
-        'default_encryption_scope': {'key': 'DefaultEncryptionScope', 'type': 'str'},
-        'prevent_encryption_scope_override': {'key': 'PreventEncryptionScopeOverride', 'type': 'bool'},
+        "default_encryption_scope": {"key": "DefaultEncryptionScope", "type": "str"},
+        "prevent_encryption_scope_override": {"key": "PreventEncryptionScopeOverride", "type": "bool"},
     }
 
     def __init__(
         self,
+        *,
+        default_encryption_scope: Optional[str] = None,
+        prevent_encryption_scope_override: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword default_encryption_scope: Optional.  Version 2019-07-07 and later.  Specifies the
          default encryption scope to set on the container and use for all future writes.
         :paramtype default_encryption_scope: str
         :keyword prevent_encryption_scope_override: Optional.  Version 2019-07-07 and newer.  If true,
          prevents any request from specifying a different encryption scope than the scope set on the
          container.
         :paramtype prevent_encryption_scope_override: bool
         """
-        super(ContainerCpkScopeInfo, self).__init__(**kwargs)
-        self.default_encryption_scope = kwargs.get('default_encryption_scope', None)
-        self.prevent_encryption_scope_override = kwargs.get('prevent_encryption_scope_override', None)
+        super().__init__(**kwargs)
+        self.default_encryption_scope = default_encryption_scope
+        self.prevent_encryption_scope_override = prevent_encryption_scope_override
 
 
-class ContainerItem(msrest.serialization.Model):
+class ContainerItem(_serialization.Model):
     """An Azure Storage container.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: str
     :ivar deleted:
     :vartype deleted: bool
     :ivar version:
     :vartype version: str
-    :ivar properties: Required. Properties of a container.
+    :ivar properties: Properties of a container. Required.
     :vartype properties: ~azure.storage.blob.models.ContainerProperties
     :ivar metadata: Dictionary of :code:`<string>`.
     :vartype metadata: dict[str, str]
     """
 
     _validation = {
-        'name': {'required': True},
-        'properties': {'required': True},
+        "name": {"required": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'str'},
-        'deleted': {'key': 'Deleted', 'type': 'bool'},
-        'version': {'key': 'Version', 'type': 'str'},
-        'properties': {'key': 'Properties', 'type': 'ContainerProperties'},
-        'metadata': {'key': 'Metadata', 'type': '{str}'},
-    }
-    _xml_map = {
-        'name': 'Container'
+        "name": {"key": "Name", "type": "str"},
+        "deleted": {"key": "Deleted", "type": "bool"},
+        "version": {"key": "Version", "type": "str"},
+        "properties": {"key": "Properties", "type": "ContainerProperties"},
+        "metadata": {"key": "Metadata", "type": "{str}"},
     }
+    _xml_map = {"name": "Container"}
 
     def __init__(
         self,
+        *,
+        name: str,
+        properties: "_models.ContainerProperties",
+        deleted: Optional[bool] = None,
+        version: Optional[str] = None,
+        metadata: Optional[Dict[str, str]] = None,
         **kwargs
     ):
         """
         :keyword name: Required.
         :paramtype name: str
         :keyword deleted:
         :paramtype deleted: bool
         :keyword version:
         :paramtype version: str
-        :keyword properties: Required. Properties of a container.
+        :keyword properties: Properties of a container. Required.
         :paramtype properties: ~azure.storage.blob.models.ContainerProperties
         :keyword metadata: Dictionary of :code:`<string>`.
         :paramtype metadata: dict[str, str]
         """
-        super(ContainerItem, self).__init__(**kwargs)
-        self.name = kwargs['name']
-        self.deleted = kwargs.get('deleted', None)
-        self.version = kwargs.get('version', None)
-        self.properties = kwargs['properties']
-        self.metadata = kwargs.get('metadata', None)
+        super().__init__(**kwargs)
+        self.name = name
+        self.deleted = deleted
+        self.version = version
+        self.properties = properties
+        self.metadata = metadata
 
 
-class ContainerProperties(msrest.serialization.Model):
+class ContainerProperties(_serialization.Model):  # pylint: disable=too-many-instance-attributes
     """Properties of a container.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar last_modified: Required.
     :vartype last_modified: ~datetime.datetime
     :ivar etag: Required.
     :vartype etag: str
-    :ivar lease_status: Possible values include: "locked", "unlocked".
+    :ivar lease_status: Known values are: "locked" and "unlocked".
     :vartype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-    :ivar lease_state: Possible values include: "available", "leased", "expired", "breaking",
+    :ivar lease_state: Known values are: "available", "leased", "expired", "breaking", and
      "broken".
     :vartype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-    :ivar lease_duration: Possible values include: "infinite", "fixed".
+    :ivar lease_duration: Known values are: "infinite" and "fixed".
     :vartype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
-    :ivar public_access: Possible values include: "container", "blob".
+    :ivar public_access: Known values are: "container" and "blob".
     :vartype public_access: str or ~azure.storage.blob.models.PublicAccessType
     :ivar has_immutability_policy:
     :vartype has_immutability_policy: bool
     :ivar has_legal_hold:
     :vartype has_legal_hold: bool
     :ivar default_encryption_scope:
     :vartype default_encryption_scope: str
@@ -1097,51 +1148,68 @@
     :vartype remaining_retention_days: int
     :ivar is_immutable_storage_with_versioning_enabled: Indicates if version level worm is enabled
      on this container.
     :vartype is_immutable_storage_with_versioning_enabled: bool
     """
 
     _validation = {
-        'last_modified': {'required': True},
-        'etag': {'required': True},
+        "last_modified": {"required": True},
+        "etag": {"required": True},
     }
 
     _attribute_map = {
-        'last_modified': {'key': 'Last-Modified', 'type': 'rfc-1123'},
-        'etag': {'key': 'Etag', 'type': 'str'},
-        'lease_status': {'key': 'LeaseStatus', 'type': 'str'},
-        'lease_state': {'key': 'LeaseState', 'type': 'str'},
-        'lease_duration': {'key': 'LeaseDuration', 'type': 'str'},
-        'public_access': {'key': 'PublicAccess', 'type': 'str'},
-        'has_immutability_policy': {'key': 'HasImmutabilityPolicy', 'type': 'bool'},
-        'has_legal_hold': {'key': 'HasLegalHold', 'type': 'bool'},
-        'default_encryption_scope': {'key': 'DefaultEncryptionScope', 'type': 'str'},
-        'prevent_encryption_scope_override': {'key': 'DenyEncryptionScopeOverride', 'type': 'bool'},
-        'deleted_time': {'key': 'DeletedTime', 'type': 'rfc-1123'},
-        'remaining_retention_days': {'key': 'RemainingRetentionDays', 'type': 'int'},
-        'is_immutable_storage_with_versioning_enabled': {'key': 'ImmutableStorageWithVersioningEnabled', 'type': 'bool'},
+        "last_modified": {"key": "Last-Modified", "type": "rfc-1123"},
+        "etag": {"key": "Etag", "type": "str"},
+        "lease_status": {"key": "LeaseStatus", "type": "str"},
+        "lease_state": {"key": "LeaseState", "type": "str"},
+        "lease_duration": {"key": "LeaseDuration", "type": "str"},
+        "public_access": {"key": "PublicAccess", "type": "str"},
+        "has_immutability_policy": {"key": "HasImmutabilityPolicy", "type": "bool"},
+        "has_legal_hold": {"key": "HasLegalHold", "type": "bool"},
+        "default_encryption_scope": {"key": "DefaultEncryptionScope", "type": "str"},
+        "prevent_encryption_scope_override": {"key": "DenyEncryptionScopeOverride", "type": "bool"},
+        "deleted_time": {"key": "DeletedTime", "type": "rfc-1123"},
+        "remaining_retention_days": {"key": "RemainingRetentionDays", "type": "int"},
+        "is_immutable_storage_with_versioning_enabled": {
+            "key": "ImmutableStorageWithVersioningEnabled",
+            "type": "bool",
+        },
     }
 
     def __init__(
         self,
+        *,
+        last_modified: datetime.datetime,
+        etag: str,
+        lease_status: Optional[Union[str, "_models.LeaseStatusType"]] = None,
+        lease_state: Optional[Union[str, "_models.LeaseStateType"]] = None,
+        lease_duration: Optional[Union[str, "_models.LeaseDurationType"]] = None,
+        public_access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+        has_immutability_policy: Optional[bool] = None,
+        has_legal_hold: Optional[bool] = None,
+        default_encryption_scope: Optional[str] = None,
+        prevent_encryption_scope_override: Optional[bool] = None,
+        deleted_time: Optional[datetime.datetime] = None,
+        remaining_retention_days: Optional[int] = None,
+        is_immutable_storage_with_versioning_enabled: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword last_modified: Required.
         :paramtype last_modified: ~datetime.datetime
         :keyword etag: Required.
         :paramtype etag: str
-        :keyword lease_status: Possible values include: "locked", "unlocked".
+        :keyword lease_status: Known values are: "locked" and "unlocked".
         :paramtype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-        :keyword lease_state: Possible values include: "available", "leased", "expired", "breaking",
+        :keyword lease_state: Known values are: "available", "leased", "expired", "breaking", and
          "broken".
         :paramtype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-        :keyword lease_duration: Possible values include: "infinite", "fixed".
+        :keyword lease_duration: Known values are: "infinite" and "fixed".
         :paramtype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
-        :keyword public_access: Possible values include: "container", "blob".
+        :keyword public_access: Known values are: "container" and "blob".
         :paramtype public_access: str or ~azure.storage.blob.models.PublicAccessType
         :keyword has_immutability_policy:
         :paramtype has_immutability_policy: bool
         :keyword has_legal_hold:
         :paramtype has_legal_hold: bool
         :keyword default_encryption_scope:
         :paramtype default_encryption_scope: str
@@ -1151,178 +1219,185 @@
         :paramtype deleted_time: ~datetime.datetime
         :keyword remaining_retention_days:
         :paramtype remaining_retention_days: int
         :keyword is_immutable_storage_with_versioning_enabled: Indicates if version level worm is
          enabled on this container.
         :paramtype is_immutable_storage_with_versioning_enabled: bool
         """
-        super(ContainerProperties, self).__init__(**kwargs)
-        self.last_modified = kwargs['last_modified']
-        self.etag = kwargs['etag']
-        self.lease_status = kwargs.get('lease_status', None)
-        self.lease_state = kwargs.get('lease_state', None)
-        self.lease_duration = kwargs.get('lease_duration', None)
-        self.public_access = kwargs.get('public_access', None)
-        self.has_immutability_policy = kwargs.get('has_immutability_policy', None)
-        self.has_legal_hold = kwargs.get('has_legal_hold', None)
-        self.default_encryption_scope = kwargs.get('default_encryption_scope', None)
-        self.prevent_encryption_scope_override = kwargs.get('prevent_encryption_scope_override', None)
-        self.deleted_time = kwargs.get('deleted_time', None)
-        self.remaining_retention_days = kwargs.get('remaining_retention_days', None)
-        self.is_immutable_storage_with_versioning_enabled = kwargs.get('is_immutable_storage_with_versioning_enabled', None)
+        super().__init__(**kwargs)
+        self.last_modified = last_modified
+        self.etag = etag
+        self.lease_status = lease_status
+        self.lease_state = lease_state
+        self.lease_duration = lease_duration
+        self.public_access = public_access
+        self.has_immutability_policy = has_immutability_policy
+        self.has_legal_hold = has_legal_hold
+        self.default_encryption_scope = default_encryption_scope
+        self.prevent_encryption_scope_override = prevent_encryption_scope_override
+        self.deleted_time = deleted_time
+        self.remaining_retention_days = remaining_retention_days
+        self.is_immutable_storage_with_versioning_enabled = is_immutable_storage_with_versioning_enabled
 
 
-class CorsRule(msrest.serialization.Model):
+class CorsRule(_serialization.Model):
     """CORS is an HTTP feature that enables a web application running under one domain to access resources in another domain. Web browsers implement a security restriction known as same-origin policy that prevents a web page from calling APIs in a different domain; CORS provides a secure way to allow one domain (the origin domain) to call APIs in another domain.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar allowed_origins: Required. The origin domains that are permitted to make a request
-     against the storage service via CORS. The origin domain is the domain from which the request
-     originates. Note that the origin must be an exact case-sensitive match with the origin that the
-     user age sends to the service. You can also use the wildcard character '*' to allow all origin
-     domains to make requests via CORS.
+    :ivar allowed_origins: The origin domains that are permitted to make a request against the
+     storage service via CORS. The origin domain is the domain from which the request originates.
+     Note that the origin must be an exact case-sensitive match with the origin that the user age
+     sends to the service. You can also use the wildcard character '*' to allow all origin domains
+     to make requests via CORS. Required.
     :vartype allowed_origins: str
-    :ivar allowed_methods: Required. The methods (HTTP request verbs) that the origin domain may
-     use for a CORS request. (comma separated).
+    :ivar allowed_methods: The methods (HTTP request verbs) that the origin domain may use for a
+     CORS request. (comma separated). Required.
     :vartype allowed_methods: str
-    :ivar allowed_headers: Required. the request headers that the origin domain may specify on the
-     CORS request.
+    :ivar allowed_headers: the request headers that the origin domain may specify on the CORS
+     request. Required.
     :vartype allowed_headers: str
-    :ivar exposed_headers: Required. The response headers that may be sent in the response to the
-     CORS request and exposed by the browser to the request issuer.
+    :ivar exposed_headers: The response headers that may be sent in the response to the CORS
+     request and exposed by the browser to the request issuer. Required.
     :vartype exposed_headers: str
-    :ivar max_age_in_seconds: Required. The maximum amount time that a browser should cache the
-     preflight OPTIONS request.
+    :ivar max_age_in_seconds: The maximum amount time that a browser should cache the preflight
+     OPTIONS request. Required.
     :vartype max_age_in_seconds: int
     """
 
     _validation = {
-        'allowed_origins': {'required': True},
-        'allowed_methods': {'required': True},
-        'allowed_headers': {'required': True},
-        'exposed_headers': {'required': True},
-        'max_age_in_seconds': {'required': True, 'minimum': 0},
+        "allowed_origins": {"required": True},
+        "allowed_methods": {"required": True},
+        "allowed_headers": {"required": True},
+        "exposed_headers": {"required": True},
+        "max_age_in_seconds": {"required": True, "minimum": 0},
     }
 
     _attribute_map = {
-        'allowed_origins': {'key': 'AllowedOrigins', 'type': 'str'},
-        'allowed_methods': {'key': 'AllowedMethods', 'type': 'str'},
-        'allowed_headers': {'key': 'AllowedHeaders', 'type': 'str'},
-        'exposed_headers': {'key': 'ExposedHeaders', 'type': 'str'},
-        'max_age_in_seconds': {'key': 'MaxAgeInSeconds', 'type': 'int'},
+        "allowed_origins": {"key": "AllowedOrigins", "type": "str"},
+        "allowed_methods": {"key": "AllowedMethods", "type": "str"},
+        "allowed_headers": {"key": "AllowedHeaders", "type": "str"},
+        "exposed_headers": {"key": "ExposedHeaders", "type": "str"},
+        "max_age_in_seconds": {"key": "MaxAgeInSeconds", "type": "int"},
     }
 
     def __init__(
         self,
+        *,
+        allowed_origins: str,
+        allowed_methods: str,
+        allowed_headers: str,
+        exposed_headers: str,
+        max_age_in_seconds: int,
         **kwargs
     ):
         """
-        :keyword allowed_origins: Required. The origin domains that are permitted to make a request
-         against the storage service via CORS. The origin domain is the domain from which the request
-         originates. Note that the origin must be an exact case-sensitive match with the origin that the
-         user age sends to the service. You can also use the wildcard character '*' to allow all origin
-         domains to make requests via CORS.
+        :keyword allowed_origins: The origin domains that are permitted to make a request against the
+         storage service via CORS. The origin domain is the domain from which the request originates.
+         Note that the origin must be an exact case-sensitive match with the origin that the user age
+         sends to the service. You can also use the wildcard character '*' to allow all origin domains
+         to make requests via CORS. Required.
         :paramtype allowed_origins: str
-        :keyword allowed_methods: Required. The methods (HTTP request verbs) that the origin domain may
-         use for a CORS request. (comma separated).
+        :keyword allowed_methods: The methods (HTTP request verbs) that the origin domain may use for a
+         CORS request. (comma separated). Required.
         :paramtype allowed_methods: str
-        :keyword allowed_headers: Required. the request headers that the origin domain may specify on
-         the CORS request.
+        :keyword allowed_headers: the request headers that the origin domain may specify on the CORS
+         request. Required.
         :paramtype allowed_headers: str
-        :keyword exposed_headers: Required. The response headers that may be sent in the response to
-         the CORS request and exposed by the browser to the request issuer.
+        :keyword exposed_headers: The response headers that may be sent in the response to the CORS
+         request and exposed by the browser to the request issuer. Required.
         :paramtype exposed_headers: str
-        :keyword max_age_in_seconds: Required. The maximum amount time that a browser should cache the
-         preflight OPTIONS request.
+        :keyword max_age_in_seconds: The maximum amount time that a browser should cache the preflight
+         OPTIONS request. Required.
         :paramtype max_age_in_seconds: int
         """
-        super(CorsRule, self).__init__(**kwargs)
-        self.allowed_origins = kwargs['allowed_origins']
-        self.allowed_methods = kwargs['allowed_methods']
-        self.allowed_headers = kwargs['allowed_headers']
-        self.exposed_headers = kwargs['exposed_headers']
-        self.max_age_in_seconds = kwargs['max_age_in_seconds']
+        super().__init__(**kwargs)
+        self.allowed_origins = allowed_origins
+        self.allowed_methods = allowed_methods
+        self.allowed_headers = allowed_headers
+        self.exposed_headers = exposed_headers
+        self.max_age_in_seconds = max_age_in_seconds
 
 
-class CpkInfo(msrest.serialization.Model):
+class CpkInfo(_serialization.Model):
     """Parameter group.
 
     :ivar encryption_key: Optional. Specifies the encryption key to use to encrypt the data
      provided in the request. If not specified, encryption is performed with the root account
      encryption key.  For more information, see Encryption at Rest for Azure Storage Services.
     :vartype encryption_key: str
     :ivar encryption_key_sha256: The SHA-256 hash of the provided encryption key. Must be provided
      if the x-ms-encryption-key header is provided.
     :vartype encryption_key_sha256: str
     :ivar encryption_algorithm: The algorithm used to produce the encryption key hash. Currently,
      the only accepted value is "AES256". Must be provided if the x-ms-encryption-key header is
-     provided. Possible values include: "None", "AES256".
+     provided. Known values are: "None" and "AES256".
     :vartype encryption_algorithm: str or ~azure.storage.blob.models.EncryptionAlgorithmType
     """
 
     _attribute_map = {
-        'encryption_key': {'key': 'encryptionKey', 'type': 'str'},
-        'encryption_key_sha256': {'key': 'encryptionKeySha256', 'type': 'str'},
-        'encryption_algorithm': {'key': 'encryptionAlgorithm', 'type': 'str'},
+        "encryption_key": {"key": "encryptionKey", "type": "str"},
+        "encryption_key_sha256": {"key": "encryptionKeySha256", "type": "str"},
+        "encryption_algorithm": {"key": "encryptionAlgorithm", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        encryption_key: Optional[str] = None,
+        encryption_key_sha256: Optional[str] = None,
+        encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
         **kwargs
     ):
         """
         :keyword encryption_key: Optional. Specifies the encryption key to use to encrypt the data
          provided in the request. If not specified, encryption is performed with the root account
          encryption key.  For more information, see Encryption at Rest for Azure Storage Services.
         :paramtype encryption_key: str
         :keyword encryption_key_sha256: The SHA-256 hash of the provided encryption key. Must be
          provided if the x-ms-encryption-key header is provided.
         :paramtype encryption_key_sha256: str
         :keyword encryption_algorithm: The algorithm used to produce the encryption key hash.
          Currently, the only accepted value is "AES256". Must be provided if the x-ms-encryption-key
-         header is provided. Possible values include: "None", "AES256".
+         header is provided. Known values are: "None" and "AES256".
         :paramtype encryption_algorithm: str or ~azure.storage.blob.models.EncryptionAlgorithmType
         """
-        super(CpkInfo, self).__init__(**kwargs)
-        self.encryption_key = kwargs.get('encryption_key', None)
-        self.encryption_key_sha256 = kwargs.get('encryption_key_sha256', None)
-        self.encryption_algorithm = kwargs.get('encryption_algorithm', None)
+        super().__init__(**kwargs)
+        self.encryption_key = encryption_key
+        self.encryption_key_sha256 = encryption_key_sha256
+        self.encryption_algorithm = encryption_algorithm
 
 
-class CpkScopeInfo(msrest.serialization.Model):
+class CpkScopeInfo(_serialization.Model):
     """Parameter group.
 
     :ivar encryption_scope: Optional. Version 2019-07-07 and later.  Specifies the name of the
      encryption scope to use to encrypt the data provided in the request. If not specified,
      encryption is performed with the default account encryption scope.  For more information, see
      Encryption at Rest for Azure Storage Services.
     :vartype encryption_scope: str
     """
 
     _attribute_map = {
-        'encryption_scope': {'key': 'encryptionScope', 'type': 'str'},
+        "encryption_scope": {"key": "encryptionScope", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, encryption_scope: Optional[str] = None, **kwargs):
         """
         :keyword encryption_scope: Optional. Version 2019-07-07 and later.  Specifies the name of the
          encryption scope to use to encrypt the data provided in the request. If not specified,
          encryption is performed with the default account encryption scope.  For more information, see
          Encryption at Rest for Azure Storage Services.
         :paramtype encryption_scope: str
         """
-        super(CpkScopeInfo, self).__init__(**kwargs)
-        self.encryption_scope = kwargs.get('encryption_scope', None)
+        super().__init__(**kwargs)
+        self.encryption_scope = encryption_scope
 
 
-class DelimitedTextConfiguration(msrest.serialization.Model):
+class DelimitedTextConfiguration(_serialization.Model):
     """Groups the settings used for interpreting the blob data if the blob is delimited text formatted.
 
     :ivar column_separator: The string used to separate columns.
     :vartype column_separator: str
     :ivar field_quote: The string used to quote a specific field.
     :vartype field_quote: str
     :ivar record_separator: The string used to separate records.
@@ -1330,94 +1405,114 @@
     :ivar escape_char: The string used as an escape character.
     :vartype escape_char: str
     :ivar headers_present: Represents whether the data has headers.
     :vartype headers_present: bool
     """
 
     _attribute_map = {
-        'column_separator': {'key': 'ColumnSeparator', 'type': 'str', 'xml': {'name': 'ColumnSeparator'}},
-        'field_quote': {'key': 'FieldQuote', 'type': 'str', 'xml': {'name': 'FieldQuote'}},
-        'record_separator': {'key': 'RecordSeparator', 'type': 'str', 'xml': {'name': 'RecordSeparator'}},
-        'escape_char': {'key': 'EscapeChar', 'type': 'str', 'xml': {'name': 'EscapeChar'}},
-        'headers_present': {'key': 'HeadersPresent', 'type': 'bool', 'xml': {'name': 'HasHeaders'}},
-    }
-    _xml_map = {
-        'name': 'DelimitedTextConfiguration'
-    }
+        "column_separator": {"key": "ColumnSeparator", "type": "str", "xml": {"name": "ColumnSeparator"}},
+        "field_quote": {"key": "FieldQuote", "type": "str", "xml": {"name": "FieldQuote"}},
+        "record_separator": {"key": "RecordSeparator", "type": "str", "xml": {"name": "RecordSeparator"}},
+        "escape_char": {"key": "EscapeChar", "type": "str", "xml": {"name": "EscapeChar"}},
+        "headers_present": {"key": "HeadersPresent", "type": "bool", "xml": {"name": "HasHeaders"}},
+    }
+    _xml_map = {"name": "DelimitedTextConfiguration"}
 
     def __init__(
         self,
+        *,
+        column_separator: Optional[str] = None,
+        field_quote: Optional[str] = None,
+        record_separator: Optional[str] = None,
+        escape_char: Optional[str] = None,
+        headers_present: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword column_separator: The string used to separate columns.
         :paramtype column_separator: str
         :keyword field_quote: The string used to quote a specific field.
         :paramtype field_quote: str
         :keyword record_separator: The string used to separate records.
         :paramtype record_separator: str
         :keyword escape_char: The string used as an escape character.
         :paramtype escape_char: str
         :keyword headers_present: Represents whether the data has headers.
         :paramtype headers_present: bool
         """
-        super(DelimitedTextConfiguration, self).__init__(**kwargs)
-        self.column_separator = kwargs.get('column_separator', None)
-        self.field_quote = kwargs.get('field_quote', None)
-        self.record_separator = kwargs.get('record_separator', None)
-        self.escape_char = kwargs.get('escape_char', None)
-        self.headers_present = kwargs.get('headers_present', None)
+        super().__init__(**kwargs)
+        self.column_separator = column_separator
+        self.field_quote = field_quote
+        self.record_separator = record_separator
+        self.escape_char = escape_char
+        self.headers_present = headers_present
 
 
-class FilterBlobItem(msrest.serialization.Model):
+class FilterBlobItem(_serialization.Model):
     """Blob info from a Filter Blobs API call.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: str
     :ivar container_name: Required.
     :vartype container_name: str
-    :ivar tags: A set of tags. Blob tags.
+    :ivar tags: Blob tags.
     :vartype tags: ~azure.storage.blob.models.BlobTags
+    :ivar version_id:
+    :vartype version_id: str
+    :ivar is_current_version:
+    :vartype is_current_version: bool
     """
 
     _validation = {
-        'name': {'required': True},
-        'container_name': {'required': True},
+        "name": {"required": True},
+        "container_name": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'str'},
-        'container_name': {'key': 'ContainerName', 'type': 'str'},
-        'tags': {'key': 'Tags', 'type': 'BlobTags'},
-    }
-    _xml_map = {
-        'name': 'Blob'
+        "name": {"key": "Name", "type": "str"},
+        "container_name": {"key": "ContainerName", "type": "str"},
+        "tags": {"key": "Tags", "type": "BlobTags"},
+        "version_id": {"key": "VersionId", "type": "str"},
+        "is_current_version": {"key": "IsCurrentVersion", "type": "bool"},
     }
+    _xml_map = {"name": "Blob"}
 
     def __init__(
         self,
+        *,
+        name: str,
+        container_name: str,
+        tags: Optional["_models.BlobTags"] = None,
+        version_id: Optional[str] = None,
+        is_current_version: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword name: Required.
         :paramtype name: str
         :keyword container_name: Required.
         :paramtype container_name: str
-        :keyword tags: A set of tags. Blob tags.
+        :keyword tags: Blob tags.
         :paramtype tags: ~azure.storage.blob.models.BlobTags
+        :keyword version_id:
+        :paramtype version_id: str
+        :keyword is_current_version:
+        :paramtype is_current_version: bool
         """
-        super(FilterBlobItem, self).__init__(**kwargs)
-        self.name = kwargs['name']
-        self.container_name = kwargs['container_name']
-        self.tags = kwargs.get('tags', None)
+        super().__init__(**kwargs)
+        self.name = name
+        self.container_name = container_name
+        self.tags = tags
+        self.version_id = version_id
+        self.is_current_version = is_current_version
 
 
-class FilterBlobSegment(msrest.serialization.Model):
+class FilterBlobSegment(_serialization.Model):
     """The result of a Filter Blobs API call.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar where: Required.
@@ -1425,180 +1520,175 @@
     :ivar blobs: Required.
     :vartype blobs: list[~azure.storage.blob.models.FilterBlobItem]
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'where': {'required': True},
-        'blobs': {'required': True},
+        "service_endpoint": {"required": True},
+        "where": {"required": True},
+        "blobs": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'where': {'key': 'Where', 'type': 'str'},
-        'blobs': {'key': 'Blobs', 'type': '[FilterBlobItem]', 'xml': {'name': 'Blobs', 'wrapped': True, 'itemsName': 'Blob'}},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "where": {"key": "Where", "type": "str"},
+        "blobs": {
+            "key": "Blobs",
+            "type": "[FilterBlobItem]",
+            "xml": {"name": "Blobs", "wrapped": True, "itemsName": "Blob"},
+        },
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
+        *,
+        service_endpoint: str,
+        where: str,
+        blobs: List["_models.FilterBlobItem"],
+        next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword service_endpoint: Required.
         :paramtype service_endpoint: str
         :keyword where: Required.
         :paramtype where: str
         :keyword blobs: Required.
         :paramtype blobs: list[~azure.storage.blob.models.FilterBlobItem]
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(FilterBlobSegment, self).__init__(**kwargs)
-        self.service_endpoint = kwargs['service_endpoint']
-        self.where = kwargs['where']
-        self.blobs = kwargs['blobs']
-        self.next_marker = kwargs.get('next_marker', None)
+        super().__init__(**kwargs)
+        self.service_endpoint = service_endpoint
+        self.where = where
+        self.blobs = blobs
+        self.next_marker = next_marker
 
 
-class GeoReplication(msrest.serialization.Model):
+class GeoReplication(_serialization.Model):
     """Geo-Replication information for the Secondary Storage Service.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar status: Required. The status of the secondary location. Possible values include: "live",
-     "bootstrap", "unavailable".
+    :ivar status: The status of the secondary location. Required. Known values are: "live",
+     "bootstrap", and "unavailable".
     :vartype status: str or ~azure.storage.blob.models.GeoReplicationStatusType
-    :ivar last_sync_time: Required. A GMT date/time value, to the second. All primary writes
-     preceding this value are guaranteed to be available for read operations at the secondary.
-     Primary writes after this point in time may or may not be available for reads.
+    :ivar last_sync_time: A GMT date/time value, to the second. All primary writes preceding this
+     value are guaranteed to be available for read operations at the secondary. Primary writes after
+     this point in time may or may not be available for reads. Required.
     :vartype last_sync_time: ~datetime.datetime
     """
 
     _validation = {
-        'status': {'required': True},
-        'last_sync_time': {'required': True},
+        "status": {"required": True},
+        "last_sync_time": {"required": True},
     }
 
     _attribute_map = {
-        'status': {'key': 'Status', 'type': 'str'},
-        'last_sync_time': {'key': 'LastSyncTime', 'type': 'rfc-1123'},
+        "status": {"key": "Status", "type": "str"},
+        "last_sync_time": {"key": "LastSyncTime", "type": "rfc-1123"},
     }
 
     def __init__(
-        self,
-        **kwargs
+        self, *, status: Union[str, "_models.GeoReplicationStatusType"], last_sync_time: datetime.datetime, **kwargs
     ):
         """
-        :keyword status: Required. The status of the secondary location. Possible values include:
-         "live", "bootstrap", "unavailable".
+        :keyword status: The status of the secondary location. Required. Known values are: "live",
+         "bootstrap", and "unavailable".
         :paramtype status: str or ~azure.storage.blob.models.GeoReplicationStatusType
-        :keyword last_sync_time: Required. A GMT date/time value, to the second. All primary writes
-         preceding this value are guaranteed to be available for read operations at the secondary.
-         Primary writes after this point in time may or may not be available for reads.
+        :keyword last_sync_time: A GMT date/time value, to the second. All primary writes preceding
+         this value are guaranteed to be available for read operations at the secondary. Primary writes
+         after this point in time may or may not be available for reads. Required.
         :paramtype last_sync_time: ~datetime.datetime
         """
-        super(GeoReplication, self).__init__(**kwargs)
-        self.status = kwargs['status']
-        self.last_sync_time = kwargs['last_sync_time']
+        super().__init__(**kwargs)
+        self.status = status
+        self.last_sync_time = last_sync_time
 
 
-class JsonTextConfiguration(msrest.serialization.Model):
+class JsonTextConfiguration(_serialization.Model):
     """json text configuration.
 
     :ivar record_separator: The string used to separate records.
     :vartype record_separator: str
     """
 
     _attribute_map = {
-        'record_separator': {'key': 'RecordSeparator', 'type': 'str', 'xml': {'name': 'RecordSeparator'}},
-    }
-    _xml_map = {
-        'name': 'JsonTextConfiguration'
+        "record_separator": {"key": "RecordSeparator", "type": "str", "xml": {"name": "RecordSeparator"}},
     }
+    _xml_map = {"name": "JsonTextConfiguration"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, record_separator: Optional[str] = None, **kwargs):
         """
         :keyword record_separator: The string used to separate records.
         :paramtype record_separator: str
         """
-        super(JsonTextConfiguration, self).__init__(**kwargs)
-        self.record_separator = kwargs.get('record_separator', None)
+        super().__init__(**kwargs)
+        self.record_separator = record_separator
 
 
-class KeyInfo(msrest.serialization.Model):
+class KeyInfo(_serialization.Model):
     """Key information.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar start: Required. The date-time the key is active in ISO 8601 UTC time.
+    :ivar start: The date-time the key is active in ISO 8601 UTC time. Required.
     :vartype start: str
-    :ivar expiry: Required. The date-time the key expires in ISO 8601 UTC time.
+    :ivar expiry: The date-time the key expires in ISO 8601 UTC time. Required.
     :vartype expiry: str
     """
 
     _validation = {
-        'start': {'required': True},
-        'expiry': {'required': True},
+        "start": {"required": True},
+        "expiry": {"required": True},
     }
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'str'},
-        'expiry': {'key': 'Expiry', 'type': 'str'},
+        "start": {"key": "Start", "type": "str"},
+        "expiry": {"key": "Expiry", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, start: str, expiry: str, **kwargs):
         """
-        :keyword start: Required. The date-time the key is active in ISO 8601 UTC time.
+        :keyword start: The date-time the key is active in ISO 8601 UTC time. Required.
         :paramtype start: str
-        :keyword expiry: Required. The date-time the key expires in ISO 8601 UTC time.
+        :keyword expiry: The date-time the key expires in ISO 8601 UTC time. Required.
         :paramtype expiry: str
         """
-        super(KeyInfo, self).__init__(**kwargs)
-        self.start = kwargs['start']
-        self.expiry = kwargs['expiry']
+        super().__init__(**kwargs)
+        self.start = start
+        self.expiry = expiry
 
 
-class LeaseAccessConditions(msrest.serialization.Model):
+class LeaseAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar lease_id: If specified, the operation only succeeds if the resource's lease is active and
      matches this ID.
     :vartype lease_id: str
     """
 
     _attribute_map = {
-        'lease_id': {'key': 'leaseId', 'type': 'str'},
+        "lease_id": {"key": "leaseId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, lease_id: Optional[str] = None, **kwargs):
         """
         :keyword lease_id: If specified, the operation only succeeds if the resource's lease is active
          and matches this ID.
         :paramtype lease_id: str
         """
-        super(LeaseAccessConditions, self).__init__(**kwargs)
-        self.lease_id = kwargs.get('lease_id', None)
+        super().__init__(**kwargs)
+        self.lease_id = lease_id
 
 
-class ListBlobsFlatSegmentResponse(msrest.serialization.Model):
+class ListBlobsFlatSegmentResponse(_serialization.Model):
     """An enumeration of blobs.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar container_name: Required.
@@ -1612,34 +1702,40 @@
     :ivar segment: Required.
     :vartype segment: ~azure.storage.blob.models.BlobFlatListSegment
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'container_name': {'required': True},
-        'segment': {'required': True},
+        "service_endpoint": {"required": True},
+        "container_name": {"required": True},
+        "segment": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'container_name': {'key': 'ContainerName', 'type': 'str', 'xml': {'attr': True}},
-        'prefix': {'key': 'Prefix', 'type': 'str'},
-        'marker': {'key': 'Marker', 'type': 'str'},
-        'max_results': {'key': 'MaxResults', 'type': 'int'},
-        'segment': {'key': 'Segment', 'type': 'BlobFlatListSegment'},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "container_name": {"key": "ContainerName", "type": "str", "xml": {"attr": True}},
+        "prefix": {"key": "Prefix", "type": "str"},
+        "marker": {"key": "Marker", "type": "str"},
+        "max_results": {"key": "MaxResults", "type": "int"},
+        "segment": {"key": "Segment", "type": "BlobFlatListSegment"},
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
+        *,
+        service_endpoint: str,
+        container_name: str,
+        segment: "_models.BlobFlatListSegment",
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        max_results: Optional[int] = None,
+        next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword service_endpoint: Required.
         :paramtype service_endpoint: str
         :keyword container_name: Required.
         :paramtype container_name: str
@@ -1650,25 +1746,25 @@
         :keyword max_results:
         :paramtype max_results: int
         :keyword segment: Required.
         :paramtype segment: ~azure.storage.blob.models.BlobFlatListSegment
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(ListBlobsFlatSegmentResponse, self).__init__(**kwargs)
-        self.service_endpoint = kwargs['service_endpoint']
-        self.container_name = kwargs['container_name']
-        self.prefix = kwargs.get('prefix', None)
-        self.marker = kwargs.get('marker', None)
-        self.max_results = kwargs.get('max_results', None)
-        self.segment = kwargs['segment']
-        self.next_marker = kwargs.get('next_marker', None)
+        super().__init__(**kwargs)
+        self.service_endpoint = service_endpoint
+        self.container_name = container_name
+        self.prefix = prefix
+        self.marker = marker
+        self.max_results = max_results
+        self.segment = segment
+        self.next_marker = next_marker
 
 
-class ListBlobsHierarchySegmentResponse(msrest.serialization.Model):
+class ListBlobsHierarchySegmentResponse(_serialization.Model):
     """An enumeration of blobs.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar container_name: Required.
@@ -1684,35 +1780,42 @@
     :ivar segment: Required.
     :vartype segment: ~azure.storage.blob.models.BlobHierarchyListSegment
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'container_name': {'required': True},
-        'segment': {'required': True},
+        "service_endpoint": {"required": True},
+        "container_name": {"required": True},
+        "segment": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'container_name': {'key': 'ContainerName', 'type': 'str', 'xml': {'attr': True}},
-        'prefix': {'key': 'Prefix', 'type': 'str'},
-        'marker': {'key': 'Marker', 'type': 'str'},
-        'max_results': {'key': 'MaxResults', 'type': 'int'},
-        'delimiter': {'key': 'Delimiter', 'type': 'str'},
-        'segment': {'key': 'Segment', 'type': 'BlobHierarchyListSegment'},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
-    }
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "container_name": {"key": "ContainerName", "type": "str", "xml": {"attr": True}},
+        "prefix": {"key": "Prefix", "type": "str"},
+        "marker": {"key": "Marker", "type": "str"},
+        "max_results": {"key": "MaxResults", "type": "int"},
+        "delimiter": {"key": "Delimiter", "type": "str"},
+        "segment": {"key": "Segment", "type": "BlobHierarchyListSegment"},
+        "next_marker": {"key": "NextMarker", "type": "str"},
+    }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
+        *,
+        service_endpoint: str,
+        container_name: str,
+        segment: "_models.BlobHierarchyListSegment",
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        max_results: Optional[int] = None,
+        delimiter: Optional[str] = None,
+        next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword service_endpoint: Required.
         :paramtype service_endpoint: str
         :keyword container_name: Required.
         :paramtype container_name: str
@@ -1725,26 +1828,26 @@
         :keyword delimiter:
         :paramtype delimiter: str
         :keyword segment: Required.
         :paramtype segment: ~azure.storage.blob.models.BlobHierarchyListSegment
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(ListBlobsHierarchySegmentResponse, self).__init__(**kwargs)
-        self.service_endpoint = kwargs['service_endpoint']
-        self.container_name = kwargs['container_name']
-        self.prefix = kwargs.get('prefix', None)
-        self.marker = kwargs.get('marker', None)
-        self.max_results = kwargs.get('max_results', None)
-        self.delimiter = kwargs.get('delimiter', None)
-        self.segment = kwargs['segment']
-        self.next_marker = kwargs.get('next_marker', None)
+        super().__init__(**kwargs)
+        self.service_endpoint = service_endpoint
+        self.container_name = container_name
+        self.prefix = prefix
+        self.marker = marker
+        self.max_results = max_results
+        self.delimiter = delimiter
+        self.segment = segment
+        self.next_marker = next_marker
 
 
-class ListContainersSegmentResponse(msrest.serialization.Model):
+class ListContainersSegmentResponse(_serialization.Model):
     """An enumeration of containers.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar prefix:
@@ -1756,32 +1859,41 @@
     :ivar container_items: Required.
     :vartype container_items: list[~azure.storage.blob.models.ContainerItem]
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'container_items': {'required': True},
+        "service_endpoint": {"required": True},
+        "container_items": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'prefix': {'key': 'Prefix', 'type': 'str'},
-        'marker': {'key': 'Marker', 'type': 'str'},
-        'max_results': {'key': 'MaxResults', 'type': 'int'},
-        'container_items': {'key': 'ContainerItems', 'type': '[ContainerItem]', 'xml': {'name': 'Containers', 'wrapped': True, 'itemsName': 'Container'}},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "prefix": {"key": "Prefix", "type": "str"},
+        "marker": {"key": "Marker", "type": "str"},
+        "max_results": {"key": "MaxResults", "type": "int"},
+        "container_items": {
+            "key": "ContainerItems",
+            "type": "[ContainerItem]",
+            "xml": {"name": "Containers", "wrapped": True, "itemsName": "Container"},
+        },
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
+        *,
+        service_endpoint: str,
+        container_items: List["_models.ContainerItem"],
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        max_results: Optional[int] = None,
+        next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword service_endpoint: Required.
         :paramtype service_endpoint: str
         :keyword prefix:
         :paramtype prefix: str
@@ -1790,134 +1902,145 @@
         :keyword max_results:
         :paramtype max_results: int
         :keyword container_items: Required.
         :paramtype container_items: list[~azure.storage.blob.models.ContainerItem]
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(ListContainersSegmentResponse, self).__init__(**kwargs)
-        self.service_endpoint = kwargs['service_endpoint']
-        self.prefix = kwargs.get('prefix', None)
-        self.marker = kwargs.get('marker', None)
-        self.max_results = kwargs.get('max_results', None)
-        self.container_items = kwargs['container_items']
-        self.next_marker = kwargs.get('next_marker', None)
+        super().__init__(**kwargs)
+        self.service_endpoint = service_endpoint
+        self.prefix = prefix
+        self.marker = marker
+        self.max_results = max_results
+        self.container_items = container_items
+        self.next_marker = next_marker
 
 
-class Logging(msrest.serialization.Model):
+class Logging(_serialization.Model):
     """Azure Analytics Logging settings.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar version: Required. The version of Storage Analytics to configure.
+    :ivar version: The version of Storage Analytics to configure. Required.
     :vartype version: str
-    :ivar delete: Required. Indicates whether all delete requests should be logged.
+    :ivar delete: Indicates whether all delete requests should be logged. Required.
     :vartype delete: bool
-    :ivar read: Required. Indicates whether all read requests should be logged.
+    :ivar read: Indicates whether all read requests should be logged. Required.
     :vartype read: bool
-    :ivar write: Required. Indicates whether all write requests should be logged.
+    :ivar write: Indicates whether all write requests should be logged. Required.
     :vartype write: bool
-    :ivar retention_policy: Required. the retention policy which determines how long the associated
-     data should persist.
+    :ivar retention_policy: the retention policy which determines how long the associated data
+     should persist. Required.
     :vartype retention_policy: ~azure.storage.blob.models.RetentionPolicy
     """
 
     _validation = {
-        'version': {'required': True},
-        'delete': {'required': True},
-        'read': {'required': True},
-        'write': {'required': True},
-        'retention_policy': {'required': True},
+        "version": {"required": True},
+        "delete": {"required": True},
+        "read": {"required": True},
+        "write": {"required": True},
+        "retention_policy": {"required": True},
     }
 
     _attribute_map = {
-        'version': {'key': 'Version', 'type': 'str'},
-        'delete': {'key': 'Delete', 'type': 'bool'},
-        'read': {'key': 'Read', 'type': 'bool'},
-        'write': {'key': 'Write', 'type': 'bool'},
-        'retention_policy': {'key': 'RetentionPolicy', 'type': 'RetentionPolicy'},
+        "version": {"key": "Version", "type": "str"},
+        "delete": {"key": "Delete", "type": "bool"},
+        "read": {"key": "Read", "type": "bool"},
+        "write": {"key": "Write", "type": "bool"},
+        "retention_policy": {"key": "RetentionPolicy", "type": "RetentionPolicy"},
     }
 
     def __init__(
         self,
+        *,
+        version: str,
+        delete: bool,
+        read: bool,
+        write: bool,
+        retention_policy: "_models.RetentionPolicy",
         **kwargs
     ):
         """
-        :keyword version: Required. The version of Storage Analytics to configure.
+        :keyword version: The version of Storage Analytics to configure. Required.
         :paramtype version: str
-        :keyword delete: Required. Indicates whether all delete requests should be logged.
+        :keyword delete: Indicates whether all delete requests should be logged. Required.
         :paramtype delete: bool
-        :keyword read: Required. Indicates whether all read requests should be logged.
+        :keyword read: Indicates whether all read requests should be logged. Required.
         :paramtype read: bool
-        :keyword write: Required. Indicates whether all write requests should be logged.
+        :keyword write: Indicates whether all write requests should be logged. Required.
         :paramtype write: bool
-        :keyword retention_policy: Required. the retention policy which determines how long the
-         associated data should persist.
+        :keyword retention_policy: the retention policy which determines how long the associated data
+         should persist. Required.
         :paramtype retention_policy: ~azure.storage.blob.models.RetentionPolicy
         """
-        super(Logging, self).__init__(**kwargs)
-        self.version = kwargs['version']
-        self.delete = kwargs['delete']
-        self.read = kwargs['read']
-        self.write = kwargs['write']
-        self.retention_policy = kwargs['retention_policy']
+        super().__init__(**kwargs)
+        self.version = version
+        self.delete = delete
+        self.read = read
+        self.write = write
+        self.retention_policy = retention_policy
 
 
-class Metrics(msrest.serialization.Model):
+class Metrics(_serialization.Model):
     """a summary of request statistics grouped by API in hour or minute aggregates for blobs.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar version: The version of Storage Analytics to configure.
     :vartype version: str
-    :ivar enabled: Required. Indicates whether metrics are enabled for the Blob service.
+    :ivar enabled: Indicates whether metrics are enabled for the Blob service. Required.
     :vartype enabled: bool
     :ivar include_apis: Indicates whether metrics should generate summary statistics for called API
      operations.
     :vartype include_apis: bool
     :ivar retention_policy: the retention policy which determines how long the associated data
      should persist.
     :vartype retention_policy: ~azure.storage.blob.models.RetentionPolicy
     """
 
     _validation = {
-        'enabled': {'required': True},
+        "enabled": {"required": True},
     }
 
     _attribute_map = {
-        'version': {'key': 'Version', 'type': 'str'},
-        'enabled': {'key': 'Enabled', 'type': 'bool'},
-        'include_apis': {'key': 'IncludeAPIs', 'type': 'bool'},
-        'retention_policy': {'key': 'RetentionPolicy', 'type': 'RetentionPolicy'},
+        "version": {"key": "Version", "type": "str"},
+        "enabled": {"key": "Enabled", "type": "bool"},
+        "include_apis": {"key": "IncludeAPIs", "type": "bool"},
+        "retention_policy": {"key": "RetentionPolicy", "type": "RetentionPolicy"},
     }
 
     def __init__(
         self,
+        *,
+        enabled: bool,
+        version: Optional[str] = None,
+        include_apis: Optional[bool] = None,
+        retention_policy: Optional["_models.RetentionPolicy"] = None,
         **kwargs
     ):
         """
         :keyword version: The version of Storage Analytics to configure.
         :paramtype version: str
-        :keyword enabled: Required. Indicates whether metrics are enabled for the Blob service.
+        :keyword enabled: Indicates whether metrics are enabled for the Blob service. Required.
         :paramtype enabled: bool
         :keyword include_apis: Indicates whether metrics should generate summary statistics for called
          API operations.
         :paramtype include_apis: bool
         :keyword retention_policy: the retention policy which determines how long the associated data
          should persist.
         :paramtype retention_policy: ~azure.storage.blob.models.RetentionPolicy
         """
-        super(Metrics, self).__init__(**kwargs)
-        self.version = kwargs.get('version', None)
-        self.enabled = kwargs['enabled']
-        self.include_apis = kwargs.get('include_apis', None)
-        self.retention_policy = kwargs.get('retention_policy', None)
+        super().__init__(**kwargs)
+        self.version = version
+        self.enabled = enabled
+        self.include_apis = include_apis
+        self.retention_policy = retention_policy
 
 
-class ModifiedAccessConditions(msrest.serialization.Model):
+class ModifiedAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar if_modified_since: Specify this header value to operate only on a blob if it has been
      modified since the specified date/time.
     :vartype if_modified_since: ~datetime.datetime
     :ivar if_unmodified_since: Specify this header value to operate only on a blob if it has not
      been modified since the specified date/time.
@@ -1928,23 +2051,29 @@
     :vartype if_none_match: str
     :ivar if_tags: Specify a SQL where clause on blob tags to operate only on blobs with a matching
      value.
     :vartype if_tags: str
     """
 
     _attribute_map = {
-        'if_modified_since': {'key': 'ifModifiedSince', 'type': 'rfc-1123'},
-        'if_unmodified_since': {'key': 'ifUnmodifiedSince', 'type': 'rfc-1123'},
-        'if_match': {'key': 'ifMatch', 'type': 'str'},
-        'if_none_match': {'key': 'ifNoneMatch', 'type': 'str'},
-        'if_tags': {'key': 'ifTags', 'type': 'str'},
+        "if_modified_since": {"key": "ifModifiedSince", "type": "rfc-1123"},
+        "if_unmodified_since": {"key": "ifUnmodifiedSince", "type": "rfc-1123"},
+        "if_match": {"key": "ifMatch", "type": "str"},
+        "if_none_match": {"key": "ifNoneMatch", "type": "str"},
+        "if_tags": {"key": "ifTags", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        if_modified_since: Optional[datetime.datetime] = None,
+        if_unmodified_since: Optional[datetime.datetime] = None,
+        if_match: Optional[str] = None,
+        if_none_match: Optional[str] = None,
+        if_tags: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword if_modified_since: Specify this header value to operate only on a blob if it has been
          modified since the specified date/time.
         :paramtype if_modified_since: ~datetime.datetime
         :keyword if_unmodified_since: Specify this header value to operate only on a blob if it has not
@@ -1955,367 +2084,375 @@
         :keyword if_none_match: Specify an ETag value to operate only on blobs without a matching
          value.
         :paramtype if_none_match: str
         :keyword if_tags: Specify a SQL where clause on blob tags to operate only on blobs with a
          matching value.
         :paramtype if_tags: str
         """
-        super(ModifiedAccessConditions, self).__init__(**kwargs)
-        self.if_modified_since = kwargs.get('if_modified_since', None)
-        self.if_unmodified_since = kwargs.get('if_unmodified_since', None)
-        self.if_match = kwargs.get('if_match', None)
-        self.if_none_match = kwargs.get('if_none_match', None)
-        self.if_tags = kwargs.get('if_tags', None)
+        super().__init__(**kwargs)
+        self.if_modified_since = if_modified_since
+        self.if_unmodified_since = if_unmodified_since
+        self.if_match = if_match
+        self.if_none_match = if_none_match
+        self.if_tags = if_tags
 
 
-class PageList(msrest.serialization.Model):
+class PageList(_serialization.Model):
     """the list of pages.
 
     :ivar page_range:
     :vartype page_range: list[~azure.storage.blob.models.PageRange]
     :ivar clear_range:
     :vartype clear_range: list[~azure.storage.blob.models.ClearRange]
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _attribute_map = {
-        'page_range': {'key': 'PageRange', 'type': '[PageRange]'},
-        'clear_range': {'key': 'ClearRange', 'type': '[ClearRange]'},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
+        "page_range": {"key": "PageRange", "type": "[PageRange]", "xml": {"itemsName": "PageRange"}},
+        "clear_range": {"key": "ClearRange", "type": "[ClearRange]", "xml": {"itemsName": "ClearRange"}},
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        page_range: Optional[List["_models.PageRange"]] = None,
+        clear_range: Optional[List["_models.ClearRange"]] = None,
+        next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword page_range:
         :paramtype page_range: list[~azure.storage.blob.models.PageRange]
         :keyword clear_range:
         :paramtype clear_range: list[~azure.storage.blob.models.ClearRange]
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(PageList, self).__init__(**kwargs)
-        self.page_range = kwargs.get('page_range', None)
-        self.clear_range = kwargs.get('clear_range', None)
-        self.next_marker = kwargs.get('next_marker', None)
+        super().__init__(**kwargs)
+        self.page_range = page_range
+        self.clear_range = clear_range
+        self.next_marker = next_marker
 
 
-class PageRange(msrest.serialization.Model):
+class PageRange(_serialization.Model):
     """PageRange.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar start: Required.
-    :vartype start: long
+    :vartype start: int
     :ivar end: Required.
-    :vartype end: long
+    :vartype end: int
     """
 
     _validation = {
-        'start': {'required': True},
-        'end': {'required': True},
+        "start": {"required": True},
+        "end": {"required": True},
     }
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'long', 'xml': {'name': 'Start'}},
-        'end': {'key': 'End', 'type': 'long', 'xml': {'name': 'End'}},
-    }
-    _xml_map = {
-        'name': 'PageRange'
+        "start": {"key": "Start", "type": "int", "xml": {"name": "Start"}},
+        "end": {"key": "End", "type": "int", "xml": {"name": "End"}},
     }
+    _xml_map = {"name": "PageRange"}
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, start: int, end: int, **kwargs):
         """
         :keyword start: Required.
-        :paramtype start: long
+        :paramtype start: int
         :keyword end: Required.
-        :paramtype end: long
+        :paramtype end: int
         """
-        super(PageRange, self).__init__(**kwargs)
-        self.start = kwargs['start']
-        self.end = kwargs['end']
+        super().__init__(**kwargs)
+        self.start = start
+        self.end = end
 
 
-class QueryFormat(msrest.serialization.Model):
+class QueryFormat(_serialization.Model):
     """QueryFormat.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar type: Required. The quick query format type. Possible values include: "delimited",
-     "json", "arrow", "parquet".
+    :ivar type: The quick query format type. Required. Known values are: "delimited", "json",
+     "arrow", and "parquet".
     :vartype type: str or ~azure.storage.blob.models.QueryFormatType
     :ivar delimited_text_configuration: Groups the settings used for interpreting the blob data if
      the blob is delimited text formatted.
     :vartype delimited_text_configuration: ~azure.storage.blob.models.DelimitedTextConfiguration
     :ivar json_text_configuration: json text configuration.
     :vartype json_text_configuration: ~azure.storage.blob.models.JsonTextConfiguration
     :ivar arrow_configuration: Groups the settings used for formatting the response if the response
      should be Arrow formatted.
     :vartype arrow_configuration: ~azure.storage.blob.models.ArrowConfiguration
-    :ivar parquet_text_configuration: Any object.
-    :vartype parquet_text_configuration: any
+    :ivar parquet_text_configuration: parquet configuration.
+    :vartype parquet_text_configuration: JSON
     """
 
     _validation = {
-        'type': {'required': True},
+        "type": {"required": True},
     }
 
     _attribute_map = {
-        'type': {'key': 'Type', 'type': 'str', 'xml': {'name': 'Type'}},
-        'delimited_text_configuration': {'key': 'DelimitedTextConfiguration', 'type': 'DelimitedTextConfiguration'},
-        'json_text_configuration': {'key': 'JsonTextConfiguration', 'type': 'JsonTextConfiguration'},
-        'arrow_configuration': {'key': 'ArrowConfiguration', 'type': 'ArrowConfiguration'},
-        'parquet_text_configuration': {'key': 'ParquetTextConfiguration', 'type': 'object'},
+        "type": {"key": "Type", "type": "str", "xml": {"name": "Type"}},
+        "delimited_text_configuration": {"key": "DelimitedTextConfiguration", "type": "DelimitedTextConfiguration"},
+        "json_text_configuration": {"key": "JsonTextConfiguration", "type": "JsonTextConfiguration"},
+        "arrow_configuration": {"key": "ArrowConfiguration", "type": "ArrowConfiguration"},
+        "parquet_text_configuration": {"key": "ParquetTextConfiguration", "type": "object"},
     }
 
     def __init__(
         self,
+        *,
+        type: Union[str, "_models.QueryFormatType"],
+        delimited_text_configuration: Optional["_models.DelimitedTextConfiguration"] = None,
+        json_text_configuration: Optional["_models.JsonTextConfiguration"] = None,
+        arrow_configuration: Optional["_models.ArrowConfiguration"] = None,
+        parquet_text_configuration: Optional[JSON] = None,
         **kwargs
     ):
         """
-        :keyword type: Required. The quick query format type. Possible values include: "delimited",
-         "json", "arrow", "parquet".
+        :keyword type: The quick query format type. Required. Known values are: "delimited", "json",
+         "arrow", and "parquet".
         :paramtype type: str or ~azure.storage.blob.models.QueryFormatType
         :keyword delimited_text_configuration: Groups the settings used for interpreting the blob data
          if the blob is delimited text formatted.
         :paramtype delimited_text_configuration: ~azure.storage.blob.models.DelimitedTextConfiguration
         :keyword json_text_configuration: json text configuration.
         :paramtype json_text_configuration: ~azure.storage.blob.models.JsonTextConfiguration
         :keyword arrow_configuration: Groups the settings used for formatting the response if the
          response should be Arrow formatted.
         :paramtype arrow_configuration: ~azure.storage.blob.models.ArrowConfiguration
-        :keyword parquet_text_configuration: Any object.
-        :paramtype parquet_text_configuration: any
+        :keyword parquet_text_configuration: parquet configuration.
+        :paramtype parquet_text_configuration: JSON
         """
-        super(QueryFormat, self).__init__(**kwargs)
-        self.type = kwargs['type']
-        self.delimited_text_configuration = kwargs.get('delimited_text_configuration', None)
-        self.json_text_configuration = kwargs.get('json_text_configuration', None)
-        self.arrow_configuration = kwargs.get('arrow_configuration', None)
-        self.parquet_text_configuration = kwargs.get('parquet_text_configuration', None)
+        super().__init__(**kwargs)
+        self.type = type
+        self.delimited_text_configuration = delimited_text_configuration
+        self.json_text_configuration = json_text_configuration
+        self.arrow_configuration = arrow_configuration
+        self.parquet_text_configuration = parquet_text_configuration
 
 
-class QueryRequest(msrest.serialization.Model):
+class QueryRequest(_serialization.Model):
     """Groups the set of query request settings.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar query_type: Required. The type of the provided query expression. Has constant value:
-     "SQL".
+    :ivar query_type: Required. The type of the provided query expression. Required. Default value
+     is "SQL".
     :vartype query_type: str
-    :ivar expression: Required. The query expression in SQL. The maximum size of the query
-     expression is 256KiB.
+    :ivar expression: The query expression in SQL. The maximum size of the query expression is
+     256KiB. Required.
     :vartype expression: str
     :ivar input_serialization:
     :vartype input_serialization: ~azure.storage.blob.models.QuerySerialization
     :ivar output_serialization:
     :vartype output_serialization: ~azure.storage.blob.models.QuerySerialization
     """
 
     _validation = {
-        'query_type': {'required': True, 'constant': True},
-        'expression': {'required': True},
+        "query_type": {"required": True, "constant": True},
+        "expression": {"required": True},
     }
 
     _attribute_map = {
-        'query_type': {'key': 'QueryType', 'type': 'str', 'xml': {'name': 'QueryType'}},
-        'expression': {'key': 'Expression', 'type': 'str', 'xml': {'name': 'Expression'}},
-        'input_serialization': {'key': 'InputSerialization', 'type': 'QuerySerialization'},
-        'output_serialization': {'key': 'OutputSerialization', 'type': 'QuerySerialization'},
-    }
-    _xml_map = {
-        'name': 'QueryRequest'
+        "query_type": {"key": "QueryType", "type": "str", "xml": {"name": "QueryType"}},
+        "expression": {"key": "Expression", "type": "str", "xml": {"name": "Expression"}},
+        "input_serialization": {"key": "InputSerialization", "type": "QuerySerialization"},
+        "output_serialization": {"key": "OutputSerialization", "type": "QuerySerialization"},
     }
+    _xml_map = {"name": "QueryRequest"}
 
     query_type = "SQL"
 
     def __init__(
         self,
+        *,
+        expression: str,
+        input_serialization: Optional["_models.QuerySerialization"] = None,
+        output_serialization: Optional["_models.QuerySerialization"] = None,
         **kwargs
     ):
         """
-        :keyword expression: Required. The query expression in SQL. The maximum size of the query
-         expression is 256KiB.
+        :keyword expression: The query expression in SQL. The maximum size of the query expression is
+         256KiB. Required.
         :paramtype expression: str
         :keyword input_serialization:
         :paramtype input_serialization: ~azure.storage.blob.models.QuerySerialization
         :keyword output_serialization:
         :paramtype output_serialization: ~azure.storage.blob.models.QuerySerialization
         """
-        super(QueryRequest, self).__init__(**kwargs)
-        self.expression = kwargs['expression']
-        self.input_serialization = kwargs.get('input_serialization', None)
-        self.output_serialization = kwargs.get('output_serialization', None)
+        super().__init__(**kwargs)
+        self.expression = expression
+        self.input_serialization = input_serialization
+        self.output_serialization = output_serialization
 
 
-class QuerySerialization(msrest.serialization.Model):
+class QuerySerialization(_serialization.Model):
     """QuerySerialization.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar format: Required.
     :vartype format: ~azure.storage.blob.models.QueryFormat
     """
 
     _validation = {
-        'format': {'required': True},
+        "format": {"required": True},
     }
 
     _attribute_map = {
-        'format': {'key': 'Format', 'type': 'QueryFormat'},
+        "format": {"key": "Format", "type": "QueryFormat"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, format: "_models.QueryFormat", **kwargs):
         """
         :keyword format: Required.
         :paramtype format: ~azure.storage.blob.models.QueryFormat
         """
-        super(QuerySerialization, self).__init__(**kwargs)
-        self.format = kwargs['format']
+        super().__init__(**kwargs)
+        self.format = format
 
 
-class RetentionPolicy(msrest.serialization.Model):
+class RetentionPolicy(_serialization.Model):
     """the retention policy which determines how long the associated data should persist.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar enabled: Required. Indicates whether a retention policy is enabled for the storage
-     service.
+    :ivar enabled: Indicates whether a retention policy is enabled for the storage service.
+     Required.
     :vartype enabled: bool
     :ivar days: Indicates the number of days that metrics or logging or soft-deleted data should be
      retained. All data older than this value will be deleted.
     :vartype days: int
     :ivar allow_permanent_delete: Indicates whether permanent delete is allowed on this storage
      account.
     :vartype allow_permanent_delete: bool
     """
 
     _validation = {
-        'enabled': {'required': True},
-        'days': {'minimum': 1},
+        "enabled": {"required": True},
+        "days": {"minimum": 1},
     }
 
     _attribute_map = {
-        'enabled': {'key': 'Enabled', 'type': 'bool'},
-        'days': {'key': 'Days', 'type': 'int'},
-        'allow_permanent_delete': {'key': 'AllowPermanentDelete', 'type': 'bool'},
+        "enabled": {"key": "Enabled", "type": "bool"},
+        "days": {"key": "Days", "type": "int"},
+        "allow_permanent_delete": {"key": "AllowPermanentDelete", "type": "bool"},
     }
 
     def __init__(
-        self,
-        **kwargs
+        self, *, enabled: bool, days: Optional[int] = None, allow_permanent_delete: Optional[bool] = None, **kwargs
     ):
         """
-        :keyword enabled: Required. Indicates whether a retention policy is enabled for the storage
-         service.
+        :keyword enabled: Indicates whether a retention policy is enabled for the storage service.
+         Required.
         :paramtype enabled: bool
         :keyword days: Indicates the number of days that metrics or logging or soft-deleted data should
          be retained. All data older than this value will be deleted.
         :paramtype days: int
         :keyword allow_permanent_delete: Indicates whether permanent delete is allowed on this storage
          account.
         :paramtype allow_permanent_delete: bool
         """
-        super(RetentionPolicy, self).__init__(**kwargs)
-        self.enabled = kwargs['enabled']
-        self.days = kwargs.get('days', None)
-        self.allow_permanent_delete = kwargs.get('allow_permanent_delete', None)
+        super().__init__(**kwargs)
+        self.enabled = enabled
+        self.days = days
+        self.allow_permanent_delete = allow_permanent_delete
 
 
-class SequenceNumberAccessConditions(msrest.serialization.Model):
+class SequenceNumberAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar if_sequence_number_less_than_or_equal_to: Specify this header value to operate only on a
      blob if it has a sequence number less than or equal to the specified.
-    :vartype if_sequence_number_less_than_or_equal_to: long
+    :vartype if_sequence_number_less_than_or_equal_to: int
     :ivar if_sequence_number_less_than: Specify this header value to operate only on a blob if it
      has a sequence number less than the specified.
-    :vartype if_sequence_number_less_than: long
+    :vartype if_sequence_number_less_than: int
     :ivar if_sequence_number_equal_to: Specify this header value to operate only on a blob if it
      has the specified sequence number.
-    :vartype if_sequence_number_equal_to: long
+    :vartype if_sequence_number_equal_to: int
     """
 
     _attribute_map = {
-        'if_sequence_number_less_than_or_equal_to': {'key': 'ifSequenceNumberLessThanOrEqualTo', 'type': 'long'},
-        'if_sequence_number_less_than': {'key': 'ifSequenceNumberLessThan', 'type': 'long'},
-        'if_sequence_number_equal_to': {'key': 'ifSequenceNumberEqualTo', 'type': 'long'},
+        "if_sequence_number_less_than_or_equal_to": {"key": "ifSequenceNumberLessThanOrEqualTo", "type": "int"},
+        "if_sequence_number_less_than": {"key": "ifSequenceNumberLessThan", "type": "int"},
+        "if_sequence_number_equal_to": {"key": "ifSequenceNumberEqualTo", "type": "int"},
     }
 
     def __init__(
         self,
+        *,
+        if_sequence_number_less_than_or_equal_to: Optional[int] = None,
+        if_sequence_number_less_than: Optional[int] = None,
+        if_sequence_number_equal_to: Optional[int] = None,
         **kwargs
     ):
         """
         :keyword if_sequence_number_less_than_or_equal_to: Specify this header value to operate only on
          a blob if it has a sequence number less than or equal to the specified.
-        :paramtype if_sequence_number_less_than_or_equal_to: long
+        :paramtype if_sequence_number_less_than_or_equal_to: int
         :keyword if_sequence_number_less_than: Specify this header value to operate only on a blob if
          it has a sequence number less than the specified.
-        :paramtype if_sequence_number_less_than: long
+        :paramtype if_sequence_number_less_than: int
         :keyword if_sequence_number_equal_to: Specify this header value to operate only on a blob if it
          has the specified sequence number.
-        :paramtype if_sequence_number_equal_to: long
+        :paramtype if_sequence_number_equal_to: int
         """
-        super(SequenceNumberAccessConditions, self).__init__(**kwargs)
-        self.if_sequence_number_less_than_or_equal_to = kwargs.get('if_sequence_number_less_than_or_equal_to', None)
-        self.if_sequence_number_less_than = kwargs.get('if_sequence_number_less_than', None)
-        self.if_sequence_number_equal_to = kwargs.get('if_sequence_number_equal_to', None)
+        super().__init__(**kwargs)
+        self.if_sequence_number_less_than_or_equal_to = if_sequence_number_less_than_or_equal_to
+        self.if_sequence_number_less_than = if_sequence_number_less_than
+        self.if_sequence_number_equal_to = if_sequence_number_equal_to
 
 
-class SignedIdentifier(msrest.serialization.Model):
+class SignedIdentifier(_serialization.Model):
     """signed identifier.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar id: Required. a unique id.
+    :ivar id: a unique id. Required.
     :vartype id: str
     :ivar access_policy: An Access policy.
     :vartype access_policy: ~azure.storage.blob.models.AccessPolicy
     """
 
     _validation = {
-        'id': {'required': True},
+        "id": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'Id', 'type': 'str'},
-        'access_policy': {'key': 'AccessPolicy', 'type': 'AccessPolicy'},
-    }
-    _xml_map = {
-        'name': 'SignedIdentifier'
+        "id": {"key": "Id", "type": "str"},
+        "access_policy": {"key": "AccessPolicy", "type": "AccessPolicy"},
     }
+    _xml_map = {"name": "SignedIdentifier"}
 
     def __init__(
         self,
+        *,
+        id: str,  # pylint: disable=redefined-builtin
+        access_policy: Optional["_models.AccessPolicy"] = None,
         **kwargs
     ):
         """
-        :keyword id: Required. a unique id.
+        :keyword id: a unique id. Required.
         :paramtype id: str
         :keyword access_policy: An Access policy.
         :paramtype access_policy: ~azure.storage.blob.models.AccessPolicy
         """
-        super(SignedIdentifier, self).__init__(**kwargs)
-        self.id = kwargs['id']
-        self.access_policy = kwargs.get('access_policy', None)
+        super().__init__(**kwargs)
+        self.id = id
+        self.access_policy = access_policy
 
 
-class SourceModifiedAccessConditions(msrest.serialization.Model):
+class SourceModifiedAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar source_if_modified_since: Specify this header value to operate only on a blob if it has
      been modified since the specified date/time.
     :vartype source_if_modified_since: ~datetime.datetime
     :ivar source_if_unmodified_since: Specify this header value to operate only on a blob if it has
      not been modified since the specified date/time.
@@ -2327,23 +2464,29 @@
     :vartype source_if_none_match: str
     :ivar source_if_tags: Specify a SQL where clause on blob tags to operate only on blobs with a
      matching value.
     :vartype source_if_tags: str
     """
 
     _attribute_map = {
-        'source_if_modified_since': {'key': 'sourceIfModifiedSince', 'type': 'rfc-1123'},
-        'source_if_unmodified_since': {'key': 'sourceIfUnmodifiedSince', 'type': 'rfc-1123'},
-        'source_if_match': {'key': 'sourceIfMatch', 'type': 'str'},
-        'source_if_none_match': {'key': 'sourceIfNoneMatch', 'type': 'str'},
-        'source_if_tags': {'key': 'sourceIfTags', 'type': 'str'},
+        "source_if_modified_since": {"key": "sourceIfModifiedSince", "type": "rfc-1123"},
+        "source_if_unmodified_since": {"key": "sourceIfUnmodifiedSince", "type": "rfc-1123"},
+        "source_if_match": {"key": "sourceIfMatch", "type": "str"},
+        "source_if_none_match": {"key": "sourceIfNoneMatch", "type": "str"},
+        "source_if_tags": {"key": "sourceIfTags", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        source_if_modified_since: Optional[datetime.datetime] = None,
+        source_if_unmodified_since: Optional[datetime.datetime] = None,
+        source_if_match: Optional[str] = None,
+        source_if_none_match: Optional[str] = None,
+        source_if_tags: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword source_if_modified_since: Specify this header value to operate only on a blob if it
          has been modified since the specified date/time.
         :paramtype source_if_modified_since: ~datetime.datetime
         :keyword source_if_unmodified_since: Specify this header value to operate only on a blob if it
@@ -2354,93 +2497,95 @@
         :keyword source_if_none_match: Specify an ETag value to operate only on blobs without a
          matching value.
         :paramtype source_if_none_match: str
         :keyword source_if_tags: Specify a SQL where clause on blob tags to operate only on blobs with
          a matching value.
         :paramtype source_if_tags: str
         """
-        super(SourceModifiedAccessConditions, self).__init__(**kwargs)
-        self.source_if_modified_since = kwargs.get('source_if_modified_since', None)
-        self.source_if_unmodified_since = kwargs.get('source_if_unmodified_since', None)
-        self.source_if_match = kwargs.get('source_if_match', None)
-        self.source_if_none_match = kwargs.get('source_if_none_match', None)
-        self.source_if_tags = kwargs.get('source_if_tags', None)
+        super().__init__(**kwargs)
+        self.source_if_modified_since = source_if_modified_since
+        self.source_if_unmodified_since = source_if_unmodified_since
+        self.source_if_match = source_if_match
+        self.source_if_none_match = source_if_none_match
+        self.source_if_tags = source_if_tags
 
 
-class StaticWebsite(msrest.serialization.Model):
+class StaticWebsite(_serialization.Model):
     """The properties that enable an account to host a static website.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar enabled: Required. Indicates whether this account is hosting a static website.
+    :ivar enabled: Indicates whether this account is hosting a static website. Required.
     :vartype enabled: bool
     :ivar index_document: The default name of the index page under each directory.
     :vartype index_document: str
     :ivar error_document404_path: The absolute path of the custom 404 page.
     :vartype error_document404_path: str
     :ivar default_index_document_path: Absolute path of the default index page.
     :vartype default_index_document_path: str
     """
 
     _validation = {
-        'enabled': {'required': True},
+        "enabled": {"required": True},
     }
 
     _attribute_map = {
-        'enabled': {'key': 'Enabled', 'type': 'bool'},
-        'index_document': {'key': 'IndexDocument', 'type': 'str'},
-        'error_document404_path': {'key': 'ErrorDocument404Path', 'type': 'str'},
-        'default_index_document_path': {'key': 'DefaultIndexDocumentPath', 'type': 'str'},
+        "enabled": {"key": "Enabled", "type": "bool"},
+        "index_document": {"key": "IndexDocument", "type": "str"},
+        "error_document404_path": {"key": "ErrorDocument404Path", "type": "str"},
+        "default_index_document_path": {"key": "DefaultIndexDocumentPath", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        enabled: bool,
+        index_document: Optional[str] = None,
+        error_document404_path: Optional[str] = None,
+        default_index_document_path: Optional[str] = None,
         **kwargs
     ):
         """
-        :keyword enabled: Required. Indicates whether this account is hosting a static website.
+        :keyword enabled: Indicates whether this account is hosting a static website. Required.
         :paramtype enabled: bool
         :keyword index_document: The default name of the index page under each directory.
         :paramtype index_document: str
         :keyword error_document404_path: The absolute path of the custom 404 page.
         :paramtype error_document404_path: str
         :keyword default_index_document_path: Absolute path of the default index page.
         :paramtype default_index_document_path: str
         """
-        super(StaticWebsite, self).__init__(**kwargs)
-        self.enabled = kwargs['enabled']
-        self.index_document = kwargs.get('index_document', None)
-        self.error_document404_path = kwargs.get('error_document404_path', None)
-        self.default_index_document_path = kwargs.get('default_index_document_path', None)
+        super().__init__(**kwargs)
+        self.enabled = enabled
+        self.index_document = index_document
+        self.error_document404_path = error_document404_path
+        self.default_index_document_path = default_index_document_path
 
 
-class StorageError(msrest.serialization.Model):
+class StorageError(_serialization.Model):
     """StorageError.
 
     :ivar message:
     :vartype message: str
     """
 
     _attribute_map = {
-        'message': {'key': 'Message', 'type': 'str'},
+        "message": {"key": "Message", "type": "str"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, message: Optional[str] = None, **kwargs):
         """
         :keyword message:
         :paramtype message: str
         """
-        super(StorageError, self).__init__(**kwargs)
-        self.message = kwargs.get('message', None)
+        super().__init__(**kwargs)
+        self.message = message
 
 
-class StorageServiceProperties(msrest.serialization.Model):
+class StorageServiceProperties(_serialization.Model):
     """Storage Service Properties.
 
     :ivar logging: Azure Analytics Logging settings.
     :vartype logging: ~azure.storage.blob.models.Logging
     :ivar hour_metrics: a summary of request statistics grouped by API in hour or minute aggregates
      for blobs.
     :vartype hour_metrics: ~azure.storage.blob.models.Metrics
@@ -2457,25 +2602,33 @@
      data should persist.
     :vartype delete_retention_policy: ~azure.storage.blob.models.RetentionPolicy
     :ivar static_website: The properties that enable an account to host a static website.
     :vartype static_website: ~azure.storage.blob.models.StaticWebsite
     """
 
     _attribute_map = {
-        'logging': {'key': 'Logging', 'type': 'Logging'},
-        'hour_metrics': {'key': 'HourMetrics', 'type': 'Metrics'},
-        'minute_metrics': {'key': 'MinuteMetrics', 'type': 'Metrics'},
-        'cors': {'key': 'Cors', 'type': '[CorsRule]', 'xml': {'wrapped': True}},
-        'default_service_version': {'key': 'DefaultServiceVersion', 'type': 'str'},
-        'delete_retention_policy': {'key': 'DeleteRetentionPolicy', 'type': 'RetentionPolicy'},
-        'static_website': {'key': 'StaticWebsite', 'type': 'StaticWebsite'},
+        "logging": {"key": "Logging", "type": "Logging"},
+        "hour_metrics": {"key": "HourMetrics", "type": "Metrics"},
+        "minute_metrics": {"key": "MinuteMetrics", "type": "Metrics"},
+        "cors": {"key": "Cors", "type": "[CorsRule]", "xml": {"wrapped": True}},
+        "default_service_version": {"key": "DefaultServiceVersion", "type": "str"},
+        "delete_retention_policy": {"key": "DeleteRetentionPolicy", "type": "RetentionPolicy"},
+        "static_website": {"key": "StaticWebsite", "type": "StaticWebsite"},
     }
 
     def __init__(
         self,
+        *,
+        logging: Optional["_models.Logging"] = None,
+        hour_metrics: Optional["_models.Metrics"] = None,
+        minute_metrics: Optional["_models.Metrics"] = None,
+        cors: Optional[List["_models.CorsRule"]] = None,
+        default_service_version: Optional[str] = None,
+        delete_retention_policy: Optional["_models.RetentionPolicy"] = None,
+        static_website: Optional["_models.StaticWebsite"] = None,
         **kwargs
     ):
         """
         :keyword logging: Azure Analytics Logging settings.
         :paramtype logging: ~azure.storage.blob.models.Logging
         :keyword hour_metrics: a summary of request statistics grouped by API in hour or minute
          aggregates for blobs.
@@ -2491,110 +2644,115 @@
         :paramtype default_service_version: str
         :keyword delete_retention_policy: the retention policy which determines how long the associated
          data should persist.
         :paramtype delete_retention_policy: ~azure.storage.blob.models.RetentionPolicy
         :keyword static_website: The properties that enable an account to host a static website.
         :paramtype static_website: ~azure.storage.blob.models.StaticWebsite
         """
-        super(StorageServiceProperties, self).__init__(**kwargs)
-        self.logging = kwargs.get('logging', None)
-        self.hour_metrics = kwargs.get('hour_metrics', None)
-        self.minute_metrics = kwargs.get('minute_metrics', None)
-        self.cors = kwargs.get('cors', None)
-        self.default_service_version = kwargs.get('default_service_version', None)
-        self.delete_retention_policy = kwargs.get('delete_retention_policy', None)
-        self.static_website = kwargs.get('static_website', None)
+        super().__init__(**kwargs)
+        self.logging = logging
+        self.hour_metrics = hour_metrics
+        self.minute_metrics = minute_metrics
+        self.cors = cors
+        self.default_service_version = default_service_version
+        self.delete_retention_policy = delete_retention_policy
+        self.static_website = static_website
 
 
-class StorageServiceStats(msrest.serialization.Model):
+class StorageServiceStats(_serialization.Model):
     """Stats for the storage service.
 
     :ivar geo_replication: Geo-Replication information for the Secondary Storage Service.
     :vartype geo_replication: ~azure.storage.blob.models.GeoReplication
     """
 
     _attribute_map = {
-        'geo_replication': {'key': 'GeoReplication', 'type': 'GeoReplication'},
+        "geo_replication": {"key": "GeoReplication", "type": "GeoReplication"},
     }
 
-    def __init__(
-        self,
-        **kwargs
-    ):
+    def __init__(self, *, geo_replication: Optional["_models.GeoReplication"] = None, **kwargs):
         """
         :keyword geo_replication: Geo-Replication information for the Secondary Storage Service.
         :paramtype geo_replication: ~azure.storage.blob.models.GeoReplication
         """
-        super(StorageServiceStats, self).__init__(**kwargs)
-        self.geo_replication = kwargs.get('geo_replication', None)
+        super().__init__(**kwargs)
+        self.geo_replication = geo_replication
 
 
-class UserDelegationKey(msrest.serialization.Model):
+class UserDelegationKey(_serialization.Model):
     """A user delegation key.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar signed_oid: Required. The Azure Active Directory object ID in GUID format.
+    :ivar signed_oid: The Azure Active Directory object ID in GUID format. Required.
     :vartype signed_oid: str
-    :ivar signed_tid: Required. The Azure Active Directory tenant ID in GUID format.
+    :ivar signed_tid: The Azure Active Directory tenant ID in GUID format. Required.
     :vartype signed_tid: str
-    :ivar signed_start: Required. The date-time the key is active.
+    :ivar signed_start: The date-time the key is active. Required.
     :vartype signed_start: ~datetime.datetime
-    :ivar signed_expiry: Required. The date-time the key expires.
+    :ivar signed_expiry: The date-time the key expires. Required.
     :vartype signed_expiry: ~datetime.datetime
-    :ivar signed_service: Required. Abbreviation of the Azure Storage service that accepts the key.
+    :ivar signed_service: Abbreviation of the Azure Storage service that accepts the key. Required.
     :vartype signed_service: str
-    :ivar signed_version: Required. The service version that created the key.
+    :ivar signed_version: The service version that created the key. Required.
     :vartype signed_version: str
-    :ivar value: Required. The key as a base64 string.
+    :ivar value: The key as a base64 string. Required.
     :vartype value: str
     """
 
     _validation = {
-        'signed_oid': {'required': True},
-        'signed_tid': {'required': True},
-        'signed_start': {'required': True},
-        'signed_expiry': {'required': True},
-        'signed_service': {'required': True},
-        'signed_version': {'required': True},
-        'value': {'required': True},
+        "signed_oid": {"required": True},
+        "signed_tid": {"required": True},
+        "signed_start": {"required": True},
+        "signed_expiry": {"required": True},
+        "signed_service": {"required": True},
+        "signed_version": {"required": True},
+        "value": {"required": True},
     }
 
     _attribute_map = {
-        'signed_oid': {'key': 'SignedOid', 'type': 'str'},
-        'signed_tid': {'key': 'SignedTid', 'type': 'str'},
-        'signed_start': {'key': 'SignedStart', 'type': 'iso-8601'},
-        'signed_expiry': {'key': 'SignedExpiry', 'type': 'iso-8601'},
-        'signed_service': {'key': 'SignedService', 'type': 'str'},
-        'signed_version': {'key': 'SignedVersion', 'type': 'str'},
-        'value': {'key': 'Value', 'type': 'str'},
+        "signed_oid": {"key": "SignedOid", "type": "str"},
+        "signed_tid": {"key": "SignedTid", "type": "str"},
+        "signed_start": {"key": "SignedStart", "type": "iso-8601"},
+        "signed_expiry": {"key": "SignedExpiry", "type": "iso-8601"},
+        "signed_service": {"key": "SignedService", "type": "str"},
+        "signed_version": {"key": "SignedVersion", "type": "str"},
+        "value": {"key": "Value", "type": "str"},
     }
 
     def __init__(
         self,
+        *,
+        signed_oid: str,
+        signed_tid: str,
+        signed_start: datetime.datetime,
+        signed_expiry: datetime.datetime,
+        signed_service: str,
+        signed_version: str,
+        value: str,
         **kwargs
     ):
         """
-        :keyword signed_oid: Required. The Azure Active Directory object ID in GUID format.
+        :keyword signed_oid: The Azure Active Directory object ID in GUID format. Required.
         :paramtype signed_oid: str
-        :keyword signed_tid: Required. The Azure Active Directory tenant ID in GUID format.
+        :keyword signed_tid: The Azure Active Directory tenant ID in GUID format. Required.
         :paramtype signed_tid: str
-        :keyword signed_start: Required. The date-time the key is active.
+        :keyword signed_start: The date-time the key is active. Required.
         :paramtype signed_start: ~datetime.datetime
-        :keyword signed_expiry: Required. The date-time the key expires.
+        :keyword signed_expiry: The date-time the key expires. Required.
         :paramtype signed_expiry: ~datetime.datetime
-        :keyword signed_service: Required. Abbreviation of the Azure Storage service that accepts the
-         key.
+        :keyword signed_service: Abbreviation of the Azure Storage service that accepts the key.
+         Required.
         :paramtype signed_service: str
-        :keyword signed_version: Required. The service version that created the key.
+        :keyword signed_version: The service version that created the key. Required.
         :paramtype signed_version: str
-        :keyword value: Required. The key as a base64 string.
+        :keyword value: The key as a base64 string. Required.
         :paramtype value: str
         """
-        super(UserDelegationKey, self).__init__(**kwargs)
-        self.signed_oid = kwargs['signed_oid']
-        self.signed_tid = kwargs['signed_tid']
-        self.signed_start = kwargs['signed_start']
-        self.signed_expiry = kwargs['signed_expiry']
-        self.signed_service = kwargs['signed_service']
-        self.signed_version = kwargs['signed_version']
-        self.value = kwargs['value']
+        super().__init__(**kwargs)
+        self.signed_oid = signed_oid
+        self.signed_tid = signed_tid
+        self.signed_start = signed_start
+        self.signed_expiry = signed_expiry
+        self.signed_service = signed_service
+        self.signed_version = signed_version
+        self.value = value
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_models_py3.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,142 +1,136 @@
 # coding=utf-8
+# pylint: disable=too-many-lines
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 import datetime
-from typing import Any, Dict, List, Optional, Union
+import sys
+from typing import Any, Dict, List, Optional, TYPE_CHECKING, Union
 
-from azure.core.exceptions import HttpResponseError
-import msrest.serialization
+from .. import _serialization
 
-from ._azure_blob_storage_enums import *
+if TYPE_CHECKING:
+    # pylint: disable=unused-import,ungrouped-imports
+    from .. import models as _models
+if sys.version_info >= (3, 9):
+    from collections.abc import MutableMapping
+else:
+    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
+JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
 
 
-class AccessPolicy(msrest.serialization.Model):
+class AccessPolicy(_serialization.Model):
     """An Access policy.
 
     :ivar start: the date-time the policy is active.
     :vartype start: str
     :ivar expiry: the date-time the policy expires.
     :vartype expiry: str
     :ivar permission: the permissions for the acl policy.
     :vartype permission: str
     """
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'str'},
-        'expiry': {'key': 'Expiry', 'type': 'str'},
-        'permission': {'key': 'Permission', 'type': 'str'},
+        "start": {"key": "Start", "type": "str"},
+        "expiry": {"key": "Expiry", "type": "str"},
+        "permission": {"key": "Permission", "type": "str"},
     }
 
     def __init__(
-        self,
-        *,
-        start: Optional[str] = None,
-        expiry: Optional[str] = None,
-        permission: Optional[str] = None,
-        **kwargs
+        self, *, start: Optional[str] = None, expiry: Optional[str] = None, permission: Optional[str] = None, **kwargs
     ):
         """
         :keyword start: the date-time the policy is active.
         :paramtype start: str
         :keyword expiry: the date-time the policy expires.
         :paramtype expiry: str
         :keyword permission: the permissions for the acl policy.
         :paramtype permission: str
         """
-        super(AccessPolicy, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.start = start
         self.expiry = expiry
         self.permission = permission
 
 
-class AppendPositionAccessConditions(msrest.serialization.Model):
+class AppendPositionAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar max_size: Optional conditional header. The max length in bytes permitted for the append
      blob. If the Append Block operation would cause the blob to exceed that limit or if the blob
      size is already greater than the value specified in this header, the request will fail with
      MaxBlobSizeConditionNotMet error (HTTP status code 412 - Precondition Failed).
-    :vartype max_size: long
+    :vartype max_size: int
     :ivar append_position: Optional conditional header, used only for the Append Block operation. A
      number indicating the byte offset to compare. Append Block will succeed only if the append
      position is equal to this number. If it is not, the request will fail with the
      AppendPositionConditionNotMet error (HTTP status code 412 - Precondition Failed).
-    :vartype append_position: long
+    :vartype append_position: int
     """
 
     _attribute_map = {
-        'max_size': {'key': 'maxSize', 'type': 'long'},
-        'append_position': {'key': 'appendPosition', 'type': 'long'},
+        "max_size": {"key": "maxSize", "type": "int"},
+        "append_position": {"key": "appendPosition", "type": "int"},
     }
 
-    def __init__(
-        self,
-        *,
-        max_size: Optional[int] = None,
-        append_position: Optional[int] = None,
-        **kwargs
-    ):
+    def __init__(self, *, max_size: Optional[int] = None, append_position: Optional[int] = None, **kwargs):
         """
         :keyword max_size: Optional conditional header. The max length in bytes permitted for the
          append blob. If the Append Block operation would cause the blob to exceed that limit or if the
          blob size is already greater than the value specified in this header, the request will fail
          with MaxBlobSizeConditionNotMet error (HTTP status code 412 - Precondition Failed).
-        :paramtype max_size: long
+        :paramtype max_size: int
         :keyword append_position: Optional conditional header, used only for the Append Block
          operation. A number indicating the byte offset to compare. Append Block will succeed only if
          the append position is equal to this number. If it is not, the request will fail with the
          AppendPositionConditionNotMet error (HTTP status code 412 - Precondition Failed).
-        :paramtype append_position: long
+        :paramtype append_position: int
         """
-        super(AppendPositionAccessConditions, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.max_size = max_size
         self.append_position = append_position
 
 
-class ArrowConfiguration(msrest.serialization.Model):
+class ArrowConfiguration(_serialization.Model):
     """Groups the settings used for formatting the response if the response should be Arrow formatted.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar schema: Required.
     :vartype schema: list[~azure.storage.blob.models.ArrowField]
     """
 
     _validation = {
-        'schema': {'required': True},
+        "schema": {"required": True},
     }
 
     _attribute_map = {
-        'schema': {'key': 'Schema', 'type': '[ArrowField]', 'xml': {'name': 'Schema', 'wrapped': True, 'itemsName': 'Field'}},
-    }
-    _xml_map = {
-        'name': 'ArrowConfiguration'
+        "schema": {
+            "key": "Schema",
+            "type": "[ArrowField]",
+            "xml": {"name": "Schema", "wrapped": True, "itemsName": "Field"},
+        },
     }
+    _xml_map = {"name": "ArrowConfiguration"}
 
-    def __init__(
-        self,
-        *,
-        schema: List["ArrowField"],
-        **kwargs
-    ):
+    def __init__(self, *, schema: List["_models.ArrowField"], **kwargs):
         """
         :keyword schema: Required.
         :paramtype schema: list[~azure.storage.blob.models.ArrowField]
         """
-        super(ArrowConfiguration, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.schema = schema
 
 
-class ArrowField(msrest.serialization.Model):
+class ArrowField(_serialization.Model):
     """Groups settings regarding specific field of an arrow schema.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar type: Required.
     :vartype type: str
     :ivar name:
@@ -144,26 +138,24 @@
     :ivar precision:
     :vartype precision: int
     :ivar scale:
     :vartype scale: int
     """
 
     _validation = {
-        'type': {'required': True},
+        "type": {"required": True},
     }
 
     _attribute_map = {
-        'type': {'key': 'Type', 'type': 'str'},
-        'name': {'key': 'Name', 'type': 'str'},
-        'precision': {'key': 'Precision', 'type': 'int'},
-        'scale': {'key': 'Scale', 'type': 'int'},
-    }
-    _xml_map = {
-        'name': 'Field'
+        "type": {"key": "Type", "type": "str"},
+        "name": {"key": "Name", "type": "str"},
+        "precision": {"key": "Precision", "type": "int"},
+        "scale": {"key": "Scale", "type": "int"},
     }
+    _xml_map = {"name": "Field"}
 
     def __init__(
         self,
         *,
         type: str,
         name: Optional[str] = None,
         precision: Optional[int] = None,
@@ -176,227 +168,216 @@
         :keyword name:
         :paramtype name: str
         :keyword precision:
         :paramtype precision: int
         :keyword scale:
         :paramtype scale: int
         """
-        super(ArrowField, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.type = type
         self.name = name
         self.precision = precision
         self.scale = scale
 
 
-class BlobFlatListSegment(msrest.serialization.Model):
+class BlobFlatListSegment(_serialization.Model):
     """BlobFlatListSegment.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar blob_items: Required.
     :vartype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
     """
 
     _validation = {
-        'blob_items': {'required': True},
+        "blob_items": {"required": True},
     }
 
     _attribute_map = {
-        'blob_items': {'key': 'BlobItems', 'type': '[BlobItemInternal]'},
-    }
-    _xml_map = {
-        'name': 'Blobs'
+        "blob_items": {"key": "BlobItems", "type": "[BlobItemInternal]", "xml": {"itemsName": "Blob"}},
     }
+    _xml_map = {"name": "Blobs"}
 
-    def __init__(
-        self,
-        *,
-        blob_items: List["BlobItemInternal"],
-        **kwargs
-    ):
+    def __init__(self, *, blob_items: List["_models.BlobItemInternal"], **kwargs):
         """
         :keyword blob_items: Required.
         :paramtype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
         """
-        super(BlobFlatListSegment, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.blob_items = blob_items
 
 
-class BlobHierarchyListSegment(msrest.serialization.Model):
+class BlobHierarchyListSegment(_serialization.Model):
     """BlobHierarchyListSegment.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar blob_prefixes:
     :vartype blob_prefixes: list[~azure.storage.blob.models.BlobPrefix]
     :ivar blob_items: Required.
     :vartype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
     """
 
     _validation = {
-        'blob_items': {'required': True},
+        "blob_items": {"required": True},
     }
 
     _attribute_map = {
-        'blob_prefixes': {'key': 'BlobPrefixes', 'type': '[BlobPrefix]', 'xml': {'name': 'BlobPrefix'}},
-        'blob_items': {'key': 'BlobItems', 'type': '[BlobItemInternal]', 'xml': {'name': 'Blob', 'itemsName': 'Blob'}},
-    }
-    _xml_map = {
-        'name': 'Blobs'
+        "blob_prefixes": {"key": "BlobPrefixes", "type": "[BlobPrefix]", "xml": {"name": "BlobPrefix"}},
+        "blob_items": {"key": "BlobItems", "type": "[BlobItemInternal]", "xml": {"name": "Blob", "itemsName": "Blob"}},
     }
+    _xml_map = {"name": "Blobs"}
 
     def __init__(
         self,
         *,
-        blob_items: List["BlobItemInternal"],
-        blob_prefixes: Optional[List["BlobPrefix"]] = None,
+        blob_items: List["_models.BlobItemInternal"],
+        blob_prefixes: Optional[List["_models.BlobPrefix"]] = None,
         **kwargs
     ):
         """
         :keyword blob_prefixes:
         :paramtype blob_prefixes: list[~azure.storage.blob.models.BlobPrefix]
         :keyword blob_items: Required.
         :paramtype blob_items: list[~azure.storage.blob.models.BlobItemInternal]
         """
-        super(BlobHierarchyListSegment, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.blob_prefixes = blob_prefixes
         self.blob_items = blob_items
 
 
-class BlobHTTPHeaders(msrest.serialization.Model):
+class BlobHTTPHeaders(_serialization.Model):
     """Parameter group.
 
     :ivar blob_cache_control: Optional. Sets the blob's cache control. If specified, this property
      is stored with the blob and returned with a read request.
     :vartype blob_cache_control: str
     :ivar blob_content_type: Optional. Sets the blob's content type. If specified, this property is
      stored with the blob and returned with a read request.
     :vartype blob_content_type: str
     :ivar blob_content_md5: Optional. An MD5 hash of the blob content. Note that this hash is not
      validated, as the hashes for the individual blocks were validated when each was uploaded.
-    :vartype blob_content_md5: bytearray
+    :vartype blob_content_md5: bytes
     :ivar blob_content_encoding: Optional. Sets the blob's content encoding. If specified, this
      property is stored with the blob and returned with a read request.
     :vartype blob_content_encoding: str
     :ivar blob_content_language: Optional. Set the blob's content language. If specified, this
      property is stored with the blob and returned with a read request.
     :vartype blob_content_language: str
     :ivar blob_content_disposition: Optional. Sets the blob's Content-Disposition header.
     :vartype blob_content_disposition: str
     """
 
     _attribute_map = {
-        'blob_cache_control': {'key': 'blobCacheControl', 'type': 'str'},
-        'blob_content_type': {'key': 'blobContentType', 'type': 'str'},
-        'blob_content_md5': {'key': 'blobContentMD5', 'type': 'bytearray'},
-        'blob_content_encoding': {'key': 'blobContentEncoding', 'type': 'str'},
-        'blob_content_language': {'key': 'blobContentLanguage', 'type': 'str'},
-        'blob_content_disposition': {'key': 'blobContentDisposition', 'type': 'str'},
+        "blob_cache_control": {"key": "blobCacheControl", "type": "str"},
+        "blob_content_type": {"key": "blobContentType", "type": "str"},
+        "blob_content_md5": {"key": "blobContentMD5", "type": "bytearray"},
+        "blob_content_encoding": {"key": "blobContentEncoding", "type": "str"},
+        "blob_content_language": {"key": "blobContentLanguage", "type": "str"},
+        "blob_content_disposition": {"key": "blobContentDisposition", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         blob_cache_control: Optional[str] = None,
         blob_content_type: Optional[str] = None,
-        blob_content_md5: Optional[bytearray] = None,
+        blob_content_md5: Optional[bytes] = None,
         blob_content_encoding: Optional[str] = None,
         blob_content_language: Optional[str] = None,
         blob_content_disposition: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword blob_cache_control: Optional. Sets the blob's cache control. If specified, this
          property is stored with the blob and returned with a read request.
         :paramtype blob_cache_control: str
         :keyword blob_content_type: Optional. Sets the blob's content type. If specified, this property
          is stored with the blob and returned with a read request.
         :paramtype blob_content_type: str
         :keyword blob_content_md5: Optional. An MD5 hash of the blob content. Note that this hash is
          not validated, as the hashes for the individual blocks were validated when each was uploaded.
-        :paramtype blob_content_md5: bytearray
+        :paramtype blob_content_md5: bytes
         :keyword blob_content_encoding: Optional. Sets the blob's content encoding. If specified, this
          property is stored with the blob and returned with a read request.
         :paramtype blob_content_encoding: str
         :keyword blob_content_language: Optional. Set the blob's content language. If specified, this
          property is stored with the blob and returned with a read request.
         :paramtype blob_content_language: str
         :keyword blob_content_disposition: Optional. Sets the blob's Content-Disposition header.
         :paramtype blob_content_disposition: str
         """
-        super(BlobHTTPHeaders, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.blob_cache_control = blob_cache_control
         self.blob_content_type = blob_content_type
         self.blob_content_md5 = blob_content_md5
         self.blob_content_encoding = blob_content_encoding
         self.blob_content_language = blob_content_language
         self.blob_content_disposition = blob_content_disposition
 
 
-class BlobItemInternal(msrest.serialization.Model):
+class BlobItemInternal(_serialization.Model):
     """An Azure Storage blob.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: ~azure.storage.blob.models.BlobName
     :ivar deleted: Required.
     :vartype deleted: bool
     :ivar snapshot: Required.
     :vartype snapshot: str
     :ivar version_id:
     :vartype version_id: str
     :ivar is_current_version:
     :vartype is_current_version: bool
-    :ivar properties: Required. Properties of a blob.
+    :ivar properties: Properties of a blob. Required.
     :vartype properties: ~azure.storage.blob.models.BlobPropertiesInternal
     :ivar metadata:
     :vartype metadata: ~azure.storage.blob.models.BlobMetadata
     :ivar blob_tags: Blob tags.
     :vartype blob_tags: ~azure.storage.blob.models.BlobTags
     :ivar has_versions_only:
     :vartype has_versions_only: bool
     :ivar object_replication_metadata: Dictionary of :code:`<string>`.
     :vartype object_replication_metadata: dict[str, str]
     """
 
     _validation = {
-        'name': {'required': True},
-        'deleted': {'required': True},
-        'snapshot': {'required': True},
-        'properties': {'required': True},
+        "name": {"required": True},
+        "deleted": {"required": True},
+        "snapshot": {"required": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'BlobName'},
-        'deleted': {'key': 'Deleted', 'type': 'bool'},
-        'snapshot': {'key': 'Snapshot', 'type': 'str'},
-        'version_id': {'key': 'VersionId', 'type': 'str'},
-        'is_current_version': {'key': 'IsCurrentVersion', 'type': 'bool'},
-        'properties': {'key': 'Properties', 'type': 'BlobPropertiesInternal'},
-        'metadata': {'key': 'Metadata', 'type': 'BlobMetadata'},
-        'blob_tags': {'key': 'BlobTags', 'type': 'BlobTags'},
-        'has_versions_only': {'key': 'HasVersionsOnly', 'type': 'bool'},
-        'object_replication_metadata': {'key': 'OrMetadata', 'type': '{str}'},
-    }
-    _xml_map = {
-        'name': 'Blob'
+        "name": {"key": "Name", "type": "BlobName"},
+        "deleted": {"key": "Deleted", "type": "bool"},
+        "snapshot": {"key": "Snapshot", "type": "str"},
+        "version_id": {"key": "VersionId", "type": "str"},
+        "is_current_version": {"key": "IsCurrentVersion", "type": "bool"},
+        "properties": {"key": "Properties", "type": "BlobPropertiesInternal"},
+        "metadata": {"key": "Metadata", "type": "BlobMetadata"},
+        "blob_tags": {"key": "BlobTags", "type": "BlobTags"},
+        "has_versions_only": {"key": "HasVersionsOnly", "type": "bool"},
+        "object_replication_metadata": {"key": "OrMetadata", "type": "{str}"},
     }
+    _xml_map = {"name": "Blob"}
 
     def __init__(
         self,
         *,
-        name: "BlobName",
+        name: "_models.BlobName",
         deleted: bool,
         snapshot: str,
-        properties: "BlobPropertiesInternal",
+        properties: "_models.BlobPropertiesInternal",
         version_id: Optional[str] = None,
         is_current_version: Optional[bool] = None,
-        metadata: Optional["BlobMetadata"] = None,
-        blob_tags: Optional["BlobTags"] = None,
+        metadata: Optional["_models.BlobMetadata"] = None,
+        blob_tags: Optional["_models.BlobTags"] = None,
         has_versions_only: Optional[bool] = None,
         object_replication_metadata: Optional[Dict[str, str]] = None,
         **kwargs
     ):
         """
         :keyword name: Required.
         :paramtype name: ~azure.storage.blob.models.BlobName
@@ -404,177 +385,160 @@
         :paramtype deleted: bool
         :keyword snapshot: Required.
         :paramtype snapshot: str
         :keyword version_id:
         :paramtype version_id: str
         :keyword is_current_version:
         :paramtype is_current_version: bool
-        :keyword properties: Required. Properties of a blob.
+        :keyword properties: Properties of a blob. Required.
         :paramtype properties: ~azure.storage.blob.models.BlobPropertiesInternal
         :keyword metadata:
         :paramtype metadata: ~azure.storage.blob.models.BlobMetadata
         :keyword blob_tags: Blob tags.
         :paramtype blob_tags: ~azure.storage.blob.models.BlobTags
         :keyword has_versions_only:
         :paramtype has_versions_only: bool
         :keyword object_replication_metadata: Dictionary of :code:`<string>`.
         :paramtype object_replication_metadata: dict[str, str]
         """
-        super(BlobItemInternal, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.name = name
         self.deleted = deleted
         self.snapshot = snapshot
         self.version_id = version_id
         self.is_current_version = is_current_version
         self.properties = properties
         self.metadata = metadata
         self.blob_tags = blob_tags
         self.has_versions_only = has_versions_only
         self.object_replication_metadata = object_replication_metadata
 
 
-class BlobMetadata(msrest.serialization.Model):
+class BlobMetadata(_serialization.Model):
     """BlobMetadata.
 
     :ivar additional_properties: Unmatched properties from the message are deserialized to this
      collection.
     :vartype additional_properties: dict[str, str]
     :ivar encrypted:
     :vartype encrypted: str
     """
 
     _attribute_map = {
-        'additional_properties': {'key': '', 'type': '{str}'},
-        'encrypted': {'key': 'Encrypted', 'type': 'str', 'xml': {'attr': True}},
-    }
-    _xml_map = {
-        'name': 'Metadata'
+        "additional_properties": {"key": "", "type": "{str}"},
+        "encrypted": {"key": "Encrypted", "type": "str", "xml": {"attr": True}},
     }
+    _xml_map = {"name": "Metadata"}
 
     def __init__(
-        self,
-        *,
-        additional_properties: Optional[Dict[str, str]] = None,
-        encrypted: Optional[str] = None,
-        **kwargs
+        self, *, additional_properties: Optional[Dict[str, str]] = None, encrypted: Optional[str] = None, **kwargs
     ):
         """
         :keyword additional_properties: Unmatched properties from the message are deserialized to this
          collection.
         :paramtype additional_properties: dict[str, str]
         :keyword encrypted:
         :paramtype encrypted: str
         """
-        super(BlobMetadata, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.additional_properties = additional_properties
         self.encrypted = encrypted
 
 
-class BlobName(msrest.serialization.Model):
+class BlobName(_serialization.Model):
     """BlobName.
 
     :ivar encoded: Indicates if the blob name is encoded.
     :vartype encoded: bool
     :ivar content: The name of the blob.
     :vartype content: str
     """
 
     _attribute_map = {
-        'encoded': {'key': 'Encoded', 'type': 'bool', 'xml': {'name': 'Encoded', 'attr': True}},
-        'content': {'key': 'content', 'type': 'str', 'xml': {'text': True}},
+        "encoded": {"key": "Encoded", "type": "bool", "xml": {"name": "Encoded", "attr": True}},
+        "content": {"key": "content", "type": "str", "xml": {"text": True}},
     }
 
-    def __init__(
-        self,
-        *,
-        encoded: Optional[bool] = None,
-        content: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, encoded: Optional[bool] = None, content: Optional[str] = None, **kwargs):
         """
         :keyword encoded: Indicates if the blob name is encoded.
         :paramtype encoded: bool
         :keyword content: The name of the blob.
         :paramtype content: str
         """
-        super(BlobName, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.encoded = encoded
         self.content = content
 
 
-class BlobPrefix(msrest.serialization.Model):
+class BlobPrefix(_serialization.Model):
     """BlobPrefix.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: ~azure.storage.blob.models.BlobName
     """
 
     _validation = {
-        'name': {'required': True},
+        "name": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'BlobName'},
+        "name": {"key": "Name", "type": "BlobName"},
     }
 
-    def __init__(
-        self,
-        *,
-        name: "BlobName",
-        **kwargs
-    ):
+    def __init__(self, *, name: "_models.BlobName", **kwargs):
         """
         :keyword name: Required.
         :paramtype name: ~azure.storage.blob.models.BlobName
         """
-        super(BlobPrefix, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.name = name
 
 
-class BlobPropertiesInternal(msrest.serialization.Model):
+class BlobPropertiesInternal(_serialization.Model):  # pylint: disable=too-many-instance-attributes
     """Properties of a blob.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar creation_time:
     :vartype creation_time: ~datetime.datetime
     :ivar last_modified: Required.
     :vartype last_modified: ~datetime.datetime
     :ivar etag: Required.
     :vartype etag: str
     :ivar content_length: Size in bytes.
-    :vartype content_length: long
+    :vartype content_length: int
     :ivar content_type:
     :vartype content_type: str
     :ivar content_encoding:
     :vartype content_encoding: str
     :ivar content_language:
     :vartype content_language: str
     :ivar content_md5:
-    :vartype content_md5: bytearray
+    :vartype content_md5: bytes
     :ivar content_disposition:
     :vartype content_disposition: str
     :ivar cache_control:
     :vartype cache_control: str
     :ivar blob_sequence_number:
-    :vartype blob_sequence_number: long
-    :ivar blob_type: Possible values include: "BlockBlob", "PageBlob", "AppendBlob".
+    :vartype blob_sequence_number: int
+    :ivar blob_type: Known values are: "BlockBlob", "PageBlob", and "AppendBlob".
     :vartype blob_type: str or ~azure.storage.blob.models.BlobType
-    :ivar lease_status: Possible values include: "locked", "unlocked".
+    :ivar lease_status: Known values are: "locked" and "unlocked".
     :vartype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-    :ivar lease_state: Possible values include: "available", "leased", "expired", "breaking",
+    :ivar lease_state: Known values are: "available", "leased", "expired", "breaking", and
      "broken".
     :vartype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-    :ivar lease_duration: Possible values include: "infinite", "fixed".
+    :ivar lease_duration: Known values are: "infinite" and "fixed".
     :vartype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
     :ivar copy_id:
     :vartype copy_id: str
-    :ivar copy_status: Possible values include: "pending", "success", "aborted", "failed".
+    :ivar copy_status: Known values are: "pending", "success", "aborted", and "failed".
     :vartype copy_status: str or ~azure.storage.blob.models.CopyStatusType
     :ivar copy_source:
     :vartype copy_source: str
     :ivar copy_progress:
     :vartype copy_progress: str
     :ivar copy_completion_time:
     :vartype copy_completion_time: ~datetime.datetime
@@ -586,20 +550,20 @@
     :vartype incremental_copy: bool
     :ivar destination_snapshot:
     :vartype destination_snapshot: str
     :ivar deleted_time:
     :vartype deleted_time: ~datetime.datetime
     :ivar remaining_retention_days:
     :vartype remaining_retention_days: int
-    :ivar access_tier: Possible values include: "P4", "P6", "P10", "P15", "P20", "P30", "P40",
-     "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive".
+    :ivar access_tier: Known values are: "P4", "P6", "P10", "P15", "P20", "P30", "P40", "P50",
+     "P60", "P70", "P80", "Hot", "Cool", "Archive", "Premium", and "Cold".
     :vartype access_tier: str or ~azure.storage.blob.models.AccessTier
     :ivar access_tier_inferred:
     :vartype access_tier_inferred: bool
-    :ivar archive_status: Possible values include: "rehydrate-pending-to-hot",
+    :ivar archive_status: Known values are: "rehydrate-pending-to-hot" and
      "rehydrate-pending-to-cool".
     :vartype archive_status: str or ~azure.storage.blob.models.ArchiveStatus
     :ivar customer_provided_key_sha256:
     :vartype customer_provided_key_sha256: str
     :ivar encryption_scope: The name of the encryption scope under which the blob is encrypted.
     :vartype encryption_scope: str
     :ivar access_tier_change_time:
@@ -607,158 +571,156 @@
     :ivar tag_count:
     :vartype tag_count: int
     :ivar expires_on:
     :vartype expires_on: ~datetime.datetime
     :ivar is_sealed:
     :vartype is_sealed: bool
     :ivar rehydrate_priority: If an object is in rehydrate pending state then this header is
-     returned with priority of rehydrate. Valid values are High and Standard. Possible values
-     include: "High", "Standard".
+     returned with priority of rehydrate. Valid values are High and Standard. Known values are:
+     "High" and "Standard".
     :vartype rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
     :ivar last_accessed_on:
     :vartype last_accessed_on: ~datetime.datetime
     :ivar immutability_policy_expires_on:
     :vartype immutability_policy_expires_on: ~datetime.datetime
-    :ivar immutability_policy_mode: Possible values include: "Mutable", "Unlocked", "Locked".
+    :ivar immutability_policy_mode: Known values are: "Mutable", "Unlocked", and "Locked".
     :vartype immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
     :ivar legal_hold:
     :vartype legal_hold: bool
     """
 
     _validation = {
-        'last_modified': {'required': True},
-        'etag': {'required': True},
+        "last_modified": {"required": True},
+        "etag": {"required": True},
     }
 
     _attribute_map = {
-        'creation_time': {'key': 'Creation-Time', 'type': 'rfc-1123'},
-        'last_modified': {'key': 'Last-Modified', 'type': 'rfc-1123'},
-        'etag': {'key': 'Etag', 'type': 'str'},
-        'content_length': {'key': 'Content-Length', 'type': 'long'},
-        'content_type': {'key': 'Content-Type', 'type': 'str'},
-        'content_encoding': {'key': 'Content-Encoding', 'type': 'str'},
-        'content_language': {'key': 'Content-Language', 'type': 'str'},
-        'content_md5': {'key': 'Content-MD5', 'type': 'bytearray'},
-        'content_disposition': {'key': 'Content-Disposition', 'type': 'str'},
-        'cache_control': {'key': 'Cache-Control', 'type': 'str'},
-        'blob_sequence_number': {'key': 'x-ms-blob-sequence-number', 'type': 'long'},
-        'blob_type': {'key': 'BlobType', 'type': 'str'},
-        'lease_status': {'key': 'LeaseStatus', 'type': 'str'},
-        'lease_state': {'key': 'LeaseState', 'type': 'str'},
-        'lease_duration': {'key': 'LeaseDuration', 'type': 'str'},
-        'copy_id': {'key': 'CopyId', 'type': 'str'},
-        'copy_status': {'key': 'CopyStatus', 'type': 'str'},
-        'copy_source': {'key': 'CopySource', 'type': 'str'},
-        'copy_progress': {'key': 'CopyProgress', 'type': 'str'},
-        'copy_completion_time': {'key': 'CopyCompletionTime', 'type': 'rfc-1123'},
-        'copy_status_description': {'key': 'CopyStatusDescription', 'type': 'str'},
-        'server_encrypted': {'key': 'ServerEncrypted', 'type': 'bool'},
-        'incremental_copy': {'key': 'IncrementalCopy', 'type': 'bool'},
-        'destination_snapshot': {'key': 'DestinationSnapshot', 'type': 'str'},
-        'deleted_time': {'key': 'DeletedTime', 'type': 'rfc-1123'},
-        'remaining_retention_days': {'key': 'RemainingRetentionDays', 'type': 'int'},
-        'access_tier': {'key': 'AccessTier', 'type': 'str'},
-        'access_tier_inferred': {'key': 'AccessTierInferred', 'type': 'bool'},
-        'archive_status': {'key': 'ArchiveStatus', 'type': 'str'},
-        'customer_provided_key_sha256': {'key': 'CustomerProvidedKeySha256', 'type': 'str'},
-        'encryption_scope': {'key': 'EncryptionScope', 'type': 'str'},
-        'access_tier_change_time': {'key': 'AccessTierChangeTime', 'type': 'rfc-1123'},
-        'tag_count': {'key': 'TagCount', 'type': 'int'},
-        'expires_on': {'key': 'Expiry-Time', 'type': 'rfc-1123'},
-        'is_sealed': {'key': 'Sealed', 'type': 'bool'},
-        'rehydrate_priority': {'key': 'RehydratePriority', 'type': 'str'},
-        'last_accessed_on': {'key': 'LastAccessTime', 'type': 'rfc-1123'},
-        'immutability_policy_expires_on': {'key': 'ImmutabilityPolicyUntilDate', 'type': 'rfc-1123'},
-        'immutability_policy_mode': {'key': 'ImmutabilityPolicyMode', 'type': 'str'},
-        'legal_hold': {'key': 'LegalHold', 'type': 'bool'},
-    }
-    _xml_map = {
-        'name': 'Properties'
+        "creation_time": {"key": "Creation-Time", "type": "rfc-1123"},
+        "last_modified": {"key": "Last-Modified", "type": "rfc-1123"},
+        "etag": {"key": "Etag", "type": "str"},
+        "content_length": {"key": "Content-Length", "type": "int"},
+        "content_type": {"key": "Content-Type", "type": "str"},
+        "content_encoding": {"key": "Content-Encoding", "type": "str"},
+        "content_language": {"key": "Content-Language", "type": "str"},
+        "content_md5": {"key": "Content-MD5", "type": "bytearray"},
+        "content_disposition": {"key": "Content-Disposition", "type": "str"},
+        "cache_control": {"key": "Cache-Control", "type": "str"},
+        "blob_sequence_number": {"key": "x-ms-blob-sequence-number", "type": "int"},
+        "blob_type": {"key": "BlobType", "type": "str"},
+        "lease_status": {"key": "LeaseStatus", "type": "str"},
+        "lease_state": {"key": "LeaseState", "type": "str"},
+        "lease_duration": {"key": "LeaseDuration", "type": "str"},
+        "copy_id": {"key": "CopyId", "type": "str"},
+        "copy_status": {"key": "CopyStatus", "type": "str"},
+        "copy_source": {"key": "CopySource", "type": "str"},
+        "copy_progress": {"key": "CopyProgress", "type": "str"},
+        "copy_completion_time": {"key": "CopyCompletionTime", "type": "rfc-1123"},
+        "copy_status_description": {"key": "CopyStatusDescription", "type": "str"},
+        "server_encrypted": {"key": "ServerEncrypted", "type": "bool"},
+        "incremental_copy": {"key": "IncrementalCopy", "type": "bool"},
+        "destination_snapshot": {"key": "DestinationSnapshot", "type": "str"},
+        "deleted_time": {"key": "DeletedTime", "type": "rfc-1123"},
+        "remaining_retention_days": {"key": "RemainingRetentionDays", "type": "int"},
+        "access_tier": {"key": "AccessTier", "type": "str"},
+        "access_tier_inferred": {"key": "AccessTierInferred", "type": "bool"},
+        "archive_status": {"key": "ArchiveStatus", "type": "str"},
+        "customer_provided_key_sha256": {"key": "CustomerProvidedKeySha256", "type": "str"},
+        "encryption_scope": {"key": "EncryptionScope", "type": "str"},
+        "access_tier_change_time": {"key": "AccessTierChangeTime", "type": "rfc-1123"},
+        "tag_count": {"key": "TagCount", "type": "int"},
+        "expires_on": {"key": "Expiry-Time", "type": "rfc-1123"},
+        "is_sealed": {"key": "Sealed", "type": "bool"},
+        "rehydrate_priority": {"key": "RehydratePriority", "type": "str"},
+        "last_accessed_on": {"key": "LastAccessTime", "type": "rfc-1123"},
+        "immutability_policy_expires_on": {"key": "ImmutabilityPolicyUntilDate", "type": "rfc-1123"},
+        "immutability_policy_mode": {"key": "ImmutabilityPolicyMode", "type": "str"},
+        "legal_hold": {"key": "LegalHold", "type": "bool"},
     }
+    _xml_map = {"name": "Properties"}
 
-    def __init__(
+    def __init__(  # pylint: disable=too-many-locals
         self,
         *,
         last_modified: datetime.datetime,
         etag: str,
         creation_time: Optional[datetime.datetime] = None,
         content_length: Optional[int] = None,
         content_type: Optional[str] = None,
         content_encoding: Optional[str] = None,
         content_language: Optional[str] = None,
-        content_md5: Optional[bytearray] = None,
+        content_md5: Optional[bytes] = None,
         content_disposition: Optional[str] = None,
         cache_control: Optional[str] = None,
         blob_sequence_number: Optional[int] = None,
-        blob_type: Optional[Union[str, "BlobType"]] = None,
-        lease_status: Optional[Union[str, "LeaseStatusType"]] = None,
-        lease_state: Optional[Union[str, "LeaseStateType"]] = None,
-        lease_duration: Optional[Union[str, "LeaseDurationType"]] = None,
+        blob_type: Optional[Union[str, "_models.BlobType"]] = None,
+        lease_status: Optional[Union[str, "_models.LeaseStatusType"]] = None,
+        lease_state: Optional[Union[str, "_models.LeaseStateType"]] = None,
+        lease_duration: Optional[Union[str, "_models.LeaseDurationType"]] = None,
         copy_id: Optional[str] = None,
-        copy_status: Optional[Union[str, "CopyStatusType"]] = None,
+        copy_status: Optional[Union[str, "_models.CopyStatusType"]] = None,
         copy_source: Optional[str] = None,
         copy_progress: Optional[str] = None,
         copy_completion_time: Optional[datetime.datetime] = None,
         copy_status_description: Optional[str] = None,
         server_encrypted: Optional[bool] = None,
         incremental_copy: Optional[bool] = None,
         destination_snapshot: Optional[str] = None,
         deleted_time: Optional[datetime.datetime] = None,
         remaining_retention_days: Optional[int] = None,
-        access_tier: Optional[Union[str, "AccessTier"]] = None,
+        access_tier: Optional[Union[str, "_models.AccessTier"]] = None,
         access_tier_inferred: Optional[bool] = None,
-        archive_status: Optional[Union[str, "ArchiveStatus"]] = None,
+        archive_status: Optional[Union[str, "_models.ArchiveStatus"]] = None,
         customer_provided_key_sha256: Optional[str] = None,
         encryption_scope: Optional[str] = None,
         access_tier_change_time: Optional[datetime.datetime] = None,
         tag_count: Optional[int] = None,
         expires_on: Optional[datetime.datetime] = None,
         is_sealed: Optional[bool] = None,
-        rehydrate_priority: Optional[Union[str, "RehydratePriority"]] = None,
+        rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
         last_accessed_on: Optional[datetime.datetime] = None,
         immutability_policy_expires_on: Optional[datetime.datetime] = None,
-        immutability_policy_mode: Optional[Union[str, "BlobImmutabilityPolicyMode"]] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
         legal_hold: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword creation_time:
         :paramtype creation_time: ~datetime.datetime
         :keyword last_modified: Required.
         :paramtype last_modified: ~datetime.datetime
         :keyword etag: Required.
         :paramtype etag: str
         :keyword content_length: Size in bytes.
-        :paramtype content_length: long
+        :paramtype content_length: int
         :keyword content_type:
         :paramtype content_type: str
         :keyword content_encoding:
         :paramtype content_encoding: str
         :keyword content_language:
         :paramtype content_language: str
         :keyword content_md5:
-        :paramtype content_md5: bytearray
+        :paramtype content_md5: bytes
         :keyword content_disposition:
         :paramtype content_disposition: str
         :keyword cache_control:
         :paramtype cache_control: str
         :keyword blob_sequence_number:
-        :paramtype blob_sequence_number: long
-        :keyword blob_type: Possible values include: "BlockBlob", "PageBlob", "AppendBlob".
+        :paramtype blob_sequence_number: int
+        :keyword blob_type: Known values are: "BlockBlob", "PageBlob", and "AppendBlob".
         :paramtype blob_type: str or ~azure.storage.blob.models.BlobType
-        :keyword lease_status: Possible values include: "locked", "unlocked".
+        :keyword lease_status: Known values are: "locked" and "unlocked".
         :paramtype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-        :keyword lease_state: Possible values include: "available", "leased", "expired", "breaking",
+        :keyword lease_state: Known values are: "available", "leased", "expired", "breaking", and
          "broken".
         :paramtype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-        :keyword lease_duration: Possible values include: "infinite", "fixed".
+        :keyword lease_duration: Known values are: "infinite" and "fixed".
         :paramtype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
         :keyword copy_id:
         :paramtype copy_id: str
-        :keyword copy_status: Possible values include: "pending", "success", "aborted", "failed".
+        :keyword copy_status: Known values are: "pending", "success", "aborted", and "failed".
         :paramtype copy_status: str or ~azure.storage.blob.models.CopyStatusType
         :keyword copy_source:
         :paramtype copy_source: str
         :keyword copy_progress:
         :paramtype copy_progress: str
         :keyword copy_completion_time:
         :paramtype copy_completion_time: ~datetime.datetime
@@ -770,20 +732,20 @@
         :paramtype incremental_copy: bool
         :keyword destination_snapshot:
         :paramtype destination_snapshot: str
         :keyword deleted_time:
         :paramtype deleted_time: ~datetime.datetime
         :keyword remaining_retention_days:
         :paramtype remaining_retention_days: int
-        :keyword access_tier: Possible values include: "P4", "P6", "P10", "P15", "P20", "P30", "P40",
-         "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive".
+        :keyword access_tier: Known values are: "P4", "P6", "P10", "P15", "P20", "P30", "P40", "P50",
+         "P60", "P70", "P80", "Hot", "Cool", "Archive", "Premium", and "Cold".
         :paramtype access_tier: str or ~azure.storage.blob.models.AccessTier
         :keyword access_tier_inferred:
         :paramtype access_tier_inferred: bool
-        :keyword archive_status: Possible values include: "rehydrate-pending-to-hot",
+        :keyword archive_status: Known values are: "rehydrate-pending-to-hot" and
          "rehydrate-pending-to-cool".
         :paramtype archive_status: str or ~azure.storage.blob.models.ArchiveStatus
         :keyword customer_provided_key_sha256:
         :paramtype customer_provided_key_sha256: str
         :keyword encryption_scope: The name of the encryption scope under which the blob is encrypted.
         :paramtype encryption_scope: str
         :keyword access_tier_change_time:
@@ -791,28 +753,28 @@
         :keyword tag_count:
         :paramtype tag_count: int
         :keyword expires_on:
         :paramtype expires_on: ~datetime.datetime
         :keyword is_sealed:
         :paramtype is_sealed: bool
         :keyword rehydrate_priority: If an object is in rehydrate pending state then this header is
-         returned with priority of rehydrate. Valid values are High and Standard. Possible values
-         include: "High", "Standard".
+         returned with priority of rehydrate. Valid values are High and Standard. Known values are:
+         "High" and "Standard".
         :paramtype rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :keyword last_accessed_on:
         :paramtype last_accessed_on: ~datetime.datetime
         :keyword immutability_policy_expires_on:
         :paramtype immutability_policy_expires_on: ~datetime.datetime
-        :keyword immutability_policy_mode: Possible values include: "Mutable", "Unlocked", "Locked".
+        :keyword immutability_policy_mode: Known values are: "Mutable", "Unlocked", and "Locked".
         :paramtype immutability_policy_mode: str or
          ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :keyword legal_hold:
         :paramtype legal_hold: bool
         """
-        super(BlobPropertiesInternal, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.creation_time = creation_time
         self.last_modified = last_modified
         self.etag = etag
         self.content_length = content_length
         self.content_type = content_type
         self.content_encoding = content_encoding
         self.content_language = content_language
@@ -847,180 +809,161 @@
         self.rehydrate_priority = rehydrate_priority
         self.last_accessed_on = last_accessed_on
         self.immutability_policy_expires_on = immutability_policy_expires_on
         self.immutability_policy_mode = immutability_policy_mode
         self.legal_hold = legal_hold
 
 
-class BlobTag(msrest.serialization.Model):
+class BlobTag(_serialization.Model):
     """BlobTag.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar key: Required.
     :vartype key: str
     :ivar value: Required.
     :vartype value: str
     """
 
     _validation = {
-        'key': {'required': True},
-        'value': {'required': True},
+        "key": {"required": True},
+        "value": {"required": True},
     }
 
     _attribute_map = {
-        'key': {'key': 'Key', 'type': 'str'},
-        'value': {'key': 'Value', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'Tag'
+        "key": {"key": "Key", "type": "str"},
+        "value": {"key": "Value", "type": "str"},
     }
+    _xml_map = {"name": "Tag"}
 
-    def __init__(
-        self,
-        *,
-        key: str,
-        value: str,
-        **kwargs
-    ):
+    def __init__(self, *, key: str, value: str, **kwargs):
         """
         :keyword key: Required.
         :paramtype key: str
         :keyword value: Required.
         :paramtype value: str
         """
-        super(BlobTag, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.key = key
         self.value = value
 
 
-class BlobTags(msrest.serialization.Model):
+class BlobTags(_serialization.Model):
     """Blob tags.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar blob_tag_set: Required.
     :vartype blob_tag_set: list[~azure.storage.blob.models.BlobTag]
     """
 
     _validation = {
-        'blob_tag_set': {'required': True},
+        "blob_tag_set": {"required": True},
     }
 
     _attribute_map = {
-        'blob_tag_set': {'key': 'BlobTagSet', 'type': '[BlobTag]', 'xml': {'name': 'TagSet', 'wrapped': True, 'itemsName': 'Tag'}},
-    }
-    _xml_map = {
-        'name': 'Tags'
+        "blob_tag_set": {
+            "key": "BlobTagSet",
+            "type": "[BlobTag]",
+            "xml": {"name": "TagSet", "wrapped": True, "itemsName": "Tag"},
+        },
     }
+    _xml_map = {"name": "Tags"}
 
-    def __init__(
-        self,
-        *,
-        blob_tag_set: List["BlobTag"],
-        **kwargs
-    ):
+    def __init__(self, *, blob_tag_set: List["_models.BlobTag"], **kwargs):
         """
         :keyword blob_tag_set: Required.
         :paramtype blob_tag_set: list[~azure.storage.blob.models.BlobTag]
         """
-        super(BlobTags, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.blob_tag_set = blob_tag_set
 
 
-class Block(msrest.serialization.Model):
+class Block(_serialization.Model):
     """Represents a single block in a block blob.  It describes the block's ID and size.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar name: Required. The base64 encoded block ID.
+    :ivar name: The base64 encoded block ID. Required.
     :vartype name: str
-    :ivar size: Required. The block size in bytes.
-    :vartype size: long
+    :ivar size: The block size in bytes. Required.
+    :vartype size: int
     """
 
     _validation = {
-        'name': {'required': True},
-        'size': {'required': True},
+        "name": {"required": True},
+        "size": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'str'},
-        'size': {'key': 'Size', 'type': 'long'},
+        "name": {"key": "Name", "type": "str"},
+        "size": {"key": "Size", "type": "int"},
     }
 
-    def __init__(
-        self,
-        *,
-        name: str,
-        size: int,
-        **kwargs
-    ):
+    def __init__(self, *, name: str, size: int, **kwargs):
         """
-        :keyword name: Required. The base64 encoded block ID.
+        :keyword name: The base64 encoded block ID. Required.
         :paramtype name: str
-        :keyword size: Required. The block size in bytes.
-        :paramtype size: long
+        :keyword size: The block size in bytes. Required.
+        :paramtype size: int
         """
-        super(Block, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.name = name
         self.size = size
 
 
-class BlockList(msrest.serialization.Model):
+class BlockList(_serialization.Model):
     """BlockList.
 
     :ivar committed_blocks:
     :vartype committed_blocks: list[~azure.storage.blob.models.Block]
     :ivar uncommitted_blocks:
     :vartype uncommitted_blocks: list[~azure.storage.blob.models.Block]
     """
 
     _attribute_map = {
-        'committed_blocks': {'key': 'CommittedBlocks', 'type': '[Block]', 'xml': {'wrapped': True}},
-        'uncommitted_blocks': {'key': 'UncommittedBlocks', 'type': '[Block]', 'xml': {'wrapped': True}},
+        "committed_blocks": {"key": "CommittedBlocks", "type": "[Block]", "xml": {"wrapped": True}},
+        "uncommitted_blocks": {"key": "UncommittedBlocks", "type": "[Block]", "xml": {"wrapped": True}},
     }
 
     def __init__(
         self,
         *,
-        committed_blocks: Optional[List["Block"]] = None,
-        uncommitted_blocks: Optional[List["Block"]] = None,
+        committed_blocks: Optional[List["_models.Block"]] = None,
+        uncommitted_blocks: Optional[List["_models.Block"]] = None,
         **kwargs
     ):
         """
         :keyword committed_blocks:
         :paramtype committed_blocks: list[~azure.storage.blob.models.Block]
         :keyword uncommitted_blocks:
         :paramtype uncommitted_blocks: list[~azure.storage.blob.models.Block]
         """
-        super(BlockList, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.committed_blocks = committed_blocks
         self.uncommitted_blocks = uncommitted_blocks
 
 
-class BlockLookupList(msrest.serialization.Model):
+class BlockLookupList(_serialization.Model):
     """BlockLookupList.
 
     :ivar committed:
     :vartype committed: list[str]
     :ivar uncommitted:
     :vartype uncommitted: list[str]
     :ivar latest:
     :vartype latest: list[str]
     """
 
     _attribute_map = {
-        'committed': {'key': 'Committed', 'type': '[str]', 'xml': {'itemsName': 'Committed'}},
-        'uncommitted': {'key': 'Uncommitted', 'type': '[str]', 'xml': {'itemsName': 'Uncommitted'}},
-        'latest': {'key': 'Latest', 'type': '[str]', 'xml': {'itemsName': 'Latest'}},
-    }
-    _xml_map = {
-        'name': 'BlockList'
+        "committed": {"key": "Committed", "type": "[str]", "xml": {"itemsName": "Committed"}},
+        "uncommitted": {"key": "Uncommitted", "type": "[str]", "xml": {"itemsName": "Uncommitted"}},
+        "latest": {"key": "Latest", "type": "[str]", "xml": {"itemsName": "Latest"}},
     }
+    _xml_map = {"name": "BlockList"}
 
     def __init__(
         self,
         *,
         committed: Optional[List[str]] = None,
         uncommitted: Optional[List[str]] = None,
         latest: Optional[List[str]] = None,
@@ -1030,77 +973,69 @@
         :keyword committed:
         :paramtype committed: list[str]
         :keyword uncommitted:
         :paramtype uncommitted: list[str]
         :keyword latest:
         :paramtype latest: list[str]
         """
-        super(BlockLookupList, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.committed = committed
         self.uncommitted = uncommitted
         self.latest = latest
 
 
-class ClearRange(msrest.serialization.Model):
+class ClearRange(_serialization.Model):
     """ClearRange.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar start: Required.
-    :vartype start: long
+    :vartype start: int
     :ivar end: Required.
-    :vartype end: long
+    :vartype end: int
     """
 
     _validation = {
-        'start': {'required': True},
-        'end': {'required': True},
+        "start": {"required": True},
+        "end": {"required": True},
     }
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'long', 'xml': {'name': 'Start'}},
-        'end': {'key': 'End', 'type': 'long', 'xml': {'name': 'End'}},
-    }
-    _xml_map = {
-        'name': 'ClearRange'
+        "start": {"key": "Start", "type": "int", "xml": {"name": "Start"}},
+        "end": {"key": "End", "type": "int", "xml": {"name": "End"}},
     }
+    _xml_map = {"name": "ClearRange"}
 
-    def __init__(
-        self,
-        *,
-        start: int,
-        end: int,
-        **kwargs
-    ):
+    def __init__(self, *, start: int, end: int, **kwargs):
         """
         :keyword start: Required.
-        :paramtype start: long
+        :paramtype start: int
         :keyword end: Required.
-        :paramtype end: long
+        :paramtype end: int
         """
-        super(ClearRange, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.start = start
         self.end = end
 
 
-class ContainerCpkScopeInfo(msrest.serialization.Model):
+class ContainerCpkScopeInfo(_serialization.Model):
     """Parameter group.
 
     :ivar default_encryption_scope: Optional.  Version 2019-07-07 and later.  Specifies the default
      encryption scope to set on the container and use for all future writes.
     :vartype default_encryption_scope: str
     :ivar prevent_encryption_scope_override: Optional.  Version 2019-07-07 and newer.  If true,
      prevents any request from specifying a different encryption scope than the scope set on the
      container.
     :vartype prevent_encryption_scope_override: bool
     """
 
     _attribute_map = {
-        'default_encryption_scope': {'key': 'DefaultEncryptionScope', 'type': 'str'},
-        'prevent_encryption_scope_override': {'key': 'PreventEncryptionScopeOverride', 'type': 'bool'},
+        "default_encryption_scope": {"key": "DefaultEncryptionScope", "type": "str"},
+        "prevent_encryption_scope_override": {"key": "PreventEncryptionScopeOverride", "type": "bool"},
     }
 
     def __init__(
         self,
         *,
         default_encryption_scope: Optional[str] = None,
         prevent_encryption_scope_override: Optional[bool] = None,
@@ -1111,99 +1046,97 @@
          default encryption scope to set on the container and use for all future writes.
         :paramtype default_encryption_scope: str
         :keyword prevent_encryption_scope_override: Optional.  Version 2019-07-07 and newer.  If true,
          prevents any request from specifying a different encryption scope than the scope set on the
          container.
         :paramtype prevent_encryption_scope_override: bool
         """
-        super(ContainerCpkScopeInfo, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.default_encryption_scope = default_encryption_scope
         self.prevent_encryption_scope_override = prevent_encryption_scope_override
 
 
-class ContainerItem(msrest.serialization.Model):
+class ContainerItem(_serialization.Model):
     """An Azure Storage container.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: str
     :ivar deleted:
     :vartype deleted: bool
     :ivar version:
     :vartype version: str
-    :ivar properties: Required. Properties of a container.
+    :ivar properties: Properties of a container. Required.
     :vartype properties: ~azure.storage.blob.models.ContainerProperties
     :ivar metadata: Dictionary of :code:`<string>`.
     :vartype metadata: dict[str, str]
     """
 
     _validation = {
-        'name': {'required': True},
-        'properties': {'required': True},
+        "name": {"required": True},
+        "properties": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'str'},
-        'deleted': {'key': 'Deleted', 'type': 'bool'},
-        'version': {'key': 'Version', 'type': 'str'},
-        'properties': {'key': 'Properties', 'type': 'ContainerProperties'},
-        'metadata': {'key': 'Metadata', 'type': '{str}'},
-    }
-    _xml_map = {
-        'name': 'Container'
+        "name": {"key": "Name", "type": "str"},
+        "deleted": {"key": "Deleted", "type": "bool"},
+        "version": {"key": "Version", "type": "str"},
+        "properties": {"key": "Properties", "type": "ContainerProperties"},
+        "metadata": {"key": "Metadata", "type": "{str}"},
     }
+    _xml_map = {"name": "Container"}
 
     def __init__(
         self,
         *,
         name: str,
-        properties: "ContainerProperties",
+        properties: "_models.ContainerProperties",
         deleted: Optional[bool] = None,
         version: Optional[str] = None,
         metadata: Optional[Dict[str, str]] = None,
         **kwargs
     ):
         """
         :keyword name: Required.
         :paramtype name: str
         :keyword deleted:
         :paramtype deleted: bool
         :keyword version:
         :paramtype version: str
-        :keyword properties: Required. Properties of a container.
+        :keyword properties: Properties of a container. Required.
         :paramtype properties: ~azure.storage.blob.models.ContainerProperties
         :keyword metadata: Dictionary of :code:`<string>`.
         :paramtype metadata: dict[str, str]
         """
-        super(ContainerItem, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.name = name
         self.deleted = deleted
         self.version = version
         self.properties = properties
         self.metadata = metadata
 
 
-class ContainerProperties(msrest.serialization.Model):
+class ContainerProperties(_serialization.Model):  # pylint: disable=too-many-instance-attributes
     """Properties of a container.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar last_modified: Required.
     :vartype last_modified: ~datetime.datetime
     :ivar etag: Required.
     :vartype etag: str
-    :ivar lease_status: Possible values include: "locked", "unlocked".
+    :ivar lease_status: Known values are: "locked" and "unlocked".
     :vartype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-    :ivar lease_state: Possible values include: "available", "leased", "expired", "breaking",
+    :ivar lease_state: Known values are: "available", "leased", "expired", "breaking", and
      "broken".
     :vartype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-    :ivar lease_duration: Possible values include: "infinite", "fixed".
+    :ivar lease_duration: Known values are: "infinite" and "fixed".
     :vartype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
-    :ivar public_access: Possible values include: "container", "blob".
+    :ivar public_access: Known values are: "container" and "blob".
     :vartype public_access: str or ~azure.storage.blob.models.PublicAccessType
     :ivar has_immutability_policy:
     :vartype has_immutability_policy: bool
     :ivar has_legal_hold:
     :vartype has_legal_hold: bool
     :ivar default_encryption_scope:
     :vartype default_encryption_scope: str
@@ -1215,65 +1148,68 @@
     :vartype remaining_retention_days: int
     :ivar is_immutable_storage_with_versioning_enabled: Indicates if version level worm is enabled
      on this container.
     :vartype is_immutable_storage_with_versioning_enabled: bool
     """
 
     _validation = {
-        'last_modified': {'required': True},
-        'etag': {'required': True},
+        "last_modified": {"required": True},
+        "etag": {"required": True},
     }
 
     _attribute_map = {
-        'last_modified': {'key': 'Last-Modified', 'type': 'rfc-1123'},
-        'etag': {'key': 'Etag', 'type': 'str'},
-        'lease_status': {'key': 'LeaseStatus', 'type': 'str'},
-        'lease_state': {'key': 'LeaseState', 'type': 'str'},
-        'lease_duration': {'key': 'LeaseDuration', 'type': 'str'},
-        'public_access': {'key': 'PublicAccess', 'type': 'str'},
-        'has_immutability_policy': {'key': 'HasImmutabilityPolicy', 'type': 'bool'},
-        'has_legal_hold': {'key': 'HasLegalHold', 'type': 'bool'},
-        'default_encryption_scope': {'key': 'DefaultEncryptionScope', 'type': 'str'},
-        'prevent_encryption_scope_override': {'key': 'DenyEncryptionScopeOverride', 'type': 'bool'},
-        'deleted_time': {'key': 'DeletedTime', 'type': 'rfc-1123'},
-        'remaining_retention_days': {'key': 'RemainingRetentionDays', 'type': 'int'},
-        'is_immutable_storage_with_versioning_enabled': {'key': 'ImmutableStorageWithVersioningEnabled', 'type': 'bool'},
+        "last_modified": {"key": "Last-Modified", "type": "rfc-1123"},
+        "etag": {"key": "Etag", "type": "str"},
+        "lease_status": {"key": "LeaseStatus", "type": "str"},
+        "lease_state": {"key": "LeaseState", "type": "str"},
+        "lease_duration": {"key": "LeaseDuration", "type": "str"},
+        "public_access": {"key": "PublicAccess", "type": "str"},
+        "has_immutability_policy": {"key": "HasImmutabilityPolicy", "type": "bool"},
+        "has_legal_hold": {"key": "HasLegalHold", "type": "bool"},
+        "default_encryption_scope": {"key": "DefaultEncryptionScope", "type": "str"},
+        "prevent_encryption_scope_override": {"key": "DenyEncryptionScopeOverride", "type": "bool"},
+        "deleted_time": {"key": "DeletedTime", "type": "rfc-1123"},
+        "remaining_retention_days": {"key": "RemainingRetentionDays", "type": "int"},
+        "is_immutable_storage_with_versioning_enabled": {
+            "key": "ImmutableStorageWithVersioningEnabled",
+            "type": "bool",
+        },
     }
 
     def __init__(
         self,
         *,
         last_modified: datetime.datetime,
         etag: str,
-        lease_status: Optional[Union[str, "LeaseStatusType"]] = None,
-        lease_state: Optional[Union[str, "LeaseStateType"]] = None,
-        lease_duration: Optional[Union[str, "LeaseDurationType"]] = None,
-        public_access: Optional[Union[str, "PublicAccessType"]] = None,
+        lease_status: Optional[Union[str, "_models.LeaseStatusType"]] = None,
+        lease_state: Optional[Union[str, "_models.LeaseStateType"]] = None,
+        lease_duration: Optional[Union[str, "_models.LeaseDurationType"]] = None,
+        public_access: Optional[Union[str, "_models.PublicAccessType"]] = None,
         has_immutability_policy: Optional[bool] = None,
         has_legal_hold: Optional[bool] = None,
         default_encryption_scope: Optional[str] = None,
         prevent_encryption_scope_override: Optional[bool] = None,
         deleted_time: Optional[datetime.datetime] = None,
         remaining_retention_days: Optional[int] = None,
         is_immutable_storage_with_versioning_enabled: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword last_modified: Required.
         :paramtype last_modified: ~datetime.datetime
         :keyword etag: Required.
         :paramtype etag: str
-        :keyword lease_status: Possible values include: "locked", "unlocked".
+        :keyword lease_status: Known values are: "locked" and "unlocked".
         :paramtype lease_status: str or ~azure.storage.blob.models.LeaseStatusType
-        :keyword lease_state: Possible values include: "available", "leased", "expired", "breaking",
+        :keyword lease_state: Known values are: "available", "leased", "expired", "breaking", and
          "broken".
         :paramtype lease_state: str or ~azure.storage.blob.models.LeaseStateType
-        :keyword lease_duration: Possible values include: "infinite", "fixed".
+        :keyword lease_duration: Known values are: "infinite" and "fixed".
         :paramtype lease_duration: str or ~azure.storage.blob.models.LeaseDurationType
-        :keyword public_access: Possible values include: "container", "blob".
+        :keyword public_access: Known values are: "container" and "blob".
         :paramtype public_access: str or ~azure.storage.blob.models.PublicAccessType
         :keyword has_immutability_policy:
         :paramtype has_immutability_policy: bool
         :keyword has_legal_hold:
         :paramtype has_legal_hold: bool
         :keyword default_encryption_scope:
         :paramtype default_encryption_scope: str
@@ -1283,15 +1219,15 @@
         :paramtype deleted_time: ~datetime.datetime
         :keyword remaining_retention_days:
         :paramtype remaining_retention_days: int
         :keyword is_immutable_storage_with_versioning_enabled: Indicates if version level worm is
          enabled on this container.
         :paramtype is_immutable_storage_with_versioning_enabled: bool
         """
-        super(ContainerProperties, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.last_modified = last_modified
         self.etag = etag
         self.lease_status = lease_status
         self.lease_state = lease_state
         self.lease_duration = lease_duration
         self.public_access = public_access
         self.has_immutability_policy = has_immutability_policy
@@ -1299,174 +1235,169 @@
         self.default_encryption_scope = default_encryption_scope
         self.prevent_encryption_scope_override = prevent_encryption_scope_override
         self.deleted_time = deleted_time
         self.remaining_retention_days = remaining_retention_days
         self.is_immutable_storage_with_versioning_enabled = is_immutable_storage_with_versioning_enabled
 
 
-class CorsRule(msrest.serialization.Model):
+class CorsRule(_serialization.Model):
     """CORS is an HTTP feature that enables a web application running under one domain to access resources in another domain. Web browsers implement a security restriction known as same-origin policy that prevents a web page from calling APIs in a different domain; CORS provides a secure way to allow one domain (the origin domain) to call APIs in another domain.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar allowed_origins: Required. The origin domains that are permitted to make a request
-     against the storage service via CORS. The origin domain is the domain from which the request
-     originates. Note that the origin must be an exact case-sensitive match with the origin that the
-     user age sends to the service. You can also use the wildcard character '*' to allow all origin
-     domains to make requests via CORS.
+    :ivar allowed_origins: The origin domains that are permitted to make a request against the
+     storage service via CORS. The origin domain is the domain from which the request originates.
+     Note that the origin must be an exact case-sensitive match with the origin that the user age
+     sends to the service. You can also use the wildcard character '*' to allow all origin domains
+     to make requests via CORS. Required.
     :vartype allowed_origins: str
-    :ivar allowed_methods: Required. The methods (HTTP request verbs) that the origin domain may
-     use for a CORS request. (comma separated).
+    :ivar allowed_methods: The methods (HTTP request verbs) that the origin domain may use for a
+     CORS request. (comma separated). Required.
     :vartype allowed_methods: str
-    :ivar allowed_headers: Required. the request headers that the origin domain may specify on the
-     CORS request.
+    :ivar allowed_headers: the request headers that the origin domain may specify on the CORS
+     request. Required.
     :vartype allowed_headers: str
-    :ivar exposed_headers: Required. The response headers that may be sent in the response to the
-     CORS request and exposed by the browser to the request issuer.
+    :ivar exposed_headers: The response headers that may be sent in the response to the CORS
+     request and exposed by the browser to the request issuer. Required.
     :vartype exposed_headers: str
-    :ivar max_age_in_seconds: Required. The maximum amount time that a browser should cache the
-     preflight OPTIONS request.
+    :ivar max_age_in_seconds: The maximum amount time that a browser should cache the preflight
+     OPTIONS request. Required.
     :vartype max_age_in_seconds: int
     """
 
     _validation = {
-        'allowed_origins': {'required': True},
-        'allowed_methods': {'required': True},
-        'allowed_headers': {'required': True},
-        'exposed_headers': {'required': True},
-        'max_age_in_seconds': {'required': True, 'minimum': 0},
+        "allowed_origins": {"required": True},
+        "allowed_methods": {"required": True},
+        "allowed_headers": {"required": True},
+        "exposed_headers": {"required": True},
+        "max_age_in_seconds": {"required": True, "minimum": 0},
     }
 
     _attribute_map = {
-        'allowed_origins': {'key': 'AllowedOrigins', 'type': 'str'},
-        'allowed_methods': {'key': 'AllowedMethods', 'type': 'str'},
-        'allowed_headers': {'key': 'AllowedHeaders', 'type': 'str'},
-        'exposed_headers': {'key': 'ExposedHeaders', 'type': 'str'},
-        'max_age_in_seconds': {'key': 'MaxAgeInSeconds', 'type': 'int'},
+        "allowed_origins": {"key": "AllowedOrigins", "type": "str"},
+        "allowed_methods": {"key": "AllowedMethods", "type": "str"},
+        "allowed_headers": {"key": "AllowedHeaders", "type": "str"},
+        "exposed_headers": {"key": "ExposedHeaders", "type": "str"},
+        "max_age_in_seconds": {"key": "MaxAgeInSeconds", "type": "int"},
     }
 
     def __init__(
         self,
         *,
         allowed_origins: str,
         allowed_methods: str,
         allowed_headers: str,
         exposed_headers: str,
         max_age_in_seconds: int,
         **kwargs
     ):
         """
-        :keyword allowed_origins: Required. The origin domains that are permitted to make a request
-         against the storage service via CORS. The origin domain is the domain from which the request
-         originates. Note that the origin must be an exact case-sensitive match with the origin that the
-         user age sends to the service. You can also use the wildcard character '*' to allow all origin
-         domains to make requests via CORS.
+        :keyword allowed_origins: The origin domains that are permitted to make a request against the
+         storage service via CORS. The origin domain is the domain from which the request originates.
+         Note that the origin must be an exact case-sensitive match with the origin that the user age
+         sends to the service. You can also use the wildcard character '*' to allow all origin domains
+         to make requests via CORS. Required.
         :paramtype allowed_origins: str
-        :keyword allowed_methods: Required. The methods (HTTP request verbs) that the origin domain may
-         use for a CORS request. (comma separated).
+        :keyword allowed_methods: The methods (HTTP request verbs) that the origin domain may use for a
+         CORS request. (comma separated). Required.
         :paramtype allowed_methods: str
-        :keyword allowed_headers: Required. the request headers that the origin domain may specify on
-         the CORS request.
+        :keyword allowed_headers: the request headers that the origin domain may specify on the CORS
+         request. Required.
         :paramtype allowed_headers: str
-        :keyword exposed_headers: Required. The response headers that may be sent in the response to
-         the CORS request and exposed by the browser to the request issuer.
+        :keyword exposed_headers: The response headers that may be sent in the response to the CORS
+         request and exposed by the browser to the request issuer. Required.
         :paramtype exposed_headers: str
-        :keyword max_age_in_seconds: Required. The maximum amount time that a browser should cache the
-         preflight OPTIONS request.
+        :keyword max_age_in_seconds: The maximum amount time that a browser should cache the preflight
+         OPTIONS request. Required.
         :paramtype max_age_in_seconds: int
         """
-        super(CorsRule, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.allowed_origins = allowed_origins
         self.allowed_methods = allowed_methods
         self.allowed_headers = allowed_headers
         self.exposed_headers = exposed_headers
         self.max_age_in_seconds = max_age_in_seconds
 
 
-class CpkInfo(msrest.serialization.Model):
+class CpkInfo(_serialization.Model):
     """Parameter group.
 
     :ivar encryption_key: Optional. Specifies the encryption key to use to encrypt the data
      provided in the request. If not specified, encryption is performed with the root account
      encryption key.  For more information, see Encryption at Rest for Azure Storage Services.
     :vartype encryption_key: str
     :ivar encryption_key_sha256: The SHA-256 hash of the provided encryption key. Must be provided
      if the x-ms-encryption-key header is provided.
     :vartype encryption_key_sha256: str
     :ivar encryption_algorithm: The algorithm used to produce the encryption key hash. Currently,
      the only accepted value is "AES256". Must be provided if the x-ms-encryption-key header is
-     provided. Possible values include: "None", "AES256".
+     provided. Known values are: "None" and "AES256".
     :vartype encryption_algorithm: str or ~azure.storage.blob.models.EncryptionAlgorithmType
     """
 
     _attribute_map = {
-        'encryption_key': {'key': 'encryptionKey', 'type': 'str'},
-        'encryption_key_sha256': {'key': 'encryptionKeySha256', 'type': 'str'},
-        'encryption_algorithm': {'key': 'encryptionAlgorithm', 'type': 'str'},
+        "encryption_key": {"key": "encryptionKey", "type": "str"},
+        "encryption_key_sha256": {"key": "encryptionKeySha256", "type": "str"},
+        "encryption_algorithm": {"key": "encryptionAlgorithm", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         encryption_key: Optional[str] = None,
         encryption_key_sha256: Optional[str] = None,
-        encryption_algorithm: Optional[Union[str, "EncryptionAlgorithmType"]] = None,
+        encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
         **kwargs
     ):
         """
         :keyword encryption_key: Optional. Specifies the encryption key to use to encrypt the data
          provided in the request. If not specified, encryption is performed with the root account
          encryption key.  For more information, see Encryption at Rest for Azure Storage Services.
         :paramtype encryption_key: str
         :keyword encryption_key_sha256: The SHA-256 hash of the provided encryption key. Must be
          provided if the x-ms-encryption-key header is provided.
         :paramtype encryption_key_sha256: str
         :keyword encryption_algorithm: The algorithm used to produce the encryption key hash.
          Currently, the only accepted value is "AES256". Must be provided if the x-ms-encryption-key
-         header is provided. Possible values include: "None", "AES256".
+         header is provided. Known values are: "None" and "AES256".
         :paramtype encryption_algorithm: str or ~azure.storage.blob.models.EncryptionAlgorithmType
         """
-        super(CpkInfo, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.encryption_key = encryption_key
         self.encryption_key_sha256 = encryption_key_sha256
         self.encryption_algorithm = encryption_algorithm
 
 
-class CpkScopeInfo(msrest.serialization.Model):
+class CpkScopeInfo(_serialization.Model):
     """Parameter group.
 
     :ivar encryption_scope: Optional. Version 2019-07-07 and later.  Specifies the name of the
      encryption scope to use to encrypt the data provided in the request. If not specified,
      encryption is performed with the default account encryption scope.  For more information, see
      Encryption at Rest for Azure Storage Services.
     :vartype encryption_scope: str
     """
 
     _attribute_map = {
-        'encryption_scope': {'key': 'encryptionScope', 'type': 'str'},
+        "encryption_scope": {"key": "encryptionScope", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        encryption_scope: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, encryption_scope: Optional[str] = None, **kwargs):
         """
         :keyword encryption_scope: Optional. Version 2019-07-07 and later.  Specifies the name of the
          encryption scope to use to encrypt the data provided in the request. If not specified,
          encryption is performed with the default account encryption scope.  For more information, see
          Encryption at Rest for Azure Storage Services.
         :paramtype encryption_scope: str
         """
-        super(CpkScopeInfo, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.encryption_scope = encryption_scope
 
 
-class DelimitedTextConfiguration(msrest.serialization.Model):
+class DelimitedTextConfiguration(_serialization.Model):
     """Groups the settings used for interpreting the blob data if the blob is delimited text formatted.
 
     :ivar column_separator: The string used to separate columns.
     :vartype column_separator: str
     :ivar field_quote: The string used to quote a specific field.
     :vartype field_quote: str
     :ivar record_separator: The string used to separate records.
@@ -1474,23 +1405,21 @@
     :ivar escape_char: The string used as an escape character.
     :vartype escape_char: str
     :ivar headers_present: Represents whether the data has headers.
     :vartype headers_present: bool
     """
 
     _attribute_map = {
-        'column_separator': {'key': 'ColumnSeparator', 'type': 'str', 'xml': {'name': 'ColumnSeparator'}},
-        'field_quote': {'key': 'FieldQuote', 'type': 'str', 'xml': {'name': 'FieldQuote'}},
-        'record_separator': {'key': 'RecordSeparator', 'type': 'str', 'xml': {'name': 'RecordSeparator'}},
-        'escape_char': {'key': 'EscapeChar', 'type': 'str', 'xml': {'name': 'EscapeChar'}},
-        'headers_present': {'key': 'HeadersPresent', 'type': 'bool', 'xml': {'name': 'HasHeaders'}},
-    }
-    _xml_map = {
-        'name': 'DelimitedTextConfiguration'
+        "column_separator": {"key": "ColumnSeparator", "type": "str", "xml": {"name": "ColumnSeparator"}},
+        "field_quote": {"key": "FieldQuote", "type": "str", "xml": {"name": "FieldQuote"}},
+        "record_separator": {"key": "RecordSeparator", "type": "str", "xml": {"name": "RecordSeparator"}},
+        "escape_char": {"key": "EscapeChar", "type": "str", "xml": {"name": "EscapeChar"}},
+        "headers_present": {"key": "HeadersPresent", "type": "bool", "xml": {"name": "HasHeaders"}},
     }
+    _xml_map = {"name": "DelimitedTextConfiguration"}
 
     def __init__(
         self,
         *,
         column_separator: Optional[str] = None,
         field_quote: Optional[str] = None,
         record_separator: Optional[str] = None,
@@ -1506,72 +1435,84 @@
         :keyword record_separator: The string used to separate records.
         :paramtype record_separator: str
         :keyword escape_char: The string used as an escape character.
         :paramtype escape_char: str
         :keyword headers_present: Represents whether the data has headers.
         :paramtype headers_present: bool
         """
-        super(DelimitedTextConfiguration, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.column_separator = column_separator
         self.field_quote = field_quote
         self.record_separator = record_separator
         self.escape_char = escape_char
         self.headers_present = headers_present
 
 
-class FilterBlobItem(msrest.serialization.Model):
+class FilterBlobItem(_serialization.Model):
     """Blob info from a Filter Blobs API call.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar name: Required.
     :vartype name: str
     :ivar container_name: Required.
     :vartype container_name: str
-    :ivar tags: A set of tags. Blob tags.
+    :ivar tags: Blob tags.
     :vartype tags: ~azure.storage.blob.models.BlobTags
+    :ivar version_id:
+    :vartype version_id: str
+    :ivar is_current_version:
+    :vartype is_current_version: bool
     """
 
     _validation = {
-        'name': {'required': True},
-        'container_name': {'required': True},
+        "name": {"required": True},
+        "container_name": {"required": True},
     }
 
     _attribute_map = {
-        'name': {'key': 'Name', 'type': 'str'},
-        'container_name': {'key': 'ContainerName', 'type': 'str'},
-        'tags': {'key': 'Tags', 'type': 'BlobTags'},
-    }
-    _xml_map = {
-        'name': 'Blob'
+        "name": {"key": "Name", "type": "str"},
+        "container_name": {"key": "ContainerName", "type": "str"},
+        "tags": {"key": "Tags", "type": "BlobTags"},
+        "version_id": {"key": "VersionId", "type": "str"},
+        "is_current_version": {"key": "IsCurrentVersion", "type": "bool"},
     }
+    _xml_map = {"name": "Blob"}
 
     def __init__(
         self,
         *,
         name: str,
         container_name: str,
-        tags: Optional["BlobTags"] = None,
+        tags: Optional["_models.BlobTags"] = None,
+        version_id: Optional[str] = None,
+        is_current_version: Optional[bool] = None,
         **kwargs
     ):
         """
         :keyword name: Required.
         :paramtype name: str
         :keyword container_name: Required.
         :paramtype container_name: str
-        :keyword tags: A set of tags. Blob tags.
+        :keyword tags: Blob tags.
         :paramtype tags: ~azure.storage.blob.models.BlobTags
+        :keyword version_id:
+        :paramtype version_id: str
+        :keyword is_current_version:
+        :paramtype is_current_version: bool
         """
-        super(FilterBlobItem, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.name = name
         self.container_name = container_name
         self.tags = tags
+        self.version_id = version_id
+        self.is_current_version = is_current_version
 
 
-class FilterBlobSegment(msrest.serialization.Model):
+class FilterBlobSegment(_serialization.Model):
     """The result of a Filter Blobs API call.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar where: Required.
@@ -1579,195 +1520,175 @@
     :ivar blobs: Required.
     :vartype blobs: list[~azure.storage.blob.models.FilterBlobItem]
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'where': {'required': True},
-        'blobs': {'required': True},
+        "service_endpoint": {"required": True},
+        "where": {"required": True},
+        "blobs": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'where': {'key': 'Where', 'type': 'str'},
-        'blobs': {'key': 'Blobs', 'type': '[FilterBlobItem]', 'xml': {'name': 'Blobs', 'wrapped': True, 'itemsName': 'Blob'}},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "where": {"key": "Where", "type": "str"},
+        "blobs": {
+            "key": "Blobs",
+            "type": "[FilterBlobItem]",
+            "xml": {"name": "Blobs", "wrapped": True, "itemsName": "Blob"},
+        },
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
         *,
         service_endpoint: str,
         where: str,
-        blobs: List["FilterBlobItem"],
+        blobs: List["_models.FilterBlobItem"],
         next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword service_endpoint: Required.
         :paramtype service_endpoint: str
         :keyword where: Required.
         :paramtype where: str
         :keyword blobs: Required.
         :paramtype blobs: list[~azure.storage.blob.models.FilterBlobItem]
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(FilterBlobSegment, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.service_endpoint = service_endpoint
         self.where = where
         self.blobs = blobs
         self.next_marker = next_marker
 
 
-class GeoReplication(msrest.serialization.Model):
+class GeoReplication(_serialization.Model):
     """Geo-Replication information for the Secondary Storage Service.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar status: Required. The status of the secondary location. Possible values include: "live",
-     "bootstrap", "unavailable".
+    :ivar status: The status of the secondary location. Required. Known values are: "live",
+     "bootstrap", and "unavailable".
     :vartype status: str or ~azure.storage.blob.models.GeoReplicationStatusType
-    :ivar last_sync_time: Required. A GMT date/time value, to the second. All primary writes
-     preceding this value are guaranteed to be available for read operations at the secondary.
-     Primary writes after this point in time may or may not be available for reads.
+    :ivar last_sync_time: A GMT date/time value, to the second. All primary writes preceding this
+     value are guaranteed to be available for read operations at the secondary. Primary writes after
+     this point in time may or may not be available for reads. Required.
     :vartype last_sync_time: ~datetime.datetime
     """
 
     _validation = {
-        'status': {'required': True},
-        'last_sync_time': {'required': True},
+        "status": {"required": True},
+        "last_sync_time": {"required": True},
     }
 
     _attribute_map = {
-        'status': {'key': 'Status', 'type': 'str'},
-        'last_sync_time': {'key': 'LastSyncTime', 'type': 'rfc-1123'},
+        "status": {"key": "Status", "type": "str"},
+        "last_sync_time": {"key": "LastSyncTime", "type": "rfc-1123"},
     }
 
     def __init__(
-        self,
-        *,
-        status: Union[str, "GeoReplicationStatusType"],
-        last_sync_time: datetime.datetime,
-        **kwargs
+        self, *, status: Union[str, "_models.GeoReplicationStatusType"], last_sync_time: datetime.datetime, **kwargs
     ):
         """
-        :keyword status: Required. The status of the secondary location. Possible values include:
-         "live", "bootstrap", "unavailable".
+        :keyword status: The status of the secondary location. Required. Known values are: "live",
+         "bootstrap", and "unavailable".
         :paramtype status: str or ~azure.storage.blob.models.GeoReplicationStatusType
-        :keyword last_sync_time: Required. A GMT date/time value, to the second. All primary writes
-         preceding this value are guaranteed to be available for read operations at the secondary.
-         Primary writes after this point in time may or may not be available for reads.
+        :keyword last_sync_time: A GMT date/time value, to the second. All primary writes preceding
+         this value are guaranteed to be available for read operations at the secondary. Primary writes
+         after this point in time may or may not be available for reads. Required.
         :paramtype last_sync_time: ~datetime.datetime
         """
-        super(GeoReplication, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.status = status
         self.last_sync_time = last_sync_time
 
 
-class JsonTextConfiguration(msrest.serialization.Model):
+class JsonTextConfiguration(_serialization.Model):
     """json text configuration.
 
     :ivar record_separator: The string used to separate records.
     :vartype record_separator: str
     """
 
     _attribute_map = {
-        'record_separator': {'key': 'RecordSeparator', 'type': 'str', 'xml': {'name': 'RecordSeparator'}},
-    }
-    _xml_map = {
-        'name': 'JsonTextConfiguration'
+        "record_separator": {"key": "RecordSeparator", "type": "str", "xml": {"name": "RecordSeparator"}},
     }
+    _xml_map = {"name": "JsonTextConfiguration"}
 
-    def __init__(
-        self,
-        *,
-        record_separator: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, record_separator: Optional[str] = None, **kwargs):
         """
         :keyword record_separator: The string used to separate records.
         :paramtype record_separator: str
         """
-        super(JsonTextConfiguration, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.record_separator = record_separator
 
 
-class KeyInfo(msrest.serialization.Model):
+class KeyInfo(_serialization.Model):
     """Key information.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar start: Required. The date-time the key is active in ISO 8601 UTC time.
+    :ivar start: The date-time the key is active in ISO 8601 UTC time. Required.
     :vartype start: str
-    :ivar expiry: Required. The date-time the key expires in ISO 8601 UTC time.
+    :ivar expiry: The date-time the key expires in ISO 8601 UTC time. Required.
     :vartype expiry: str
     """
 
     _validation = {
-        'start': {'required': True},
-        'expiry': {'required': True},
+        "start": {"required": True},
+        "expiry": {"required": True},
     }
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'str'},
-        'expiry': {'key': 'Expiry', 'type': 'str'},
+        "start": {"key": "Start", "type": "str"},
+        "expiry": {"key": "Expiry", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        start: str,
-        expiry: str,
-        **kwargs
-    ):
+    def __init__(self, *, start: str, expiry: str, **kwargs):
         """
-        :keyword start: Required. The date-time the key is active in ISO 8601 UTC time.
+        :keyword start: The date-time the key is active in ISO 8601 UTC time. Required.
         :paramtype start: str
-        :keyword expiry: Required. The date-time the key expires in ISO 8601 UTC time.
+        :keyword expiry: The date-time the key expires in ISO 8601 UTC time. Required.
         :paramtype expiry: str
         """
-        super(KeyInfo, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.start = start
         self.expiry = expiry
 
 
-class LeaseAccessConditions(msrest.serialization.Model):
+class LeaseAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar lease_id: If specified, the operation only succeeds if the resource's lease is active and
      matches this ID.
     :vartype lease_id: str
     """
 
     _attribute_map = {
-        'lease_id': {'key': 'leaseId', 'type': 'str'},
+        "lease_id": {"key": "leaseId", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        lease_id: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, lease_id: Optional[str] = None, **kwargs):
         """
         :keyword lease_id: If specified, the operation only succeeds if the resource's lease is active
          and matches this ID.
         :paramtype lease_id: str
         """
-        super(LeaseAccessConditions, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.lease_id = lease_id
 
 
-class ListBlobsFlatSegmentResponse(msrest.serialization.Model):
+class ListBlobsFlatSegmentResponse(_serialization.Model):
     """An enumeration of blobs.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar container_name: Required.
@@ -1781,38 +1702,36 @@
     :ivar segment: Required.
     :vartype segment: ~azure.storage.blob.models.BlobFlatListSegment
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'container_name': {'required': True},
-        'segment': {'required': True},
+        "service_endpoint": {"required": True},
+        "container_name": {"required": True},
+        "segment": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'container_name': {'key': 'ContainerName', 'type': 'str', 'xml': {'attr': True}},
-        'prefix': {'key': 'Prefix', 'type': 'str'},
-        'marker': {'key': 'Marker', 'type': 'str'},
-        'max_results': {'key': 'MaxResults', 'type': 'int'},
-        'segment': {'key': 'Segment', 'type': 'BlobFlatListSegment'},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "container_name": {"key": "ContainerName", "type": "str", "xml": {"attr": True}},
+        "prefix": {"key": "Prefix", "type": "str"},
+        "marker": {"key": "Marker", "type": "str"},
+        "max_results": {"key": "MaxResults", "type": "int"},
+        "segment": {"key": "Segment", "type": "BlobFlatListSegment"},
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
         *,
         service_endpoint: str,
         container_name: str,
-        segment: "BlobFlatListSegment",
+        segment: "_models.BlobFlatListSegment",
         prefix: Optional[str] = None,
         marker: Optional[str] = None,
         max_results: Optional[int] = None,
         next_marker: Optional[str] = None,
         **kwargs
     ):
         """
@@ -1827,25 +1746,25 @@
         :keyword max_results:
         :paramtype max_results: int
         :keyword segment: Required.
         :paramtype segment: ~azure.storage.blob.models.BlobFlatListSegment
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(ListBlobsFlatSegmentResponse, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.service_endpoint = service_endpoint
         self.container_name = container_name
         self.prefix = prefix
         self.marker = marker
         self.max_results = max_results
         self.segment = segment
         self.next_marker = next_marker
 
 
-class ListBlobsHierarchySegmentResponse(msrest.serialization.Model):
+class ListBlobsHierarchySegmentResponse(_serialization.Model):
     """An enumeration of blobs.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar container_name: Required.
@@ -1861,39 +1780,37 @@
     :ivar segment: Required.
     :vartype segment: ~azure.storage.blob.models.BlobHierarchyListSegment
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'container_name': {'required': True},
-        'segment': {'required': True},
+        "service_endpoint": {"required": True},
+        "container_name": {"required": True},
+        "segment": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'container_name': {'key': 'ContainerName', 'type': 'str', 'xml': {'attr': True}},
-        'prefix': {'key': 'Prefix', 'type': 'str'},
-        'marker': {'key': 'Marker', 'type': 'str'},
-        'max_results': {'key': 'MaxResults', 'type': 'int'},
-        'delimiter': {'key': 'Delimiter', 'type': 'str'},
-        'segment': {'key': 'Segment', 'type': 'BlobHierarchyListSegment'},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "container_name": {"key": "ContainerName", "type": "str", "xml": {"attr": True}},
+        "prefix": {"key": "Prefix", "type": "str"},
+        "marker": {"key": "Marker", "type": "str"},
+        "max_results": {"key": "MaxResults", "type": "int"},
+        "delimiter": {"key": "Delimiter", "type": "str"},
+        "segment": {"key": "Segment", "type": "BlobHierarchyListSegment"},
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
         *,
         service_endpoint: str,
         container_name: str,
-        segment: "BlobHierarchyListSegment",
+        segment: "_models.BlobHierarchyListSegment",
         prefix: Optional[str] = None,
         marker: Optional[str] = None,
         max_results: Optional[int] = None,
         delimiter: Optional[str] = None,
         next_marker: Optional[str] = None,
         **kwargs
     ):
@@ -1911,26 +1828,26 @@
         :keyword delimiter:
         :paramtype delimiter: str
         :keyword segment: Required.
         :paramtype segment: ~azure.storage.blob.models.BlobHierarchyListSegment
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(ListBlobsHierarchySegmentResponse, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.service_endpoint = service_endpoint
         self.container_name = container_name
         self.prefix = prefix
         self.marker = marker
         self.max_results = max_results
         self.delimiter = delimiter
         self.segment = segment
         self.next_marker = next_marker
 
 
-class ListContainersSegmentResponse(msrest.serialization.Model):
+class ListContainersSegmentResponse(_serialization.Model):
     """An enumeration of containers.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar service_endpoint: Required.
     :vartype service_endpoint: str
     :ivar prefix:
@@ -1942,35 +1859,37 @@
     :ivar container_items: Required.
     :vartype container_items: list[~azure.storage.blob.models.ContainerItem]
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _validation = {
-        'service_endpoint': {'required': True},
-        'container_items': {'required': True},
+        "service_endpoint": {"required": True},
+        "container_items": {"required": True},
     }
 
     _attribute_map = {
-        'service_endpoint': {'key': 'ServiceEndpoint', 'type': 'str', 'xml': {'attr': True}},
-        'prefix': {'key': 'Prefix', 'type': 'str'},
-        'marker': {'key': 'Marker', 'type': 'str'},
-        'max_results': {'key': 'MaxResults', 'type': 'int'},
-        'container_items': {'key': 'ContainerItems', 'type': '[ContainerItem]', 'xml': {'name': 'Containers', 'wrapped': True, 'itemsName': 'Container'}},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
-    }
-    _xml_map = {
-        'name': 'EnumerationResults'
+        "service_endpoint": {"key": "ServiceEndpoint", "type": "str", "xml": {"attr": True}},
+        "prefix": {"key": "Prefix", "type": "str"},
+        "marker": {"key": "Marker", "type": "str"},
+        "max_results": {"key": "MaxResults", "type": "int"},
+        "container_items": {
+            "key": "ContainerItems",
+            "type": "[ContainerItem]",
+            "xml": {"name": "Containers", "wrapped": True, "itemsName": "Container"},
+        },
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
+    _xml_map = {"name": "EnumerationResults"}
 
     def __init__(
         self,
         *,
         service_endpoint: str,
-        container_items: List["ContainerItem"],
+        container_items: List["_models.ContainerItem"],
         prefix: Optional[str] = None,
         marker: Optional[str] = None,
         max_results: Optional[int] = None,
         next_marker: Optional[str] = None,
         **kwargs
     ):
         """
@@ -1983,145 +1902,145 @@
         :keyword max_results:
         :paramtype max_results: int
         :keyword container_items: Required.
         :paramtype container_items: list[~azure.storage.blob.models.ContainerItem]
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(ListContainersSegmentResponse, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.service_endpoint = service_endpoint
         self.prefix = prefix
         self.marker = marker
         self.max_results = max_results
         self.container_items = container_items
         self.next_marker = next_marker
 
 
-class Logging(msrest.serialization.Model):
+class Logging(_serialization.Model):
     """Azure Analytics Logging settings.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar version: Required. The version of Storage Analytics to configure.
+    :ivar version: The version of Storage Analytics to configure. Required.
     :vartype version: str
-    :ivar delete: Required. Indicates whether all delete requests should be logged.
+    :ivar delete: Indicates whether all delete requests should be logged. Required.
     :vartype delete: bool
-    :ivar read: Required. Indicates whether all read requests should be logged.
+    :ivar read: Indicates whether all read requests should be logged. Required.
     :vartype read: bool
-    :ivar write: Required. Indicates whether all write requests should be logged.
+    :ivar write: Indicates whether all write requests should be logged. Required.
     :vartype write: bool
-    :ivar retention_policy: Required. the retention policy which determines how long the associated
-     data should persist.
+    :ivar retention_policy: the retention policy which determines how long the associated data
+     should persist. Required.
     :vartype retention_policy: ~azure.storage.blob.models.RetentionPolicy
     """
 
     _validation = {
-        'version': {'required': True},
-        'delete': {'required': True},
-        'read': {'required': True},
-        'write': {'required': True},
-        'retention_policy': {'required': True},
+        "version": {"required": True},
+        "delete": {"required": True},
+        "read": {"required": True},
+        "write": {"required": True},
+        "retention_policy": {"required": True},
     }
 
     _attribute_map = {
-        'version': {'key': 'Version', 'type': 'str'},
-        'delete': {'key': 'Delete', 'type': 'bool'},
-        'read': {'key': 'Read', 'type': 'bool'},
-        'write': {'key': 'Write', 'type': 'bool'},
-        'retention_policy': {'key': 'RetentionPolicy', 'type': 'RetentionPolicy'},
+        "version": {"key": "Version", "type": "str"},
+        "delete": {"key": "Delete", "type": "bool"},
+        "read": {"key": "Read", "type": "bool"},
+        "write": {"key": "Write", "type": "bool"},
+        "retention_policy": {"key": "RetentionPolicy", "type": "RetentionPolicy"},
     }
 
     def __init__(
         self,
         *,
         version: str,
         delete: bool,
         read: bool,
         write: bool,
-        retention_policy: "RetentionPolicy",
+        retention_policy: "_models.RetentionPolicy",
         **kwargs
     ):
         """
-        :keyword version: Required. The version of Storage Analytics to configure.
+        :keyword version: The version of Storage Analytics to configure. Required.
         :paramtype version: str
-        :keyword delete: Required. Indicates whether all delete requests should be logged.
+        :keyword delete: Indicates whether all delete requests should be logged. Required.
         :paramtype delete: bool
-        :keyword read: Required. Indicates whether all read requests should be logged.
+        :keyword read: Indicates whether all read requests should be logged. Required.
         :paramtype read: bool
-        :keyword write: Required. Indicates whether all write requests should be logged.
+        :keyword write: Indicates whether all write requests should be logged. Required.
         :paramtype write: bool
-        :keyword retention_policy: Required. the retention policy which determines how long the
-         associated data should persist.
+        :keyword retention_policy: the retention policy which determines how long the associated data
+         should persist. Required.
         :paramtype retention_policy: ~azure.storage.blob.models.RetentionPolicy
         """
-        super(Logging, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.version = version
         self.delete = delete
         self.read = read
         self.write = write
         self.retention_policy = retention_policy
 
 
-class Metrics(msrest.serialization.Model):
+class Metrics(_serialization.Model):
     """a summary of request statistics grouped by API in hour or minute aggregates for blobs.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar version: The version of Storage Analytics to configure.
     :vartype version: str
-    :ivar enabled: Required. Indicates whether metrics are enabled for the Blob service.
+    :ivar enabled: Indicates whether metrics are enabled for the Blob service. Required.
     :vartype enabled: bool
     :ivar include_apis: Indicates whether metrics should generate summary statistics for called API
      operations.
     :vartype include_apis: bool
     :ivar retention_policy: the retention policy which determines how long the associated data
      should persist.
     :vartype retention_policy: ~azure.storage.blob.models.RetentionPolicy
     """
 
     _validation = {
-        'enabled': {'required': True},
+        "enabled": {"required": True},
     }
 
     _attribute_map = {
-        'version': {'key': 'Version', 'type': 'str'},
-        'enabled': {'key': 'Enabled', 'type': 'bool'},
-        'include_apis': {'key': 'IncludeAPIs', 'type': 'bool'},
-        'retention_policy': {'key': 'RetentionPolicy', 'type': 'RetentionPolicy'},
+        "version": {"key": "Version", "type": "str"},
+        "enabled": {"key": "Enabled", "type": "bool"},
+        "include_apis": {"key": "IncludeAPIs", "type": "bool"},
+        "retention_policy": {"key": "RetentionPolicy", "type": "RetentionPolicy"},
     }
 
     def __init__(
         self,
         *,
         enabled: bool,
         version: Optional[str] = None,
         include_apis: Optional[bool] = None,
-        retention_policy: Optional["RetentionPolicy"] = None,
+        retention_policy: Optional["_models.RetentionPolicy"] = None,
         **kwargs
     ):
         """
         :keyword version: The version of Storage Analytics to configure.
         :paramtype version: str
-        :keyword enabled: Required. Indicates whether metrics are enabled for the Blob service.
+        :keyword enabled: Indicates whether metrics are enabled for the Blob service. Required.
         :paramtype enabled: bool
         :keyword include_apis: Indicates whether metrics should generate summary statistics for called
          API operations.
         :paramtype include_apis: bool
         :keyword retention_policy: the retention policy which determines how long the associated data
          should persist.
         :paramtype retention_policy: ~azure.storage.blob.models.RetentionPolicy
         """
-        super(Metrics, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.version = version
         self.enabled = enabled
         self.include_apis = include_apis
         self.retention_policy = retention_policy
 
 
-class ModifiedAccessConditions(msrest.serialization.Model):
+class ModifiedAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar if_modified_since: Specify this header value to operate only on a blob if it has been
      modified since the specified date/time.
     :vartype if_modified_since: ~datetime.datetime
     :ivar if_unmodified_since: Specify this header value to operate only on a blob if it has not
      been modified since the specified date/time.
@@ -2132,19 +2051,19 @@
     :vartype if_none_match: str
     :ivar if_tags: Specify a SQL where clause on blob tags to operate only on blobs with a matching
      value.
     :vartype if_tags: str
     """
 
     _attribute_map = {
-        'if_modified_since': {'key': 'ifModifiedSince', 'type': 'rfc-1123'},
-        'if_unmodified_since': {'key': 'ifUnmodifiedSince', 'type': 'rfc-1123'},
-        'if_match': {'key': 'ifMatch', 'type': 'str'},
-        'if_none_match': {'key': 'ifNoneMatch', 'type': 'str'},
-        'if_tags': {'key': 'ifTags', 'type': 'str'},
+        "if_modified_since": {"key": "ifModifiedSince", "type": "rfc-1123"},
+        "if_unmodified_since": {"key": "ifUnmodifiedSince", "type": "rfc-1123"},
+        "if_match": {"key": "ifMatch", "type": "str"},
+        "if_none_match": {"key": "ifNoneMatch", "type": "str"},
+        "if_tags": {"key": "ifTags", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         if_modified_since: Optional[datetime.datetime] = None,
         if_unmodified_since: Optional[datetime.datetime] = None,
@@ -2165,397 +2084,375 @@
         :keyword if_none_match: Specify an ETag value to operate only on blobs without a matching
          value.
         :paramtype if_none_match: str
         :keyword if_tags: Specify a SQL where clause on blob tags to operate only on blobs with a
          matching value.
         :paramtype if_tags: str
         """
-        super(ModifiedAccessConditions, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.if_modified_since = if_modified_since
         self.if_unmodified_since = if_unmodified_since
         self.if_match = if_match
         self.if_none_match = if_none_match
         self.if_tags = if_tags
 
 
-class PageList(msrest.serialization.Model):
+class PageList(_serialization.Model):
     """the list of pages.
 
     :ivar page_range:
     :vartype page_range: list[~azure.storage.blob.models.PageRange]
     :ivar clear_range:
     :vartype clear_range: list[~azure.storage.blob.models.ClearRange]
     :ivar next_marker:
     :vartype next_marker: str
     """
 
     _attribute_map = {
-        'page_range': {'key': 'PageRange', 'type': '[PageRange]'},
-        'clear_range': {'key': 'ClearRange', 'type': '[ClearRange]'},
-        'next_marker': {'key': 'NextMarker', 'type': 'str'},
+        "page_range": {"key": "PageRange", "type": "[PageRange]", "xml": {"itemsName": "PageRange"}},
+        "clear_range": {"key": "ClearRange", "type": "[ClearRange]", "xml": {"itemsName": "ClearRange"}},
+        "next_marker": {"key": "NextMarker", "type": "str"},
     }
 
     def __init__(
         self,
         *,
-        page_range: Optional[List["PageRange"]] = None,
-        clear_range: Optional[List["ClearRange"]] = None,
+        page_range: Optional[List["_models.PageRange"]] = None,
+        clear_range: Optional[List["_models.ClearRange"]] = None,
         next_marker: Optional[str] = None,
         **kwargs
     ):
         """
         :keyword page_range:
         :paramtype page_range: list[~azure.storage.blob.models.PageRange]
         :keyword clear_range:
         :paramtype clear_range: list[~azure.storage.blob.models.ClearRange]
         :keyword next_marker:
         :paramtype next_marker: str
         """
-        super(PageList, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.page_range = page_range
         self.clear_range = clear_range
         self.next_marker = next_marker
 
 
-class PageRange(msrest.serialization.Model):
+class PageRange(_serialization.Model):
     """PageRange.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar start: Required.
-    :vartype start: long
+    :vartype start: int
     :ivar end: Required.
-    :vartype end: long
+    :vartype end: int
     """
 
     _validation = {
-        'start': {'required': True},
-        'end': {'required': True},
+        "start": {"required": True},
+        "end": {"required": True},
     }
 
     _attribute_map = {
-        'start': {'key': 'Start', 'type': 'long', 'xml': {'name': 'Start'}},
-        'end': {'key': 'End', 'type': 'long', 'xml': {'name': 'End'}},
-    }
-    _xml_map = {
-        'name': 'PageRange'
+        "start": {"key": "Start", "type": "int", "xml": {"name": "Start"}},
+        "end": {"key": "End", "type": "int", "xml": {"name": "End"}},
     }
+    _xml_map = {"name": "PageRange"}
 
-    def __init__(
-        self,
-        *,
-        start: int,
-        end: int,
-        **kwargs
-    ):
+    def __init__(self, *, start: int, end: int, **kwargs):
         """
         :keyword start: Required.
-        :paramtype start: long
+        :paramtype start: int
         :keyword end: Required.
-        :paramtype end: long
+        :paramtype end: int
         """
-        super(PageRange, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.start = start
         self.end = end
 
 
-class QueryFormat(msrest.serialization.Model):
+class QueryFormat(_serialization.Model):
     """QueryFormat.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar type: Required. The quick query format type. Possible values include: "delimited",
-     "json", "arrow", "parquet".
+    :ivar type: The quick query format type. Required. Known values are: "delimited", "json",
+     "arrow", and "parquet".
     :vartype type: str or ~azure.storage.blob.models.QueryFormatType
     :ivar delimited_text_configuration: Groups the settings used for interpreting the blob data if
      the blob is delimited text formatted.
     :vartype delimited_text_configuration: ~azure.storage.blob.models.DelimitedTextConfiguration
     :ivar json_text_configuration: json text configuration.
     :vartype json_text_configuration: ~azure.storage.blob.models.JsonTextConfiguration
     :ivar arrow_configuration: Groups the settings used for formatting the response if the response
      should be Arrow formatted.
     :vartype arrow_configuration: ~azure.storage.blob.models.ArrowConfiguration
-    :ivar parquet_text_configuration: Any object.
-    :vartype parquet_text_configuration: any
+    :ivar parquet_text_configuration: parquet configuration.
+    :vartype parquet_text_configuration: JSON
     """
 
     _validation = {
-        'type': {'required': True},
+        "type": {"required": True},
     }
 
     _attribute_map = {
-        'type': {'key': 'Type', 'type': 'str', 'xml': {'name': 'Type'}},
-        'delimited_text_configuration': {'key': 'DelimitedTextConfiguration', 'type': 'DelimitedTextConfiguration'},
-        'json_text_configuration': {'key': 'JsonTextConfiguration', 'type': 'JsonTextConfiguration'},
-        'arrow_configuration': {'key': 'ArrowConfiguration', 'type': 'ArrowConfiguration'},
-        'parquet_text_configuration': {'key': 'ParquetTextConfiguration', 'type': 'object'},
+        "type": {"key": "Type", "type": "str", "xml": {"name": "Type"}},
+        "delimited_text_configuration": {"key": "DelimitedTextConfiguration", "type": "DelimitedTextConfiguration"},
+        "json_text_configuration": {"key": "JsonTextConfiguration", "type": "JsonTextConfiguration"},
+        "arrow_configuration": {"key": "ArrowConfiguration", "type": "ArrowConfiguration"},
+        "parquet_text_configuration": {"key": "ParquetTextConfiguration", "type": "object"},
     }
 
     def __init__(
         self,
         *,
-        type: Union[str, "QueryFormatType"],
-        delimited_text_configuration: Optional["DelimitedTextConfiguration"] = None,
-        json_text_configuration: Optional["JsonTextConfiguration"] = None,
-        arrow_configuration: Optional["ArrowConfiguration"] = None,
-        parquet_text_configuration: Optional[Any] = None,
+        type: Union[str, "_models.QueryFormatType"],
+        delimited_text_configuration: Optional["_models.DelimitedTextConfiguration"] = None,
+        json_text_configuration: Optional["_models.JsonTextConfiguration"] = None,
+        arrow_configuration: Optional["_models.ArrowConfiguration"] = None,
+        parquet_text_configuration: Optional[JSON] = None,
         **kwargs
     ):
         """
-        :keyword type: Required. The quick query format type. Possible values include: "delimited",
-         "json", "arrow", "parquet".
+        :keyword type: The quick query format type. Required. Known values are: "delimited", "json",
+         "arrow", and "parquet".
         :paramtype type: str or ~azure.storage.blob.models.QueryFormatType
         :keyword delimited_text_configuration: Groups the settings used for interpreting the blob data
          if the blob is delimited text formatted.
         :paramtype delimited_text_configuration: ~azure.storage.blob.models.DelimitedTextConfiguration
         :keyword json_text_configuration: json text configuration.
         :paramtype json_text_configuration: ~azure.storage.blob.models.JsonTextConfiguration
         :keyword arrow_configuration: Groups the settings used for formatting the response if the
          response should be Arrow formatted.
         :paramtype arrow_configuration: ~azure.storage.blob.models.ArrowConfiguration
-        :keyword parquet_text_configuration: Any object.
-        :paramtype parquet_text_configuration: any
+        :keyword parquet_text_configuration: parquet configuration.
+        :paramtype parquet_text_configuration: JSON
         """
-        super(QueryFormat, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.type = type
         self.delimited_text_configuration = delimited_text_configuration
         self.json_text_configuration = json_text_configuration
         self.arrow_configuration = arrow_configuration
         self.parquet_text_configuration = parquet_text_configuration
 
 
-class QueryRequest(msrest.serialization.Model):
+class QueryRequest(_serialization.Model):
     """Groups the set of query request settings.
 
     Variables are only populated by the server, and will be ignored when sending a request.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar query_type: Required. The type of the provided query expression. Has constant value:
-     "SQL".
+    :ivar query_type: Required. The type of the provided query expression. Required. Default value
+     is "SQL".
     :vartype query_type: str
-    :ivar expression: Required. The query expression in SQL. The maximum size of the query
-     expression is 256KiB.
+    :ivar expression: The query expression in SQL. The maximum size of the query expression is
+     256KiB. Required.
     :vartype expression: str
     :ivar input_serialization:
     :vartype input_serialization: ~azure.storage.blob.models.QuerySerialization
     :ivar output_serialization:
     :vartype output_serialization: ~azure.storage.blob.models.QuerySerialization
     """
 
     _validation = {
-        'query_type': {'required': True, 'constant': True},
-        'expression': {'required': True},
+        "query_type": {"required": True, "constant": True},
+        "expression": {"required": True},
     }
 
     _attribute_map = {
-        'query_type': {'key': 'QueryType', 'type': 'str', 'xml': {'name': 'QueryType'}},
-        'expression': {'key': 'Expression', 'type': 'str', 'xml': {'name': 'Expression'}},
-        'input_serialization': {'key': 'InputSerialization', 'type': 'QuerySerialization'},
-        'output_serialization': {'key': 'OutputSerialization', 'type': 'QuerySerialization'},
-    }
-    _xml_map = {
-        'name': 'QueryRequest'
+        "query_type": {"key": "QueryType", "type": "str", "xml": {"name": "QueryType"}},
+        "expression": {"key": "Expression", "type": "str", "xml": {"name": "Expression"}},
+        "input_serialization": {"key": "InputSerialization", "type": "QuerySerialization"},
+        "output_serialization": {"key": "OutputSerialization", "type": "QuerySerialization"},
     }
+    _xml_map = {"name": "QueryRequest"}
 
     query_type = "SQL"
 
     def __init__(
         self,
         *,
         expression: str,
-        input_serialization: Optional["QuerySerialization"] = None,
-        output_serialization: Optional["QuerySerialization"] = None,
+        input_serialization: Optional["_models.QuerySerialization"] = None,
+        output_serialization: Optional["_models.QuerySerialization"] = None,
         **kwargs
     ):
         """
-        :keyword expression: Required. The query expression in SQL. The maximum size of the query
-         expression is 256KiB.
+        :keyword expression: The query expression in SQL. The maximum size of the query expression is
+         256KiB. Required.
         :paramtype expression: str
         :keyword input_serialization:
         :paramtype input_serialization: ~azure.storage.blob.models.QuerySerialization
         :keyword output_serialization:
         :paramtype output_serialization: ~azure.storage.blob.models.QuerySerialization
         """
-        super(QueryRequest, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.expression = expression
         self.input_serialization = input_serialization
         self.output_serialization = output_serialization
 
 
-class QuerySerialization(msrest.serialization.Model):
+class QuerySerialization(_serialization.Model):
     """QuerySerialization.
 
     All required parameters must be populated in order to send to Azure.
 
     :ivar format: Required.
     :vartype format: ~azure.storage.blob.models.QueryFormat
     """
 
     _validation = {
-        'format': {'required': True},
+        "format": {"required": True},
     }
 
     _attribute_map = {
-        'format': {'key': 'Format', 'type': 'QueryFormat'},
+        "format": {"key": "Format", "type": "QueryFormat"},
     }
 
-    def __init__(
-        self,
-        *,
-        format: "QueryFormat",
-        **kwargs
-    ):
+    def __init__(self, *, format: "_models.QueryFormat", **kwargs):
         """
         :keyword format: Required.
         :paramtype format: ~azure.storage.blob.models.QueryFormat
         """
-        super(QuerySerialization, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.format = format
 
 
-class RetentionPolicy(msrest.serialization.Model):
+class RetentionPolicy(_serialization.Model):
     """the retention policy which determines how long the associated data should persist.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar enabled: Required. Indicates whether a retention policy is enabled for the storage
-     service.
+    :ivar enabled: Indicates whether a retention policy is enabled for the storage service.
+     Required.
     :vartype enabled: bool
     :ivar days: Indicates the number of days that metrics or logging or soft-deleted data should be
      retained. All data older than this value will be deleted.
     :vartype days: int
     :ivar allow_permanent_delete: Indicates whether permanent delete is allowed on this storage
      account.
     :vartype allow_permanent_delete: bool
     """
 
     _validation = {
-        'enabled': {'required': True},
-        'days': {'minimum': 1},
+        "enabled": {"required": True},
+        "days": {"minimum": 1},
     }
 
     _attribute_map = {
-        'enabled': {'key': 'Enabled', 'type': 'bool'},
-        'days': {'key': 'Days', 'type': 'int'},
-        'allow_permanent_delete': {'key': 'AllowPermanentDelete', 'type': 'bool'},
+        "enabled": {"key": "Enabled", "type": "bool"},
+        "days": {"key": "Days", "type": "int"},
+        "allow_permanent_delete": {"key": "AllowPermanentDelete", "type": "bool"},
     }
 
     def __init__(
-        self,
-        *,
-        enabled: bool,
-        days: Optional[int] = None,
-        allow_permanent_delete: Optional[bool] = None,
-        **kwargs
+        self, *, enabled: bool, days: Optional[int] = None, allow_permanent_delete: Optional[bool] = None, **kwargs
     ):
         """
-        :keyword enabled: Required. Indicates whether a retention policy is enabled for the storage
-         service.
+        :keyword enabled: Indicates whether a retention policy is enabled for the storage service.
+         Required.
         :paramtype enabled: bool
         :keyword days: Indicates the number of days that metrics or logging or soft-deleted data should
          be retained. All data older than this value will be deleted.
         :paramtype days: int
         :keyword allow_permanent_delete: Indicates whether permanent delete is allowed on this storage
          account.
         :paramtype allow_permanent_delete: bool
         """
-        super(RetentionPolicy, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.enabled = enabled
         self.days = days
         self.allow_permanent_delete = allow_permanent_delete
 
 
-class SequenceNumberAccessConditions(msrest.serialization.Model):
+class SequenceNumberAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar if_sequence_number_less_than_or_equal_to: Specify this header value to operate only on a
      blob if it has a sequence number less than or equal to the specified.
-    :vartype if_sequence_number_less_than_or_equal_to: long
+    :vartype if_sequence_number_less_than_or_equal_to: int
     :ivar if_sequence_number_less_than: Specify this header value to operate only on a blob if it
      has a sequence number less than the specified.
-    :vartype if_sequence_number_less_than: long
+    :vartype if_sequence_number_less_than: int
     :ivar if_sequence_number_equal_to: Specify this header value to operate only on a blob if it
      has the specified sequence number.
-    :vartype if_sequence_number_equal_to: long
+    :vartype if_sequence_number_equal_to: int
     """
 
     _attribute_map = {
-        'if_sequence_number_less_than_or_equal_to': {'key': 'ifSequenceNumberLessThanOrEqualTo', 'type': 'long'},
-        'if_sequence_number_less_than': {'key': 'ifSequenceNumberLessThan', 'type': 'long'},
-        'if_sequence_number_equal_to': {'key': 'ifSequenceNumberEqualTo', 'type': 'long'},
+        "if_sequence_number_less_than_or_equal_to": {"key": "ifSequenceNumberLessThanOrEqualTo", "type": "int"},
+        "if_sequence_number_less_than": {"key": "ifSequenceNumberLessThan", "type": "int"},
+        "if_sequence_number_equal_to": {"key": "ifSequenceNumberEqualTo", "type": "int"},
     }
 
     def __init__(
         self,
         *,
         if_sequence_number_less_than_or_equal_to: Optional[int] = None,
         if_sequence_number_less_than: Optional[int] = None,
         if_sequence_number_equal_to: Optional[int] = None,
         **kwargs
     ):
         """
         :keyword if_sequence_number_less_than_or_equal_to: Specify this header value to operate only on
          a blob if it has a sequence number less than or equal to the specified.
-        :paramtype if_sequence_number_less_than_or_equal_to: long
+        :paramtype if_sequence_number_less_than_or_equal_to: int
         :keyword if_sequence_number_less_than: Specify this header value to operate only on a blob if
          it has a sequence number less than the specified.
-        :paramtype if_sequence_number_less_than: long
+        :paramtype if_sequence_number_less_than: int
         :keyword if_sequence_number_equal_to: Specify this header value to operate only on a blob if it
          has the specified sequence number.
-        :paramtype if_sequence_number_equal_to: long
+        :paramtype if_sequence_number_equal_to: int
         """
-        super(SequenceNumberAccessConditions, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.if_sequence_number_less_than_or_equal_to = if_sequence_number_less_than_or_equal_to
         self.if_sequence_number_less_than = if_sequence_number_less_than
         self.if_sequence_number_equal_to = if_sequence_number_equal_to
 
 
-class SignedIdentifier(msrest.serialization.Model):
+class SignedIdentifier(_serialization.Model):
     """signed identifier.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar id: Required. a unique id.
+    :ivar id: a unique id. Required.
     :vartype id: str
     :ivar access_policy: An Access policy.
     :vartype access_policy: ~azure.storage.blob.models.AccessPolicy
     """
 
     _validation = {
-        'id': {'required': True},
+        "id": {"required": True},
     }
 
     _attribute_map = {
-        'id': {'key': 'Id', 'type': 'str'},
-        'access_policy': {'key': 'AccessPolicy', 'type': 'AccessPolicy'},
-    }
-    _xml_map = {
-        'name': 'SignedIdentifier'
+        "id": {"key": "Id", "type": "str"},
+        "access_policy": {"key": "AccessPolicy", "type": "AccessPolicy"},
     }
+    _xml_map = {"name": "SignedIdentifier"}
 
     def __init__(
         self,
         *,
-        id: str,
-        access_policy: Optional["AccessPolicy"] = None,
+        id: str,  # pylint: disable=redefined-builtin
+        access_policy: Optional["_models.AccessPolicy"] = None,
         **kwargs
     ):
         """
-        :keyword id: Required. a unique id.
+        :keyword id: a unique id. Required.
         :paramtype id: str
         :keyword access_policy: An Access policy.
         :paramtype access_policy: ~azure.storage.blob.models.AccessPolicy
         """
-        super(SignedIdentifier, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.id = id
         self.access_policy = access_policy
 
 
-class SourceModifiedAccessConditions(msrest.serialization.Model):
+class SourceModifiedAccessConditions(_serialization.Model):
     """Parameter group.
 
     :ivar source_if_modified_since: Specify this header value to operate only on a blob if it has
      been modified since the specified date/time.
     :vartype source_if_modified_since: ~datetime.datetime
     :ivar source_if_unmodified_since: Specify this header value to operate only on a blob if it has
      not been modified since the specified date/time.
@@ -2567,19 +2464,19 @@
     :vartype source_if_none_match: str
     :ivar source_if_tags: Specify a SQL where clause on blob tags to operate only on blobs with a
      matching value.
     :vartype source_if_tags: str
     """
 
     _attribute_map = {
-        'source_if_modified_since': {'key': 'sourceIfModifiedSince', 'type': 'rfc-1123'},
-        'source_if_unmodified_since': {'key': 'sourceIfUnmodifiedSince', 'type': 'rfc-1123'},
-        'source_if_match': {'key': 'sourceIfMatch', 'type': 'str'},
-        'source_if_none_match': {'key': 'sourceIfNoneMatch', 'type': 'str'},
-        'source_if_tags': {'key': 'sourceIfTags', 'type': 'str'},
+        "source_if_modified_since": {"key": "sourceIfModifiedSince", "type": "rfc-1123"},
+        "source_if_unmodified_since": {"key": "sourceIfUnmodifiedSince", "type": "rfc-1123"},
+        "source_if_match": {"key": "sourceIfMatch", "type": "str"},
+        "source_if_none_match": {"key": "sourceIfNoneMatch", "type": "str"},
+        "source_if_tags": {"key": "sourceIfTags", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         source_if_modified_since: Optional[datetime.datetime] = None,
         source_if_unmodified_since: Optional[datetime.datetime] = None,
@@ -2600,100 +2497,95 @@
         :keyword source_if_none_match: Specify an ETag value to operate only on blobs without a
          matching value.
         :paramtype source_if_none_match: str
         :keyword source_if_tags: Specify a SQL where clause on blob tags to operate only on blobs with
          a matching value.
         :paramtype source_if_tags: str
         """
-        super(SourceModifiedAccessConditions, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.source_if_modified_since = source_if_modified_since
         self.source_if_unmodified_since = source_if_unmodified_since
         self.source_if_match = source_if_match
         self.source_if_none_match = source_if_none_match
         self.source_if_tags = source_if_tags
 
 
-class StaticWebsite(msrest.serialization.Model):
+class StaticWebsite(_serialization.Model):
     """The properties that enable an account to host a static website.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar enabled: Required. Indicates whether this account is hosting a static website.
+    :ivar enabled: Indicates whether this account is hosting a static website. Required.
     :vartype enabled: bool
     :ivar index_document: The default name of the index page under each directory.
     :vartype index_document: str
     :ivar error_document404_path: The absolute path of the custom 404 page.
     :vartype error_document404_path: str
     :ivar default_index_document_path: Absolute path of the default index page.
     :vartype default_index_document_path: str
     """
 
     _validation = {
-        'enabled': {'required': True},
+        "enabled": {"required": True},
     }
 
     _attribute_map = {
-        'enabled': {'key': 'Enabled', 'type': 'bool'},
-        'index_document': {'key': 'IndexDocument', 'type': 'str'},
-        'error_document404_path': {'key': 'ErrorDocument404Path', 'type': 'str'},
-        'default_index_document_path': {'key': 'DefaultIndexDocumentPath', 'type': 'str'},
+        "enabled": {"key": "Enabled", "type": "bool"},
+        "index_document": {"key": "IndexDocument", "type": "str"},
+        "error_document404_path": {"key": "ErrorDocument404Path", "type": "str"},
+        "default_index_document_path": {"key": "DefaultIndexDocumentPath", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         enabled: bool,
         index_document: Optional[str] = None,
         error_document404_path: Optional[str] = None,
         default_index_document_path: Optional[str] = None,
         **kwargs
     ):
         """
-        :keyword enabled: Required. Indicates whether this account is hosting a static website.
+        :keyword enabled: Indicates whether this account is hosting a static website. Required.
         :paramtype enabled: bool
         :keyword index_document: The default name of the index page under each directory.
         :paramtype index_document: str
         :keyword error_document404_path: The absolute path of the custom 404 page.
         :paramtype error_document404_path: str
         :keyword default_index_document_path: Absolute path of the default index page.
         :paramtype default_index_document_path: str
         """
-        super(StaticWebsite, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.enabled = enabled
         self.index_document = index_document
         self.error_document404_path = error_document404_path
         self.default_index_document_path = default_index_document_path
 
 
-class StorageError(msrest.serialization.Model):
+class StorageError(_serialization.Model):
     """StorageError.
 
     :ivar message:
     :vartype message: str
     """
 
     _attribute_map = {
-        'message': {'key': 'Message', 'type': 'str'},
+        "message": {"key": "Message", "type": "str"},
     }
 
-    def __init__(
-        self,
-        *,
-        message: Optional[str] = None,
-        **kwargs
-    ):
+    def __init__(self, *, message: Optional[str] = None, **kwargs):
         """
         :keyword message:
         :paramtype message: str
         """
-        super(StorageError, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.message = message
 
 
-class StorageServiceProperties(msrest.serialization.Model):
+class StorageServiceProperties(_serialization.Model):
     """Storage Service Properties.
 
     :ivar logging: Azure Analytics Logging settings.
     :vartype logging: ~azure.storage.blob.models.Logging
     :ivar hour_metrics: a summary of request statistics grouped by API in hour or minute aggregates
      for blobs.
     :vartype hour_metrics: ~azure.storage.blob.models.Metrics
@@ -2710,33 +2602,33 @@
      data should persist.
     :vartype delete_retention_policy: ~azure.storage.blob.models.RetentionPolicy
     :ivar static_website: The properties that enable an account to host a static website.
     :vartype static_website: ~azure.storage.blob.models.StaticWebsite
     """
 
     _attribute_map = {
-        'logging': {'key': 'Logging', 'type': 'Logging'},
-        'hour_metrics': {'key': 'HourMetrics', 'type': 'Metrics'},
-        'minute_metrics': {'key': 'MinuteMetrics', 'type': 'Metrics'},
-        'cors': {'key': 'Cors', 'type': '[CorsRule]', 'xml': {'wrapped': True}},
-        'default_service_version': {'key': 'DefaultServiceVersion', 'type': 'str'},
-        'delete_retention_policy': {'key': 'DeleteRetentionPolicy', 'type': 'RetentionPolicy'},
-        'static_website': {'key': 'StaticWebsite', 'type': 'StaticWebsite'},
+        "logging": {"key": "Logging", "type": "Logging"},
+        "hour_metrics": {"key": "HourMetrics", "type": "Metrics"},
+        "minute_metrics": {"key": "MinuteMetrics", "type": "Metrics"},
+        "cors": {"key": "Cors", "type": "[CorsRule]", "xml": {"wrapped": True}},
+        "default_service_version": {"key": "DefaultServiceVersion", "type": "str"},
+        "delete_retention_policy": {"key": "DeleteRetentionPolicy", "type": "RetentionPolicy"},
+        "static_website": {"key": "StaticWebsite", "type": "StaticWebsite"},
     }
 
     def __init__(
         self,
         *,
-        logging: Optional["Logging"] = None,
-        hour_metrics: Optional["Metrics"] = None,
-        minute_metrics: Optional["Metrics"] = None,
-        cors: Optional[List["CorsRule"]] = None,
+        logging: Optional["_models.Logging"] = None,
+        hour_metrics: Optional["_models.Metrics"] = None,
+        minute_metrics: Optional["_models.Metrics"] = None,
+        cors: Optional[List["_models.CorsRule"]] = None,
         default_service_version: Optional[str] = None,
-        delete_retention_policy: Optional["RetentionPolicy"] = None,
-        static_website: Optional["StaticWebsite"] = None,
+        delete_retention_policy: Optional["_models.RetentionPolicy"] = None,
+        static_website: Optional["_models.StaticWebsite"] = None,
         **kwargs
     ):
         """
         :keyword logging: Azure Analytics Logging settings.
         :paramtype logging: ~azure.storage.blob.models.Logging
         :keyword hour_metrics: a summary of request statistics grouped by API in hour or minute
          aggregates for blobs.
@@ -2752,88 +2644,83 @@
         :paramtype default_service_version: str
         :keyword delete_retention_policy: the retention policy which determines how long the associated
          data should persist.
         :paramtype delete_retention_policy: ~azure.storage.blob.models.RetentionPolicy
         :keyword static_website: The properties that enable an account to host a static website.
         :paramtype static_website: ~azure.storage.blob.models.StaticWebsite
         """
-        super(StorageServiceProperties, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.logging = logging
         self.hour_metrics = hour_metrics
         self.minute_metrics = minute_metrics
         self.cors = cors
         self.default_service_version = default_service_version
         self.delete_retention_policy = delete_retention_policy
         self.static_website = static_website
 
 
-class StorageServiceStats(msrest.serialization.Model):
+class StorageServiceStats(_serialization.Model):
     """Stats for the storage service.
 
     :ivar geo_replication: Geo-Replication information for the Secondary Storage Service.
     :vartype geo_replication: ~azure.storage.blob.models.GeoReplication
     """
 
     _attribute_map = {
-        'geo_replication': {'key': 'GeoReplication', 'type': 'GeoReplication'},
+        "geo_replication": {"key": "GeoReplication", "type": "GeoReplication"},
     }
 
-    def __init__(
-        self,
-        *,
-        geo_replication: Optional["GeoReplication"] = None,
-        **kwargs
-    ):
+    def __init__(self, *, geo_replication: Optional["_models.GeoReplication"] = None, **kwargs):
         """
         :keyword geo_replication: Geo-Replication information for the Secondary Storage Service.
         :paramtype geo_replication: ~azure.storage.blob.models.GeoReplication
         """
-        super(StorageServiceStats, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.geo_replication = geo_replication
 
 
-class UserDelegationKey(msrest.serialization.Model):
+class UserDelegationKey(_serialization.Model):
     """A user delegation key.
 
     All required parameters must be populated in order to send to Azure.
 
-    :ivar signed_oid: Required. The Azure Active Directory object ID in GUID format.
+    :ivar signed_oid: The Azure Active Directory object ID in GUID format. Required.
     :vartype signed_oid: str
-    :ivar signed_tid: Required. The Azure Active Directory tenant ID in GUID format.
+    :ivar signed_tid: The Azure Active Directory tenant ID in GUID format. Required.
     :vartype signed_tid: str
-    :ivar signed_start: Required. The date-time the key is active.
+    :ivar signed_start: The date-time the key is active. Required.
     :vartype signed_start: ~datetime.datetime
-    :ivar signed_expiry: Required. The date-time the key expires.
+    :ivar signed_expiry: The date-time the key expires. Required.
     :vartype signed_expiry: ~datetime.datetime
-    :ivar signed_service: Required. Abbreviation of the Azure Storage service that accepts the key.
+    :ivar signed_service: Abbreviation of the Azure Storage service that accepts the key. Required.
     :vartype signed_service: str
-    :ivar signed_version: Required. The service version that created the key.
+    :ivar signed_version: The service version that created the key. Required.
     :vartype signed_version: str
-    :ivar value: Required. The key as a base64 string.
+    :ivar value: The key as a base64 string. Required.
     :vartype value: str
     """
 
     _validation = {
-        'signed_oid': {'required': True},
-        'signed_tid': {'required': True},
-        'signed_start': {'required': True},
-        'signed_expiry': {'required': True},
-        'signed_service': {'required': True},
-        'signed_version': {'required': True},
-        'value': {'required': True},
+        "signed_oid": {"required": True},
+        "signed_tid": {"required": True},
+        "signed_start": {"required": True},
+        "signed_expiry": {"required": True},
+        "signed_service": {"required": True},
+        "signed_version": {"required": True},
+        "value": {"required": True},
     }
 
     _attribute_map = {
-        'signed_oid': {'key': 'SignedOid', 'type': 'str'},
-        'signed_tid': {'key': 'SignedTid', 'type': 'str'},
-        'signed_start': {'key': 'SignedStart', 'type': 'iso-8601'},
-        'signed_expiry': {'key': 'SignedExpiry', 'type': 'iso-8601'},
-        'signed_service': {'key': 'SignedService', 'type': 'str'},
-        'signed_version': {'key': 'SignedVersion', 'type': 'str'},
-        'value': {'key': 'Value', 'type': 'str'},
+        "signed_oid": {"key": "SignedOid", "type": "str"},
+        "signed_tid": {"key": "SignedTid", "type": "str"},
+        "signed_start": {"key": "SignedStart", "type": "iso-8601"},
+        "signed_expiry": {"key": "SignedExpiry", "type": "iso-8601"},
+        "signed_service": {"key": "SignedService", "type": "str"},
+        "signed_version": {"key": "SignedVersion", "type": "str"},
+        "value": {"key": "Value", "type": "str"},
     }
 
     def __init__(
         self,
         *,
         signed_oid: str,
         signed_tid: str,
@@ -2841,31 +2728,31 @@
         signed_expiry: datetime.datetime,
         signed_service: str,
         signed_version: str,
         value: str,
         **kwargs
     ):
         """
-        :keyword signed_oid: Required. The Azure Active Directory object ID in GUID format.
+        :keyword signed_oid: The Azure Active Directory object ID in GUID format. Required.
         :paramtype signed_oid: str
-        :keyword signed_tid: Required. The Azure Active Directory tenant ID in GUID format.
+        :keyword signed_tid: The Azure Active Directory tenant ID in GUID format. Required.
         :paramtype signed_tid: str
-        :keyword signed_start: Required. The date-time the key is active.
+        :keyword signed_start: The date-time the key is active. Required.
         :paramtype signed_start: ~datetime.datetime
-        :keyword signed_expiry: Required. The date-time the key expires.
+        :keyword signed_expiry: The date-time the key expires. Required.
         :paramtype signed_expiry: ~datetime.datetime
-        :keyword signed_service: Required. Abbreviation of the Azure Storage service that accepts the
-         key.
+        :keyword signed_service: Abbreviation of the Azure Storage service that accepts the key.
+         Required.
         :paramtype signed_service: str
-        :keyword signed_version: Required. The service version that created the key.
+        :keyword signed_version: The service version that created the key. Required.
         :paramtype signed_version: str
-        :keyword value: Required. The key as a base64 string.
+        :keyword value: The key as a base64 string. Required.
         :paramtype value: str
         """
-        super(UserDelegationKey, self).__init__(**kwargs)
+        super().__init__(**kwargs)
         self.signed_oid = signed_oid
         self.signed_tid = signed_tid
         self.signed_start = signed_start
         self.signed_expiry = signed_expiry
         self.signed_service = signed_service
         self.signed_version = signed_version
         self.value = value
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -3,21 +3,17 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from ._service_operations import ServiceOperations
-from ._container_operations import ContainerOperations
-from ._blob_operations import BlobOperations
-from ._page_blob_operations import PageBlobOperations
-from ._append_blob_operations import AppendBlobOperations
-from ._block_blob_operations import BlockBlobOperations
+from ._queue_operations import QueueOperations
+from ._messages_operations import MessagesOperations
+from ._message_id_operations import MessageIdOperations
 
 __all__ = [
     'ServiceOperations',
-    'ContainerOperations',
-    'BlobOperations',
-    'PageBlobOperations',
-    'AppendBlobOperations',
-    'BlockBlobOperations',
+    'QueueOperations',
+    'MessagesOperations',
+    'MessageIdOperations',
 ]
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_blob_operations.py`

 * *Files 16% similar despite different names*

```diff
@@ -3,1578 +3,1497 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
-from typing import TYPE_CHECKING
+from typing import Any, Callable, Dict, Iterator, Optional, TypeVar, Union
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
+from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
+from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
-    T = TypeVar('T')
-    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
+T = TypeVar("T")
+ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
-# fmt: off
+
 
 def build_download_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    version_id = kwargs.pop('version_id', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    range = kwargs.pop('range', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    range_get_content_md5 = kwargs.pop('range_get_content_md5', None)  # type: Optional[bool]
-    range_get_content_crc64 = kwargs.pop('range_get_content_crc64', None)  # type: Optional[bool]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    snapshot: Optional[str] = None,
+    version_id: Optional[str] = None,
+    timeout: Optional[int] = None,
+    range: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    range_get_content_md5: Optional[bool] = None,
+    range_get_content_crc64: Optional[bool] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if version_id is not None:
-        _query_parameters['versionid'] = _SERIALIZER.query("version_id", version_id, 'str')
+        _params["versionid"] = _SERIALIZER.query("version_id", version_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if range is not None:
-        _header_parameters['x-ms-range'] = _SERIALIZER.header("range", range, 'str')
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if range_get_content_md5 is not None:
-        _header_parameters['x-ms-range-get-content-md5'] = _SERIALIZER.header("range_get_content_md5", range_get_content_md5, 'bool')
+        _headers["x-ms-range-get-content-md5"] = _SERIALIZER.header(
+            "range_get_content_md5", range_get_content_md5, "bool"
+        )
     if range_get_content_crc64 is not None:
-        _header_parameters['x-ms-range-get-content-crc64'] = _SERIALIZER.header("range_get_content_crc64", range_get_content_crc64, 'bool')
+        _headers["x-ms-range-get-content-crc64"] = _SERIALIZER.header(
+            "range_get_content_crc64", range_get_content_crc64, "bool"
+        )
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_get_properties_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    version_id = kwargs.pop('version_id', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    snapshot: Optional[str] = None,
+    version_id: Optional[str] = None,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if version_id is not None:
-        _query_parameters['versionid'] = _SERIALIZER.query("version_id", version_id, 'str')
+        _params["versionid"] = _SERIALIZER.query("version_id", version_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="HEAD",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="HEAD", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_delete_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    version_id = kwargs.pop('version_id', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    delete_snapshots = kwargs.pop('delete_snapshots', None)  # type: Optional[Union[str, "_models.DeleteSnapshotsOptionType"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    blob_delete_type = kwargs.pop('blob_delete_type', "Permanent")  # type: Optional[str]
+    url: str,
+    *,
+    snapshot: Optional[str] = None,
+    version_id: Optional[str] = None,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    delete_snapshots: Optional[Union[str, "_models.DeleteSnapshotsOptionType"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    blob_delete_type: str = "Permanent",
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if version_id is not None:
-        _query_parameters['versionid'] = _SERIALIZER.query("version_id", version_id, 'str')
+        _params["versionid"] = _SERIALIZER.query("version_id", version_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
     if blob_delete_type is not None:
-        _query_parameters['deletetype'] = _SERIALIZER.query("blob_delete_type", blob_delete_type, 'str')
+        _params["deletetype"] = _SERIALIZER.query("blob_delete_type", blob_delete_type, "str")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if delete_snapshots is not None:
-        _header_parameters['x-ms-delete-snapshots'] = _SERIALIZER.header("delete_snapshots", delete_snapshots, 'str')
+        _headers["x-ms-delete-snapshots"] = _SERIALIZER.header("delete_snapshots", delete_snapshots, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_undelete_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "undelete")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_expiry_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "expiry")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    expiry_options = kwargs.pop('expiry_options')  # type: Union[str, "_models.BlobExpiryOptions"]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    expires_on = kwargs.pop('expires_on', None)  # type: Optional[str]
+    url: str,
+    *,
+    expiry_options: Union[str, "_models.BlobExpiryOptions"],
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    expires_on: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['x-ms-expiry-option'] = _SERIALIZER.header("expiry_options", expiry_options, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-expiry-option"] = _SERIALIZER.header("expiry_options", expiry_options, "str")
     if expires_on is not None:
-        _header_parameters['x-ms-expiry-time'] = _SERIALIZER.header("expires_on", expires_on, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-expiry-time"] = _SERIALIZER.header("expires_on", expires_on, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_http_headers_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    blob_cache_control = kwargs.pop('blob_cache_control', None)  # type: Optional[str]
-    blob_content_type = kwargs.pop('blob_content_type', None)  # type: Optional[str]
-    blob_content_md5 = kwargs.pop('blob_content_md5', None)  # type: Optional[bytearray]
-    blob_content_encoding = kwargs.pop('blob_content_encoding', None)  # type: Optional[str]
-    blob_content_language = kwargs.pop('blob_content_language', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    blob_content_disposition = kwargs.pop('blob_content_disposition', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    blob_cache_control: Optional[str] = None,
+    blob_content_type: Optional[str] = None,
+    blob_content_md5: Optional[bytes] = None,
+    blob_content_encoding: Optional[str] = None,
+    blob_content_language: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    blob_content_disposition: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if blob_cache_control is not None:
-        _header_parameters['x-ms-blob-cache-control'] = _SERIALIZER.header("blob_cache_control", blob_cache_control, 'str')
+        _headers["x-ms-blob-cache-control"] = _SERIALIZER.header("blob_cache_control", blob_cache_control, "str")
     if blob_content_type is not None:
-        _header_parameters['x-ms-blob-content-type'] = _SERIALIZER.header("blob_content_type", blob_content_type, 'str')
+        _headers["x-ms-blob-content-type"] = _SERIALIZER.header("blob_content_type", blob_content_type, "str")
     if blob_content_md5 is not None:
-        _header_parameters['x-ms-blob-content-md5'] = _SERIALIZER.header("blob_content_md5", blob_content_md5, 'bytearray')
+        _headers["x-ms-blob-content-md5"] = _SERIALIZER.header("blob_content_md5", blob_content_md5, "bytearray")
     if blob_content_encoding is not None:
-        _header_parameters['x-ms-blob-content-encoding'] = _SERIALIZER.header("blob_content_encoding", blob_content_encoding, 'str')
+        _headers["x-ms-blob-content-encoding"] = _SERIALIZER.header(
+            "blob_content_encoding", blob_content_encoding, "str"
+        )
     if blob_content_language is not None:
-        _header_parameters['x-ms-blob-content-language'] = _SERIALIZER.header("blob_content_language", blob_content_language, 'str')
+        _headers["x-ms-blob-content-language"] = _SERIALIZER.header(
+            "blob_content_language", blob_content_language, "str"
+        )
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     if blob_content_disposition is not None:
-        _header_parameters['x-ms-blob-content-disposition'] = _SERIALIZER.header("blob_content_disposition", blob_content_disposition, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-blob-content-disposition"] = _SERIALIZER.header(
+            "blob_content_disposition", blob_content_disposition, "str"
+        )
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_immutability_policy_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "immutabilityPolicies")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    immutability_policy_expiry = kwargs.pop('immutability_policy_expiry', None)  # type: Optional[datetime.datetime]
-    immutability_policy_mode = kwargs.pop('immutability_policy_mode', None)  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    immutability_policy_expiry: Optional[datetime.datetime] = None,
+    immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if immutability_policy_expiry is not None:
-        _header_parameters['x-ms-immutability-policy-until-date'] = _SERIALIZER.header("immutability_policy_expiry", immutability_policy_expiry, 'rfc-1123')
+        _headers["x-ms-immutability-policy-until-date"] = _SERIALIZER.header(
+            "immutability_policy_expiry", immutability_policy_expiry, "rfc-1123"
+        )
     if immutability_policy_mode is not None:
-        _header_parameters['x-ms-immutability-policy-mode'] = _SERIALIZER.header("immutability_policy_mode", immutability_policy_mode, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-immutability-policy-mode"] = _SERIALIZER.header(
+            "immutability_policy_mode", immutability_policy_mode, "str"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_delete_immutability_policy_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "immutabilityPolicies")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_legal_hold_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "legalhold")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    legal_hold = kwargs.pop('legal_hold')  # type: bool
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    legal_hold: bool,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "legalhold"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['x-ms-legal-hold'] = _SERIALIZER.header("legal_hold", legal_hold, 'bool')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
-
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-legal-hold"] = _SERIALIZER.header("legal_hold", legal_hold, "bool")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_metadata_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "metadata")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    lease_id: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_acquire_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    action = kwargs.pop('action', "acquire")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    duration = kwargs.pop('duration', None)  # type: Optional[int]
-    proposed_lease_id = kwargs.pop('proposed_lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    duration: Optional[int] = None,
+    proposed_lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
     if duration is not None:
-        _header_parameters['x-ms-lease-duration'] = _SERIALIZER.header("duration", duration, 'int')
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
     if proposed_lease_id is not None:
-        _header_parameters['x-ms-proposed-lease-id'] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, 'str')
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_release_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    action = kwargs.pop('action', "release")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    lease_id = kwargs.pop('lease_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
-    _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_renew_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    action = kwargs.pop('action', "renew")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    lease_id = kwargs.pop('lease_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
-    _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_change_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    action = kwargs.pop('action', "change")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    lease_id = kwargs.pop('lease_id')  # type: str
-    proposed_lease_id = kwargs.pop('proposed_lease_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    lease_id: str,
+    proposed_lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
-    _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-proposed-lease-id'] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_break_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    action = kwargs.pop('action', "break")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    break_period = kwargs.pop('break_period', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    break_period: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
     if break_period is not None:
-        _header_parameters['x-ms-lease-break-period'] = _SERIALIZER.header("break_period", break_period, 'int')
+        _headers["x-ms-lease-break-period"] = _SERIALIZER.header("break_period", break_period, "int")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_create_snapshot_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "snapshot")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "snapshot"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_start_copy_from_url_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    copy_source = kwargs.pop('copy_source')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    tier = kwargs.pop('tier', None)  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-    rehydrate_priority = kwargs.pop('rehydrate_priority', None)  # type: Optional[Union[str, "_models.RehydratePriority"]]
-    source_if_modified_since = kwargs.pop('source_if_modified_since', None)  # type: Optional[datetime.datetime]
-    source_if_unmodified_since = kwargs.pop('source_if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    source_if_match = kwargs.pop('source_if_match', None)  # type: Optional[str]
-    source_if_none_match = kwargs.pop('source_if_none_match', None)  # type: Optional[str]
-    source_if_tags = kwargs.pop('source_if_tags', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    blob_tags_string = kwargs.pop('blob_tags_string', None)  # type: Optional[str]
-    seal_blob = kwargs.pop('seal_blob', None)  # type: Optional[bool]
-    immutability_policy_expiry = kwargs.pop('immutability_policy_expiry', None)  # type: Optional[datetime.datetime]
-    immutability_policy_mode = kwargs.pop('immutability_policy_mode', None)  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-    legal_hold = kwargs.pop('legal_hold', None)  # type: Optional[bool]
+    url: str,
+    *,
+    copy_source: str,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+    rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
+    source_if_modified_since: Optional[datetime.datetime] = None,
+    source_if_unmodified_since: Optional[datetime.datetime] = None,
+    source_if_match: Optional[str] = None,
+    source_if_none_match: Optional[str] = None,
+    source_if_tags: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    blob_tags_string: Optional[str] = None,
+    seal_blob: Optional[bool] = None,
+    immutability_policy_expiry: Optional[datetime.datetime] = None,
+    immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+    legal_hold: Optional[bool] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if tier is not None:
-        _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
     if rehydrate_priority is not None:
-        _header_parameters['x-ms-rehydrate-priority'] = _SERIALIZER.header("rehydrate_priority", rehydrate_priority, 'str')
+        _headers["x-ms-rehydrate-priority"] = _SERIALIZER.header("rehydrate_priority", rehydrate_priority, "str")
     if source_if_modified_since is not None:
-        _header_parameters['x-ms-source-if-modified-since'] = _SERIALIZER.header("source_if_modified_since", source_if_modified_since, 'rfc-1123')
+        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
+            "source_if_modified_since", source_if_modified_since, "rfc-1123"
+        )
     if source_if_unmodified_since is not None:
-        _header_parameters['x-ms-source-if-unmodified-since'] = _SERIALIZER.header("source_if_unmodified_since", source_if_unmodified_since, 'rfc-1123')
+        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
+            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
+        )
     if source_if_match is not None:
-        _header_parameters['x-ms-source-if-match'] = _SERIALIZER.header("source_if_match", source_if_match, 'str')
+        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
     if source_if_none_match is not None:
-        _header_parameters['x-ms-source-if-none-match'] = _SERIALIZER.header("source_if_none_match", source_if_none_match, 'str')
+        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
     if source_if_tags is not None:
-        _header_parameters['x-ms-source-if-tags'] = _SERIALIZER.header("source_if_tags", source_if_tags, 'str')
+        _headers["x-ms-source-if-tags"] = _SERIALIZER.header("source_if_tags", source_if_tags, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-copy-source'] = _SERIALIZER.header("copy_source", copy_source, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if blob_tags_string is not None:
-        _header_parameters['x-ms-tags'] = _SERIALIZER.header("blob_tags_string", blob_tags_string, 'str')
+        _headers["x-ms-tags"] = _SERIALIZER.header("blob_tags_string", blob_tags_string, "str")
     if seal_blob is not None:
-        _header_parameters['x-ms-seal-blob'] = _SERIALIZER.header("seal_blob", seal_blob, 'bool')
+        _headers["x-ms-seal-blob"] = _SERIALIZER.header("seal_blob", seal_blob, "bool")
     if immutability_policy_expiry is not None:
-        _header_parameters['x-ms-immutability-policy-until-date'] = _SERIALIZER.header("immutability_policy_expiry", immutability_policy_expiry, 'rfc-1123')
+        _headers["x-ms-immutability-policy-until-date"] = _SERIALIZER.header(
+            "immutability_policy_expiry", immutability_policy_expiry, "rfc-1123"
+        )
     if immutability_policy_mode is not None:
-        _header_parameters['x-ms-immutability-policy-mode'] = _SERIALIZER.header("immutability_policy_mode", immutability_policy_mode, 'str')
+        _headers["x-ms-immutability-policy-mode"] = _SERIALIZER.header(
+            "immutability_policy_mode", immutability_policy_mode, "str"
+        )
     if legal_hold is not None:
-        _header_parameters['x-ms-legal-hold'] = _SERIALIZER.header("legal_hold", legal_hold, 'bool')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-legal-hold"] = _SERIALIZER.header("legal_hold", legal_hold, "bool")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_copy_from_url_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    x_ms_requires_sync = kwargs.pop('x_ms_requires_sync', "true")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    copy_source = kwargs.pop('copy_source')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    tier = kwargs.pop('tier', None)  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-    source_if_modified_since = kwargs.pop('source_if_modified_since', None)  # type: Optional[datetime.datetime]
-    source_if_unmodified_since = kwargs.pop('source_if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    source_if_match = kwargs.pop('source_if_match', None)  # type: Optional[str]
-    source_if_none_match = kwargs.pop('source_if_none_match', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    source_content_md5 = kwargs.pop('source_content_md5', None)  # type: Optional[bytearray]
-    blob_tags_string = kwargs.pop('blob_tags_string', None)  # type: Optional[str]
-    immutability_policy_expiry = kwargs.pop('immutability_policy_expiry', None)  # type: Optional[datetime.datetime]
-    immutability_policy_mode = kwargs.pop('immutability_policy_mode', None)  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-    legal_hold = kwargs.pop('legal_hold', None)  # type: Optional[bool]
-    copy_source_authorization = kwargs.pop('copy_source_authorization', None)  # type: Optional[str]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    copy_source_tags = kwargs.pop('copy_source_tags', None)  # type: Optional[Union[str, "_models.BlobCopySourceTags"]]
+    url: str,
+    *,
+    copy_source: str,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+    source_if_modified_since: Optional[datetime.datetime] = None,
+    source_if_unmodified_since: Optional[datetime.datetime] = None,
+    source_if_match: Optional[str] = None,
+    source_if_none_match: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    source_content_md5: Optional[bytes] = None,
+    blob_tags_string: Optional[str] = None,
+    immutability_policy_expiry: Optional[datetime.datetime] = None,
+    immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+    legal_hold: Optional[bool] = None,
+    copy_source_authorization: Optional[str] = None,
+    encryption_scope: Optional[str] = None,
+    copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    x_ms_requires_sync = kwargs.pop("x_ms_requires_sync", _headers.pop("x-ms-requires-sync", "true"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-requires-sync'] = _SERIALIZER.header("x_ms_requires_sync", x_ms_requires_sync, 'str')
+    _headers["x-ms-requires-sync"] = _SERIALIZER.header("x_ms_requires_sync", x_ms_requires_sync, "str")
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if tier is not None:
-        _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
     if source_if_modified_since is not None:
-        _header_parameters['x-ms-source-if-modified-since'] = _SERIALIZER.header("source_if_modified_since", source_if_modified_since, 'rfc-1123')
+        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
+            "source_if_modified_since", source_if_modified_since, "rfc-1123"
+        )
     if source_if_unmodified_since is not None:
-        _header_parameters['x-ms-source-if-unmodified-since'] = _SERIALIZER.header("source_if_unmodified_since", source_if_unmodified_since, 'rfc-1123')
+        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
+            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
+        )
     if source_if_match is not None:
-        _header_parameters['x-ms-source-if-match'] = _SERIALIZER.header("source_if_match", source_if_match, 'str')
+        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
     if source_if_none_match is not None:
-        _header_parameters['x-ms-source-if-none-match'] = _SERIALIZER.header("source_if_none_match", source_if_none_match, 'str')
+        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-copy-source'] = _SERIALIZER.header("copy_source", copy_source, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if source_content_md5 is not None:
-        _header_parameters['x-ms-source-content-md5'] = _SERIALIZER.header("source_content_md5", source_content_md5, 'bytearray')
+        _headers["x-ms-source-content-md5"] = _SERIALIZER.header("source_content_md5", source_content_md5, "bytearray")
     if blob_tags_string is not None:
-        _header_parameters['x-ms-tags'] = _SERIALIZER.header("blob_tags_string", blob_tags_string, 'str')
+        _headers["x-ms-tags"] = _SERIALIZER.header("blob_tags_string", blob_tags_string, "str")
     if immutability_policy_expiry is not None:
-        _header_parameters['x-ms-immutability-policy-until-date'] = _SERIALIZER.header("immutability_policy_expiry", immutability_policy_expiry, 'rfc-1123')
+        _headers["x-ms-immutability-policy-until-date"] = _SERIALIZER.header(
+            "immutability_policy_expiry", immutability_policy_expiry, "rfc-1123"
+        )
     if immutability_policy_mode is not None:
-        _header_parameters['x-ms-immutability-policy-mode'] = _SERIALIZER.header("immutability_policy_mode", immutability_policy_mode, 'str')
+        _headers["x-ms-immutability-policy-mode"] = _SERIALIZER.header(
+            "immutability_policy_mode", immutability_policy_mode, "str"
+        )
     if legal_hold is not None:
-        _header_parameters['x-ms-legal-hold'] = _SERIALIZER.header("legal_hold", legal_hold, 'bool')
+        _headers["x-ms-legal-hold"] = _SERIALIZER.header("legal_hold", legal_hold, "bool")
     if copy_source_authorization is not None:
-        _header_parameters['x-ms-copy-source-authorization'] = _SERIALIZER.header("copy_source_authorization", copy_source_authorization, 'str')
+        _headers["x-ms-copy-source-authorization"] = _SERIALIZER.header(
+            "copy_source_authorization", copy_source_authorization, "str"
+        )
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if copy_source_tags is not None:
-        _header_parameters['x-ms-copy-source-tag-option'] = _SERIALIZER.header("copy_source_tags", copy_source_tags, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-copy-source-tag-option"] = _SERIALIZER.header("copy_source_tags", copy_source_tags, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_abort_copy_from_url_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "copy")  # type: str
-    copy_action_abort_constant = kwargs.pop('copy_action_abort_constant', "abort")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    copy_id = kwargs.pop('copy_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    copy_id: str,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "copy"))  # type: str
+    copy_action_abort_constant = kwargs.pop(
+        "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
+    )  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['copyid'] = _SERIALIZER.query("copy_id", copy_id, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["copyid"] = _SERIALIZER.query("copy_id", copy_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-copy-action'] = _SERIALIZER.header("copy_action_abort_constant", copy_action_abort_constant, 'str')
+    _headers["x-ms-copy-action"] = _SERIALIZER.header("copy_action_abort_constant", copy_action_abort_constant, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_tier_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "tier")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    tier = kwargs.pop('tier')  # type: Union[str, "_models.AccessTierRequired"]
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    version_id = kwargs.pop('version_id', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    rehydrate_priority = kwargs.pop('rehydrate_priority', None)  # type: Optional[Union[str, "_models.RehydratePriority"]]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
+    url: str,
+    *,
+    tier: Union[str, "_models.AccessTierRequired"],
+    snapshot: Optional[str] = None,
+    version_id: Optional[str] = None,
+    timeout: Optional[int] = None,
+    rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
+    request_id_parameter: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "tier"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if version_id is not None:
-        _query_parameters['versionid'] = _SERIALIZER.query("version_id", version_id, 'str')
+        _params["versionid"] = _SERIALIZER.query("version_id", version_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
+    _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
     if rehydrate_priority is not None:
-        _header_parameters['x-ms-rehydrate-priority'] = _SERIALIZER.header("rehydrate_priority", rehydrate_priority, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-rehydrate-priority"] = _SERIALIZER.header("rehydrate_priority", rehydrate_priority, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_get_account_info_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "account")  # type: str
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
+def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
-
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_query_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "query")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    snapshot: Optional[str] = None,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    content: Any = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "query"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="POST",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_get_tags_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "tags")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    version_id = kwargs.pop('version_id', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    snapshot: Optional[str] = None,
+    version_id: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if version_id is not None:
-        _query_parameters['versionid'] = _SERIALIZER.query("version_id", version_id, 'str')
+        _params["versionid"] = _SERIALIZER.query("version_id", version_id, "str")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_tags_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "tags")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    version_id = kwargs.pop('version_id', None)  # type: Optional[str]
-    transactional_content_md5 = kwargs.pop('transactional_content_md5', None)  # type: Optional[bytearray]
-    transactional_content_crc64 = kwargs.pop('transactional_content_crc64', None)  # type: Optional[bytearray]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    version_id: Optional[str] = None,
+    transactional_content_md5: Optional[bytes] = None,
+    transactional_content_crc64: Optional[bytes] = None,
+    request_id_parameter: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    content: Any = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
     if version_id is not None:
-        _query_parameters['versionid'] = _SERIALIZER.query("version_id", version_id, 'str')
+        _params["versionid"] = _SERIALIZER.query("version_id", version_id, "str")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if transactional_content_md5 is not None:
-        _header_parameters['Content-MD5'] = _SERIALIZER.header("transactional_content_md5", transactional_content_md5, 'bytearray')
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_md5", transactional_content_md5, "bytearray"
+        )
     if transactional_content_crc64 is not None:
-        _header_parameters['x-ms-content-crc64'] = _SERIALIZER.header("transactional_content_crc64", transactional_content_crc64, 'bytearray')
+        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
+            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+        )
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
-# fmt: on
-class BlobOperations(object):  # pylint: disable=too-many-public-methods
+
+class BlobOperations:  # pylint: disable=too-many-public-methods
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.AzureBlobStorage`'s
         :attr:`blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def download(
         self,
-        snapshot=None,  # type: Optional[str]
-        version_id=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        range=None,  # type: Optional[str]
-        range_get_content_md5=None,  # type: Optional[bool]
-        range_get_content_crc64=None,  # type: Optional[bool]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> IO
+        snapshot: Optional[str] = None,
+        version_id: Optional[str] = None,
+        timeout: Optional[int] = None,
+        range: Optional[str] = None,
+        range_get_content_md5: Optional[bool] = None,
+        range_get_content_crc64: Optional[bool] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> Iterator[bytes]:
         """The Download operation reads or downloads a blob from the system, including its metadata and
         properties. You can also call Download to read a snapshot.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -1606,49 +1525,50 @@
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_download_request(
             url=self._config.url,
-            version=self._config.version,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             range=range,
             lease_id=_lease_id,
             range_get_content_md5=range_get_content_md5,
             range_get_content_crc64=range_get_content_crc64,
@@ -1657,146 +1577,212 @@
             encryption_algorithm=_encryption_algorithm,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.download.metadata['url'],
+            version=self._config.version,
+            template_url=self.download.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 206]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['x-ms-or-policy-id']=self._deserialize('str', response.headers.get('x-ms-or-policy-id'))
-            response_headers['x-ms-or']=self._deserialize('{str}', response.headers.get('x-ms-or'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-            response_headers['x-ms-is-current-version']=self._deserialize('bool', response.headers.get('x-ms-is-current-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            response_headers['x-ms-tag-count']=self._deserialize('long', response.headers.get('x-ms-tag-count'))
-            response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-            response_headers['x-ms-last-access-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-last-access-time'))
-            response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-            response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-            response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
+            response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+            response_headers["x-ms-is-current-version"] = self._deserialize(
+                "bool", response.headers.get("x-ms-is-current-version")
+            )
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+            response_headers["x-ms-tag-count"] = self._deserialize("int", response.headers.get("x-ms-tag-count"))
+            response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
+            response_headers["x-ms-last-access-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-last-access-time")
+            )
+            response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+            )
+            response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+                "str", response.headers.get("x-ms-immutability-policy-mode")
+            )
+            response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if response.status_code == 206:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['x-ms-or-policy-id']=self._deserialize('str', response.headers.get('x-ms-or-policy-id'))
-            response_headers['x-ms-or']=self._deserialize('{str}', response.headers.get('x-ms-or'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-            response_headers['x-ms-is-current-version']=self._deserialize('bool', response.headers.get('x-ms-is-current-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            response_headers['x-ms-tag-count']=self._deserialize('long', response.headers.get('x-ms-tag-count'))
-            response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-            response_headers['x-ms-last-access-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-last-access-time'))
-            response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-            response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-            response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
+            response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-content-crc64"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-content-crc64")
+            )
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+            response_headers["x-ms-is-current-version"] = self._deserialize(
+                "bool", response.headers.get("x-ms-is-current-version")
+            )
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+            response_headers["x-ms-tag-count"] = self._deserialize("int", response.headers.get("x-ms-tag-count"))
+            response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
+            response_headers["x-ms-last-access-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-last-access-time")
+            )
+            response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+            )
+            response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+                "str", response.headers.get("x-ms-immutability-policy-mode")
+            )
+            response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    download.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    download.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        snapshot=None,  # type: Optional[str]
-        version_id=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        snapshot: Optional[str] = None,
+        version_id: Optional[str] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Get Properties operation returns all user-defined metadata, standard HTTP properties, and
         system properties for the blob. It does not return the content of the blob.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -1818,151 +1804,187 @@
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_get_properties_request(
             url=self._config.url,
-            version=self._config.version,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_properties.metadata['url'],
+            version=self._config.version,
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-creation-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-creation-time'))
-        response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-        response_headers['x-ms-or-policy-id']=self._deserialize('str', response.headers.get('x-ms-or-policy-id'))
-        response_headers['x-ms-or']=self._deserialize('{str}', response.headers.get('x-ms-or'))
-        response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-        response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-        response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-        response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-        response_headers['x-ms-incremental-copy']=self._deserialize('bool', response.headers.get('x-ms-incremental-copy'))
-        response_headers['x-ms-copy-destination-snapshot']=self._deserialize('str', response.headers.get('x-ms-copy-destination-snapshot'))
-        response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-        response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-        response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-        response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-        response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-        response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-        response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-        response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-        response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-        response_headers['x-ms-access-tier']=self._deserialize('str', response.headers.get('x-ms-access-tier'))
-        response_headers['x-ms-access-tier-inferred']=self._deserialize('bool', response.headers.get('x-ms-access-tier-inferred'))
-        response_headers['x-ms-archive-status']=self._deserialize('str', response.headers.get('x-ms-archive-status'))
-        response_headers['x-ms-access-tier-change-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-access-tier-change-time'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['x-ms-is-current-version']=self._deserialize('bool', response.headers.get('x-ms-is-current-version'))
-        response_headers['x-ms-tag-count']=self._deserialize('long', response.headers.get('x-ms-tag-count'))
-        response_headers['x-ms-expiry-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-expiry-time'))
-        response_headers['x-ms-blob-sealed']=self._deserialize('bool', response.headers.get('x-ms-blob-sealed'))
-        response_headers['x-ms-rehydrate-priority']=self._deserialize('str', response.headers.get('x-ms-rehydrate-priority'))
-        response_headers['x-ms-last-access-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-last-access-time'))
-        response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-        response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-        response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-creation-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-creation-time")
+        )
+        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
+        response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
+        response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+        response_headers["x-ms-copy-completion-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+        )
+        response_headers["x-ms-copy-status-description"] = self._deserialize(
+            "str", response.headers.get("x-ms-copy-status-description")
+        )
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-progress"] = self._deserialize("str", response.headers.get("x-ms-copy-progress"))
+        response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+        response_headers["x-ms-incremental-copy"] = self._deserialize(
+            "bool", response.headers.get("x-ms-incremental-copy")
+        )
+        response_headers["x-ms-copy-destination-snapshot"] = self._deserialize(
+            "str", response.headers.get("x-ms-copy-destination-snapshot")
+        )
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+        response_headers["Content-Disposition"] = self._deserialize("str", response.headers.get("Content-Disposition"))
+        response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+        response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+        response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-committed-block-count")
+        )
+        response_headers["x-ms-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
+        response_headers["x-ms-access-tier"] = self._deserialize("str", response.headers.get("x-ms-access-tier"))
+        response_headers["x-ms-access-tier-inferred"] = self._deserialize(
+            "bool", response.headers.get("x-ms-access-tier-inferred")
+        )
+        response_headers["x-ms-archive-status"] = self._deserialize("str", response.headers.get("x-ms-archive-status"))
+        response_headers["x-ms-access-tier-change-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-access-tier-change-time")
+        )
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["x-ms-is-current-version"] = self._deserialize(
+            "bool", response.headers.get("x-ms-is-current-version")
+        )
+        response_headers["x-ms-tag-count"] = self._deserialize("int", response.headers.get("x-ms-tag-count"))
+        response_headers["x-ms-expiry-time"] = self._deserialize("rfc-1123", response.headers.get("x-ms-expiry-time"))
+        response_headers["x-ms-blob-sealed"] = self._deserialize("bool", response.headers.get("x-ms-blob-sealed"))
+        response_headers["x-ms-rehydrate-priority"] = self._deserialize(
+            "str", response.headers.get("x-ms-rehydrate-priority")
+        )
+        response_headers["x-ms-last-access-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-last-access-time")
+        )
+        response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+        )
+        response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+            "str", response.headers.get("x-ms-immutability-policy-mode")
+        )
+        response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def delete(  # pylint: disable=inconsistent-return-statements
         self,
-        snapshot=None,  # type: Optional[str]
-        version_id=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        delete_snapshots=None,  # type: Optional[Union[str, "_models.DeleteSnapshotsOptionType"]]
-        request_id_parameter=None,  # type: Optional[str]
-        blob_delete_type="Permanent",  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        snapshot: Optional[str] = None,
+        version_id: Optional[str] = None,
+        timeout: Optional[int] = None,
+        delete_snapshots: Optional[Union[str, "_models.DeleteSnapshotsOptionType"]] = None,
+        request_id_parameter: Optional[str] = None,
+        blob_delete_type: str = "Permanent",
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """If the storage account's soft delete feature is disabled then, when a blob is deleted, it is
         permanently removed from the storage account. If the storage account's soft delete feature is
         enabled, then, when a blob is deleted, it is marked for deletion and becomes inaccessible
         immediately. However, the blob service retains the blob or snapshot for the number of days
         specified by the DeleteRetentionPolicy section of [Storage service properties]
         (Set-Blob-Service-Properties.md). After the specified number of days has passed, the blob's
         data is permanently removed from the storage account. Note that you continue to be charged for
@@ -1985,107 +2007,107 @@
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param delete_snapshots: Required if the blob has associated snapshots. Specify one of the
          following two options: include: Delete the base blob and all of its snapshots. only: Delete
-         only the blob's snapshots and not the blob itself. Default value is None.
+         only the blob's snapshots and not the blob itself. Known values are: "include" and "only".
+         Default value is None.
         :type delete_snapshots: str or ~azure.storage.blob.models.DeleteSnapshotsOptionType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_delete_type: Optional.  Only possible value is 'permanent', which specifies to
-         permanently delete a blob if blob soft delete is enabled. Possible values are "Permanent" or
+         permanently delete a blob if blob soft delete is enabled. Known values are "Permanent" and
          None. Default value is "Permanent".
         :type blob_delete_type: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_delete_request(
             url=self._config.url,
-            version=self._config.version,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             lease_id=_lease_id,
             delete_snapshots=delete_snapshots,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_delete_type=blob_delete_type,
-            template_url=self.delete.metadata['url'],
+            version=self._config.version,
+            template_url=self.delete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    delete.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def undelete(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> None:
         """Undelete a blob that was previously soft deleted.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -2093,76 +2115,77 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "undelete")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_undelete_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.undelete.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.undelete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    undelete.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    undelete.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_expiry(  # pylint: disable=inconsistent-return-statements
         self,
-        expiry_options,  # type: Union[str, "_models.BlobExpiryOptions"]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        expires_on=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        expiry_options: Union[str, "_models.BlobExpiryOptions"],
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        expires_on: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
         """Sets the time a blob will expire and be deleted.
 
-        :param expiry_options: Required. Indicates mode of the expiry time.
+        :param expiry_options: Required. Indicates mode of the expiry time. Known values are:
+         "NeverExpire", "RelativeToCreation", "RelativeToNow", and "Absolute". Required.
         :type expiry_options: str or ~azure.storage.blob.models.BlobExpiryOptions
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2171,78 +2194,78 @@
         :type request_id_parameter: str
         :param expires_on: The time to set the blob to expiry. Default value is None.
         :type expires_on: str
         :keyword comp: comp. Default value is "expiry". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "expiry")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_set_expiry_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             expiry_options=expiry_options,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             expires_on=expires_on,
-            template_url=self.set_expiry.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_expiry.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_expiry.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_expiry.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_http_headers(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        blob_http_headers=None,  # type: Optional["_models.BlobHTTPHeaders"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Set HTTP Headers operation sets system properties on the blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -2256,25 +2279,26 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "properties")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_cache_control = None
         _blob_content_type = None
         _blob_content_md5 = None
         _blob_content_encoding = None
         _blob_content_language = None
         _lease_id = None
@@ -2282,91 +2306,92 @@
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _blob_content_disposition = None
         if blob_http_headers is not None:
             _blob_cache_control = blob_http_headers.blob_cache_control
-            _blob_content_type = blob_http_headers.blob_content_type
-            _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
+            _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_set_http_headers_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             blob_cache_control=_blob_cache_control,
             blob_content_type=_blob_content_type,
             blob_content_md5=_blob_content_md5,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             blob_content_disposition=_blob_content_disposition,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_http_headers.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_http_headers.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_http_headers.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_http_headers.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_immutability_policy(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        immutability_policy_expiry=None,  # type: Optional[datetime.datetime]
-        immutability_policy_mode=None,  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        immutability_policy_expiry: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Set Immutability Policy operation sets the immutability policy on the blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -2374,87 +2399,89 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "immutabilityPolicies". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "immutabilityPolicies")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_set_immutability_policy_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             if_unmodified_since=_if_unmodified_since,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
-            template_url=self.set_immutability_policy.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_immutability_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-immutability-policy-until-date']=self._deserialize('rfc-1123', response.headers.get('x-ms-immutability-policy-until-date'))
-        response_headers['x-ms-immutability-policy-mode']=self._deserialize('str', response.headers.get('x-ms-immutability-policy-mode'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-immutability-policy-until-date"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-immutability-policy-until-date")
+        )
+        response_headers["x-ms-immutability-policy-mode"] = self._deserialize(
+            "str", response.headers.get("x-ms-immutability-policy-mode")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_immutability_policy.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_immutability_policy.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def delete_immutability_policy(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> None:
         """The Delete Immutability Policy operation deletes the immutability policy on the blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -2462,153 +2489,149 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "immutabilityPolicies". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "immutabilityPolicies")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_delete_immutability_policy_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.delete_immutability_policy.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.delete_immutability_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete_immutability_policy.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    delete_immutability_policy.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_legal_hold(  # pylint: disable=inconsistent-return-statements
-        self,
-        legal_hold,  # type: bool
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        self, legal_hold: bool, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> None:
         """The Set Legal Hold operation sets a legal hold on the blob.
 
-        :param legal_hold: Specified if a legal hold should be set on the blob.
+        :param legal_hold: Specified if a legal hold should be set on the blob. Required.
         :type legal_hold: bool
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "legalhold". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "legalhold")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "legalhold"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_set_legal_hold_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             legal_hold=legal_hold,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_legal_hold.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_legal_hold.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-legal-hold'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_legal_hold.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_legal_hold.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Set Blob Metadata operation sets user-defined metadata for the specified blob as one or
         more name-value pairs.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -2633,115 +2656,122 @@
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "metadata")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_set_metadata_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             metadata=metadata,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_metadata.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_metadata.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_metadata.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_metadata.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        duration=None,  # type: Optional[int]
-        proposed_lease_id=None,  # type: Optional[str]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        duration: Optional[int] = None,
+        proposed_lease_id: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -2763,100 +2793,101 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "acquire". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "acquire")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_acquire_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             duration=duration,
             proposed_lease_id=proposed_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.acquire_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.acquire_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    acquire_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    acquire_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def release_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2868,98 +2899,99 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "release". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "release")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_release_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.release_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.release_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    release_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    release_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def renew_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2971,104 +3003,105 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "renew". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "renew")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_renew_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.renew_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.renew_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    renew_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    renew_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def change_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id,  # type: str
-        proposed_lease_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        lease_id: str,
+        proposed_lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
          400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats.
+         Constructor (String) for a list of valid GUID string formats. Required.
         :type proposed_lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -3080,96 +3113,97 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "change". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "change")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_change_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             proposed_lease_id=proposed_lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.change_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.change_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    change_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        break_period=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        break_period: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] The Lease Blob operation establishes and manages a lock on a blob for write and delete
         operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -3191,98 +3225,99 @@
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword action: Describes what lease action to take. Default value is "break". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "lease")  # type: str
-        action = kwargs.pop('action', "break")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_break_lease_request(
             url=self._config.url,
-            comp=comp,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             break_period=break_period,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.break_lease.metadata['url'],
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.break_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-time']=self._deserialize('int', response.headers.get('x-ms-lease-time'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    break_lease.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    break_lease.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def create_snapshot(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        request_id_parameter=None,  # type: Optional[str]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        request_id_parameter: Optional[str] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Create Snapshot operation creates a read-only snapshot of a blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -3306,147 +3341,152 @@
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword comp: comp. Default value is "snapshot". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "snapshot")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "snapshot"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _lease_id = None
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_create_snapshot_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             metadata=metadata,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.create_snapshot.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.create_snapshot.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-snapshot']=self._deserialize('str', response.headers.get('x-ms-snapshot'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-
+        response_headers["x-ms-snapshot"] = self._deserialize("str", response.headers.get("x-ms-snapshot"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create_snapshot.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    create_snapshot.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def start_copy_from_url(  # pylint: disable=inconsistent-return-statements
         self,
-        copy_source,  # type: str
-        timeout=None,  # type: Optional[int]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        tier=None,  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-        rehydrate_priority=None,  # type: Optional[Union[str, "_models.RehydratePriority"]]
-        request_id_parameter=None,  # type: Optional[str]
-        blob_tags_string=None,  # type: Optional[str]
-        seal_blob=None,  # type: Optional[bool]
-        immutability_policy_expiry=None,  # type: Optional[datetime.datetime]
-        immutability_policy_mode=None,  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-        legal_hold=None,  # type: Optional[bool]
-        source_modified_access_conditions=None,  # type: Optional["_models.SourceModifiedAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        copy_source: str,
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+        rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
+        request_id_parameter: Optional[str] = None,
+        blob_tags_string: Optional[str] = None,
+        seal_blob: Optional[bool] = None,
+        immutability_policy_expiry: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        legal_hold: Optional[bool] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Start Copy From URL operation copies a blob or an internet resource to a new blob.
 
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
+         Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param rehydrate_priority: Optional: Indicates the priority with which to rehydrate an archived
-         blob. Default value is None.
+         blob. Known values are: "High" and "Standard". Default value is None.
         :type rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
@@ -3454,65 +3494,66 @@
         :param seal_blob: Overrides the sealed state of the destination blob.  Service version
          2019-12-12 and newer. Default value is None.
         :type seal_blob: bool
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         _source_if_tags = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _lease_id = None
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
             _source_if_tags = source_modified_access_conditions.source_if_tags
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_start_copy_from_url_request(
             url=self._config.url,
-            version=self._config.version,
             copy_source=copy_source,
             timeout=timeout,
             metadata=metadata,
             tier=tier,
             rehydrate_priority=rehydrate_priority,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
@@ -3527,117 +3568,121 @@
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             seal_blob=seal_blob,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.start_copy_from_url.metadata['url'],
+            version=self._config.version,
+            template_url=self.start_copy_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    start_copy_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    start_copy_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def copy_from_url(  # pylint: disable=inconsistent-return-statements
         self,
-        copy_source,  # type: str
-        timeout=None,  # type: Optional[int]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        tier=None,  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-        request_id_parameter=None,  # type: Optional[str]
-        source_content_md5=None,  # type: Optional[bytearray]
-        blob_tags_string=None,  # type: Optional[str]
-        immutability_policy_expiry=None,  # type: Optional[datetime.datetime]
-        immutability_policy_mode=None,  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-        legal_hold=None,  # type: Optional[bool]
-        copy_source_authorization=None,  # type: Optional[str]
-        copy_source_tags=None,  # type: Optional[Union[str, "_models.BlobCopySourceTags"]]
-        source_modified_access_conditions=None,  # type: Optional["_models.SourceModifiedAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        copy_source: str,
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+        request_id_parameter: Optional[str] = None,
+        source_content_md5: Optional[bytes] = None,
+        blob_tags_string: Optional[str] = None,
+        immutability_policy_expiry: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        legal_hold: Optional[bool] = None,
+        copy_source_authorization: Optional[str] = None,
+        copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        **kwargs: Any
+    ) -> None:
         """The Copy From URL operation copies a blob or an internet resource to a new blob. It will not
         return a response until the copy is complete.
 
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
+         Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
          OAuth access token to copy source. Default value is None.
         :type copy_source_authorization: str
         :param copy_source_tags: Optional, default 'replace'.  Indicates if source tags should be
-         copied or replaced with the tags specified by x-ms-tags. Default value is None.
+         copied or replaced with the tags specified by x-ms-tags. Known values are: "REPLACE" and
+         "COPY". Default value is None.
         :type copy_source_tags: str or ~azure.storage.blob.models.BlobCopySourceTags
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
@@ -3645,57 +3690,56 @@
         :param cpk_scope_info: Parameter group. Default value is None.
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :keyword x_ms_requires_sync: This header indicates that this is a synchronous Copy Blob From
          URL instead of a Asynchronous Copy Blob. Default value is "true". Note that overriding this
          default value may result in unsupported behavior.
         :paramtype x_ms_requires_sync: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        x_ms_requires_sync = kwargs.pop('x_ms_requires_sync', "true")  # type: str
+        x_ms_requires_sync = kwargs.pop("x_ms_requires_sync", _headers.pop("x-ms-requires-sync", "true"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         _lease_id = None
         _encryption_scope = None
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
 
         request = build_copy_from_url_request(
             url=self._config.url,
-            x_ms_requires_sync=x_ms_requires_sync,
-            version=self._config.version,
             copy_source=copy_source,
             timeout=timeout,
             metadata=metadata,
             tier=tier,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
             source_if_match=_source_if_match,
@@ -3711,67 +3755,73 @@
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
             copy_source_authorization=copy_source_authorization,
             encryption_scope=_encryption_scope,
             copy_source_tags=copy_source_tags,
-            template_url=self.copy_from_url.metadata['url'],
+            x_ms_requires_sync=x_ms_requires_sync,
+            version=self._config.version,
+            template_url=self.copy_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    copy_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    copy_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def abort_copy_from_url(  # pylint: disable=inconsistent-return-statements
         self,
-        copy_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        copy_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Abort Copy From URL operation aborts a pending Copy From URL operation, and leaves a
         destination blob with zero length and full metadata.
 
         :param copy_id: The copy identifier provided in the x-ms-copy-id header of the original Copy
-         Blob operation.
+         Blob operation. Required.
         :type copy_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -3783,91 +3833,95 @@
         :keyword comp: comp. Default value is "copy". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword copy_action_abort_constant: Copy action. Default value is "abort". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype copy_action_abort_constant: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "copy")  # type: str
-        copy_action_abort_constant = kwargs.pop('copy_action_abort_constant', "abort")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "copy"))  # type: str
+        copy_action_abort_constant = kwargs.pop(
+            "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_abort_copy_from_url_request(
             url=self._config.url,
-            comp=comp,
-            copy_action_abort_constant=copy_action_abort_constant,
-            version=self._config.version,
             copy_id=copy_id,
             timeout=timeout,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.abort_copy_from_url.metadata['url'],
+            comp=comp,
+            copy_action_abort_constant=copy_action_abort_constant,
+            version=self._config.version,
+            template_url=self.abort_copy_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    abort_copy_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    abort_copy_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_tier(  # pylint: disable=inconsistent-return-statements
         self,
-        tier,  # type: Union[str, "_models.AccessTierRequired"]
-        snapshot=None,  # type: Optional[str]
-        version_id=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        rehydrate_priority=None,  # type: Optional[Union[str, "_models.RehydratePriority"]]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        tier: Union[str, "_models.AccessTierRequired"],
+        snapshot: Optional[str] = None,
+        version_id: Optional[str] = None,
+        timeout: Optional[int] = None,
+        rehydrate_priority: Optional[Union[str, "_models.RehydratePriority"]] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Set Tier operation sets the tier on a blob. The operation is allowed on a page blob in a
         premium storage account and on a block blob in a blob storage account (locally redundant
         storage only). A premium page blob's tier determines the allowed size, IOPS, and bandwidth of
         the blob. A block blob's tier determines Hot/Cool/Archive storage type. This operation does not
         update the blob's ETag.
 
-        :param tier: Indicates the tier to be set on the blob.
+        :param tier: Indicates the tier to be set on the blob. Known values are: "P4", "P6", "P10",
+         "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive". Required.
         :type tier: str or ~azure.storage.blob.models.AccessTierRequired
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
          a Snapshot of a Blob.</a>`. Default value is None.
         :type snapshot: str
@@ -3877,174 +3931,173 @@
         :type version_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param rehydrate_priority: Optional: Indicates the priority with which to rehydrate an archived
-         blob. Default value is None.
+         blob. Known values are: "High" and "Standard". Default value is None.
         :type rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "tier". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "tier")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "tier"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
 
         request = build_set_tier_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             tier=tier,
             snapshot=snapshot,
             version_id=version_id,
             timeout=timeout,
             rehydrate_priority=rehydrate_priority,
             request_id_parameter=request_id_parameter,
             lease_id=_lease_id,
             if_tags=_if_tags,
-            template_url=self.set_tier.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_tier.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if response.status_code == 202:
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_tier.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_tier.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def get_account_info(  # pylint: disable=inconsistent-return-statements
-        self,
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+    def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
         """Returns the sku name and account kind.
 
         :keyword restype: restype. Default value is "account". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "account")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_get_account_info_request(
             url=self._config.url,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata['url'],
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-sku-name']=self._deserialize('str', response.headers.get('x-ms-sku-name'))
-        response_headers['x-ms-account-kind']=self._deserialize('str', response.headers.get('x-ms-account-kind'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_account_info.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def query(
         self,
-        snapshot=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        query_request=None,  # type: Optional["_models.QueryRequest"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> IO
+        snapshot: Optional[str] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        query_request: Optional[_models.QueryRequest] = None,
+        **kwargs: Any
+    ) -> Iterator[bytes]:
         """The Query operation enables users to select/project on blob data by providing simple query
         expressions.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
@@ -4055,194 +4108,244 @@
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param query_request: the query request. Default value is None.
-        :type query_request: ~azure.storage.blob.models.QueryRequest
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :param query_request: the query request. Default value is None.
+        :type query_request: ~azure.storage.blob.models.QueryRequest
         :keyword comp: comp. Default value is "query". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "query")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "query"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if query_request is not None:
-            _content = self._serialize.body(query_request, 'QueryRequest', is_xml=True)
+            _content = self._serialize.body(query_request, "QueryRequest", is_xml=True)
         else:
             _content = None
 
         request = build_query_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             snapshot=snapshot,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             if_match=_if_match,
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.query.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.query.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200, 206]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if response.status_code == 206:
-            response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-            response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-            response_headers['Content-Length']=self._deserialize('long', response.headers.get('Content-Length'))
-            response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-            response_headers['Content-Range']=self._deserialize('str', response.headers.get('Content-Range'))
-            response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-            response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-            response_headers['Content-Encoding']=self._deserialize('str', response.headers.get('Content-Encoding'))
-            response_headers['Cache-Control']=self._deserialize('str', response.headers.get('Cache-Control'))
-            response_headers['Content-Disposition']=self._deserialize('str', response.headers.get('Content-Disposition'))
-            response_headers['Content-Language']=self._deserialize('str', response.headers.get('Content-Language'))
-            response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-            response_headers['x-ms-blob-type']=self._deserialize('str', response.headers.get('x-ms-blob-type'))
-            response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-            response_headers['x-ms-copy-completion-time']=self._deserialize('rfc-1123', response.headers.get('x-ms-copy-completion-time'))
-            response_headers['x-ms-copy-status-description']=self._deserialize('str', response.headers.get('x-ms-copy-status-description'))
-            response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-            response_headers['x-ms-copy-progress']=self._deserialize('str', response.headers.get('x-ms-copy-progress'))
-            response_headers['x-ms-copy-source']=self._deserialize('str', response.headers.get('x-ms-copy-source'))
-            response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
-            response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-            response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-            response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-            response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-            response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-            response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-            response_headers['Accept-Ranges']=self._deserialize('str', response.headers.get('Accept-Ranges'))
-            response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-            response_headers['x-ms-blob-committed-block-count']=self._deserialize('int', response.headers.get('x-ms-blob-committed-block-count'))
-            response_headers['x-ms-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-server-encrypted'))
-            response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-            response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-            response_headers['x-ms-blob-content-md5']=self._deserialize('bytearray', response.headers.get('x-ms-blob-content-md5'))
-            
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-sequence-number")
+            )
+            response_headers["x-ms-blob-type"] = self._deserialize("str", response.headers.get("x-ms-blob-type"))
+            response_headers["x-ms-content-crc64"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-content-crc64")
+            )
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-client-request-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-client-request-id")
+            )
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-blob-committed-block-count"] = self._deserialize(
+                "int", response.headers.get("x-ms-blob-committed-block-count")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+            response_headers["x-ms-encryption-scope"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-scope")
+            )
+            response_headers["x-ms-blob-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-blob-content-md5")
+            )
+
             deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    query.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    query.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def get_tags(
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        snapshot=None,  # type: Optional[str]
-        version_id=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.BlobTags"
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        snapshot: Optional[str] = None,
+        version_id: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> _models.BlobTags:
         """The Get Tags operation enables users to get the tags associated with a blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -4264,180 +4367,184 @@
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword comp: comp. Default value is "tags". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: BlobTags, or the result of cls(response)
+        :return: BlobTags or the result of cls(response)
         :rtype: ~azure.storage.blob.models.BlobTags
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.BlobTags"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "tags")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.BlobTags]
 
         _if_tags = None
         _lease_id = None
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_tags_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             snapshot=snapshot,
             version_id=version_id,
             if_tags=_if_tags,
             lease_id=_lease_id,
-            template_url=self.get_tags.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_tags.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('BlobTags', pipeline_response)
+        deserialized = self._deserialize("BlobTags", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_tags.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_tags.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def set_tags(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        version_id=None,  # type: Optional[str]
-        transactional_content_md5=None,  # type: Optional[bytearray]
-        transactional_content_crc64=None,  # type: Optional[bytearray]
-        request_id_parameter=None,  # type: Optional[str]
-        tags=None,  # type: Optional["_models.BlobTags"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        version_id: Optional[str] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        tags: Optional[_models.BlobTags] = None,
+        **kwargs: Any
+    ) -> None:
         """The Set Tags operation enables users to set tags on a blob.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param version_id: The version id parameter is an opaque DateTime value that, when present,
          specifies the version of the blob to operate on. It's for service version 2019-10-10 and newer.
          Default value is None.
         :type version_id: str
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param tags: Blob tags. Default value is None.
-        :type tags: ~azure.storage.blob.models.BlobTags
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param tags: Blob tags. Default value is None.
+        :type tags: ~azure.storage.blob.models.BlobTags
         :keyword comp: comp. Default value is "tags". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "tags")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_tags = None
         _lease_id = None
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if tags is not None:
-            _content = self._serialize.body(tags, 'BlobTags', is_xml=True)
+            _content = self._serialize.body(tags, "BlobTags", is_xml=True)
         else:
             _content = None
 
         request = build_set_tags_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             timeout=timeout,
             version_id=version_id,
             transactional_content_md5=transactional_content_md5,
             transactional_content_crc64=transactional_content_crc64,
             request_id_parameter=request_id_parameter,
             if_tags=_if_tags,
             lease_id=_lease_id,
-            template_url=self.set_tags.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.set_tags.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [204]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_tags.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    set_tags.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_block_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_block_blob_operations.py`

 * *Files 18% similar despite different names*

```diff
@@ -3,692 +3,741 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
-from typing import TYPE_CHECKING
+from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
+from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
+from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
-    T = TypeVar('T')
-    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
+T = TypeVar("T")
+ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
-# fmt: off
+
 
 def build_upload_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    blob_type = kwargs.pop('blob_type', "BlockBlob")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    content_length = kwargs.pop('content_length')  # type: int
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    transactional_content_md5 = kwargs.pop('transactional_content_md5', None)  # type: Optional[bytearray]
-    blob_content_type = kwargs.pop('blob_content_type', None)  # type: Optional[str]
-    blob_content_encoding = kwargs.pop('blob_content_encoding', None)  # type: Optional[str]
-    blob_content_language = kwargs.pop('blob_content_language', None)  # type: Optional[str]
-    blob_content_md5 = kwargs.pop('blob_content_md5', None)  # type: Optional[bytearray]
-    blob_cache_control = kwargs.pop('blob_cache_control', None)  # type: Optional[str]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    blob_content_disposition = kwargs.pop('blob_content_disposition', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    tier = kwargs.pop('tier', None)  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    blob_tags_string = kwargs.pop('blob_tags_string', None)  # type: Optional[str]
-    immutability_policy_expiry = kwargs.pop('immutability_policy_expiry', None)  # type: Optional[datetime.datetime]
-    immutability_policy_mode = kwargs.pop('immutability_policy_mode', None)  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-    legal_hold = kwargs.pop('legal_hold', None)  # type: Optional[bool]
+    url: str,
+    *,
+    content_length: int,
+    content: IO,
+    timeout: Optional[int] = None,
+    transactional_content_md5: Optional[bytes] = None,
+    blob_content_type: Optional[str] = None,
+    blob_content_encoding: Optional[str] = None,
+    blob_content_language: Optional[str] = None,
+    blob_content_md5: Optional[bytes] = None,
+    blob_cache_control: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    lease_id: Optional[str] = None,
+    blob_content_disposition: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    blob_tags_string: Optional[str] = None,
+    immutability_policy_expiry: Optional[datetime.datetime] = None,
+    immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+    legal_hold: Optional[bool] = None,
+    transactional_content_crc64: Optional[bytes] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "BlockBlob"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-blob-type'] = _SERIALIZER.header("blob_type", blob_type, 'str')
+    _headers["x-ms-blob-type"] = _SERIALIZER.header("blob_type", blob_type, "str")
     if transactional_content_md5 is not None:
-        _header_parameters['Content-MD5'] = _SERIALIZER.header("transactional_content_md5", transactional_content_md5, 'bytearray')
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_md5", transactional_content_md5, "bytearray"
+        )
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
     if blob_content_type is not None:
-        _header_parameters['x-ms-blob-content-type'] = _SERIALIZER.header("blob_content_type", blob_content_type, 'str')
+        _headers["x-ms-blob-content-type"] = _SERIALIZER.header("blob_content_type", blob_content_type, "str")
     if blob_content_encoding is not None:
-        _header_parameters['x-ms-blob-content-encoding'] = _SERIALIZER.header("blob_content_encoding", blob_content_encoding, 'str')
+        _headers["x-ms-blob-content-encoding"] = _SERIALIZER.header(
+            "blob_content_encoding", blob_content_encoding, "str"
+        )
     if blob_content_language is not None:
-        _header_parameters['x-ms-blob-content-language'] = _SERIALIZER.header("blob_content_language", blob_content_language, 'str')
+        _headers["x-ms-blob-content-language"] = _SERIALIZER.header(
+            "blob_content_language", blob_content_language, "str"
+        )
     if blob_content_md5 is not None:
-        _header_parameters['x-ms-blob-content-md5'] = _SERIALIZER.header("blob_content_md5", blob_content_md5, 'bytearray')
+        _headers["x-ms-blob-content-md5"] = _SERIALIZER.header("blob_content_md5", blob_content_md5, "bytearray")
     if blob_cache_control is not None:
-        _header_parameters['x-ms-blob-cache-control'] = _SERIALIZER.header("blob_cache_control", blob_cache_control, 'str')
+        _headers["x-ms-blob-cache-control"] = _SERIALIZER.header("blob_cache_control", blob_cache_control, "str")
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if blob_content_disposition is not None:
-        _header_parameters['x-ms-blob-content-disposition'] = _SERIALIZER.header("blob_content_disposition", blob_content_disposition, 'str')
+        _headers["x-ms-blob-content-disposition"] = _SERIALIZER.header(
+            "blob_content_disposition", blob_content_disposition, "str"
+        )
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if tier is not None:
-        _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if blob_tags_string is not None:
-        _header_parameters['x-ms-tags'] = _SERIALIZER.header("blob_tags_string", blob_tags_string, 'str')
+        _headers["x-ms-tags"] = _SERIALIZER.header("blob_tags_string", blob_tags_string, "str")
     if immutability_policy_expiry is not None:
-        _header_parameters['x-ms-immutability-policy-until-date'] = _SERIALIZER.header("immutability_policy_expiry", immutability_policy_expiry, 'rfc-1123')
+        _headers["x-ms-immutability-policy-until-date"] = _SERIALIZER.header(
+            "immutability_policy_expiry", immutability_policy_expiry, "rfc-1123"
+        )
     if immutability_policy_mode is not None:
-        _header_parameters['x-ms-immutability-policy-mode'] = _SERIALIZER.header("immutability_policy_mode", immutability_policy_mode, 'str')
+        _headers["x-ms-immutability-policy-mode"] = _SERIALIZER.header(
+            "immutability_policy_mode", immutability_policy_mode, "str"
+        )
     if legal_hold is not None:
-        _header_parameters['x-ms-legal-hold'] = _SERIALIZER.header("legal_hold", legal_hold, 'bool')
+        _headers["x-ms-legal-hold"] = _SERIALIZER.header("legal_hold", legal_hold, "bool")
+    if transactional_content_crc64 is not None:
+        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
+            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+        )
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_put_blob_from_url_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    blob_type = kwargs.pop('blob_type', "BlockBlob")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    copy_source = kwargs.pop('copy_source')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    transactional_content_md5 = kwargs.pop('transactional_content_md5', None)  # type: Optional[bytearray]
-    blob_content_type = kwargs.pop('blob_content_type', None)  # type: Optional[str]
-    blob_content_encoding = kwargs.pop('blob_content_encoding', None)  # type: Optional[str]
-    blob_content_language = kwargs.pop('blob_content_language', None)  # type: Optional[str]
-    blob_content_md5 = kwargs.pop('blob_content_md5', None)  # type: Optional[bytearray]
-    blob_cache_control = kwargs.pop('blob_cache_control', None)  # type: Optional[str]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    blob_content_disposition = kwargs.pop('blob_content_disposition', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    tier = kwargs.pop('tier', None)  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    source_if_modified_since = kwargs.pop('source_if_modified_since', None)  # type: Optional[datetime.datetime]
-    source_if_unmodified_since = kwargs.pop('source_if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    source_if_match = kwargs.pop('source_if_match', None)  # type: Optional[str]
-    source_if_none_match = kwargs.pop('source_if_none_match', None)  # type: Optional[str]
-    source_if_tags = kwargs.pop('source_if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    source_content_md5 = kwargs.pop('source_content_md5', None)  # type: Optional[bytearray]
-    blob_tags_string = kwargs.pop('blob_tags_string', None)  # type: Optional[str]
-    copy_source_blob_properties = kwargs.pop('copy_source_blob_properties', None)  # type: Optional[bool]
-    copy_source_authorization = kwargs.pop('copy_source_authorization', None)  # type: Optional[str]
-    copy_source_tags = kwargs.pop('copy_source_tags', None)  # type: Optional[Union[str, "_models.BlobCopySourceTags"]]
+    url: str,
+    *,
+    content_length: int,
+    copy_source: str,
+    timeout: Optional[int] = None,
+    transactional_content_md5: Optional[bytes] = None,
+    blob_content_type: Optional[str] = None,
+    blob_content_encoding: Optional[str] = None,
+    blob_content_language: Optional[str] = None,
+    blob_content_md5: Optional[bytes] = None,
+    blob_cache_control: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    lease_id: Optional[str] = None,
+    blob_content_disposition: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    source_if_modified_since: Optional[datetime.datetime] = None,
+    source_if_unmodified_since: Optional[datetime.datetime] = None,
+    source_if_match: Optional[str] = None,
+    source_if_none_match: Optional[str] = None,
+    source_if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    source_content_md5: Optional[bytes] = None,
+    blob_tags_string: Optional[str] = None,
+    copy_source_blob_properties: Optional[bool] = None,
+    copy_source_authorization: Optional[str] = None,
+    copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "BlockBlob"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-blob-type'] = _SERIALIZER.header("blob_type", blob_type, 'str')
+    _headers["x-ms-blob-type"] = _SERIALIZER.header("blob_type", blob_type, "str")
     if transactional_content_md5 is not None:
-        _header_parameters['Content-MD5'] = _SERIALIZER.header("transactional_content_md5", transactional_content_md5, 'bytearray')
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_md5", transactional_content_md5, "bytearray"
+        )
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
     if blob_content_type is not None:
-        _header_parameters['x-ms-blob-content-type'] = _SERIALIZER.header("blob_content_type", blob_content_type, 'str')
+        _headers["x-ms-blob-content-type"] = _SERIALIZER.header("blob_content_type", blob_content_type, "str")
     if blob_content_encoding is not None:
-        _header_parameters['x-ms-blob-content-encoding'] = _SERIALIZER.header("blob_content_encoding", blob_content_encoding, 'str')
+        _headers["x-ms-blob-content-encoding"] = _SERIALIZER.header(
+            "blob_content_encoding", blob_content_encoding, "str"
+        )
     if blob_content_language is not None:
-        _header_parameters['x-ms-blob-content-language'] = _SERIALIZER.header("blob_content_language", blob_content_language, 'str')
+        _headers["x-ms-blob-content-language"] = _SERIALIZER.header(
+            "blob_content_language", blob_content_language, "str"
+        )
     if blob_content_md5 is not None:
-        _header_parameters['x-ms-blob-content-md5'] = _SERIALIZER.header("blob_content_md5", blob_content_md5, 'bytearray')
+        _headers["x-ms-blob-content-md5"] = _SERIALIZER.header("blob_content_md5", blob_content_md5, "bytearray")
     if blob_cache_control is not None:
-        _header_parameters['x-ms-blob-cache-control'] = _SERIALIZER.header("blob_cache_control", blob_cache_control, 'str')
+        _headers["x-ms-blob-cache-control"] = _SERIALIZER.header("blob_cache_control", blob_cache_control, "str")
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if blob_content_disposition is not None:
-        _header_parameters['x-ms-blob-content-disposition'] = _SERIALIZER.header("blob_content_disposition", blob_content_disposition, 'str')
+        _headers["x-ms-blob-content-disposition"] = _SERIALIZER.header(
+            "blob_content_disposition", blob_content_disposition, "str"
+        )
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if tier is not None:
-        _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     if source_if_modified_since is not None:
-        _header_parameters['x-ms-source-if-modified-since'] = _SERIALIZER.header("source_if_modified_since", source_if_modified_since, 'rfc-1123')
+        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
+            "source_if_modified_since", source_if_modified_since, "rfc-1123"
+        )
     if source_if_unmodified_since is not None:
-        _header_parameters['x-ms-source-if-unmodified-since'] = _SERIALIZER.header("source_if_unmodified_since", source_if_unmodified_since, 'rfc-1123')
+        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
+            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
+        )
     if source_if_match is not None:
-        _header_parameters['x-ms-source-if-match'] = _SERIALIZER.header("source_if_match", source_if_match, 'str')
+        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
     if source_if_none_match is not None:
-        _header_parameters['x-ms-source-if-none-match'] = _SERIALIZER.header("source_if_none_match", source_if_none_match, 'str')
+        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
     if source_if_tags is not None:
-        _header_parameters['x-ms-source-if-tags'] = _SERIALIZER.header("source_if_tags", source_if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-source-if-tags"] = _SERIALIZER.header("source_if_tags", source_if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if source_content_md5 is not None:
-        _header_parameters['x-ms-source-content-md5'] = _SERIALIZER.header("source_content_md5", source_content_md5, 'bytearray')
+        _headers["x-ms-source-content-md5"] = _SERIALIZER.header("source_content_md5", source_content_md5, "bytearray")
     if blob_tags_string is not None:
-        _header_parameters['x-ms-tags'] = _SERIALIZER.header("blob_tags_string", blob_tags_string, 'str')
-    _header_parameters['x-ms-copy-source'] = _SERIALIZER.header("copy_source", copy_source, 'str')
+        _headers["x-ms-tags"] = _SERIALIZER.header("blob_tags_string", blob_tags_string, "str")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
     if copy_source_blob_properties is not None:
-        _header_parameters['x-ms-copy-source-blob-properties'] = _SERIALIZER.header("copy_source_blob_properties", copy_source_blob_properties, 'bool')
+        _headers["x-ms-copy-source-blob-properties"] = _SERIALIZER.header(
+            "copy_source_blob_properties", copy_source_blob_properties, "bool"
+        )
     if copy_source_authorization is not None:
-        _header_parameters['x-ms-copy-source-authorization'] = _SERIALIZER.header("copy_source_authorization", copy_source_authorization, 'str')
+        _headers["x-ms-copy-source-authorization"] = _SERIALIZER.header(
+            "copy_source_authorization", copy_source_authorization, "str"
+        )
     if copy_source_tags is not None:
-        _header_parameters['x-ms-copy-source-tag-option'] = _SERIALIZER.header("copy_source_tags", copy_source_tags, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-copy-source-tag-option"] = _SERIALIZER.header("copy_source_tags", copy_source_tags, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_stage_block_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "block")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    block_id = kwargs.pop('block_id')  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    transactional_content_md5 = kwargs.pop('transactional_content_md5', None)  # type: Optional[bytearray]
-    transactional_content_crc64 = kwargs.pop('transactional_content_crc64', None)  # type: Optional[bytearray]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    block_id: str,
+    content_length: int,
+    content: IO,
+    transactional_content_md5: Optional[bytes] = None,
+    transactional_content_crc64: Optional[bytes] = None,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "block"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['blockid'] = _SERIALIZER.query("block_id", block_id, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["blockid"] = _SERIALIZER.query("block_id", block_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
     if transactional_content_md5 is not None:
-        _header_parameters['Content-MD5'] = _SERIALIZER.header("transactional_content_md5", transactional_content_md5, 'bytearray')
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_md5", transactional_content_md5, "bytearray"
+        )
     if transactional_content_crc64 is not None:
-        _header_parameters['x-ms-content-crc64'] = _SERIALIZER.header("transactional_content_crc64", transactional_content_crc64, 'bytearray')
+        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
+            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+        )
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_stage_block_from_url_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "block")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    block_id = kwargs.pop('block_id')  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    source_url = kwargs.pop('source_url')  # type: str
-    source_range = kwargs.pop('source_range', None)  # type: Optional[str]
-    source_content_md5 = kwargs.pop('source_content_md5', None)  # type: Optional[bytearray]
-    source_contentcrc64 = kwargs.pop('source_contentcrc64', None)  # type: Optional[bytearray]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    source_if_modified_since = kwargs.pop('source_if_modified_since', None)  # type: Optional[datetime.datetime]
-    source_if_unmodified_since = kwargs.pop('source_if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    source_if_match = kwargs.pop('source_if_match', None)  # type: Optional[str]
-    source_if_none_match = kwargs.pop('source_if_none_match', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    copy_source_authorization = kwargs.pop('copy_source_authorization', None)  # type: Optional[str]
+    url: str,
+    *,
+    block_id: str,
+    content_length: int,
+    source_url: str,
+    source_range: Optional[str] = None,
+    source_content_md5: Optional[bytes] = None,
+    source_contentcrc64: Optional[bytes] = None,
+    timeout: Optional[int] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    source_if_modified_since: Optional[datetime.datetime] = None,
+    source_if_unmodified_since: Optional[datetime.datetime] = None,
+    source_if_match: Optional[str] = None,
+    source_if_none_match: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    copy_source_authorization: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "block"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['blockid'] = _SERIALIZER.query("block_id", block_id, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["blockid"] = _SERIALIZER.query("block_id", block_id, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    _header_parameters['x-ms-copy-source'] = _SERIALIZER.header("source_url", source_url, 'str')
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("source_url", source_url, "str")
     if source_range is not None:
-        _header_parameters['x-ms-source-range'] = _SERIALIZER.header("source_range", source_range, 'str')
+        _headers["x-ms-source-range"] = _SERIALIZER.header("source_range", source_range, "str")
     if source_content_md5 is not None:
-        _header_parameters['x-ms-source-content-md5'] = _SERIALIZER.header("source_content_md5", source_content_md5, 'bytearray')
+        _headers["x-ms-source-content-md5"] = _SERIALIZER.header("source_content_md5", source_content_md5, "bytearray")
     if source_contentcrc64 is not None:
-        _header_parameters['x-ms-source-content-crc64'] = _SERIALIZER.header("source_contentcrc64", source_contentcrc64, 'bytearray')
+        _headers["x-ms-source-content-crc64"] = _SERIALIZER.header(
+            "source_contentcrc64", source_contentcrc64, "bytearray"
+        )
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if source_if_modified_since is not None:
-        _header_parameters['x-ms-source-if-modified-since'] = _SERIALIZER.header("source_if_modified_since", source_if_modified_since, 'rfc-1123')
+        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
+            "source_if_modified_since", source_if_modified_since, "rfc-1123"
+        )
     if source_if_unmodified_since is not None:
-        _header_parameters['x-ms-source-if-unmodified-since'] = _SERIALIZER.header("source_if_unmodified_since", source_if_unmodified_since, 'rfc-1123')
+        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
+            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
+        )
     if source_if_match is not None:
-        _header_parameters['x-ms-source-if-match'] = _SERIALIZER.header("source_if_match", source_if_match, 'str')
+        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
     if source_if_none_match is not None:
-        _header_parameters['x-ms-source-if-none-match'] = _SERIALIZER.header("source_if_none_match", source_if_none_match, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if copy_source_authorization is not None:
-        _header_parameters['x-ms-copy-source-authorization'] = _SERIALIZER.header("copy_source_authorization", copy_source_authorization, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-copy-source-authorization"] = _SERIALIZER.header(
+            "copy_source_authorization", copy_source_authorization, "str"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_commit_block_list_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "blocklist")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    blob_cache_control = kwargs.pop('blob_cache_control', None)  # type: Optional[str]
-    blob_content_type = kwargs.pop('blob_content_type', None)  # type: Optional[str]
-    blob_content_encoding = kwargs.pop('blob_content_encoding', None)  # type: Optional[str]
-    blob_content_language = kwargs.pop('blob_content_language', None)  # type: Optional[str]
-    blob_content_md5 = kwargs.pop('blob_content_md5', None)  # type: Optional[bytearray]
-    transactional_content_md5 = kwargs.pop('transactional_content_md5', None)  # type: Optional[bytearray]
-    transactional_content_crc64 = kwargs.pop('transactional_content_crc64', None)  # type: Optional[bytearray]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    blob_content_disposition = kwargs.pop('blob_content_disposition', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    tier = kwargs.pop('tier', None)  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    blob_tags_string = kwargs.pop('blob_tags_string', None)  # type: Optional[str]
-    immutability_policy_expiry = kwargs.pop('immutability_policy_expiry', None)  # type: Optional[datetime.datetime]
-    immutability_policy_mode = kwargs.pop('immutability_policy_mode', None)  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-    legal_hold = kwargs.pop('legal_hold', None)  # type: Optional[bool]
+    url: str,
+    *,
+    content: Any,
+    timeout: Optional[int] = None,
+    blob_cache_control: Optional[str] = None,
+    blob_content_type: Optional[str] = None,
+    blob_content_encoding: Optional[str] = None,
+    blob_content_language: Optional[str] = None,
+    blob_content_md5: Optional[bytes] = None,
+    transactional_content_md5: Optional[bytes] = None,
+    transactional_content_crc64: Optional[bytes] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    lease_id: Optional[str] = None,
+    blob_content_disposition: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    blob_tags_string: Optional[str] = None,
+    immutability_policy_expiry: Optional[datetime.datetime] = None,
+    immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+    legal_hold: Optional[bool] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "blocklist"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if blob_cache_control is not None:
-        _header_parameters['x-ms-blob-cache-control'] = _SERIALIZER.header("blob_cache_control", blob_cache_control, 'str')
+        _headers["x-ms-blob-cache-control"] = _SERIALIZER.header("blob_cache_control", blob_cache_control, "str")
     if blob_content_type is not None:
-        _header_parameters['x-ms-blob-content-type'] = _SERIALIZER.header("blob_content_type", blob_content_type, 'str')
+        _headers["x-ms-blob-content-type"] = _SERIALIZER.header("blob_content_type", blob_content_type, "str")
     if blob_content_encoding is not None:
-        _header_parameters['x-ms-blob-content-encoding'] = _SERIALIZER.header("blob_content_encoding", blob_content_encoding, 'str')
+        _headers["x-ms-blob-content-encoding"] = _SERIALIZER.header(
+            "blob_content_encoding", blob_content_encoding, "str"
+        )
     if blob_content_language is not None:
-        _header_parameters['x-ms-blob-content-language'] = _SERIALIZER.header("blob_content_language", blob_content_language, 'str')
+        _headers["x-ms-blob-content-language"] = _SERIALIZER.header(
+            "blob_content_language", blob_content_language, "str"
+        )
     if blob_content_md5 is not None:
-        _header_parameters['x-ms-blob-content-md5'] = _SERIALIZER.header("blob_content_md5", blob_content_md5, 'bytearray')
+        _headers["x-ms-blob-content-md5"] = _SERIALIZER.header("blob_content_md5", blob_content_md5, "bytearray")
     if transactional_content_md5 is not None:
-        _header_parameters['Content-MD5'] = _SERIALIZER.header("transactional_content_md5", transactional_content_md5, 'bytearray')
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_md5", transactional_content_md5, "bytearray"
+        )
     if transactional_content_crc64 is not None:
-        _header_parameters['x-ms-content-crc64'] = _SERIALIZER.header("transactional_content_crc64", transactional_content_crc64, 'bytearray')
+        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
+            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+        )
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if blob_content_disposition is not None:
-        _header_parameters['x-ms-blob-content-disposition'] = _SERIALIZER.header("blob_content_disposition", blob_content_disposition, 'str')
+        _headers["x-ms-blob-content-disposition"] = _SERIALIZER.header(
+            "blob_content_disposition", blob_content_disposition, "str"
+        )
     if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
     if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
     if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
     if tier is not None:
-        _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
     if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if blob_tags_string is not None:
-        _header_parameters['x-ms-tags'] = _SERIALIZER.header("blob_tags_string", blob_tags_string, 'str')
+        _headers["x-ms-tags"] = _SERIALIZER.header("blob_tags_string", blob_tags_string, "str")
     if immutability_policy_expiry is not None:
-        _header_parameters['x-ms-immutability-policy-until-date'] = _SERIALIZER.header("immutability_policy_expiry", immutability_policy_expiry, 'rfc-1123')
+        _headers["x-ms-immutability-policy-until-date"] = _SERIALIZER.header(
+            "immutability_policy_expiry", immutability_policy_expiry, "rfc-1123"
+        )
     if immutability_policy_mode is not None:
-        _header_parameters['x-ms-immutability-policy-mode'] = _SERIALIZER.header("immutability_policy_mode", immutability_policy_mode, 'str')
+        _headers["x-ms-immutability-policy-mode"] = _SERIALIZER.header(
+            "immutability_policy_mode", immutability_policy_mode, "str"
+        )
     if legal_hold is not None:
-        _header_parameters['x-ms-legal-hold'] = _SERIALIZER.header("legal_hold", legal_hold, 'bool')
+        _headers["x-ms-legal-hold"] = _SERIALIZER.header("legal_hold", legal_hold, "bool")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_get_block_list_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "blocklist")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    list_type = kwargs.pop('list_type', "committed")  # type: Union[str, "_models.BlockListType"]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    snapshot: Optional[str] = None,
+    list_type: Union[str, "_models.BlockListType"] = "committed",
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "blocklist"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
-    _query_parameters['blocklisttype'] = _SERIALIZER.query("list_type", list_type, 'str')
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
+    _params["blocklisttype"] = _SERIALIZER.query("list_type", list_type, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
-# fmt: on
-class BlockBlobOperations(object):
+
+class BlockBlobOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.AzureBlobStorage`'s
         :attr:`block_blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def upload(  # pylint: disable=inconsistent-return-statements
         self,
-        content_length,  # type: int
-        body,  # type: IO
-        timeout=None,  # type: Optional[int]
-        transactional_content_md5=None,  # type: Optional[bytearray]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        tier=None,  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-        request_id_parameter=None,  # type: Optional[str]
-        blob_tags_string=None,  # type: Optional[str]
-        immutability_policy_expiry=None,  # type: Optional[datetime.datetime]
-        immutability_policy_mode=None,  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-        legal_hold=None,  # type: Optional[bool]
-        blob_http_headers=None,  # type: Optional["_models.BlobHTTPHeaders"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        content_length: int,
+        body: IO,
+        timeout: Optional[int] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+        request_id_parameter: Optional[str] = None,
+        blob_tags_string: Optional[str] = None,
+        immutability_policy_expiry: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        legal_hold: Optional[bool] = None,
+        transactional_content_crc64: Optional[bytes] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Upload Block Blob operation updates the content of an existing block blob. Updating an
         existing block blob overwrites any existing metadata on the blob. Partial updates are not
         supported with Put Blob; the content of the existing blob is overwritten with the content of
         the new blob. To perform a partial update of the content of a block blob, use the Put Block
         List operation.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
+        :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
+         validated by the service. Default value is None.
+        :type transactional_content_crc64: bytes
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param cpk_scope_info: Parameter group. Default value is None.
@@ -696,26 +745,27 @@
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
          blob. Default value is "BlockBlob". Note that overriding this default value may result in
          unsupported behavior.
         :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        blob_type = kwargs.pop('blob_type', "BlockBlob")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "BlockBlob"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _blob_cache_control = None
         _lease_id = None
@@ -726,43 +776,38 @@
         _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         _content = body
 
         request = build_upload_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             content_length=content_length,
             timeout=timeout,
             transactional_content_md5=transactional_content_md5,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             blob_content_md5=_blob_content_md5,
@@ -781,124 +826,138 @@
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.upload.metadata['url'],
+            transactional_content_crc64=transactional_content_crc64,
+            blob_type=blob_type,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.upload.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    upload.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def put_blob_from_url(  # pylint: disable=inconsistent-return-statements
         self,
-        content_length,  # type: int
-        copy_source,  # type: str
-        timeout=None,  # type: Optional[int]
-        transactional_content_md5=None,  # type: Optional[bytearray]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        tier=None,  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-        request_id_parameter=None,  # type: Optional[str]
-        source_content_md5=None,  # type: Optional[bytearray]
-        blob_tags_string=None,  # type: Optional[str]
-        copy_source_blob_properties=None,  # type: Optional[bool]
-        copy_source_authorization=None,  # type: Optional[str]
-        copy_source_tags=None,  # type: Optional[Union[str, "_models.BlobCopySourceTags"]]
-        blob_http_headers=None,  # type: Optional["_models.BlobHTTPHeaders"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        source_modified_access_conditions=None,  # type: Optional["_models.SourceModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        content_length: int,
+        copy_source: str,
+        timeout: Optional[int] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+        request_id_parameter: Optional[str] = None,
+        source_content_md5: Optional[bytes] = None,
+        blob_tags_string: Optional[str] = None,
+        copy_source_blob_properties: Optional[bool] = None,
+        copy_source_authorization: Optional[str] = None,
+        copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Put Blob from URL operation creates a new Block Blob where the contents of the blob are
         read from a given URL.  This API is supported beginning with the 2020-04-08 version. Partial
         updates are not supported with Put Blob from URL; the content of an existing blob is
         overwritten with the content of the new blob.  To perform partial updates to a block blobs
         contents using a source URL, use the Put Block from URL API in conjunction with Put Block List.
 
-        :param content_length: The length of the request.
-        :type content_length: long
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
          up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
          would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
+         via a shared access signature. Required.
         :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param copy_source_blob_properties: Optional, default is true.  Indicates if properties from
-         the source blob should be copied.
+         the source blob should be copied. Default value is None.
         :type copy_source_blob_properties: bool
         :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
          OAuth access token to copy source. Default value is None.
         :type copy_source_authorization: str
         :param copy_source_tags: Optional, default 'replace'.  Indicates if source tags should be
-         copied or replaced with the tags specified by x-ms-tags. Default value is None.
+         copied or replaced with the tags specified by x-ms-tags. Known values are: "REPLACE" and
+         "COPY". Default value is None.
         :type copy_source_tags: str or ~azure.storage.blob.models.BlobCopySourceTags
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param cpk_info: Parameter group. Default value is None.
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
@@ -910,25 +969,26 @@
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
          blob. Default value is "BlockBlob". Note that overriding this default value may result in
          unsupported behavior.
         :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        blob_type = kwargs.pop('blob_type', "BlockBlob")  # type: str
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "BlockBlob"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _blob_cache_control = None
         _lease_id = None
@@ -944,46 +1004,43 @@
         _if_tags = None
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         _source_if_tags = None
         if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
             _source_if_tags = source_modified_access_conditions.source_if_tags
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
         request = build_put_blob_from_url_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
             content_length=content_length,
             copy_source=copy_source,
             timeout=timeout,
             transactional_content_md5=transactional_content_md5,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
@@ -1009,83 +1066,91 @@
             source_if_tags=_source_if_tags,
             request_id_parameter=request_id_parameter,
             source_content_md5=source_content_md5,
             blob_tags_string=blob_tags_string,
             copy_source_blob_properties=copy_source_blob_properties,
             copy_source_authorization=copy_source_authorization,
             copy_source_tags=copy_source_tags,
-            template_url=self.put_blob_from_url.metadata['url'],
+            blob_type=blob_type,
+            version=self._config.version,
+            template_url=self.put_blob_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    put_blob_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    put_blob_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def stage_block(  # pylint: disable=inconsistent-return-statements
         self,
-        block_id,  # type: str
-        content_length,  # type: int
-        body,  # type: IO
-        transactional_content_md5=None,  # type: Optional[bytearray]
-        transactional_content_crc64=None,  # type: Optional[bytearray]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        block_id: str,
+        content_length: int,
+        body: IO,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        **kwargs: Any
+    ) -> None:
         """The Stage Block operation creates a new block to be committed as part of a blob.
 
         :param block_id: A valid Base64 string value that identifies the block. Prior to encoding, the
          string must be less than or equal to 64 bytes in size. For a given blob, the length of the
-         value specified for the blockid parameter must be the same size for each block.
+         value specified for the blockid parameter must be the same size for each block. Required.
         :type block_id: str
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
@@ -1097,132 +1162,141 @@
         :type cpk_info: ~azure.storage.blob.models.CpkInfo
         :param cpk_scope_info: Parameter group. Default value is None.
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :keyword comp: comp. Default value is "block". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "block")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        comp = kwargs.pop("comp", _params.pop("comp", "block"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         _content = body
 
         request = build_stage_block_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             block_id=block_id,
             content_length=content_length,
             transactional_content_md5=transactional_content_md5,
             transactional_content_crc64=transactional_content_crc64,
             timeout=timeout,
             lease_id=_lease_id,
             encryption_key=_encryption_key,
             encryption_key_sha256=_encryption_key_sha256,
             encryption_algorithm=_encryption_algorithm,
             encryption_scope=_encryption_scope,
             request_id_parameter=request_id_parameter,
-            template_url=self.stage_block.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.stage_block.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    stage_block.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    stage_block.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def stage_block_from_url(  # pylint: disable=inconsistent-return-statements
         self,
-        block_id,  # type: str
-        content_length,  # type: int
-        source_url,  # type: str
-        source_range=None,  # type: Optional[str]
-        source_content_md5=None,  # type: Optional[bytearray]
-        source_contentcrc64=None,  # type: Optional[bytearray]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        copy_source_authorization=None,  # type: Optional[str]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        source_modified_access_conditions=None,  # type: Optional["_models.SourceModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        block_id: str,
+        content_length: int,
+        source_url: str,
+        source_range: Optional[str] = None,
+        source_content_md5: Optional[bytes] = None,
+        source_contentcrc64: Optional[bytes] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        copy_source_authorization: Optional[str] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Stage Block operation creates a new block to be committed as part of a blob where the
         contents are read from a URL.
 
         :param block_id: A valid Base64 string value that identifies the block. Prior to encoding, the
          string must be less than or equal to 64 bytes in size. For a given blob, the length of the
-         value specified for the blockid parameter must be the same size for each block.
+         value specified for the blockid parameter must be the same size for each block. Required.
         :type block_id: str
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param source_url: Specify a URL to the copy source.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param source_url: Specify a URL to the copy source. Required.
         :type source_url: str
         :param source_range: Bytes of source data in the specified range. Default value is None.
         :type source_range: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
-        :type source_content_md5: bytearray
+        :type source_content_md5: bytes
         :param source_contentcrc64: Specify the crc64 calculated for the range of bytes that must be
          read from the copy source. Default value is None.
-        :type source_contentcrc64: bytearray
+        :type source_contentcrc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
@@ -1240,53 +1314,52 @@
         :param source_modified_access_conditions: Parameter group. Default value is None.
         :type source_modified_access_conditions:
          ~azure.storage.blob.models.SourceModifiedAccessConditions
         :keyword comp: comp. Default value is "block". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "block")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "block"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _encryption_key = None
         _encryption_key_sha256 = None
         _encryption_algorithm = None
         _encryption_scope = None
         _lease_id = None
         _source_if_modified_since = None
         _source_if_unmodified_since = None
         _source_if_match = None
         _source_if_none_match = None
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
             _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
             _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
         request = build_stage_block_from_url_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             block_id=block_id,
             content_length=content_length,
             source_url=source_url,
             source_range=source_range,
             source_content_md5=source_content_md5,
             source_contentcrc64=source_contentcrc64,
             timeout=timeout,
@@ -1297,114 +1370,126 @@
             lease_id=_lease_id,
             source_if_modified_since=_source_if_modified_since,
             source_if_unmodified_since=_source_if_unmodified_since,
             source_if_match=_source_if_match,
             source_if_none_match=_source_if_none_match,
             request_id_parameter=request_id_parameter,
             copy_source_authorization=copy_source_authorization,
-            template_url=self.stage_block_from_url.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.stage_block_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    stage_block_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    stage_block_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def commit_block_list(  # pylint: disable=inconsistent-return-statements
         self,
-        blocks,  # type: "_models.BlockLookupList"
-        timeout=None,  # type: Optional[int]
-        transactional_content_md5=None,  # type: Optional[bytearray]
-        transactional_content_crc64=None,  # type: Optional[bytearray]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        tier=None,  # type: Optional[Union[str, "_models.AccessTierOptional"]]
-        request_id_parameter=None,  # type: Optional[str]
-        blob_tags_string=None,  # type: Optional[str]
-        immutability_policy_expiry=None,  # type: Optional[datetime.datetime]
-        immutability_policy_mode=None,  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-        legal_hold=None,  # type: Optional[bool]
-        blob_http_headers=None,  # type: Optional["_models.BlobHTTPHeaders"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        blocks: _models.BlockLookupList,
+        timeout: Optional[int] = None,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        tier: Optional[Union[str, "_models.AccessTierOptional"]] = None,
+        request_id_parameter: Optional[str] = None,
+        blob_tags_string: Optional[str] = None,
+        immutability_policy_expiry: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        legal_hold: Optional[bool] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """The Commit Block List operation writes a blob by specifying the list of block IDs that make up
         the blob. In order to be written as part of a blob, a block must have been successfully written
         to the server in a prior Put Block operation. You can call Put Block List to update a blob by
         uploading only those blocks that have changed, then committing the new and existing blocks
         together. You can do this by specifying whether to commit a block from the committed block list
         or from the uncommitted block list, or to commit the most recently uploaded version of the
         block, whichever list it may belong to.
 
-        :param blocks: Blob Blocks.
+        :param blocks: Blob Blocks. Required.
         :type blocks: ~azure.storage.blob.models.BlockLookupList
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
          by the service. Default value is None.
-        :type transactional_content_md5: bytearray
+        :type transactional_content_md5: bytes
         :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
          validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        :type transactional_content_crc64: bytes
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param tier: Optional. Indicates the tier to be set on the blob. Default value is None.
+        :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
          value is None.
         :type blob_tags_string: str
         :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
          is set to expire. Default value is None.
         :type immutability_policy_expiry: ~datetime.datetime
         :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
         :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
         :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
         :type legal_hold: bool
         :param blob_http_headers: Parameter group. Default value is None.
         :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
@@ -1414,26 +1499,27 @@
         :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "blocklist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "blocklist")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "blocklist"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _blob_cache_control = None
         _blob_content_type = None
         _blob_content_encoding = None
         _blob_content_language = None
         _blob_content_md5 = None
         _lease_id = None
@@ -1445,42 +1531,37 @@
         _if_modified_since = None
         _if_unmodified_since = None
         _if_match = None
         _if_none_match = None
         _if_tags = None
         if blob_http_headers is not None:
             _blob_cache_control = blob_http_headers.blob_cache_control
-            _blob_content_type = blob_http_headers.blob_content_type
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
             _blob_content_encoding = blob_http_headers.blob_content_encoding
             _blob_content_language = blob_http_headers.blob_content_language
             _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
         if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
             _encryption_key = cpk_info.encryption_key
             _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
         if cpk_scope_info is not None:
             _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
             _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
             _if_none_match = modified_access_conditions.if_none_match
             _if_tags = modified_access_conditions.if_tags
-        _content = self._serialize.body(blocks, 'BlockLookupList', is_xml=True)
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        _content = self._serialize.body(blocks, "BlockLookupList", is_xml=True)
 
         request = build_commit_block_list_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             timeout=timeout,
             blob_cache_control=_blob_cache_control,
             blob_content_type=_blob_content_type,
             blob_content_encoding=_blob_content_encoding,
             blob_content_language=_blob_content_language,
             blob_content_md5=_blob_content_md5,
             transactional_content_md5=transactional_content_md5,
@@ -1499,75 +1580,88 @@
             if_none_match=_if_none_match,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             blob_tags_string=blob_tags_string,
             immutability_policy_expiry=immutability_policy_expiry,
             immutability_policy_mode=immutability_policy_mode,
             legal_hold=legal_hold,
-            template_url=self.commit_block_list.metadata['url'],
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.commit_block_list.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    commit_block_list.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    commit_block_list.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
     def get_block_list(
         self,
-        snapshot=None,  # type: Optional[str]
-        list_type="committed",  # type: Union[str, "_models.BlockListType"]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.BlockList"
+        snapshot: Optional[str] = None,
+        list_type: Union[str, "_models.BlockListType"] = "committed",
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> _models.BlockList:
         """The Get Block List operation retrieves the list of blocks that have been uploaded as part of a
         block blob.
 
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
          a Snapshot of a Blob.</a>`. Default value is None.
         :type snapshot: str
         :param list_type: Specifies whether to return the list of committed blocks, the list of
-         uncommitted blocks, or both lists together. Default value is "committed".
+         uncommitted blocks, or both lists together. Known values are: "committed", "uncommitted", and
+         "all". Default value is "committed".
         :type list_type: str or ~azure.storage.blob.models.BlockListType
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1578,72 +1672,77 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword comp: comp. Default value is "blocklist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: BlockList, or the result of cls(response)
+        :return: BlockList or the result of cls(response)
         :rtype: ~azure.storage.blob.models.BlockList
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.BlockList"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "blocklist")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blocklist"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.BlockList]
 
         _lease_id = None
         _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_tags = modified_access_conditions.if_tags
 
         request = build_get_block_list_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             snapshot=snapshot,
             list_type=list_type,
             timeout=timeout,
             lease_id=_lease_id,
             if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_block_list.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_block_list.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-blob-content-length']=self._deserialize('long', response.headers.get('x-ms-blob-content-length'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-blob-content-length"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-content-length")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('BlockList', pipeline_response)
+        deserialized = self._deserialize("BlockList", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_block_list.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_block_list.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_container_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_container_operations.py`

 * *Files 12% similar despite different names*

```diff
@@ -3,988 +3,911 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
-from typing import TYPE_CHECKING
+from typing import Any, Callable, Dict, IO, Iterator, List, Optional, TypeVar, Union
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
+from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
+from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union
-    T = TypeVar('T')
-    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
+T = TypeVar("T")
+ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
-# fmt: off
+
 
 def build_create_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    access = kwargs.pop('access', None)  # type: Optional[Union[str, "_models.PublicAccessType"]]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    default_encryption_scope = kwargs.pop('default_encryption_scope', None)  # type: Optional[str]
-    prevent_encryption_scope_override = kwargs.pop('prevent_encryption_scope_override', None)  # type: Optional[bool]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+    request_id_parameter: Optional[str] = None,
+    default_encryption_scope: Optional[str] = None,
+    prevent_encryption_scope_override: Optional[bool] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if access is not None:
-        _header_parameters['x-ms-blob-public-access'] = _SERIALIZER.header("access", access, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-blob-public-access"] = _SERIALIZER.header("access", access, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if default_encryption_scope is not None:
-        _header_parameters['x-ms-default-encryption-scope'] = _SERIALIZER.header("default_encryption_scope", default_encryption_scope, 'str')
+        _headers["x-ms-default-encryption-scope"] = _SERIALIZER.header(
+            "default_encryption_scope", default_encryption_scope, "str"
+        )
     if prevent_encryption_scope_override is not None:
-        _header_parameters['x-ms-deny-encryption-scope-override'] = _SERIALIZER.header("prevent_encryption_scope_override", prevent_encryption_scope_override, 'bool')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-deny-encryption-scope-override"] = _SERIALIZER.header(
+            "prevent_encryption_scope_override", prevent_encryption_scope_override, "bool"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_get_properties_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_delete_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="DELETE",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_metadata_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "metadata")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_get_access_policy_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "acl")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_set_access_policy_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "acl")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    access = kwargs.pop('access', None)  # type: Optional[Union[str, "_models.PublicAccessType"]]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    content: Any = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if access is not None:
-        _header_parameters['x-ms-blob-public-access'] = _SERIALIZER.header("access", access, 'str')
+        _headers["x-ms-blob-public-access"] = _SERIALIZER.header("access", access, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_restore_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "undelete")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    deleted_container_name = kwargs.pop('deleted_container_name', None)  # type: Optional[str]
-    deleted_container_version = kwargs.pop('deleted_container_version', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    deleted_container_name: Optional[str] = None,
+    deleted_container_version: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if deleted_container_name is not None:
-        _header_parameters['x-ms-deleted-container-name'] = _SERIALIZER.header("deleted_container_name", deleted_container_name, 'str')
+        _headers["x-ms-deleted-container-name"] = _SERIALIZER.header(
+            "deleted_container_name", deleted_container_name, "str"
+        )
     if deleted_container_version is not None:
-        _header_parameters['x-ms-deleted-container-version'] = _SERIALIZER.header("deleted_container_version", deleted_container_version, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-deleted-container-version"] = _SERIALIZER.header(
+            "deleted_container_version", deleted_container_version, "str"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_rename_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "rename")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    source_container_name = kwargs.pop('source_container_name')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    source_lease_id = kwargs.pop('source_lease_id', None)  # type: Optional[str]
+    url: str,
+    *,
+    source_container_name: str,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    source_lease_id: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['x-ms-source-container-name'] = _SERIALIZER.header("source_container_name", source_container_name, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-source-container-name"] = _SERIALIZER.header("source_container_name", source_container_name, "str")
     if source_lease_id is not None:
-        _header_parameters['x-ms-source-lease-id'] = _SERIALIZER.header("source_lease_id", source_lease_id, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_submit_batch_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    multipart_content_type = kwargs.pop('multipart_content_type')  # type: str
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "batch")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    content_length: int,
+    content: IO,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+    multipart_content_type = kwargs.pop(
+        "multipart_content_type", _headers.pop("Content-Type", None)
+    )  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    _header_parameters['Content-Type'] = _SERIALIZER.header("multipart_content_type", multipart_content_type, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if multipart_content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("multipart_content_type", multipart_content_type, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="POST",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_filter_blobs_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "blobs")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    where = kwargs.pop('where', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    where: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
     if where is not None:
-        _query_parameters['where'] = _SERIALIZER.query("where", where, 'str')
+        _params["where"] = _SERIALIZER.query("where", where, "str")
     if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
     if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
+    if include is not None:
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_acquire_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    restype = kwargs.pop('restype', "container")  # type: str
-    action = kwargs.pop('action', "acquire")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    duration = kwargs.pop('duration', None)  # type: Optional[int]
-    proposed_lease_id = kwargs.pop('proposed_lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    duration: Optional[int] = None,
+    proposed_lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
     if duration is not None:
-        _header_parameters['x-ms-lease-duration'] = _SERIALIZER.header("duration", duration, 'int')
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
     if proposed_lease_id is not None:
-        _header_parameters['x-ms-proposed-lease-id'] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, 'str')
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_release_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    restype = kwargs.pop('restype', "container")  # type: str
-    action = kwargs.pop('action', "release")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    lease_id = kwargs.pop('lease_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
-    _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_renew_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    restype = kwargs.pop('restype', "container")  # type: str
-    action = kwargs.pop('action', "renew")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    lease_id = kwargs.pop('lease_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
-    _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_break_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    restype = kwargs.pop('restype', "container")  # type: str
-    action = kwargs.pop('action', "break")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    break_period = kwargs.pop('break_period', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    break_period: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
     if break_period is not None:
-        _header_parameters['x-ms-lease-break-period'] = _SERIALIZER.header("break_period", break_period, 'int')
+        _headers["x-ms-lease-break-period"] = _SERIALIZER.header("break_period", break_period, "int")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_change_lease_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "lease")  # type: str
-    restype = kwargs.pop('restype', "container")  # type: str
-    action = kwargs.pop('action', "change")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    lease_id = kwargs.pop('lease_id')  # type: str
-    proposed_lease_id = kwargs.pop('proposed_lease_id')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    lease_id: str,
+    proposed_lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-lease-action'] = _SERIALIZER.header("action", action, 'str')
-    _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    _header_parameters['x-ms-proposed-lease-id'] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_list_blob_flat_segment_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "list")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    prefix = kwargs.pop('prefix', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
-    include = kwargs.pop('include', None)  # type: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    prefix: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if prefix is not None:
-        _query_parameters['prefix'] = _SERIALIZER.query("prefix", prefix, 'str')
+        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
     if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
     if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
     if include is not None:
-        _query_parameters['include'] = _SERIALIZER.query("include", include, '[str]', div=',')
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_list_blob_hierarchy_segment_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "container")  # type: str
-    comp = kwargs.pop('comp', "list")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    delimiter = kwargs.pop('delimiter')  # type: str
-    prefix = kwargs.pop('prefix', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
-    include = kwargs.pop('include', None)  # type: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    delimiter: str,
+    prefix: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if prefix is not None:
-        _query_parameters['prefix'] = _SERIALIZER.query("prefix", prefix, 'str')
-    _query_parameters['delimiter'] = _SERIALIZER.query("delimiter", delimiter, 'str')
+        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
+    _params["delimiter"] = _SERIALIZER.query("delimiter", delimiter, "str")
     if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
     if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
     if include is not None:
-        _query_parameters['include'] = _SERIALIZER.query("include", include, '[str]', div=',')
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_get_account_info_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "account")  # type: str
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
-
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
-# fmt: on
-class ContainerOperations(object):
+
+class ContainerOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.AzureBlobStorage`'s
         :attr:`container` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def create(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        access=None,  # type: Optional[Union[str, "_models.PublicAccessType"]]
-        request_id_parameter=None,  # type: Optional[str]
-        container_cpk_scope_info=None,  # type: Optional["_models.ContainerCpkScopeInfo"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+        request_id_parameter: Optional[str] = None,
+        container_cpk_scope_info: Optional[_models.ContainerCpkScopeInfo] = None,
+        **kwargs: Any
+    ) -> None:
         """creates a new container under the specified account. If the container with the same name
         already exists, the operation fails.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -994,95 +917,96 @@
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param access: Specifies whether data in the container may be accessed publicly and the level
-         of access. Default value is None.
+         of access. Known values are: "container" and "blob". Default value is None.
         :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param container_cpk_scope_info: Parameter group. Default value is None.
         :type container_cpk_scope_info: ~azure.storage.blob.models.ContainerCpkScopeInfo
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _default_encryption_scope = None
         _prevent_encryption_scope_override = None
         if container_cpk_scope_info is not None:
             _default_encryption_scope = container_cpk_scope_info.default_encryption_scope
             _prevent_encryption_scope_override = container_cpk_scope_info.prevent_encryption_scope_override
 
         request = build_create_request(
             url=self._config.url,
-            restype=restype,
-            version=self._config.version,
             timeout=timeout,
             metadata=metadata,
             access=access,
             request_id_parameter=request_id_parameter,
             default_encryption_scope=_default_encryption_scope,
             prevent_encryption_scope_override=_prevent_encryption_scope_override,
-            template_url=self.create.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.create.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    create.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """returns all user-defined metadata and system properties for the specified container. The data
         returned does not include the container's list of blobs.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -1093,89 +1017,100 @@
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_properties_request(
             url=self._config.url,
-            restype=restype,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_properties.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-meta']=self._deserialize('{str}', response.headers.get('x-ms-meta'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-duration']=self._deserialize('str', response.headers.get('x-ms-lease-duration'))
-        response_headers['x-ms-lease-state']=self._deserialize('str', response.headers.get('x-ms-lease-state'))
-        response_headers['x-ms-lease-status']=self._deserialize('str', response.headers.get('x-ms-lease-status'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-blob-public-access']=self._deserialize('str', response.headers.get('x-ms-blob-public-access'))
-        response_headers['x-ms-has-immutability-policy']=self._deserialize('bool', response.headers.get('x-ms-has-immutability-policy'))
-        response_headers['x-ms-has-legal-hold']=self._deserialize('bool', response.headers.get('x-ms-has-legal-hold'))
-        response_headers['x-ms-default-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-default-encryption-scope'))
-        response_headers['x-ms-deny-encryption-scope-override']=self._deserialize('bool', response.headers.get('x-ms-deny-encryption-scope-override'))
-        response_headers['x-ms-immutable-storage-with-versioning-enabled']=self._deserialize('bool', response.headers.get('x-ms-immutable-storage-with-versioning-enabled'))
-
+        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-blob-public-access"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-public-access")
+        )
+        response_headers["x-ms-has-immutability-policy"] = self._deserialize(
+            "bool", response.headers.get("x-ms-has-immutability-policy")
+        )
+        response_headers["x-ms-has-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-has-legal-hold"))
+        response_headers["x-ms-default-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-default-encryption-scope")
+        )
+        response_headers["x-ms-deny-encryption-scope-override"] = self._deserialize(
+            "bool", response.headers.get("x-ms-deny-encryption-scope-override")
+        )
+        response_headers["x-ms-immutable-storage-with-versioning-enabled"] = self._deserialize(
+            "bool", response.headers.get("x-ms-immutable-storage-with-versioning-enabled")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def delete(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """operation marks the specified container for deletion. The container and any blobs contained
         within it are later deleted during garbage collection.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -1188,85 +1123,86 @@
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_delete_request(
             url=self._config.url,
-            restype=restype,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.delete.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.delete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    delete.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """operation sets one or more user-defined name-value pairs for the specified container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -1289,85 +1225,86 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "metadata")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
 
         request = build_set_metadata_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             metadata=metadata,
             if_modified_since=_if_modified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_metadata.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.set_metadata.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_metadata.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    set_metadata.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def get_access_policy(
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> List["_models.SignedIdentifier"]
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> List[_models.SignedIdentifier]:
         """gets the permissions for the specified container. The permissions indicate whether container
         data may be accessed publicly.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -1381,198 +1318,205 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
          in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: list of SignedIdentifier, or the result of cls(response)
+        :return: list of SignedIdentifier or the result of cls(response)
         :rtype: list[~azure.storage.blob.models.SignedIdentifier]
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.SignedIdentifier"]]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "acl")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[List[_models.SignedIdentifier]]
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_access_policy_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            template_url=self.get_access_policy.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_access_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-blob-public-access']=self._deserialize('str', response.headers.get('x-ms-blob-public-access'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-blob-public-access"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-public-access")
+        )
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('[SignedIdentifier]', pipeline_response)
+        deserialized = self._deserialize("[SignedIdentifier]", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_access_policy.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    get_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def set_access_policy(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        access=None,  # type: Optional[Union[str, "_models.PublicAccessType"]]
-        request_id_parameter=None,  # type: Optional[str]
-        container_acl=None,  # type: Optional[List["_models.SignedIdentifier"]]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        container_acl: Optional[List[_models.SignedIdentifier]] = None,
+        **kwargs: Any
+    ) -> None:
         """sets the permissions for the specified container. The permissions indicate whether blobs in a
         container may be accessed publicly.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param access: Specifies whether data in the container may be accessed publicly and the level
-         of access. Default value is None.
+         of access. Known values are: "container" and "blob". Default value is None.
         :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param container_acl: the acls for the container. Default value is None.
-        :type container_acl: list[~azure.storage.blob.models.SignedIdentifier]
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :param container_acl: the acls for the container. Default value is None.
+        :type container_acl: list[~azure.storage.blob.models.SignedIdentifier]
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
          in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "acl")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        serialization_ctxt = {"xml": {'name': 'SignedIdentifiers', 'wrapped': True, 'itemsName': 'SignedIdentifier'}}
+        serialization_ctxt = {"xml": {"name": "SignedIdentifiers", "wrapped": True, "itemsName": "SignedIdentifier"}}
         if container_acl is not None:
-            _content = self._serialize.body(container_acl, '[SignedIdentifier]', is_xml=True, serialization_ctxt=serialization_ctxt)
+            _content = self._serialize.body(
+                container_acl, "[SignedIdentifier]", is_xml=True, serialization_ctxt=serialization_ctxt
+            )
         else:
             _content = None
 
         request = build_set_access_policy_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
             timeout=timeout,
             lease_id=_lease_id,
             access=access,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.set_access_policy.metadata['url'],
+            restype=restype,
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.set_access_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_access_policy.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    set_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def restore(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        deleted_container_name=None,  # type: Optional[str]
-        deleted_container_version=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        deleted_container_name: Optional[str] = None,
+        deleted_container_version: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
         """Restores a previously-deleted container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
@@ -1589,80 +1533,81 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "undelete")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_restore_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             deleted_container_name=deleted_container_name,
             deleted_container_version=deleted_container_version,
-            template_url=self.restore.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.restore.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    restore.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    restore.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def rename(  # pylint: disable=inconsistent-return-statements
         self,
-        source_container_name,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        source_lease_id=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        source_container_name: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        source_lease_id: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
         """Renames an existing container.
 
         :param source_container_name: Required.  Specifies the name of the container to rename.
+         Required.
         :type source_container_name: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -1675,171 +1620,171 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "rename". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "rename")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_rename_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             source_container_name=source_container_name,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             source_lease_id=source_lease_id,
-            template_url=self.rename.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.rename.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    rename.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    rename.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def submit_batch(
         self,
-        content_length,  # type: int
-        body,  # type: IO
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> IO
+        content_length: int,
+        body: IO,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> Iterator[bytes]:
         """The Batch operation allows multiple API calls to be embedded into a single HTTP request.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword multipart_content_type: Required. The value of this header must be multipart/mixed
-         with a batch boundary. Example header value: multipart/mixed; boundary=batch_:code:`<GUID>`.
-        :paramtype multipart_content_type: str
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "batch". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        multipart_content_type = kwargs.pop('multipart_content_type')  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "batch")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _content = self._serialize.body(body, 'IO')
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+        multipart_content_type = kwargs.pop(
+            "multipart_content_type", _headers.pop("Content-Type", "application/xml")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
+
+        _content = body
 
         request = build_submit_batch_request(
             url=self._config.url,
-            multipart_content_type=multipart_content_type,
+            content_length=content_length,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
+            multipart_content_type=multipart_content_type,
             version=self._config.version,
             content=_content,
-            content_length=content_length,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.submit_batch.metadata['url'],
+            template_url=self.submit_batch.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    submit_batch.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    submit_batch.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def filter_blobs(
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        where=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.FilterBlobSegment"
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        where: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
+        **kwargs: Any
+    ) -> _models.FilterBlobSegment:
         """The Filter Blobs operation enables callers to list blobs in a container whose tags match a
         given search expression.  Filter blobs searches within the given container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -1861,89 +1806,94 @@
         :param maxresults: Specifies the maximum number of containers to return. If the request does
          not specify maxresults, or specifies a value greater than 5000, the server will return up to
          5000 items. Note that if the listing operation crosses a partition boundary, then the service
          will return a continuation token for retrieving the remainder of the results. For this reason,
          it is possible that the service will return fewer results than specified by maxresults, or than
          the default of 5000. Default value is None.
         :type maxresults: int
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.FilterBlobsIncludeItem]
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "blobs". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: FilterBlobSegment, or the result of cls(response)
+        :return: FilterBlobSegment or the result of cls(response)
         :rtype: ~azure.storage.blob.models.FilterBlobSegment
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.FilterBlobSegment"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "blobs")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.FilterBlobSegment]
 
-        
         request = build_filter_blobs_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             where=where,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.filter_blobs.metadata['url'],
+            include=include,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.filter_blobs.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('FilterBlobSegment', pipeline_response)
+        deserialized = self._deserialize("FilterBlobSegment", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    filter_blobs.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    filter_blobs.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        duration=None,  # type: Optional[int]
-        proposed_lease_id=None,  # type: Optional[str]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        duration: Optional[int] = None,
+        proposed_lease_id: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -1968,93 +1918,94 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "acquire". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "acquire")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_acquire_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             duration=duration,
             proposed_lease_id=proposed_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.acquire_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.acquire_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    acquire_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    acquire_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def release_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2069,91 +2020,92 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "release". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "release")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_release_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.release_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.release_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    release_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    release_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def renew_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2168,88 +2120,89 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "renew". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "renew")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_renew_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.renew_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.renew_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    renew_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    renew_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout=None,  # type: Optional[int]
-        break_period=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        timeout: Optional[int] = None,
+        break_period: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -2274,97 +2227,98 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "break". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "break")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_break_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             timeout=timeout,
             break_period=break_period,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.break_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.break_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-time']=self._deserialize('int', response.headers.get('x-ms-lease-time'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    break_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    break_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def change_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id,  # type: str
-        proposed_lease_id,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        lease_id: str,
+        proposed_lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
         """[Update] establishes and manages a lock on a container for delete operations. The lock duration
         can be 15 to 60 seconds, or can be infinite.
 
-        :param lease_id: Specifies the current lease ID on the resource.
+        :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
          400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats.
+         Constructor (String) for a list of valid GUID string formats. Required.
         :type proposed_lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -2379,91 +2333,92 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword action: Describes what lease action to take. Default value is "change". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "lease")  # type: str
-        restype = kwargs.pop('restype', "container")  # type: str
-        action = kwargs.pop('action', "change")  # type: str
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
         request = build_change_lease_request(
             url=self._config.url,
-            comp=comp,
-            restype=restype,
-            action=action,
-            version=self._config.version,
             lease_id=lease_id,
             proposed_lease_id=proposed_lease_id,
             timeout=timeout,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            template_url=self.change_lease.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.change_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-lease-id']=self._deserialize('str', response.headers.get('x-ms-lease-id'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    change_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def list_blob_flat_segment(
         self,
-        prefix=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        include=None,  # type: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.ListBlobsFlatSegmentResponse"
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.ListBlobsFlatSegmentResponse:
         """[Update] The List Blobs operation returns a list of the blobs under the specified container.
 
         :param prefix: Filters the results to return only containers whose name begins with the
          specified prefix. Default value is None.
         :type prefix: str
         :param marker: A string value that identifies the portion of the list of containers to be
          returned with the next listing operation. The operation returns the NextMarker value within the
@@ -2494,92 +2449,93 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "list". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListBlobsFlatSegmentResponse, or the result of cls(response)
+        :return: ListBlobsFlatSegmentResponse or the result of cls(response)
         :rtype: ~azure.storage.blob.models.ListBlobsFlatSegmentResponse
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ListBlobsFlatSegmentResponse"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "list")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsFlatSegmentResponse]
 
-        
         request = build_list_blob_flat_segment_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             prefix=prefix,
             marker=marker,
             maxresults=maxresults,
             include=include,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.list_blob_flat_segment.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_blob_flat_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('ListBlobsFlatSegmentResponse', pipeline_response)
+        deserialized = self._deserialize("ListBlobsFlatSegmentResponse", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    list_blob_flat_segment.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    list_blob_flat_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
     def list_blob_hierarchy_segment(
         self,
-        delimiter,  # type: str
-        prefix=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        include=None,  # type: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.ListBlobsHierarchySegmentResponse"
+        delimiter: str,
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.ListBlobsHierarchySegmentResponse:
         """[Update] The List Blobs operation returns a list of the blobs under the specified container.
 
         :param delimiter: When the request includes this parameter, the operation returns a BlobPrefix
          element in the response body that acts as a placeholder for all blobs whose names begin with
          the same substring up to the appearance of the delimiter character. The delimiter may be a
-         single character or a string.
+         single character or a string. Required.
         :type delimiter: str
         :param prefix: Filters the results to return only containers whose name begins with the
          specified prefix. Default value is None.
         :type prefix: str
         :param marker: A string value that identifies the portion of the list of containers to be
          returned with the next listing operation. The operation returns the NextMarker value within the
          response body if the listing operation did not return all containers remaining to be listed
@@ -2609,132 +2565,131 @@
         :keyword restype: restype. Default value is "container". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "list". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListBlobsHierarchySegmentResponse, or the result of cls(response)
+        :return: ListBlobsHierarchySegmentResponse or the result of cls(response)
         :rtype: ~azure.storage.blob.models.ListBlobsHierarchySegmentResponse
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ListBlobsHierarchySegmentResponse"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "container")  # type: str
-        comp = kwargs.pop('comp', "list")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsHierarchySegmentResponse]
 
-        
         request = build_list_blob_hierarchy_segment_request(
             url=self._config.url,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
             delimiter=delimiter,
             prefix=prefix,
             marker=marker,
             maxresults=maxresults,
             include=include,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.list_blob_hierarchy_segment.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_blob_hierarchy_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('ListBlobsHierarchySegmentResponse', pipeline_response)
+        deserialized = self._deserialize("ListBlobsHierarchySegmentResponse", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    list_blob_hierarchy_segment.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    list_blob_hierarchy_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def get_account_info(  # pylint: disable=inconsistent-return-statements
-        self,
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+    def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
         """Returns the sku name and account kind.
 
         :keyword restype: restype. Default value is "account". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "account")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_get_account_info_request(
             url=self._config.url,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata['url'],
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-sku-name']=self._deserialize('str', response.headers.get('x-ms-sku-name'))
-        response_headers['x-ms-account-kind']=self._deserialize('str', response.headers.get('x-ms-account-kind'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {'url': "{url}/{containerName}"}  # type: ignore
-
+    get_account_info.metadata = {"url": "{url}/{containerName}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_page_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_container_operations.py`

 * *Files 16% similar despite different names*

```diff
@@ -3,2164 +3,2693 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
-from typing import TYPE_CHECKING
+from typing import Any, Callable, Dict, IO, Iterator, List, Optional, TypeVar, Union
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
+from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
+from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
-    T = TypeVar('T')
-    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
+T = TypeVar("T")
+ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
-# fmt: off
+
 
 def build_create_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    blob_type = kwargs.pop('blob_type', "PageBlob")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    blob_content_length = kwargs.pop('blob_content_length')  # type: int
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    tier = kwargs.pop('tier', None)  # type: Optional[Union[str, "_models.PremiumPageBlobAccessTier"]]
-    blob_content_type = kwargs.pop('blob_content_type', None)  # type: Optional[str]
-    blob_content_encoding = kwargs.pop('blob_content_encoding', None)  # type: Optional[str]
-    blob_content_language = kwargs.pop('blob_content_language', None)  # type: Optional[str]
-    blob_content_md5 = kwargs.pop('blob_content_md5', None)  # type: Optional[bytearray]
-    blob_cache_control = kwargs.pop('blob_cache_control', None)  # type: Optional[str]
-    metadata = kwargs.pop('metadata', None)  # type: Optional[Dict[str, str]]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    blob_content_disposition = kwargs.pop('blob_content_disposition', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    blob_sequence_number = kwargs.pop('blob_sequence_number', 0)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    blob_tags_string = kwargs.pop('blob_tags_string', None)  # type: Optional[str]
-    immutability_policy_expiry = kwargs.pop('immutability_policy_expiry', None)  # type: Optional[datetime.datetime]
-    immutability_policy_mode = kwargs.pop('immutability_policy_mode', None)  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-    legal_hold = kwargs.pop('legal_hold', None)  # type: Optional[bool]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+    request_id_parameter: Optional[str] = None,
+    default_encryption_scope: Optional[str] = None,
+    prevent_encryption_scope_override: Optional[bool] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-blob-type'] = _SERIALIZER.header("blob_type", blob_type, 'str')
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    if tier is not None:
-        _header_parameters['x-ms-access-tier'] = _SERIALIZER.header("tier", tier, 'str')
-    if blob_content_type is not None:
-        _header_parameters['x-ms-blob-content-type'] = _SERIALIZER.header("blob_content_type", blob_content_type, 'str')
-    if blob_content_encoding is not None:
-        _header_parameters['x-ms-blob-content-encoding'] = _SERIALIZER.header("blob_content_encoding", blob_content_encoding, 'str')
-    if blob_content_language is not None:
-        _header_parameters['x-ms-blob-content-language'] = _SERIALIZER.header("blob_content_language", blob_content_language, 'str')
-    if blob_content_md5 is not None:
-        _header_parameters['x-ms-blob-content-md5'] = _SERIALIZER.header("blob_content_md5", blob_content_md5, 'bytearray')
-    if blob_cache_control is not None:
-        _header_parameters['x-ms-blob-cache-control'] = _SERIALIZER.header("blob_cache_control", blob_cache_control, 'str')
     if metadata is not None:
-        _header_parameters['x-ms-meta'] = _SERIALIZER.header("metadata", metadata, '{str}')
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
+    if access is not None:
+        _headers["x-ms-blob-public-access"] = _SERIALIZER.header("access", access, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if default_encryption_scope is not None:
+        _headers["x-ms-default-encryption-scope"] = _SERIALIZER.header(
+            "default_encryption_scope", default_encryption_scope, "str"
+        )
+    if prevent_encryption_scope_override is not None:
+        _headers["x-ms-deny-encryption-scope-override"] = _SERIALIZER.header(
+            "prevent_encryption_scope_override", prevent_encryption_scope_override, "bool"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_get_properties_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    if blob_content_disposition is not None:
-        _header_parameters['x-ms-blob-content-disposition'] = _SERIALIZER.header("blob_content_disposition", blob_content_disposition, 'str')
-    if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
-    if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
-    if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
-    if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
-    if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
-    if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-blob-content-length'] = _SERIALIZER.header("blob_content_length", blob_content_length, 'long')
-    if blob_sequence_number is not None:
-        _header_parameters['x-ms-blob-sequence-number'] = _SERIALIZER.header("blob_sequence_number", blob_sequence_number, 'long')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    if blob_tags_string is not None:
-        _header_parameters['x-ms-tags'] = _SERIALIZER.header("blob_tags_string", blob_tags_string, 'str')
-    if immutability_policy_expiry is not None:
-        _header_parameters['x-ms-immutability-policy-until-date'] = _SERIALIZER.header("immutability_policy_expiry", immutability_policy_expiry, 'rfc-1123')
-    if immutability_policy_mode is not None:
-        _header_parameters['x-ms-immutability-policy-mode'] = _SERIALIZER.header("immutability_policy_mode", immutability_policy_mode, 'str')
-    if legal_hold is not None:
-        _header_parameters['x-ms-legal-hold'] = _SERIALIZER.header("legal_hold", legal_hold, 'bool')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
-
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_upload_pages_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "page")  # type: str
-    page_write = kwargs.pop('page_write', "update")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    content_length = kwargs.pop('content_length')  # type: int
-    transactional_content_md5 = kwargs.pop('transactional_content_md5', None)  # type: Optional[bytearray]
-    transactional_content_crc64 = kwargs.pop('transactional_content_crc64', None)  # type: Optional[bytearray]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    range = kwargs.pop('range', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    if_sequence_number_less_than_or_equal_to = kwargs.pop('if_sequence_number_less_than_or_equal_to', None)  # type: Optional[int]
-    if_sequence_number_less_than = kwargs.pop('if_sequence_number_less_than', None)  # type: Optional[int]
-    if_sequence_number_equal_to = kwargs.pop('if_sequence_number_equal_to', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_delete_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-page-write'] = _SERIALIZER.header("page_write", page_write, 'str')
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    if transactional_content_md5 is not None:
-        _header_parameters['Content-MD5'] = _SERIALIZER.header("transactional_content_md5", transactional_content_md5, 'bytearray')
-    if transactional_content_crc64 is not None:
-        _header_parameters['x-ms-content-crc64'] = _SERIALIZER.header("transactional_content_crc64", transactional_content_crc64, 'bytearray')
-    if range is not None:
-        _header_parameters['x-ms-range'] = _SERIALIZER.header("range", range, 'str')
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
-    if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
-    if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
-    if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
-    if if_sequence_number_less_than_or_equal_to is not None:
-        _header_parameters['x-ms-if-sequence-number-le'] = _SERIALIZER.header("if_sequence_number_less_than_or_equal_to", if_sequence_number_less_than_or_equal_to, 'long')
-    if if_sequence_number_less_than is not None:
-        _header_parameters['x-ms-if-sequence-number-lt'] = _SERIALIZER.header("if_sequence_number_less_than", if_sequence_number_less_than, 'long')
-    if if_sequence_number_equal_to is not None:
-        _header_parameters['x-ms-if-sequence-number-eq'] = _SERIALIZER.header("if_sequence_number_equal_to", if_sequence_number_equal_to, 'long')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_clear_pages_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "page")  # type: str
-    page_write = kwargs.pop('page_write', "clear")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    range = kwargs.pop('range', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    if_sequence_number_less_than_or_equal_to = kwargs.pop('if_sequence_number_less_than_or_equal_to', None)  # type: Optional[int]
-    if_sequence_number_less_than = kwargs.pop('if_sequence_number_less_than', None)  # type: Optional[int]
-    if_sequence_number_equal_to = kwargs.pop('if_sequence_number_equal_to', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
 
-    accept = "application/xml"
+def build_set_metadata_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-page-write'] = _SERIALIZER.header("page_write", page_write, 'str')
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    if range is not None:
-        _header_parameters['x-ms-range'] = _SERIALIZER.header("range", range, 'str')
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
-    if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
-    if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
-    if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
-    if if_sequence_number_less_than_or_equal_to is not None:
-        _header_parameters['x-ms-if-sequence-number-le'] = _SERIALIZER.header("if_sequence_number_less_than_or_equal_to", if_sequence_number_less_than_or_equal_to, 'long')
-    if if_sequence_number_less_than is not None:
-        _header_parameters['x-ms-if-sequence-number-lt'] = _SERIALIZER.header("if_sequence_number_less_than", if_sequence_number_less_than, 'long')
-    if if_sequence_number_equal_to is not None:
-        _header_parameters['x-ms-if-sequence-number-eq'] = _SERIALIZER.header("if_sequence_number_equal_to", if_sequence_number_equal_to, 'long')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if metadata is not None:
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
-    if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_get_access_policy_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_upload_pages_from_url_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "page")  # type: str
-    page_write = kwargs.pop('page_write', "update")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    source_url = kwargs.pop('source_url')  # type: str
-    source_range = kwargs.pop('source_range')  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    range = kwargs.pop('range')  # type: str
-    source_content_md5 = kwargs.pop('source_content_md5', None)  # type: Optional[bytearray]
-    source_contentcrc64 = kwargs.pop('source_contentcrc64', None)  # type: Optional[bytearray]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_sequence_number_less_than_or_equal_to = kwargs.pop('if_sequence_number_less_than_or_equal_to', None)  # type: Optional[int]
-    if_sequence_number_less_than = kwargs.pop('if_sequence_number_less_than', None)  # type: Optional[int]
-    if_sequence_number_equal_to = kwargs.pop('if_sequence_number_equal_to', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    source_if_modified_since = kwargs.pop('source_if_modified_since', None)  # type: Optional[datetime.datetime]
-    source_if_unmodified_since = kwargs.pop('source_if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    source_if_match = kwargs.pop('source_if_match', None)  # type: Optional[str]
-    source_if_none_match = kwargs.pop('source_if_none_match', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    copy_source_authorization = kwargs.pop('copy_source_authorization', None)  # type: Optional[str]
 
-    accept = "application/xml"
+def build_set_access_policy_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    content: Any = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-page-write'] = _SERIALIZER.header("page_write", page_write, 'str')
-    _header_parameters['x-ms-copy-source'] = _SERIALIZER.header("source_url", source_url, 'str')
-    _header_parameters['x-ms-source-range'] = _SERIALIZER.header("source_range", source_range, 'str')
-    if source_content_md5 is not None:
-        _header_parameters['x-ms-source-content-md5'] = _SERIALIZER.header("source_content_md5", source_content_md5, 'bytearray')
-    if source_contentcrc64 is not None:
-        _header_parameters['x-ms-source-content-crc64'] = _SERIALIZER.header("source_contentcrc64", source_contentcrc64, 'bytearray')
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    _header_parameters['x-ms-range'] = _SERIALIZER.header("range", range, 'str')
-    if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
-    if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
-    if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
-    if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
     if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    if if_sequence_number_less_than_or_equal_to is not None:
-        _header_parameters['x-ms-if-sequence-number-le'] = _SERIALIZER.header("if_sequence_number_less_than_or_equal_to", if_sequence_number_less_than_or_equal_to, 'long')
-    if if_sequence_number_less_than is not None:
-        _header_parameters['x-ms-if-sequence-number-lt'] = _SERIALIZER.header("if_sequence_number_less_than", if_sequence_number_less_than, 'long')
-    if if_sequence_number_equal_to is not None:
-        _header_parameters['x-ms-if-sequence-number-eq'] = _SERIALIZER.header("if_sequence_number_equal_to", if_sequence_number_equal_to, 'long')
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if access is not None:
+        _headers["x-ms-blob-public-access"] = _SERIALIZER.header("access", access, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    if source_if_modified_since is not None:
-        _header_parameters['x-ms-source-if-modified-since'] = _SERIALIZER.header("source_if_modified_since", source_if_modified_since, 'rfc-1123')
-    if source_if_unmodified_since is not None:
-        _header_parameters['x-ms-source-if-unmodified-since'] = _SERIALIZER.header("source_if_unmodified_since", source_if_unmodified_since, 'rfc-1123')
-    if source_if_match is not None:
-        _header_parameters['x-ms-source-if-match'] = _SERIALIZER.header("source_if_match", source_if_match, 'str')
-    if source_if_none_match is not None:
-        _header_parameters['x-ms-source-if-none-match'] = _SERIALIZER.header("source_if_none_match", source_if_none_match, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
+
+
+def build_restore_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    deleted_container_name: Optional[str] = None,
+    deleted_container_version: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if deleted_container_name is not None:
+        _headers["x-ms-deleted-container-name"] = _SERIALIZER.header(
+            "deleted_container_name", deleted_container_name, "str"
+        )
+    if deleted_container_version is not None:
+        _headers["x-ms-deleted-container-version"] = _SERIALIZER.header(
+            "deleted_container_version", deleted_container_version, "str"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_rename_request(
+    url: str,
+    *,
+    source_container_name: str,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    source_lease_id: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-source-container-name"] = _SERIALIZER.header("source_container_name", source_container_name, "str")
+    if source_lease_id is not None:
+        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_submit_batch_request(
+    url: str,
+    *,
+    content_length: int,
+    content: IO,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+    multipart_content_type = kwargs.pop(
+        "multipart_content_type", _headers.pop("Content-Type", None)
+    )  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if multipart_content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("multipart_content_type", multipart_content_type, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    if copy_source_authorization is not None:
-        _header_parameters['x-ms-copy-source-authorization'] = _SERIALIZER.header("copy_source_authorization", copy_source_authorization, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
-
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_get_page_ranges_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "pagelist")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    range = kwargs.pop('range', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, content=content, **kwargs)
+
+
+def build_filter_blobs_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    where: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if where is not None:
+        _params["where"] = _SERIALIZER.query("where", where, "str")
     if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
     if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
+    if include is not None:
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    if range is not None:
-        _header_parameters['x-ms-range'] = _SERIALIZER.header("range", range, 'str')
-    if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_acquire_lease_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    duration: Optional[int] = None,
+    proposed_lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    if duration is not None:
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
+    if proposed_lease_id is not None:
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_get_page_ranges_diff_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "pagelist")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    snapshot = kwargs.pop('snapshot', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    prevsnapshot = kwargs.pop('prevsnapshot', None)  # type: Optional[str]
-    prev_snapshot_url = kwargs.pop('prev_snapshot_url', None)  # type: Optional[str]
-    range = kwargs.pop('range', None)  # type: Optional[str]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_release_lease_request(
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
-    if snapshot is not None:
-        _query_parameters['snapshot'] = _SERIALIZER.query("snapshot", snapshot, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
-    if prevsnapshot is not None:
-        _query_parameters['prevsnapshot'] = _SERIALIZER.query("prevsnapshot", prevsnapshot, 'str')
-    if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
-    if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    if prev_snapshot_url is not None:
-        _header_parameters['x-ms-previous-snapshot-url'] = _SERIALIZER.header("prev_snapshot_url", prev_snapshot_url, 'str')
-    if range is not None:
-        _header_parameters['x-ms-range'] = _SERIALIZER.header("range", range, 'str')
-    if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_resize_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    blob_content_length = kwargs.pop('blob_content_length')  # type: int
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    encryption_key = kwargs.pop('encryption_key', None)  # type: Optional[str]
-    encryption_key_sha256 = kwargs.pop('encryption_key_sha256', None)  # type: Optional[str]
-    encryption_algorithm = kwargs.pop('encryption_algorithm', None)  # type: Optional[Union[str, "_models.EncryptionAlgorithmType"]]
-    encryption_scope = kwargs.pop('encryption_scope', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
 
-    accept = "application/xml"
+def build_renew_lease_request(
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
-    if encryption_key is not None:
-        _header_parameters['x-ms-encryption-key'] = _SERIALIZER.header("encryption_key", encryption_key, 'str')
-    if encryption_key_sha256 is not None:
-        _header_parameters['x-ms-encryption-key-sha256'] = _SERIALIZER.header("encryption_key_sha256", encryption_key_sha256, 'str')
-    if encryption_algorithm is not None:
-        _header_parameters['x-ms-encryption-algorithm'] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, 'str')
-    if encryption_scope is not None:
-        _header_parameters['x-ms-encryption-scope'] = _SERIALIZER.header("encryption_scope", encryption_scope, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-blob-content-length'] = _SERIALIZER.header("blob_content_length", blob_content_length, 'long')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_update_sequence_number_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    sequence_number_action = kwargs.pop('sequence_number_action')  # type: Union[str, "_models.SequenceNumberActionType"]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    lease_id = kwargs.pop('lease_id', None)  # type: Optional[str]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    blob_sequence_number = kwargs.pop('blob_sequence_number', 0)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+def build_break_lease_request(
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    break_period: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    if lease_id is not None:
-        _header_parameters['x-ms-lease-id'] = _SERIALIZER.header("lease_id", lease_id, 'str')
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    if break_period is not None:
+        _headers["x-ms-lease-break-period"] = _SERIALIZER.header("break_period", break_period, "int")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-sequence-number-action'] = _SERIALIZER.header("sequence_number_action", sequence_number_action, 'str')
-    if blob_sequence_number is not None:
-        _header_parameters['x-ms-blob-sequence-number'] = _SERIALIZER.header("blob_sequence_number", blob_sequence_number, 'long')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_copy_incremental_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "incrementalcopy")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    copy_source = kwargs.pop('copy_source')  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    if_modified_since = kwargs.pop('if_modified_since', None)  # type: Optional[datetime.datetime]
-    if_unmodified_since = kwargs.pop('if_unmodified_since', None)  # type: Optional[datetime.datetime]
-    if_match = kwargs.pop('if_match', None)  # type: Optional[str]
-    if_none_match = kwargs.pop('if_none_match', None)  # type: Optional[str]
-    if_tags = kwargs.pop('if_tags', None)  # type: Optional[str]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+def build_change_lease_request(
+    url: str,
+    *,
+    lease_id: str,
+    proposed_lease_id: str,
+    timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     if if_modified_since is not None:
-        _header_parameters['If-Modified-Since'] = _SERIALIZER.header("if_modified_since", if_modified_since, 'rfc-1123')
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
-        _header_parameters['If-Unmodified-Since'] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, 'rfc-1123')
-    if if_match is not None:
-        _header_parameters['If-Match'] = _SERIALIZER.header("if_match", if_match, 'str')
-    if if_none_match is not None:
-        _header_parameters['If-None-Match'] = _SERIALIZER.header("if_none_match", if_none_match, 'str')
-    if if_tags is not None:
-        _header_parameters['x-ms-if-tags'] = _SERIALIZER.header("if_tags", if_tags, 'str')
-    _header_parameters['x-ms-copy-source'] = _SERIALIZER.header("copy_source", copy_source, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_list_blob_flat_segment_request(
+    url: str,
+    *,
+    prefix: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if prefix is not None:
+        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
+    if marker is not None:
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
+    if maxresults is not None:
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
+    if include is not None:
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_list_blob_hierarchy_segment_request(
+    url: str,
+    *,
+    delimiter: str,
+    prefix: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if prefix is not None:
+        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
+    _params["delimiter"] = _SERIALIZER.query("delimiter", delimiter, "str")
+    if marker is not None:
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
+    if maxresults is not None:
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
+    if include is not None:
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url = _format_url_section(_url, **path_format_arguments)
+
+    # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
 
-# fmt: on
-class PageBlobOperations(object):
+class ContainerOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.AzureBlobStorage`'s
-        :attr:`page_blob` attribute.
+        :attr:`container` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def create(  # pylint: disable=inconsistent-return-statements
         self,
-        content_length,  # type: int
-        blob_content_length,  # type: int
-        timeout=None,  # type: Optional[int]
-        tier=None,  # type: Optional[Union[str, "_models.PremiumPageBlobAccessTier"]]
-        metadata=None,  # type: Optional[Dict[str, str]]
-        blob_sequence_number=0,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        blob_tags_string=None,  # type: Optional[str]
-        immutability_policy_expiry=None,  # type: Optional[datetime.datetime]
-        immutability_policy_mode=None,  # type: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]]
-        legal_hold=None,  # type: Optional[bool]
-        blob_http_headers=None,  # type: Optional["_models.BlobHTTPHeaders"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """The Create operation creates a new page blob.
-
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param blob_content_length: This header specifies the maximum size for the page blob, up to 1
-         TB. The page blob size must be aligned to a 512-byte boundary.
-        :type blob_content_length: long
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+        request_id_parameter: Optional[str] = None,
+        container_cpk_scope_info: Optional[_models.ContainerCpkScopeInfo] = None,
+        **kwargs: Any
+    ) -> None:
+        """creates a new container under the specified account. If the container with the same name
+        already exists, the operation fails.
+
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param tier: Optional. Indicates the tier to be set on the page blob. Default value is None.
-        :type tier: str or ~azure.storage.blob.models.PremiumPageBlobAccessTier
         :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
          If no name-value pairs are specified, the operation will copy the metadata from the source blob
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
-        :param blob_sequence_number: Set for page blobs only. The sequence number is a user-controlled
-         value that you can use to track requests. The value of the sequence number must be between 0
-         and 2^63 - 1. Default value is 0.
-        :type blob_sequence_number: long
+        :param access: Specifies whether data in the container may be accessed publicly and the level
+         of access. Known values are: "container" and "blob". Default value is None.
+        :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
+        :param container_cpk_scope_info: Parameter group. Default value is None.
+        :type container_cpk_scope_info: ~azure.storage.blob.models.ContainerCpkScopeInfo
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        _default_encryption_scope = None
+        _prevent_encryption_scope_override = None
+        if container_cpk_scope_info is not None:
+            _default_encryption_scope = container_cpk_scope_info.default_encryption_scope
+            _prevent_encryption_scope_override = container_cpk_scope_info.prevent_encryption_scope_override
+
+        request = build_create_request(
+            url=self._config.url,
+            timeout=timeout,
+            metadata=metadata,
+            access=access,
+            request_id_parameter=request_id_parameter,
+            default_encryption_scope=_default_encryption_scope,
+            prevent_encryption_scope_override=_prevent_encryption_scope_override,
+            restype=restype,
+            version=self._config.version,
+            template_url=self.create.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [201]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    create.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def get_properties(  # pylint: disable=inconsistent-return-statements
+        self,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """returns all user-defined metadata and system properties for the specified container. The data
+        returned does not include the container's list of blobs.
+
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
-        :type blob_tags_string: str
-        :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
-         is set to expire. Default value is None.
-        :type immutability_policy_expiry: ~datetime.datetime
-        :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
-         Default value is None.
-        :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
-        :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
-        :type legal_hold: bool
-        :param blob_http_headers: Parameter group. Default value is None.
-        :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
+        :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.blob.models.CpkInfo
-        :param cpk_scope_info: Parameter group. Default value is None.
-        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
-         blob. Default value is "PageBlob". Note that overriding this default value may result in
-         unsupported behavior.
-        :paramtype blob_type: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        blob_type = kwargs.pop('blob_type', "PageBlob")  # type: str
-
-        _blob_content_type = None
-        _blob_content_encoding = None
-        _blob_content_language = None
-        _blob_content_md5 = None
-        _blob_cache_control = None
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
         _lease_id = None
-        _blob_content_disposition = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        _encryption_scope = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
-        if blob_http_headers is not None:
-            _blob_content_type = blob_http_headers.blob_content_type
-            _blob_content_encoding = blob_http_headers.blob_content_encoding
-            _blob_content_language = blob_http_headers.blob_content_language
-            _blob_content_md5 = blob_http_headers.blob_content_md5
-            _blob_cache_control = blob_http_headers.blob_cache_control
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if blob_http_headers is not None:
-            _blob_content_disposition = blob_http_headers.blob_content_disposition
-        if cpk_info is not None:
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
-        if cpk_scope_info is not None:
-            _encryption_scope = cpk_scope_info.encryption_scope
-        if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
 
-        request = build_create_request(
+        request = build_get_properties_request(
             url=self._config.url,
-            blob_type=blob_type,
-            version=self._config.version,
-            content_length=content_length,
-            blob_content_length=blob_content_length,
             timeout=timeout,
-            tier=tier,
-            blob_content_type=_blob_content_type,
-            blob_content_encoding=_blob_content_encoding,
-            blob_content_language=_blob_content_language,
-            blob_content_md5=_blob_content_md5,
-            blob_cache_control=_blob_cache_control,
-            metadata=metadata,
             lease_id=_lease_id,
-            blob_content_disposition=_blob_content_disposition,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            encryption_scope=_encryption_scope,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
-            blob_sequence_number=blob_sequence_number,
             request_id_parameter=request_id_parameter,
-            blob_tags_string=blob_tags_string,
-            immutability_policy_expiry=immutability_policy_expiry,
-            immutability_policy_mode=immutability_policy_mode,
-            legal_hold=legal_hold,
-            template_url=self.create.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['x-ms-version-id']=self._deserialize('str', response.headers.get('x-ms-version-id'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-blob-public-access"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-public-access")
+        )
+        response_headers["x-ms-has-immutability-policy"] = self._deserialize(
+            "bool", response.headers.get("x-ms-has-immutability-policy")
+        )
+        response_headers["x-ms-has-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-has-legal-hold"))
+        response_headers["x-ms-default-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-default-encryption-scope")
+        )
+        response_headers["x-ms-deny-encryption-scope-override"] = self._deserialize(
+            "bool", response.headers.get("x-ms-deny-encryption-scope-override")
+        )
+        response_headers["x-ms-immutable-storage-with-versioning-enabled"] = self._deserialize(
+            "bool", response.headers.get("x-ms-immutable-storage-with-versioning-enabled")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def upload_pages(  # pylint: disable=inconsistent-return-statements
+    def delete(  # pylint: disable=inconsistent-return-statements
         self,
-        content_length,  # type: int
-        body,  # type: IO
-        transactional_content_md5=None,  # type: Optional[bytearray]
-        transactional_content_crc64=None,  # type: Optional[bytearray]
-        timeout=None,  # type: Optional[int]
-        range=None,  # type: Optional[str]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        sequence_number_access_conditions=None,  # type: Optional["_models.SequenceNumberAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """The Upload Pages operation writes a range of pages to a page blob.
-
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
-        :type body: IO
-        :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
-         by the service. Default value is None.
-        :type transactional_content_md5: bytearray
-        :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
-         validated by the service. Default value is None.
-        :type transactional_content_crc64: bytearray
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """operation marks the specified container for deletion. The container and any blobs contained
+        within it are later deleted during garbage collection.
+
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param range: Return only the bytes of the blob in the specified range. Default value is None.
-        :type range: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.blob.models.CpkInfo
-        :param cpk_scope_info: Parameter group. Default value is None.
-        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
-        :param sequence_number_access_conditions: Parameter group. Default value is None.
-        :type sequence_number_access_conditions:
-         ~azure.storage.blob.models.SequenceNumberAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "page". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword page_write: Required. You may specify one of the following options:
-
-
-         * Update: Writes the bytes specified by the request body into the specified range. The Range
-         and Content-Length headers must match to perform the update.
-         * Clear: Clears the specified range and releases the space used in storage for that range. To
-         clear a range, set the Content-Length header to zero, and the Range header to a value that
-         indicates the range to clear, up to maximum blob size. Default value is "update". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype page_write: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "page")  # type: str
-        page_write = kwargs.pop('page_write', "update")  # type: str
-        content_type = kwargs.pop('content_type', "application/octet-stream")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        _encryption_scope = None
-        _if_sequence_number_less_than_or_equal_to = None
-        _if_sequence_number_less_than = None
-        _if_sequence_number_equal_to = None
         _if_modified_since = None
         _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if cpk_info is not None:
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
-        if cpk_scope_info is not None:
-            _encryption_scope = cpk_scope_info.encryption_scope
-        if sequence_number_access_conditions is not None:
-            _if_sequence_number_less_than_or_equal_to = sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
-            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
-            _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
-        _content = body
 
-        request = build_upload_pages_request(
+        request = build_delete_request(
             url=self._config.url,
-            comp=comp,
-            page_write=page_write,
-            version=self._config.version,
-            content_type=content_type,
-            content=_content,
-            content_length=content_length,
-            transactional_content_md5=transactional_content_md5,
-            transactional_content_crc64=transactional_content_crc64,
             timeout=timeout,
-            range=range,
             lease_id=_lease_id,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            encryption_scope=_encryption_scope,
-            if_sequence_number_less_than_or_equal_to=_if_sequence_number_less_than_or_equal_to,
-            if_sequence_number_less_than=_if_sequence_number_less_than,
-            if_sequence_number_equal_to=_if_sequence_number_equal_to,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.upload_pages.metadata['url'],
+            restype=restype,
+            version=self._config.version,
+            template_url=self.delete.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload_pages.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    delete.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def clear_pages(  # pylint: disable=inconsistent-return-statements
+    def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
-        content_length,  # type: int
-        timeout=None,  # type: Optional[int]
-        range=None,  # type: Optional[str]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        sequence_number_access_conditions=None,  # type: Optional["_models.SequenceNumberAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """The Clear Pages operation clears a set of pages from a page blob.
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """operation sets one or more user-defined name-value pairs for the specified container.
 
-        :param content_length: The length of the request.
-        :type content_length: long
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param range: Return only the bytes of the blob in the specified range. Default value is None.
-        :type range: str
+        :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
+         If no name-value pairs are specified, the operation will copy the metadata from the source blob
+         or file to the destination blob. If one or more name-value pairs are specified, the destination
+         blob is created with the specified metadata, and metadata is not copied from the source blob or
+         file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
+         rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
+         information. Default value is None.
+        :type metadata: dict[str, str]
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.blob.models.CpkInfo
-        :param cpk_scope_info: Parameter group. Default value is None.
-        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
-        :param sequence_number_access_conditions: Parameter group. Default value is None.
-        :type sequence_number_access_conditions:
-         ~azure.storage.blob.models.SequenceNumberAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "page". Note that overriding this default value may
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword page_write: Required. You may specify one of the following options:
-
-
-         * Update: Writes the bytes specified by the request body into the specified range. The Range
-         and Content-Length headers must match to perform the update.
-         * Clear: Clears the specified range and releases the space used in storage for that range. To
-         clear a range, set the Content-Length header to zero, and the Range header to a value that
-         indicates the range to clear, up to maximum blob size. Default value is "clear". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "page")  # type: str
-        page_write = kwargs.pop('page_write', "clear")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        _encryption_scope = None
-        _if_sequence_number_less_than_or_equal_to = None
-        _if_sequence_number_less_than = None
-        _if_sequence_number_equal_to = None
         _if_modified_since = None
-        _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if cpk_info is not None:
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
-        if cpk_scope_info is not None:
-            _encryption_scope = cpk_scope_info.encryption_scope
-        if sequence_number_access_conditions is not None:
-            _if_sequence_number_less_than_or_equal_to = sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
-            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
-            _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
 
-        request = build_clear_pages_request(
+        request = build_set_metadata_request(
             url=self._config.url,
+            timeout=timeout,
+            lease_id=_lease_id,
+            metadata=metadata,
+            if_modified_since=_if_modified_since,
+            request_id_parameter=request_id_parameter,
+            restype=restype,
             comp=comp,
-            page_write=page_write,
             version=self._config.version,
-            content_length=content_length,
+            template_url=self.set_metadata.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    set_metadata.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def get_access_policy(
+        self,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> List[_models.SignedIdentifier]:
+        """gets the permissions for the specified container. The permissions indicate whether container
+        data may be accessed publicly.
+
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
+         in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: list of SignedIdentifier or the result of cls(response)
+        :rtype: list[~azure.storage.blob.models.SignedIdentifier]
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[List[_models.SignedIdentifier]]
+
+        _lease_id = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+
+        request = build_get_access_policy_request(
+            url=self._config.url,
             timeout=timeout,
-            range=range,
             lease_id=_lease_id,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            encryption_scope=_encryption_scope,
-            if_sequence_number_less_than_or_equal_to=_if_sequence_number_less_than_or_equal_to,
-            if_sequence_number_less_than=_if_sequence_number_less_than,
-            if_sequence_number_equal_to=_if_sequence_number_equal_to,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.clear_pages.metadata['url'],
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_access_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-blob-public-access"] = self._deserialize(
+            "str", response.headers.get("x-ms-blob-public-access")
+        )
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
+        deserialized = self._deserialize("[SignedIdentifier]", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    clear_pages.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
+        return deserialized
 
+    get_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def upload_pages_from_url(  # pylint: disable=inconsistent-return-statements
+    def set_access_policy(  # pylint: disable=inconsistent-return-statements
         self,
-        source_url,  # type: str
-        source_range,  # type: str
-        content_length,  # type: int
-        range,  # type: str
-        source_content_md5=None,  # type: Optional[bytearray]
-        source_contentcrc64=None,  # type: Optional[bytearray]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        copy_source_authorization=None,  # type: Optional[str]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        sequence_number_access_conditions=None,  # type: Optional["_models.SequenceNumberAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        source_modified_access_conditions=None,  # type: Optional["_models.SourceModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """The Upload Pages operation writes a range of pages to a page blob where the contents are read
-        from a URL.
-
-        :param source_url: Specify a URL to the copy source.
-        :type source_url: str
-        :param source_range: Bytes of source data in the specified range. The length of this range
-         should match the ContentLength header and x-ms-range/Range destination range header.
-        :type source_range: str
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param range: The range of bytes to which the source range would be written. The range should
-         be 512 aligned and range-end is required.
-        :type range: str
-        :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
-         from the copy source. Default value is None.
-        :type source_content_md5: bytearray
-        :param source_contentcrc64: Specify the crc64 calculated for the range of bytes that must be
-         read from the copy source. Default value is None.
-        :type source_contentcrc64: bytearray
+        timeout: Optional[int] = None,
+        access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        container_acl: Optional[List[_models.SignedIdentifier]] = None,
+        **kwargs: Any
+    ) -> None:
+        """sets the permissions for the specified container. The permissions indicate whether blobs in a
+        container may be accessed publicly.
+
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param access: Specifies whether data in the container may be accessed publicly and the level
+         of access. Known values are: "container" and "blob". Default value is None.
+        :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
-         OAuth access token to copy source. Default value is None.
-        :type copy_source_authorization: str
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.blob.models.CpkInfo
-        :param cpk_scope_info: Parameter group. Default value is None.
-        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :param sequence_number_access_conditions: Parameter group. Default value is None.
-        :type sequence_number_access_conditions:
-         ~azure.storage.blob.models.SequenceNumberAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :param source_modified_access_conditions: Parameter group. Default value is None.
-        :type source_modified_access_conditions:
-         ~azure.storage.blob.models.SourceModifiedAccessConditions
-        :keyword comp: comp. Default value is "page". Note that overriding this default value may
-         result in unsupported behavior.
+        :param container_acl: the acls for the container. Default value is None.
+        :type container_acl: list[~azure.storage.blob.models.SignedIdentifier]
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
+         in unsupported behavior.
         :paramtype comp: str
-        :keyword page_write: Required. You may specify one of the following options:
-
-
-         * Update: Writes the bytes specified by the request body into the specified range. The Range
-         and Content-Length headers must match to perform the update.
-         * Clear: Clears the specified range and releases the space used in storage for that range. To
-         clear a range, set the Content-Length header to zero, and the Range header to a value that
-         indicates the range to clear, up to maximum blob size. Default value is "update". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        comp = kwargs.pop('comp', "page")  # type: str
-        page_write = kwargs.pop('page_write', "update")  # type: str
-
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        _encryption_scope = None
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
         _lease_id = None
-        _if_sequence_number_less_than_or_equal_to = None
-        _if_sequence_number_less_than = None
-        _if_sequence_number_equal_to = None
         _if_modified_since = None
         _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
-        _source_if_modified_since = None
-        _source_if_unmodified_since = None
-        _source_if_match = None
-        _source_if_none_match = None
-        if cpk_info is not None:
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
-        if cpk_scope_info is not None:
-            _encryption_scope = cpk_scope_info.encryption_scope
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if sequence_number_access_conditions is not None:
-            _if_sequence_number_less_than_or_equal_to = sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
-            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
-            _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
-        if source_modified_access_conditions is not None:
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
-            _source_if_match = source_modified_access_conditions.source_if_match
-            _source_if_none_match = source_modified_access_conditions.source_if_none_match
+        serialization_ctxt = {"xml": {"name": "SignedIdentifiers", "wrapped": True, "itemsName": "SignedIdentifier"}}
+        if container_acl is not None:
+            _content = self._serialize.body(
+                container_acl, "[SignedIdentifier]", is_xml=True, serialization_ctxt=serialization_ctxt
+            )
+        else:
+            _content = None
 
-        request = build_upload_pages_from_url_request(
+        request = build_set_access_policy_request(
             url=self._config.url,
-            comp=comp,
-            page_write=page_write,
-            version=self._config.version,
-            source_url=source_url,
-            source_range=source_range,
-            content_length=content_length,
-            range=range,
-            source_content_md5=source_content_md5,
-            source_contentcrc64=source_contentcrc64,
             timeout=timeout,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            encryption_scope=_encryption_scope,
             lease_id=_lease_id,
-            if_sequence_number_less_than_or_equal_to=_if_sequence_number_less_than_or_equal_to,
-            if_sequence_number_less_than=_if_sequence_number_less_than,
-            if_sequence_number_equal_to=_if_sequence_number_equal_to,
+            access=access,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
-            source_if_modified_since=_source_if_modified_since,
-            source_if_unmodified_since=_source_if_unmodified_since,
-            source_if_match=_source_if_match,
-            source_if_none_match=_source_if_none_match,
             request_id_parameter=request_id_parameter,
-            copy_source_authorization=copy_source_authorization,
-            template_url=self.upload_pages_from_url.metadata['url'],
+            restype=restype,
+            comp=comp,
+            content_type=content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.set_access_policy.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    set_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def restore(  # pylint: disable=inconsistent-return-statements
+        self,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        deleted_container_name: Optional[str] = None,
+        deleted_container_version: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
+        """Restores a previously-deleted container.
+
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param deleted_container_name: Optional.  Version 2019-12-12 and later.  Specifies the name of
+         the deleted container to restore. Default value is None.
+        :type deleted_container_name: str
+        :param deleted_container_version: Optional.  Version 2019-12-12 and later.  Specifies the
+         version of the deleted container to restore. Default value is None.
+        :type deleted_container_version: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        request = build_restore_request(
+            url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
+            deleted_container_name=deleted_container_name,
+            deleted_container_version=deleted_container_version,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.restore.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['Content-MD5']=self._deserialize('bytearray', response.headers.get('Content-MD5'))
-        response_headers['x-ms-content-crc64']=self._deserialize('bytearray', response.headers.get('x-ms-content-crc64'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-request-server-encrypted']=self._deserialize('bool', response.headers.get('x-ms-request-server-encrypted'))
-        response_headers['x-ms-encryption-key-sha256']=self._deserialize('str', response.headers.get('x-ms-encryption-key-sha256'))
-        response_headers['x-ms-encryption-scope']=self._deserialize('str', response.headers.get('x-ms-encryption-scope'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
 
+    restore.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def rename(  # pylint: disable=inconsistent-return-statements
+        self,
+        source_container_name: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        source_lease_id: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
+        """Renames an existing container.
+
+        :param source_container_name: Required.  Specifies the name of the container to rename.
+         Required.
+        :type source_container_name: str
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param source_lease_id: A lease ID for the source path. If specified, the source path must have
+         an active lease and the lease ID must match. Default value is None.
+        :type source_lease_id: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "rename". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        request = build_rename_request(
+            url=self._config.url,
+            source_container_name=source_container_name,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
+            source_lease_id=source_lease_id,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.rename.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload_pages_from_url.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
+    rename.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def submit_batch(
+        self,
+        content_length: int,
+        body: IO,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> Iterator[bytes]:
+        """The Batch operation allows multiple API calls to be embedded into a single HTTP request.
+
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
+        :type body: IO
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "batch". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+        multipart_content_type = kwargs.pop(
+            "multipart_content_type", _headers.pop("Content-Type", "application/xml")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
+
+        _content = body
+
+        request = build_submit_batch_request(
+            url=self._config.url,
+            content_length=content_length,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
+            restype=restype,
+            comp=comp,
+            multipart_content_type=multipart_content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.submit_batch.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [202]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
+        deserialized = response.stream_download(self._client._pipeline)
+
+        if cls:
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
+
+    submit_batch.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def get_page_ranges(
+    def filter_blobs(
         self,
-        snapshot=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        range=None,  # type: Optional[str]
-        request_id_parameter=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.PageList"
-        """The Get Page Ranges operation returns the list of valid page ranges for a page blob or snapshot
-        of a page blob.
-
-        :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
-         see :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
-         a Snapshot of a Blob.</a>`. Default value is None.
-        :type snapshot: str
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        where: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
+        **kwargs: Any
+    ) -> _models.FilterBlobSegment:
+        """The Filter Blobs operation enables callers to list blobs in a container whose tags match a
+        given search expression.  Filter blobs searches within the given container.
+
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param range: Return only the bytes of the blob in the specified range. Default value is None.
-        :type range: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
+        :param where: Filters the results to return only to return only blobs whose tags match the
+         specified expression. Default value is None.
+        :type where: str
         :param marker: A string value that identifies the portion of the list of containers to be
          returned with the next listing operation. The operation returns the NextMarker value within the
          response body if the listing operation did not return all containers remaining to be listed
          with the current page. The NextMarker value can be used as the value for the marker parameter
          in a subsequent call to request the next page of list items. The marker value is opaque to the
          client. Default value is None.
         :type marker: str
         :param maxresults: Specifies the maximum number of containers to return. If the request does
          not specify maxresults, or specifies a value greater than 5000, the server will return up to
          5000 items. Note that if the listing operation crosses a partition boundary, then the service
          will return a continuation token for retrieving the remainder of the results. For this reason,
          it is possible that the service will return fewer results than specified by maxresults, or than
          the default of 5000. Default value is None.
         :type maxresults: int
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "pagelist". Note that overriding this default value may
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.FilterBlobsIncludeItem]
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "blobs". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: PageList, or the result of cls(response)
-        :rtype: ~azure.storage.blob.models.PageList
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: FilterBlobSegment or the result of cls(response)
+        :rtype: ~azure.storage.blob.models.FilterBlobSegment
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.PageList"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "pagelist")  # type: str
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        _lease_id = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.FilterBlobSegment]
 
-        request = build_get_page_ranges_request(
+        request = build_filter_blobs_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            snapshot=snapshot,
             timeout=timeout,
-            range=range,
-            lease_id=_lease_id,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
+            where=where,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.get_page_ranges.metadata['url'],
+            include=include,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.filter_blobs.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['x-ms-blob-content-length']=self._deserialize('long', response.headers.get('x-ms-blob-content-length'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('PageList', pipeline_response)
+        deserialized = self._deserialize("FilterBlobSegment", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_page_ranges.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    filter_blobs.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def get_page_ranges_diff(
+    def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        snapshot=None,  # type: Optional[str]
-        timeout=None,  # type: Optional[int]
-        prevsnapshot=None,  # type: Optional[str]
-        prev_snapshot_url=None,  # type: Optional[str]
-        range=None,  # type: Optional[str]
-        request_id_parameter=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.PageList"
-        """The Get Page Ranges Diff operation returns the list of valid page ranges for a page blob that
-        were changed between target blob and previous snapshot.
-
-        :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
-         see :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
-         a Snapshot of a Blob.</a>`. Default value is None.
-        :type snapshot: str
+        timeout: Optional[int] = None,
+        duration: Optional[int] = None,
+        proposed_lease_id: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
+        can be 15 to 60 seconds, or can be infinite.
+
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param prevsnapshot: Optional in version 2015-07-08 and newer. The prevsnapshot parameter is a
-         DateTime value that specifies that the response will contain only pages that were changed
-         between target blob and previous snapshot. Changed pages include both updated and cleared
-         pages. The target blob may be a snapshot, as long as the snapshot specified by prevsnapshot is
-         the older of the two. Note that incremental snapshots are currently supported only for blobs
-         created on or after January 1, 2016. Default value is None.
-        :type prevsnapshot: str
-        :param prev_snapshot_url: Optional. This header is only supported in service versions
-         2019-04-19 and after and specifies the URL of a previous snapshot of the target blob. The
-         response will only contain pages that were changed between the target blob and its previous
-         snapshot. Default value is None.
-        :type prev_snapshot_url: str
-        :param range: Return only the bytes of the blob in the specified range. Default value is None.
-        :type range: str
+        :param duration: Specifies the duration of the lease, in seconds, or negative one (-1) for a
+         lease that never expires. A non-infinite lease can be between 15 and 60 seconds. A lease
+         duration cannot be changed using renew or change. Default value is None.
+        :type duration: int
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Default value is None.
+        :type proposed_lease_id: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param marker: A string value that identifies the portion of the list of containers to be
-         returned with the next listing operation. The operation returns the NextMarker value within the
-         response body if the listing operation did not return all containers remaining to be listed
-         with the current page. The NextMarker value can be used as the value for the marker parameter
-         in a subsequent call to request the next page of list items. The marker value is opaque to the
-         client. Default value is None.
-        :type marker: str
-        :param maxresults: Specifies the maximum number of containers to return. If the request does
-         not specify maxresults, or specifies a value greater than 5000, the server will return up to
-         5000 items. Note that if the listing operation crosses a partition boundary, then the service
-         will return a continuation token for retrieving the remainder of the results. For this reason,
-         it is possible that the service will return fewer results than specified by maxresults, or than
-         the default of 5000. Default value is None.
-        :type maxresults: int
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "pagelist". Note that overriding this default value may
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword action: Describes what lease action to take. Default value is "acquire". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: PageList, or the result of cls(response)
-        :rtype: ~azure.storage.blob.models.PageList
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.PageList"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "pagelist")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
 
-        request = build_get_page_ranges_diff_request(
+        request = build_acquire_lease_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            snapshot=snapshot,
             timeout=timeout,
-            prevsnapshot=prevsnapshot,
-            prev_snapshot_url=prev_snapshot_url,
-            range=range,
-            lease_id=_lease_id,
+            duration=duration,
+            proposed_lease_id=proposed_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            marker=marker,
-            maxresults=maxresults,
-            template_url=self.get_page_ranges_diff.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.acquire_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['x-ms-blob-content-length']=self._deserialize('long', response.headers.get('x-ms-blob-content-length'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
-        deserialized = self._deserialize('PageList', pipeline_response)
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
-
-    get_page_ranges_diff.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
+            return cls(pipeline_response, None, response_headers)
 
+    acquire_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def resize(  # pylint: disable=inconsistent-return-statements
+    def release_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        blob_content_length,  # type: int
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        cpk_info=None,  # type: Optional["_models.CpkInfo"]
-        cpk_scope_info=None,  # type: Optional["_models.CpkScopeInfo"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """Resize the Blob.
-
-        :param blob_content_length: This header specifies the maximum size for the page blob, up to 1
-         TB. The page blob size must be aligned to a 512-byte boundary.
-        :type blob_content_length: long
+        lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
+        can be 15 to 60 seconds, or can be infinite.
+
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.blob.models.CpkInfo
-        :param cpk_scope_info: Parameter group. Default value is None.
-        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword action: Describes what lease action to take. Default value is "release". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "properties")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        _lease_id = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        _encryption_scope = None
         _if_modified_since = None
         _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-        if cpk_info is not None:
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
-            _encryption_algorithm = cpk_info.encryption_algorithm
-        if cpk_scope_info is not None:
-            _encryption_scope = cpk_scope_info.encryption_scope
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
 
-        request = build_resize_request(
+        request = build_release_lease_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            blob_content_length=blob_content_length,
+            lease_id=lease_id,
             timeout=timeout,
-            lease_id=_lease_id,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            encryption_scope=_encryption_scope,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.resize.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.release_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    resize.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    release_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def update_sequence_number(  # pylint: disable=inconsistent-return-statements
+    def renew_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        sequence_number_action,  # type: Union[str, "_models.SequenceNumberActionType"]
-        timeout=None,  # type: Optional[int]
-        blob_sequence_number=0,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        lease_access_conditions=None,  # type: Optional["_models.LeaseAccessConditions"]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """Update the sequence number of the blob.
-
-        :param sequence_number_action: Required if the x-ms-blob-sequence-number header is set for the
-         request. This property applies to page blobs only. This property indicates how the service
-         should modify the blob's sequence number.
-        :type sequence_number_action: str or ~azure.storage.blob.models.SequenceNumberActionType
+        lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
+        can be 15 to 60 seconds, or can be infinite.
+
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param blob_sequence_number: Set for page blobs only. The sequence number is a user-controlled
-         value that you can use to track requests. The value of the sequence number must be between 0
-         and 2^63 - 1. Default value is 0.
-        :type blob_sequence_number: long
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword action: Describes what lease action to take. Default value is "renew". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
 
-        comp = kwargs.pop('comp', "properties")  # type: str
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        _lease_id = None
         _if_modified_since = None
         _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
 
-        request = build_update_sequence_number_request(
+        request = build_renew_lease_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            sequence_number_action=sequence_number_action,
+            lease_id=lease_id,
             timeout=timeout,
-            lease_id=_lease_id,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
-            blob_sequence_number=blob_sequence_number,
             request_id_parameter=request_id_parameter,
-            template_url=self.update_sequence_number.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.renew_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-blob-sequence-number']=self._deserialize('long', response.headers.get('x-ms-blob-sequence-number'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    update_sequence_number.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
-
+    renew_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
 
     @distributed_trace
-    def copy_incremental(  # pylint: disable=inconsistent-return-statements
+    def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        copy_source,  # type: str
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        modified_access_conditions=None,  # type: Optional["_models.ModifiedAccessConditions"]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
-        """The Copy Incremental operation copies a snapshot of the source page blob to a destination page
-        blob. The snapshot is copied such that only the differential changes between the previously
-        copied snapshot are transferred to the destination. The copied snapshots are complete copies of
-        the original snapshot and can be read or copied from as usual. This API is supported since REST
-        version 2016-05-31.
-
-        :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
-         up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
-         would appear in a request URI. The source blob must either be public or must be authenticated
-         via a shared access signature.
-        :type copy_source: str
+        timeout: Optional[int] = None,
+        break_period: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
+        can be 15 to 60 seconds, or can be infinite.
+
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param break_period: For a break operation, proposed duration the lease should continue before
+         it is broken, in seconds, between 0 and 60. This break period is only used if it is shorter
+         than the time remaining on the lease. If longer, the time remaining on the lease is used. A new
+         lease will not be available before the break period has expired, but the lease may be held for
+         longer than the break period. If this header does not appear with a break operation, a
+         fixed-duration lease breaks after the remaining lease period elapses, and an infinite lease
+         breaks immediately. Default value is None.
+        :type break_period: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param modified_access_conditions: Parameter group. Default value is None.
         :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "incrementalcopy". Note that overriding this default
-         value may result in unsupported behavior.
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+         result in unsupported behavior.
         :paramtype comp: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword action: Describes what lease action to take. Default value is "break". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "incrementalcopy")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _if_modified_since = None
         _if_unmodified_since = None
-        _if_match = None
-        _if_none_match = None
-        _if_tags = None
         if modified_access_conditions is not None:
             _if_modified_since = modified_access_conditions.if_modified_since
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-            _if_match = modified_access_conditions.if_match
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_tags = modified_access_conditions.if_tags
 
-        request = build_copy_incremental_request(
+        request = build_break_lease_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
-            copy_source=copy_source,
             timeout=timeout,
+            break_period=break_period,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            template_url=self.copy_incremental.metadata['url'],
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.break_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
-        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-copy-id']=self._deserialize('str', response.headers.get('x-ms-copy-id'))
-        response_headers['x-ms-copy-status']=self._deserialize('str', response.headers.get('x-ms-copy-status'))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
 
+    break_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def change_lease(  # pylint: disable=inconsistent-return-statements
+        self,
+        lease_id: str,
+        proposed_lease_id: str,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
+        can be 15 to 60 seconds, or can be infinite.
+
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Required.
+        :type proposed_lease_id: str
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword action: Describes what lease action to take. Default value is "change". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        _if_modified_since = None
+        _if_unmodified_since = None
+        if modified_access_conditions is not None:
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+
+        request = build_change_lease_request(
+            url=self._config.url,
+            lease_id=lease_id,
+            proposed_lease_id=proposed_lease_id,
+            timeout=timeout,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            request_id_parameter=request_id_parameter,
+            comp=comp,
+            restype=restype,
+            action=action,
+            version=self._config.version,
+            template_url=self.change_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    copy_incremental.metadata = {'url': "{url}/{containerName}/{blob}"}  # type: ignore
+    change_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def list_blob_flat_segment(
+        self,
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.ListBlobsFlatSegmentResponse:
+        """[Update] The List Blobs operation returns a list of the blobs under the specified container.
+
+        :param prefix: Filters the results to return only containers whose name begins with the
+         specified prefix. Default value is None.
+        :type prefix: str
+        :param marker: A string value that identifies the portion of the list of containers to be
+         returned with the next listing operation. The operation returns the NextMarker value within the
+         response body if the listing operation did not return all containers remaining to be listed
+         with the current page. The NextMarker value can be used as the value for the marker parameter
+         in a subsequent call to request the next page of list items. The marker value is opaque to the
+         client. Default value is None.
+        :type marker: str
+        :param maxresults: Specifies the maximum number of containers to return. If the request does
+         not specify maxresults, or specifies a value greater than 5000, the server will return up to
+         5000 items. Note that if the listing operation crosses a partition boundary, then the service
+         will return a continuation token for retrieving the remainder of the results. For this reason,
+         it is possible that the service will return fewer results than specified by maxresults, or than
+         the default of 5000. Default value is None.
+        :type maxresults: int
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.ListBlobsIncludeItem]
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "list". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: ListBlobsFlatSegmentResponse or the result of cls(response)
+        :rtype: ~azure.storage.blob.models.ListBlobsFlatSegmentResponse
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsFlatSegmentResponse]
+
+        request = build_list_blob_flat_segment_request(
+            url=self._config.url,
+            prefix=prefix,
+            marker=marker,
+            maxresults=maxresults,
+            include=include,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_blob_flat_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        deserialized = self._deserialize("ListBlobsFlatSegmentResponse", pipeline_response)
+
+        if cls:
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
+
+    list_blob_flat_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def list_blob_hierarchy_segment(
+        self,
+        delimiter: str,
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.ListBlobsHierarchySegmentResponse:
+        """[Update] The List Blobs operation returns a list of the blobs under the specified container.
+
+        :param delimiter: When the request includes this parameter, the operation returns a BlobPrefix
+         element in the response body that acts as a placeholder for all blobs whose names begin with
+         the same substring up to the appearance of the delimiter character. The delimiter may be a
+         single character or a string. Required.
+        :type delimiter: str
+        :param prefix: Filters the results to return only containers whose name begins with the
+         specified prefix. Default value is None.
+        :type prefix: str
+        :param marker: A string value that identifies the portion of the list of containers to be
+         returned with the next listing operation. The operation returns the NextMarker value within the
+         response body if the listing operation did not return all containers remaining to be listed
+         with the current page. The NextMarker value can be used as the value for the marker parameter
+         in a subsequent call to request the next page of list items. The marker value is opaque to the
+         client. Default value is None.
+        :type marker: str
+        :param maxresults: Specifies the maximum number of containers to return. If the request does
+         not specify maxresults, or specifies a value greater than 5000, the server will return up to
+         5000 items. Note that if the listing operation crosses a partition boundary, then the service
+         will return a continuation token for retrieving the remainder of the results. For this reason,
+         it is possible that the service will return fewer results than specified by maxresults, or than
+         the default of 5000. Default value is None.
+        :type maxresults: int
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.ListBlobsIncludeItem]
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :keyword restype: restype. Default value is "container". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "list". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: ListBlobsHierarchySegmentResponse or the result of cls(response)
+        :rtype: ~azure.storage.blob.models.ListBlobsHierarchySegmentResponse
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsHierarchySegmentResponse]
+
+        request = build_list_blob_hierarchy_segment_request(
+            url=self._config.url,
+            delimiter=delimiter,
+            prefix=prefix,
+            marker=marker,
+            maxresults=maxresults,
+            include=include,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_blob_hierarchy_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        deserialized = self._deserialize("ListBlobsHierarchySegmentResponse", pipeline_response)
+
+        if cls:
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
+
+    list_blob_hierarchy_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+
+    @distributed_trace
+    def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
+        """Returns the sku name and account kind.
+
+        :keyword restype: restype. Default value is "account". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        request = build_get_account_info_request(
+            url=self._config.url,
+            restype=restype,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)  # type: ignore
+
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
 
+    get_account_info.metadata = {"url": "{url}/{containerName}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_service_operations.py`

 * *Files 17% similar despite different names*

```diff
@@ -2,433 +2,381 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-from typing import TYPE_CHECKING
+from typing import Any, Callable, Dict, IO, Iterator, List, Optional, TypeVar, Union
 
-from msrest import Serializer
-
-from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
+from azure.core.exceptions import (
+    ClientAuthenticationError,
+    HttpResponseError,
+    ResourceExistsError,
+    ResourceNotFoundError,
+    map_error,
+)
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
+from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
+from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
-if TYPE_CHECKING:
-    # pylint: disable=unused-import,ungrouped-imports
-    from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union
-    T = TypeVar('T')
-    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
+T = TypeVar("T")
+ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
-# fmt: off
+
 
 def build_set_properties_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "service")  # type: str
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str, *, content: Any, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="PUT",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_get_properties_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "service")  # type: str
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_get_statistics_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "service")  # type: str
-    comp = kwargs.pop('comp', "stats")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "stats"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_list_containers_segment_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "list")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    prefix = kwargs.pop('prefix', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
-    include = kwargs.pop('include', None)  # type: Optional[List[Union[str, "_models.ListContainersIncludeType"]]]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    prefix: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.ListContainersIncludeType"]]] = None,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if prefix is not None:
-        _query_parameters['prefix'] = _SERIALIZER.query("prefix", prefix, 'str')
+        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
     if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
     if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
     if include is not None:
-        _query_parameters['include'] = _SERIALIZER.query("include", include, '[str]', div=',')
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_get_user_delegation_key_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "service")  # type: str
-    comp = kwargs.pop('comp', "userdelegationkey")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_type = kwargs.pop('content_type', None)  # type: Optional[str]
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str, *, content: Any, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "userdelegationkey"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     if content_type is not None:
-        _header_parameters['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
-    return HttpRequest(
-        method="POST",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
-
-
-def build_get_account_info_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    restype = kwargs.pop('restype', "account")  # type: str
-    comp = kwargs.pop('comp', "properties")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
 
-    accept = "application/xml"
+def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
+
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['restype'] = _SERIALIZER.query("restype", restype, 'str')
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
-
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_submit_batch_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    multipart_content_type = kwargs.pop('multipart_content_type')  # type: str
-    comp = kwargs.pop('comp', "batch")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    content_length = kwargs.pop('content_length')  # type: int
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
+    url: str,
+    *,
+    content_length: int,
+    content: IO,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+    multipart_content_type = kwargs.pop(
+        "multipart_content_type", _headers.pop("Content-Type", None)
+    )  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['Content-Length'] = _SERIALIZER.header("content_length", content_length, 'long')
-    _header_parameters['Content-Type'] = _SERIALIZER.header("multipart_content_type", multipart_content_type, 'str')
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if multipart_content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("multipart_content_type", multipart_content_type, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(
-        method="POST",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
+    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
 def build_filter_blobs_request(
-    url,  # type: str
-    **kwargs  # type: Any
-):
-    # type: (...) -> HttpRequest
-    comp = kwargs.pop('comp', "blobs")  # type: str
-    version = kwargs.pop('version', "2021-04-10")  # type: str
-    timeout = kwargs.pop('timeout', None)  # type: Optional[int]
-    request_id_parameter = kwargs.pop('request_id_parameter', None)  # type: Optional[str]
-    where = kwargs.pop('where', None)  # type: Optional[str]
-    marker = kwargs.pop('marker', None)  # type: Optional[str]
-    maxresults = kwargs.pop('maxresults', None)  # type: Optional[int]
+    url: str,
+    *,
+    timeout: Optional[int] = None,
+    request_id_parameter: Optional[str] = None,
+    where: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
+    include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    accept = _headers.pop("Accept", "application/xml")
 
-    accept = "application/xml"
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, 'str', skip_quote=True),
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _query_parameters = kwargs.pop("params", {})  # type: Dict[str, Any]
-    _query_parameters['comp'] = _SERIALIZER.query("comp", comp, 'str')
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
-        _query_parameters['timeout'] = _SERIALIZER.query("timeout", timeout, 'int', minimum=0)
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
     if where is not None:
-        _query_parameters['where'] = _SERIALIZER.query("where", where, 'str')
+        _params["where"] = _SERIALIZER.query("where", where, "str")
     if marker is not None:
-        _query_parameters['marker'] = _SERIALIZER.query("marker", marker, 'str')
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
     if maxresults is not None:
-        _query_parameters['maxresults'] = _SERIALIZER.query("maxresults", maxresults, 'int', minimum=1)
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
+    if include is not None:
+        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
 
     # Construct headers
-    _header_parameters = kwargs.pop("headers", {})  # type: Dict[str, Any]
-    _header_parameters['x-ms-version'] = _SERIALIZER.header("version", version, 'str')
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
-        _header_parameters['x-ms-client-request-id'] = _SERIALIZER.header("request_id_parameter", request_id_parameter, 'str')
-    _header_parameters['Accept'] = _SERIALIZER.header("accept", accept, 'str')
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
-    return HttpRequest(
-        method="GET",
-        url=_url,
-        params=_query_parameters,
-        headers=_header_parameters,
-        **kwargs
-    )
 
-# fmt: on
-class ServiceOperations(object):
+class ServiceOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.blob.AzureBlobStorage`'s
         :attr:`service` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
-        args = list(args)
-        self._client = args.pop(0) if args else kwargs.pop("client")
-        self._config = args.pop(0) if args else kwargs.pop("config")
-        self._serialize = args.pop(0) if args else kwargs.pop("serializer")
-        self._deserialize = args.pop(0) if args else kwargs.pop("deserializer")
-
+        input_args = list(args)
+        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
+        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
+        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
+        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def set_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        storage_service_properties,  # type: "_models.StorageServiceProperties"
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+        storage_service_properties: _models.StorageServiceProperties,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
         """Sets properties for a storage account's Blob service endpoint, including properties for Storage
         Analytics and CORS (Cross-Origin Resource Sharing) rules.
 
-        :param storage_service_properties: The StorageService properties.
+        :param storage_service_properties: The StorageService properties. Required.
         :type storage_service_properties: ~azure.storage.blob.models.StorageServiceProperties
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -438,76 +386,74 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        _content = self._serialize.body(storage_service_properties, 'StorageServiceProperties', is_xml=True)
+        _content = self._serialize.body(storage_service_properties, "StorageServiceProperties", is_xml=True)
 
         request = build_set_properties_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
-            version=self._config.version,
             content_type=content_type,
+            version=self._config.version,
             content=_content,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.set_properties.metadata['url'],
+            template_url=self.set_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_properties.metadata = {'url': "{url}"}  # type: ignore
-
+    set_properties.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
     def get_properties(
-        self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.StorageServiceProperties"
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> _models.StorageServiceProperties:
         """gets the properties of a storage account's Blob service, including properties for Storage
         Analytics and CORS (Cross-Origin Resource Sharing) rules.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
@@ -519,75 +465,73 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: StorageServiceProperties, or the result of cls(response)
+        :return: StorageServiceProperties or the result of cls(response)
         :rtype: ~azure.storage.blob.models.StorageServiceProperties
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.StorageServiceProperties"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.StorageServiceProperties]
 
-        
         request = build_get_properties_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.get_properties.metadata['url'],
+            template_url=self.get_properties.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
-        deserialized = self._deserialize('StorageServiceProperties', pipeline_response)
+        deserialized = self._deserialize("StorageServiceProperties", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_properties.metadata = {'url': "{url}"}  # type: ignore
-
+    get_properties.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
     def get_statistics(
-        self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.StorageServiceStats"
+        self, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> _models.StorageServiceStats:
         """Retrieves statistics related to replication for the Blob service. It is only available on the
         secondary location endpoint when read-access geo-redundant replication is enabled for the
         storage account.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -600,80 +544,81 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "stats". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: StorageServiceStats, or the result of cls(response)
+        :return: StorageServiceStats or the result of cls(response)
         :rtype: ~azure.storage.blob.models.StorageServiceStats
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.StorageServiceStats"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "stats")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "stats"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.StorageServiceStats]
 
-        
         request = build_get_statistics_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.get_statistics.metadata['url'],
+            template_url=self.get_statistics.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('StorageServiceStats', pipeline_response)
+        deserialized = self._deserialize("StorageServiceStats", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_statistics.metadata = {'url': "{url}"}  # type: ignore
-
+    get_statistics.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
     def list_containers_segment(
         self,
-        prefix=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        include=None,  # type: Optional[List[Union[str, "_models.ListContainersIncludeType"]]]
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.ListContainersSegmentResponse"
+        prefix: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.ListContainersIncludeType"]]] = None,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.ListContainersSegmentResponse:
         """The List Containers Segment operation returns a list of the containers under the specified
         account.
 
         :param prefix: Filters the results to return only containers whose name begins with the
          specified prefix. Default value is None.
         :type prefix: str
         :param marker: A string value that identifies the portion of the list of containers to be
@@ -702,82 +647,83 @@
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "list". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListContainersSegmentResponse, or the result of cls(response)
+        :return: ListContainersSegmentResponse or the result of cls(response)
         :rtype: ~azure.storage.blob.models.ListContainersSegmentResponse
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.ListContainersSegmentResponse"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "list")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListContainersSegmentResponse]
 
-        
         request = build_list_containers_segment_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             prefix=prefix,
             marker=marker,
             maxresults=maxresults,
             include=include,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.list_containers_segment.metadata['url'],
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_containers_segment.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
-        deserialized = self._deserialize('ListContainersSegmentResponse', pipeline_response)
+        deserialized = self._deserialize("ListContainersSegmentResponse", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    list_containers_segment.metadata = {'url': "{url}"}  # type: ignore
-
+    list_containers_segment.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
     def get_user_delegation_key(
         self,
-        key_info,  # type: "_models.KeyInfo"
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.UserDelegationKey"
+        key_info: _models.KeyInfo,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.UserDelegationKey:
         """Retrieves a user delegation key for the Blob service. This is only a valid operation when using
         bearer token authentication.
 
-        :param key_info: Key information.
+        :param key_info: Key information. Required.
         :type key_info: ~azure.storage.blob.models.KeyInfo
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
@@ -787,238 +733,237 @@
         :keyword restype: restype. Default value is "service". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "userdelegationkey". Note that overriding this default
          value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: UserDelegationKey, or the result of cls(response)
+        :return: UserDelegationKey or the result of cls(response)
         :rtype: ~azure.storage.blob.models.UserDelegationKey
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.UserDelegationKey"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
-
-        restype = kwargs.pop('restype', "service")  # type: str
-        comp = kwargs.pop('comp', "userdelegationkey")  # type: str
-        content_type = kwargs.pop('content_type', "application/xml")  # type: Optional[str]
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        _content = self._serialize.body(key_info, 'KeyInfo', is_xml=True)
+        restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "userdelegationkey"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.UserDelegationKey]
+
+        _content = self._serialize.body(key_info, "KeyInfo", is_xml=True)
 
         request = build_get_user_delegation_key_request(
             url=self._config.url,
+            timeout=timeout,
+            request_id_parameter=request_id_parameter,
             restype=restype,
             comp=comp,
-            version=self._config.version,
             content_type=content_type,
+            version=self._config.version,
             content=_content,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            template_url=self.get_user_delegation_key.metadata['url'],
+            template_url=self.get_user_delegation_key.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('UserDelegationKey', pipeline_response)
+        deserialized = self._deserialize("UserDelegationKey", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_user_delegation_key.metadata = {'url': "{url}"}  # type: ignore
-
+    get_user_delegation_key.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
-    def get_account_info(  # pylint: disable=inconsistent-return-statements
-        self,
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> None
+    def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
         """Returns the sku name and account kind.
 
         :keyword restype: restype. Default value is "account". Note that overriding this default value
          may result in unsupported behavior.
         :paramtype restype: str
         :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None, or the result of cls(response)
+        :return: None or the result of cls(response)
         :rtype: None
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[None]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop('restype', "account")  # type: str
-        comp = kwargs.pop('comp', "properties")  # type: str
+        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        
         request = build_get_account_info_request(
             url=self._config.url,
             restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata['url'],
+            template_url=self.get_account_info.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
-        response_headers['x-ms-sku-name']=self._deserialize('str', response.headers.get('x-ms-sku-name'))
-        response_headers['x-ms-account-kind']=self._deserialize('str', response.headers.get('x-ms-account-kind'))
-        response_headers['x-ms-is-hns-enabled']=self._deserialize('bool', response.headers.get('x-ms-is-hns-enabled'))
-
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
+        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
+        response_headers["x-ms-is-hns-enabled"] = self._deserialize("bool", response.headers.get("x-ms-is-hns-enabled"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {'url': "{url}"}  # type: ignore
-
+    get_account_info.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
     def submit_batch(
         self,
-        content_length,  # type: int
-        body,  # type: IO
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> IO
+        content_length: int,
+        body: IO,
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
+    ) -> Iterator[bytes]:
         """The Batch operation allows multiple API calls to be embedded into a single HTTP request.
 
-        :param content_length: The length of the request.
-        :type content_length: long
-        :param body: Initial data.
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
         :type body: IO
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword multipart_content_type: Required. The value of this header must be multipart/mixed
-         with a batch boundary. Example header value: multipart/mixed; boundary=batch_:code:`<GUID>`.
-        :paramtype multipart_content_type: str
         :keyword comp: comp. Default value is "batch". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: IO, or the result of cls(response)
-        :rtype: IO
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType[IO]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        multipart_content_type = kwargs.pop('multipart_content_type')  # type: str
-        comp = kwargs.pop('comp', "batch")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
+        multipart_content_type = kwargs.pop(
+            "multipart_content_type", _headers.pop("Content-Type", "application/xml")
+        )  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
 
-        _content = self._serialize.body(body, 'IO')
+        _content = body
 
         request = build_submit_batch_request(
             url=self._config.url,
-            multipart_content_type=multipart_content_type,
-            comp=comp,
-            version=self._config.version,
-            content=_content,
             content_length=content_length,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            template_url=self.submit_batch.metadata['url'],
+            comp=comp,
+            multipart_content_type=multipart_content_type,
+            version=self._config.version,
+            content=_content,
+            template_url=self.submit_batch.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=True,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['Content-Type']=self._deserialize('str', response.headers.get('Content-Type'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    submit_batch.metadata = {'url': "{url}"}  # type: ignore
-
+    submit_batch.metadata = {"url": "{url}"}  # type: ignore
 
     @distributed_trace
     def filter_blobs(
         self,
-        timeout=None,  # type: Optional[int]
-        request_id_parameter=None,  # type: Optional[str]
-        where=None,  # type: Optional[str]
-        marker=None,  # type: Optional[str]
-        maxresults=None,  # type: Optional[int]
-        **kwargs  # type: Any
-    ):
-        # type: (...) -> "_models.FilterBlobSegment"
+        timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
+        where: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
+        **kwargs: Any
+    ) -> _models.FilterBlobSegment:
         """The Filter Blobs operation enables callers to list blobs across all containers whose tags match
         a given search expression.  Filter blobs searches across all containers within a storage
         account but can be scoped within the expression to a single container.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
@@ -1041,65 +986,71 @@
         :param maxresults: Specifies the maximum number of containers to return. If the request does
          not specify maxresults, or specifies a value greater than 5000, the server will return up to
          5000 items. Note that if the listing operation crosses a partition boundary, then the service
          will return a continuation token for retrieving the remainder of the results. For this reason,
          it is possible that the service will return fewer results than specified by maxresults, or than
          the default of 5000. Default value is None.
         :type maxresults: int
+        :param include: Include this parameter to specify one or more datasets to include in the
+         response. Default value is None.
+        :type include: list[str or ~azure.storage.blob.models.FilterBlobsIncludeItem]
         :keyword comp: comp. Default value is "blobs". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: FilterBlobSegment, or the result of cls(response)
+        :return: FilterBlobSegment or the result of cls(response)
         :rtype: ~azure.storage.blob.models.FilterBlobSegment
-        :raises: ~azure.core.exceptions.HttpResponseError
+        :raises ~azure.core.exceptions.HttpResponseError:
         """
-        cls = kwargs.pop('cls', None)  # type: ClsType["_models.FilterBlobSegment"]
-        error_map = {
-            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
-        }
-        error_map.update(kwargs.pop('error_map', {}))
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop('comp', "blobs")  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.FilterBlobSegment]
 
-        
         request = build_filter_blobs_request(
             url=self._config.url,
-            comp=comp,
-            version=self._config.version,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
             where=where,
             marker=marker,
             maxresults=maxresults,
-            template_url=self.filter_blobs.metadata['url'],
+            include=include,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.filter_blobs.metadata["url"],
+            headers=_headers,
+            params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
-            request,
-            stream=False,
-            **kwargs
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers['x-ms-client-request-id']=self._deserialize('str', response.headers.get('x-ms-client-request-id'))
-        response_headers['x-ms-request-id']=self._deserialize('str', response.headers.get('x-ms-request-id'))
-        response_headers['x-ms-version']=self._deserialize('str', response.headers.get('x-ms-version'))
-        response_headers['Date']=self._deserialize('rfc-1123', response.headers.get('Date'))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize('FilterBlobSegment', pipeline_response)
+        deserialized = self._deserialize("FilterBlobSegment", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    filter_blobs.metadata = {'url': "{url}"}  # type: ignore
-
+    filter_blobs.metadata = {"url": "{url}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_lease.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_list_blobs_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_list_blobs_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_quick_query_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_quick_query_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_serialize.py`

 * *Files 1% similar despite different names*

```diff
@@ -46,15 +46,16 @@
     '2020-04-08',
     '2020-06-12',
     '2020-08-04',
     '2020-10-02',
     '2020-12-06',
     '2021-02-12',
     '2021-04-10',
-    '2021-06-08'
+    '2021-06-08',
+    '2021-08-06'
 ]
 
 
 def _get_match_headers(kwargs, match_param, etag_param):
     # type: (Dict[str, Any], str, str) -> Tuple(Dict[str, Any], Optional[str], Optional[str])
     if_match = None
     if_none_match = None
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/avro_io.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/avro_io_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/datafile.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/datafile_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/schema.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/schema.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,52 +21,51 @@
 
 from azure.core.configuration import Configuration
 from azure.core.credentials import AzureSasCredential
 from azure.core.exceptions import HttpResponseError
 from azure.core.pipeline import Pipeline
 from azure.core.pipeline.transport import RequestsTransport, HttpTransport
 from azure.core.pipeline.policies import (
-    AzureSasCredentialPolicy,
+    RedirectPolicy,
     ContentDecodePolicy,
+    BearerTokenCredentialPolicy,
+    ProxyPolicy,
     DistributedTracingPolicy,
     HttpLoggingPolicy,
-    RedirectPolicy,
-    ProxyPolicy,
     UserAgentPolicy,
+    AzureSasCredentialPolicy
 )
 
-from .constants import CONNECTION_TIMEOUT, READ_TIMEOUT, SERVICE_HOST_BASE
+from .constants import STORAGE_OAUTH_SCOPE, SERVICE_HOST_BASE, CONNECTION_TIMEOUT, READ_TIMEOUT
 from .models import LocationMode
 from .authentication import SharedKeyCredentialPolicy
 from .shared_access_signature import QueryStringConstants
 from .request_handlers import serialize_batch_body, _get_batch_request_delimiter
 from .policies import (
-    ExponentialRetry,
-    StorageBearerTokenCredentialPolicy,
-    StorageContentValidation,
     StorageHeadersPolicy,
-    StorageHosts,
-    StorageLoggingPolicy,
+    StorageContentValidation,
     StorageRequestHook,
     StorageResponseHook,
+    StorageLoggingPolicy,
+    StorageHosts,
     QueueMessagePolicy,
+    ExponentialRetry,
 )
 from .._version import VERSION
 from .response_handlers import process_storage_error, PartialBatchErrorException
 
 
 _LOGGER = logging.getLogger(__name__)
 _SERVICE_PARAMS = {
     "blob": {"primary": "BLOBENDPOINT", "secondary": "BLOBSECONDARYENDPOINT"},
     "queue": {"primary": "QUEUEENDPOINT", "secondary": "QUEUESECONDARYENDPOINT"},
     "file": {"primary": "FILEENDPOINT", "secondary": "FILESECONDARYENDPOINT"},
     "dfs": {"primary": "BLOBENDPOINT", "secondary": "BLOBENDPOINT"},
 }
 
-
 class StorageAccountHostsMixin(object):  # pylint: disable=too-many-instance-attributes
     def __init__(
         self,
         parsed_url,  # type: Any
         service,  # type: str
         credential=None,  # type: Optional[Any]
         **kwargs  # type: Any
@@ -204,26 +203,26 @@
         if snapshot:
             query_str += "snapshot={}&".format(self.snapshot)
         if share_snapshot:
             query_str += "sharesnapshot={}&".format(self.snapshot)
         if sas_token and isinstance(credential, AzureSasCredential):
             raise ValueError(
                 "You cannot use AzureSasCredential when the resource URI also contains a Shared Access Signature.")
-        if is_credential_sastoken(credential):
+        if sas_token and not credential:
+            query_str += sas_token
+        elif is_credential_sastoken(credential):
             query_str += credential.lstrip("?")
             credential = None
-        elif sas_token:
-            query_str += sas_token
         return query_str.rstrip("?&"), credential
 
     def _create_pipeline(self, credential, **kwargs):
         # type: (Any, **Any) -> Tuple[Configuration, Pipeline]
         self._credential_policy = None
         if hasattr(credential, "get_token"):
-            self._credential_policy = StorageBearerTokenCredentialPolicy(credential)
+            self._credential_policy = BearerTokenCredentialPolicy(credential, STORAGE_OAUTH_SCOPE)
         elif isinstance(credential, SharedKeyCredentialPolicy):
             self._credential_policy = credential
         elif isinstance(credential, AzureSasCredential):
             self._credential_policy = AzureSasCredentialPolicy(credential)
         elif credential is not None:
             raise TypeError("Unsupported credential: {}".format(credential))
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies.py`

 * *Files 1% similar despite different names*

```diff
@@ -346,14 +346,17 @@
     header_name = 'Content-MD5'
 
     def __init__(self, **kwargs):  # pylint: disable=unused-argument
         super(StorageContentValidation, self).__init__()
 
     @staticmethod
     def get_content_md5(data):
+        # Since HTTP does not differentiate between no content and empty content,
+        # we have to perform a None check.
+        data = data or b""
         md5 = hashlib.md5() # nosec
         if isinstance(data, bytes):
             md5.update(data)
         elif hasattr(data, 'read'):
             pos = 0
             try:
                 pos = data.tell()
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/response_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads.py`

 * *Files 1% similar despite different names*

```diff
@@ -606,15 +606,14 @@
         try:
             while count < size:
                 chunk = self.__next__()
                 if isinstance(chunk, six.text_type):
                     chunk = chunk.encode(self.encoding)
                 data += chunk
                 count += len(chunk)
-        # This means count < size and what's leftover will be returned in this call.
         except StopIteration:
-            self.leftover = b""
+            pass
 
-        if count >= size:
+        if count > size:
             self.leftover = data[size:]
 
         return data[:size]
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads_async.py`

 * *Files 0% similar despite different names*

```diff
@@ -213,15 +213,15 @@
         if self.progress_lock is not None:
             async with self.progress_lock:
                 self.progress_total += length
         else:
             self.progress_total += length
 
         if self.progress_hook:
-            await self.progress_hook(self.progress_total, self.total_size)
+            self.progress_hook(self.progress_total, self.total_size)
 
     async def _upload_chunk(self, chunk_offset, chunk_data):
         raise NotImplementedError("Must be implemented by child class.")
 
     async def _upload_chunk_with_progress(self, chunk_offset, chunk_data):
         range_id = await self._upload_chunk(chunk_offset, chunk_data)
         await self._update_progress(len(chunk_data))
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/_upload_helpers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_upload_helpers.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,38 +2,44 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=no-self-use
 
 from io import SEEK_SET, UnsupportedOperation
-from typing import Optional, Union, Any, TypeVar, TYPE_CHECKING # pylint: disable=unused-import
+from typing import TypeVar, TYPE_CHECKING
 
 import six
 from azure.core.exceptions import ResourceExistsError, ResourceModifiedError, HttpResponseError
 
-from ._shared.response_handlers import (
-    process_storage_error,
-    return_response_headers)
+from ._shared.response_handlers import process_storage_error, return_response_headers
 from ._shared.models import StorageErrorCode
 from ._shared.uploads import (
     upload_data_chunks,
     upload_substream_blocks,
     BlockBlobChunkUploader,
     PageBlobChunkUploader,
-    AppendBlobChunkUploader)
-from ._shared.encryption import generate_blob_encryption_data, encrypt_blob
+    AppendBlobChunkUploader
+)
 from ._generated.models import (
     BlockLookupList,
     AppendPositionAccessConditions,
     ModifiedAccessConditions,
 )
+from ._encryption import (
+    GCMBlobEncryptionStream,
+    encrypt_blob,
+    get_adjusted_upload_size,
+    get_blob_encryptor_and_padder,
+    generate_blob_encryption_data,
+    _ENCRYPTION_PROTOCOL_V1,
+    _ENCRYPTION_PROTOCOL_V2
+)
 
 if TYPE_CHECKING:
-    from datetime import datetime # pylint: disable=unused-import
     BlobLeaseClient = TypeVar("BlobLeaseClient")
 
 _LARGE_BLOB_UPLOAD_MAX_READ_BUFFER_SIZE = 4 * 1024 * 1024
 _ERROR_VALUE_SHOULD_BE_SEEKABLE_STREAM = '{0} should be a seekable file-like/io.IOBase type stream object.'
 
 
 def _convert_mod_error(error):
@@ -54,15 +60,15 @@
         modified_access_conditions.if_modified_since,
         modified_access_conditions.if_unmodified_since,
         modified_access_conditions.if_none_match,
         modified_access_conditions.if_match
     ])
 
 
-def upload_block_blob(  # pylint: disable=too-many-locals
+def upload_block_blob(  # pylint: disable=too-many-locals, too-many-statements
         client=None,
         data=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
@@ -71,15 +77,15 @@
         encryption_options=None,
         **kwargs):
     try:
         if not overwrite and not _any_conditions(**kwargs):
             kwargs['modified_access_conditions'].if_none_match = '*'
         adjusted_count = length
         if (encryption_options.get('key') is not None) and (adjusted_count is not None):
-            adjusted_count += (16 - (length % 16))
+            adjusted_count = get_adjusted_upload_size(adjusted_count, encryption_options['version'])
         blob_headers = kwargs.pop('blob_headers', None)
         tier = kwargs.pop('standard_blob_tier', None)
         blob_tags_string = kwargs.pop('blob_tags_string', None)
 
         immutability_policy = kwargs.pop('immutability_policy', None)
         immutability_policy_expiry = None if immutability_policy is None else immutability_policy.expiry_time
         immutability_policy_mode = None if immutability_policy is None else immutability_policy.policy_mode
@@ -91,15 +97,15 @@
             try:
                 data = data.read(length)
                 if not isinstance(data, six.binary_type):
                     raise TypeError('Blob data should be of type bytes.')
             except AttributeError:
                 pass
             if encryption_options.get('key'):
-                encryption_data, data = encrypt_blob(data, encryption_options['key'])
+                encryption_data, data = encrypt_blob(data, encryption_options['key'], encryption_options['version'])
                 headers['x-ms-meta-encryptiondata'] = encryption_data
 
             response = client.upload(
                 body=data,
                 content_length=adjusted_count,
                 blob_http_headers=blob_headers,
                 headers=headers,
@@ -122,29 +128,43 @@
         use_original_upload_path = blob_settings.use_byte_buffer or \
             validate_content or encryption_options.get('required') or \
             blob_settings.max_block_size < blob_settings.min_large_block_upload_threshold or \
             hasattr(stream, 'seekable') and not stream.seekable() or \
             not hasattr(stream, 'seek') or not hasattr(stream, 'tell')
 
         if use_original_upload_path:
-            if encryption_options.get('key'):
-                cek, iv, encryption_data = generate_blob_encryption_data(encryption_options['key'])
+            total_size = length
+            encryptor, padder = None, None
+            if encryption_options and encryption_options.get('key'):
+                cek, iv, encryption_data = generate_blob_encryption_data(
+                    encryption_options['key'],
+                    encryption_options['version'])
                 headers['x-ms-meta-encryptiondata'] = encryption_data
-                encryption_options['cek'] = cek
-                encryption_options['vector'] = iv
+
+                if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V1:
+                    encryptor, padder = get_blob_encryptor_and_padder(cek, iv, True)
+
+                # Adjust total_size for encryption V2
+                if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V2:
+                    # Adjust total_size for encryption V2
+                    total_size = adjusted_count
+                    # V2 wraps the data stream with an encryption stream
+                    stream = GCMBlobEncryptionStream(cek, stream)
+
             block_ids = upload_data_chunks(
                 service=client,
                 uploader_class=BlockBlobChunkUploader,
-                total_size=length,
+                total_size=total_size,
                 chunk_size=blob_settings.max_block_size,
                 max_concurrency=max_concurrency,
                 stream=stream,
                 validate_content=validate_content,
-                encryption_options=encryption_options,
                 progress_hook=progress_hook,
+                encryptor=encryptor,
+                padder=padder,
                 headers=headers,
                 **kwargs
             )
         else:
             block_ids = upload_substream_blocks(
                 service=client,
                 uploader_class=BlockBlobChunkUploader,
@@ -196,47 +216,59 @@
         if not overwrite and not _any_conditions(**kwargs):
             kwargs['modified_access_conditions'].if_none_match = '*'
         if length is None or length < 0:
             raise ValueError("A content length must be specified for a Page Blob.")
         if length % 512 != 0:
             raise ValueError("Invalid page blob size: {0}. "
                              "The size must be aligned to a 512-byte boundary.".format(length))
+        tier = None
         if kwargs.get('premium_page_blob_tier'):
             premium_page_blob_tier = kwargs.pop('premium_page_blob_tier')
             try:
-                headers['x-ms-access-tier'] = premium_page_blob_tier.value
+                tier = premium_page_blob_tier.value
             except AttributeError:
-                headers['x-ms-access-tier'] = premium_page_blob_tier
-        if encryption_options and encryption_options.get('data'):
-            headers['x-ms-meta-encryptiondata'] = encryption_options['data']
+                tier = premium_page_blob_tier
+
+        if encryption_options and encryption_options.get('key'):
+            cek, iv, encryption_data = generate_blob_encryption_data(
+                encryption_options['key'],
+                encryption_options['version'])
+            headers['x-ms-meta-encryptiondata'] = encryption_data
+
         blob_tags_string = kwargs.pop('blob_tags_string', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
         response = client.create(
             content_length=0,
             blob_content_length=length,
             blob_sequence_number=None,
             blob_http_headers=kwargs.pop('blob_headers', None),
             blob_tags_string=blob_tags_string,
+            tier=tier,
             cls=return_response_headers,
             headers=headers,
             **kwargs)
         if length == 0:
             return response
 
+        if encryption_options and encryption_options.get('key'):
+            if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V1:
+                encryptor, padder = get_blob_encryptor_and_padder(cek, iv, False)
+                kwargs['encryptor'] = encryptor
+                kwargs['padder'] = padder
+
         kwargs['modified_access_conditions'] = ModifiedAccessConditions(if_match=response['etag'])
         return upload_data_chunks(
             service=client,
             uploader_class=PageBlobChunkUploader,
             total_size=length,
             chunk_size=blob_settings.max_page_size,
             stream=stream,
             max_concurrency=max_concurrency,
             validate_content=validate_content,
-            encryption_options=encryption_options,
             progress_hook=progress_hook,
             headers=headers,
             **kwargs)
 
     except HttpResponseError as error:
         try:
             process_storage_error(error)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -15,33 +15,35 @@
 from ._lease_async import BlobLeaseClient
 from ._download_async import StorageStreamDownloader
 
 
 async def upload_blob_to_url(
         blob_url,  # type: str
         data,  # type: Union[Iterable[AnyStr], IO[AnyStr]]
-        credential=None,  # type: Any
+        credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
         **kwargs):
     # type: (...) -> dict[str, Any]
     """Upload data to a given URL
 
     The data will be uploaded as a block blob.
 
     :param str blob_url:
         The full URI to the blob. This can also include a SAS token.
     :param data:
         The data to upload. This can be bytes, text, an iterable or a file-like object.
     :type data: bytes or str or Iterable
-    :param credential:
+   :param credential:
         The credentials with which to authenticate. This is optional if the
         blob URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword bool overwrite:
         Whether the blob to be uploaded should overwrite the current data.
         If True, upload_blob_to_url will overwrite any existing data. If set to False, the
         operation will fail with a ResourceExistsError.
     :keyword int max_concurrency:
         The number of parallel connections with which to download.
     :keyword int length:
@@ -72,32 +74,34 @@
     stream = await client.download_blob(**kwargs)
     await stream.readinto(handle)
 
 
 async def download_blob_from_url(
         blob_url,  # type: str
         output,  # type: str
-        credential=None,  # type: Any
+        credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
         **kwargs):
     # type: (...) -> None
     """Download the contents of a blob to a local file or stream.
 
     :param str blob_url:
         The full URI to the blob. This can also include a SAS token.
     :param output:
         Where the data should be downloaded to. This could be either a file path to write to,
         or an open IO handle to write to.
     :type output: str or writable stream
     :param credential:
         The credentials with which to authenticate. This is optional if the
         blob URL already has a SAS token or the blob is public. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials,
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
         an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword bool overwrite:
         Whether the local file should be overwritten if it already exists. The default value is
         `False` - in which case a ValueError will be raised if the file already exists. If set to
         `True`, an attempt will be made to write to the existing file. If a stream handle is passed
         in, this value is ignored.
     :keyword int max_concurrency:
         The number of parallel connections with which to download.
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_blob_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_client_async.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,58 +1,63 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-lines, invalid-overridden-method
+
+import warnings
 from functools import partial
 from typing import (  # pylint: disable=unused-import
-    Union, Optional, Any, IO, Iterable, AnyStr, Dict, List, Tuple,
+    Any, AnyStr, Dict, IO, Iterable, List, Optional, overload, Tuple, Union,
     TYPE_CHECKING
 )
-import warnings
 
 from azure.core.async_paging import AsyncItemPaged
 from azure.core.exceptions import ResourceNotFoundError, HttpResponseError, ResourceExistsError
 from azure.core.pipeline import AsyncPipeline
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
 
-
 from .._shared.base_client_async import AsyncStorageAccountHostsMixin, AsyncTransportWrapper
 from .._shared.policies_async import ExponentialRetry
 from .._shared.response_handlers import return_response_headers, process_storage_error
-from .._deserialize import get_page_ranges_result, parse_tags, deserialize_pipeline_response_into_cls
-from .._serialize import get_modify_conditions, get_api_version, get_access_conditions
 from .._generated.aio import AzureBlobStorage
 from .._generated.models import CpkInfo
-from .._deserialize import deserialize_blob_properties
 from .._blob_client import BlobClient as BlobClientBase
+from .._deserialize import (
+    deserialize_blob_properties,
+    deserialize_pipeline_response_into_cls,
+    get_page_ranges_result,
+    parse_tags
+)
+from .._encryption import StorageEncryptionMixin
+from .._models import BlobType, BlobBlock, BlobProperties, PageRange
+from .._serialize import get_modify_conditions, get_api_version, get_access_conditions
+from ._download_async import StorageStreamDownloader
+from ._lease_async import BlobLeaseClient
+from ._models import PageRangePaged
 from ._upload_helpers import (
     upload_block_blob,
     upload_append_blob,
-    upload_page_blob)
-from .._models import BlobType, BlobBlock, BlobProperties, PageRange
-from ._models import PageRangePaged
-from ._lease_async import BlobLeaseClient
-from ._download_async import StorageStreamDownloader
-
+    upload_page_blob
+)
 
 if TYPE_CHECKING:
     from datetime import datetime
     from .._models import (  # pylint: disable=unused-import
         ContentSettings,
         ImmutabilityPolicy,
         PremiumPageBlobTier,
         StandardBlobTier,
         SequenceNumberAction
     )
 
 
-class BlobClient(AsyncStorageAccountHostsMixin, BlobClientBase):  # pylint: disable=too-many-public-methods
+class BlobClient(AsyncStorageAccountHostsMixin, BlobClientBase, StorageEncryptionMixin):  # pylint: disable=too-many-public-methods
     """A client to interact with a specific blob, although that blob may not yet exist.
 
     :param str account_url:
         The URI to the storage account. In order to create a client given the full URI to the blob,
         use the :func:`from_blob_url` classmethod.
     :param container_name: The container name for the blob.
     :type container_name: str
@@ -61,18 +66,20 @@
     :type blob_name: str
     :param str snapshot:
         The optional blob snapshot on which to operate. This can be the snapshot ID string
         or the response returned from :func:`create_snapshot`.
     :param credential:
         The credentials with which to authenticate. This is optional if the
         account URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword str api_version:
         The Storage API version to use for requests. Default value is the most recent service version that is
         compatible with the current SDK. Setting to an older version may result in reduced feature compatibility.
 
         .. versionadded:: 12.2.0
 
     :keyword str secondary_hostname:
@@ -108,28 +115,29 @@
             :caption: Creating the BlobClient from a SAS URL to a blob.
     """
     def __init__(
             self, account_url,  # type: str
             container_name,  # type: str
             blob_name,  # type: str
             snapshot=None,  # type: Optional[Union[str, Dict[str, Any]]]
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):
         # type: (...) -> None
         kwargs['retry_policy'] = kwargs.get('retry_policy') or ExponentialRetry(**kwargs)
         super(BlobClient, self).__init__(
             account_url,
             container_name=container_name,
             blob_name=blob_name,
             snapshot=snapshot,
             credential=credential,
             **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
+        self._configure_encryption(kwargs)
 
     @distributed_trace_async
     async def get_account_information(self, **kwargs): # type: ignore
         # type: (Optional[int]) -> Dict[str, str]
         """Gets information related to the storage account in which the blob resides.
 
         The information can also be retrieved if the user has a SAS to a container or blob.
@@ -243,15 +251,15 @@
         try:
             return await self._client.block_blob.put_blob_from_url(**options)
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace_async
     async def upload_blob(
-            self, data,  # type: Union[AnyStr, Iterable[AnyStr], IO[AnyStr]]
+            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
             blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
             length=None,  # type: Optional[int]
             metadata=None,  # type: Optional[Dict[str, str]]
             **kwargs
         ):
         # type: (...) -> Any
         """Creates a new blob from a data source with automatic chunking.
@@ -395,17 +403,39 @@
             **kwargs)
         if blob_type == BlobType.BlockBlob:
             return await upload_block_blob(**options)
         if blob_type == BlobType.PageBlob:
             return await upload_page_blob(**options)
         return await upload_append_blob(**options)
 
+    @overload
+    async def download_blob(
+            self, offset: int = None,
+            length: int = None,
+            *,
+            encoding: str,
+            **kwargs) -> StorageStreamDownloader[str]:
+        ...
+
+    @overload
+    async def download_blob(
+            self, offset: int = None,
+            length: int = None,
+            *,
+            encoding: None = None,
+            **kwargs) -> StorageStreamDownloader[bytes]:
+        ...
+
     @distributed_trace_async
-    async def download_blob(self, offset=None, length=None, **kwargs):
-        # type: (Optional[int], Optional[int], Any) -> StorageStreamDownloader
+    async def download_blob(
+            self, offset: int = None,
+            length: int = None,
+            *,
+            encoding: Optional[str] = None,
+            **kwargs) -> StorageStreamDownloader:
         """Downloads a blob to the StorageStreamDownloader. The readall() method must
         be used to read all the content or readinto() must be used to download the blob into
         a stream. Using chunks() returns an async iterator which allows the user to iterate over the content in chunks.
 
         :param int offset:
             Start of byte range to use for downloading a section of the blob.
             Must be set if length is provided.
@@ -485,14 +515,15 @@
                 :language: python
                 :dedent: 16
                 :caption: Download a blob.
         """
         options = self._download_blob_options(
             offset=offset,
             length=length,
+            encoding=encoding,
             **kwargs)
         downloader = StorageStreamDownloader(**options)
         await downloader._setup()  # pylint: disable=protected-access
         return downloader
 
     @distributed_trace_async
     async def delete_blob(self, delete_snapshots=None, **kwargs):
@@ -2461,15 +2492,15 @@
         try:
             return await self._client.page_blob.clear_pages(**options)  # type: ignore
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace_async
     async def append_block( # type: ignore
-            self, data,  # type: Union[AnyStr, Iterable[AnyStr], IO[AnyStr]]
+            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
             length=None,  # type: Optional[int]
             **kwargs
         ):
         # type: (...) -> Dict[str, Union[str, datetime, int]]
         """Commits a new block of data to the end of the existing append blob.
 
         :param data:
@@ -2727,10 +2758,10 @@
                 policies=self._pipeline._impl_policies # pylint: disable = protected-access
             )
         else:
             _pipeline = self._pipeline  # pylint: disable = protected-access
         return ContainerClient(
             "{}://{}".format(self.scheme, self.primary_hostname), container_name=self.container_name,
             credential=self._raw_credential, api_version=self.api_version, _configuration=self._config,
-            _location_mode=self._location_mode, _hosts=self._hosts, require_encryption=self.require_encryption,
-            _pipeline=_pipeline, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_blob_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_service_client_async.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,76 +1,84 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=invalid-overridden-method
+
 import functools
 import warnings
 from typing import (  # pylint: disable=unused-import
-    Union, Optional, Any, Iterable, Dict, List,
+    Any, Dict, List, Optional, Union,
     TYPE_CHECKING
 )
 
+from azure.core.async_paging import AsyncItemPaged
 from azure.core.exceptions import HttpResponseError
-from azure.core.tracing.decorator import distributed_trace
 from azure.core.pipeline import AsyncPipeline
+from azure.core.tracing.decorator import distributed_trace
 from azure.core.tracing.decorator_async import distributed_trace_async
-from azure.core.async_paging import AsyncItemPaged
 
-from .._shared.models import LocationMode
-from .._shared.policies_async import ExponentialRetry
+
 from .._shared.base_client_async import AsyncStorageAccountHostsMixin, AsyncTransportWrapper
-from .._shared.response_handlers import return_response_headers, process_storage_error
+from .._shared.response_handlers import (
+    parse_to_internal_user_delegation_key,
+    process_storage_error,
+    return_response_headers,
+)
+from .._shared.models import LocationMode
 from .._shared.parser import _to_utc_datetime
-from .._shared.response_handlers import parse_to_internal_user_delegation_key
+from .._shared.policies_async import ExponentialRetry
 from .._generated.aio import AzureBlobStorage
 from .._generated.models import StorageServiceProperties, KeyInfo
 from .._blob_service_client import BlobServiceClient as BlobServiceClientBase
-from ._container_client_async import ContainerClient
-from ._blob_client_async import BlobClient
-from .._models import ContainerProperties
 from .._deserialize import service_stats_deserialize, service_properties_deserialize
+from .._encryption import StorageEncryptionMixin
+from .._models import ContainerProperties
 from .._serialize import get_api_version
+from ._blob_client_async import BlobClient
+from ._container_client_async import ContainerClient
 from ._models import ContainerPropertiesPaged, FilteredBlobPaged
 
 if TYPE_CHECKING:
     from datetime import datetime
-    from .._shared.models import AccountSasPermissions, ResourceTypes, UserDelegationKey
+    from .._shared.models import UserDelegationKey
     from ._lease_async import BlobLeaseClient
     from .._models import (
         BlobProperties,
         PublicAccess,
         BlobAnalyticsLogging,
         Metrics,
         CorsRule,
         RetentionPolicy,
         StaticWebsite,
     )
 
 
-class BlobServiceClient(AsyncStorageAccountHostsMixin, BlobServiceClientBase):
+class BlobServiceClient(AsyncStorageAccountHostsMixin, BlobServiceClientBase, StorageEncryptionMixin):
     """A client to interact with the Blob Service at the account level.
 
     This client provides operations to retrieve and configure the account properties
     as well as list, create and delete containers within the account.
     For operations relating to a specific container or blob, clients for those entities
     can also be retrieved using the `get_client` functions.
 
     :param str account_url:
         The URL to the blob storage account. Any other entities included
         in the URL path (e.g. container or blob) will be discarded. This URL can be optionally
         authenticated with a SAS token.
     :param credential:
         The credentials with which to authenticate. This is optional if the
         account URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword str api_version:
         The Storage API version to use for requests. Default value is the most recent service version that is
         compatible with the current SDK. Setting to an older version may result in reduced feature compatibility.
 
         .. versionadded:: 12.2.0
 
     :keyword str secondary_hostname:
@@ -104,25 +112,26 @@
             :language: python
             :dedent: 8
             :caption: Creating the BlobServiceClient with Azure Identity credentials.
     """
 
     def __init__(
             self, account_url,  # type: str
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):
         # type: (...) -> None
         kwargs['retry_policy'] = kwargs.get('retry_policy') or ExponentialRetry(**kwargs)
         super(BlobServiceClient, self).__init__(
             account_url,
             credential=credential,
             **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
+        self._configure_encryption(kwargs)
 
     @distributed_trace_async
     async def get_user_delegation_key(self, key_start_time,  # type: datetime
                                       key_expiry_time,  # type: datetime
                                       **kwargs  # type: Any
                                       ):
         # type: (...) -> UserDelegationKey
@@ -619,16 +628,16 @@
             transport=AsyncTransportWrapper(self._pipeline._transport), # pylint: disable = protected-access
             policies=self._pipeline._impl_policies # pylint: disable = protected-access
         )
         return ContainerClient(
             self.url, container_name=container_name,
             credential=self.credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
 
     def get_blob_client(
             self, container,  # type: Union[ContainerProperties, str]
             blob,  # type: Union[BlobProperties, str]
             snapshot=None  # type: Optional[Union[Dict[str, Any], str]]
         ):
         # type: (...) -> BlobClient
@@ -674,9 +683,9 @@
             transport=AsyncTransportWrapper(self._pipeline._transport), # pylint: disable = protected-access
             policies=self._pipeline._impl_policies # pylint: disable = protected-access
         )
         return BlobClient( # type: ignore
             self.url, container_name=container_name, blob_name=blob_name, snapshot=snapshot,
             credential=self.credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_container_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_container_client_async.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,56 +1,58 @@
-# pylint: disable=too-many-lines
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
-# pylint: disable=invalid-overridden-method
+# pylint: disable=too-many-lines, invalid-overridden-method
+
 import functools
 from typing import (  # pylint: disable=unused-import
-    Union, Optional, Any, Iterable, AnyStr, Dict, List, IO, AsyncIterator,
+    Any, AnyStr, AsyncIterator, Dict, List, IO, Iterable, Optional, overload, Union,
     TYPE_CHECKING
 )
 
-from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
-from azure.core.tracing.decorator import distributed_trace
-from azure.core.tracing.decorator_async import distributed_trace_async
 from azure.core.async_paging import AsyncItemPaged
+from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
 from azure.core.pipeline import AsyncPipeline
 from azure.core.pipeline.transport import AsyncHttpResponse
+from azure.core.tracing.decorator import distributed_trace
+from azure.core.tracing.decorator_async import distributed_trace_async
 
 from .._shared.base_client_async import AsyncStorageAccountHostsMixin, AsyncTransportWrapper
 from .._shared.policies_async import ExponentialRetry
 from .._shared.request_handlers import add_metadata_headers, serialize_iso
 from .._shared.response_handlers import (
     process_storage_error,
     return_response_headers,
-    return_headers_and_deserialized)
+    return_headers_and_deserialized
+)
 from .._generated.aio import AzureBlobStorage
 from .._generated.models import SignedIdentifier
+from .._container_client import ContainerClient as ContainerClientBase, _get_blob_name
 from .._deserialize import deserialize_container_properties
+from ._download_async import StorageStreamDownloader
+from .._encryption import StorageEncryptionMixin
+from .._models import ContainerProperties, BlobType, BlobProperties, FilteredBlob
 from .._serialize import get_modify_conditions, get_container_cpk_scope_info, get_api_version, get_access_conditions
-from .._container_client import ContainerClient as ContainerClientBase, _get_blob_name
-from .._models import ContainerProperties, BlobType, BlobProperties, FilteredBlob  # pylint: disable=unused-import
-from ._list_blobs_helper import BlobPropertiesPaged, BlobPrefix
-from ._lease_async import BlobLeaseClient
 from ._blob_client_async import BlobClient
+from ._lease_async import BlobLeaseClient
+from ._list_blobs_helper import BlobPropertiesPaged, BlobPrefix
 from ._models import FilteredBlobPaged
 
 if TYPE_CHECKING:
-    from .._models import PublicAccess
-    from ._download_async import StorageStreamDownloader
     from datetime import datetime
     from .._models import ( # pylint: disable=unused-import
         AccessPolicy,
         StandardBlobTier,
-        PremiumPageBlobTier)
+        PremiumPageBlobTier,
+        PublicAccess)
 
 
-class ContainerClient(AsyncStorageAccountHostsMixin, ContainerClientBase):
+class ContainerClient(AsyncStorageAccountHostsMixin, ContainerClientBase, StorageEncryptionMixin):
     """A client to interact with a specific container, although that container
     may not yet exist.
 
     For operations relating to a specific blob within this container, a blob client can be
     retrieved using the :func:`~get_blob_client` function.
 
     :param str account_url:
@@ -58,18 +60,20 @@
         use the :func:`from_container_url` classmethod.
     :param container_name:
         The name of the container for the blob.
     :type container_name: str
     :param credential:
         The credentials with which to authenticate. This is optional if the
         account URL already has a SAS token. The value can be a SAS token string,
-        an instance of a AzureSasCredential from azure.core.credentials, an account
-        shared access key, or an instance of a TokenCredentials class from azure.identity.
+        an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,
+        an account shared access key, or an instance of a TokenCredentials class from azure.identity.
         If the resource URI already contains a SAS token, this will be ignored in favor of an explicit credential
         - except in the case of AzureSasCredential, where the conflicting SAS tokens will raise a ValueError.
+        If using an instance of AzureNamedKeyCredential, "name" should be the storage account name, and "key"
+        should be the storage account key.
     :keyword str api_version:
         The Storage API version to use for requests. Default value is the most recent service version that is
         compatible with the current SDK. Setting to an older version may result in reduced feature compatibility.
 
         .. versionadded:: 12.2.0
 
     :keyword str secondary_hostname:
@@ -103,26 +107,27 @@
             :language: python
             :dedent: 12
             :caption: Creating the container client directly.
     """
     def __init__(
             self, account_url,  # type: str
             container_name,  # type: str
-            credential=None,  # type: Optional[Any]
+            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
             **kwargs  # type: Any
         ):
         # type: (...) -> None
         kwargs['retry_policy'] = kwargs.get('retry_policy') or ExponentialRetry(**kwargs)
         super(ContainerClient, self).__init__(
             account_url,
             container_name=container_name,
             credential=credential,
             **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
+        self._configure_encryption(kwargs)
 
     @distributed_trace_async
     async def create_container(self, metadata=None, public_access=None, **kwargs):
         # type: (Optional[Dict[str, str]], Optional[Union[PublicAccess, str]], **Any) -> Dict[str, Union[str, datetime]]
         """
         Creates a new container under the specified account. If the container
         with the same name already exists, the operation fails.
@@ -184,24 +189,24 @@
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
             The timeout parameter is expressed in seconds.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         lease = kwargs.pop('lease', None)
         try:
-            kwargs['source_lease_id'] = lease.id  # type: str
+            kwargs['source_lease_id'] = lease.id
         except AttributeError:
             kwargs['source_lease_id'] = lease
         try:
             renamed_container = ContainerClient(
                 "{}://{}".format(self.scheme, self.primary_hostname), container_name=new_name,
                 credential=self.credential, api_version=self.api_version, _configuration=self._config,
                 _pipeline=self._pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-                require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-                key_resolver_function=self.key_resolver_function)
+                require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+                key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
             await renamed_container._client.container.rename(self.container_name, **kwargs)   # pylint: disable = protected-access
             return renamed_container
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace_async
     async def delete_container(
@@ -470,16 +475,16 @@
             )
         else:
             _pipeline = self._pipeline  # pylint: disable = protected-access
         return BlobServiceClient(
             "{}://{}".format(self.scheme, self.primary_hostname),
             credential=self._raw_credential, api_version=self.api_version, _configuration=self._config,
             _location_mode=self._location_mode, _hosts=self._hosts, require_encryption=self.require_encryption,
-            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function,
-            _pipeline=_pipeline)
+            encryption_version=self.encryption_version, key_encryption_key=self.key_encryption_key,
+            key_resolver_function=self.key_resolver_function, _pipeline=_pipeline)
 
 
     @distributed_trace_async
     async def get_container_access_policy(self, **kwargs):
         # type: (Any) -> Dict[str, Any]
         """Gets the permissions for the specified container.
         The permissions indicate whether container data may be accessed publicly.
@@ -599,18 +604,19 @@
         """Returns a generator to list the blobs under the specified container.
         The generator will lazily follow the continuation tokens returned by
         the service.
 
         :param str name_starts_with:
             Filters the results to return only blobs whose names
             begin with the specified prefix.
-        :param list[str] or str include:
+        :param include:
             Specifies one or more additional datasets to include in the response.
             Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted', 'deletedwithversions',
             'tags', 'versions'.
+        :paramtype include: list[str] or str
         :keyword int timeout:
             The timeout parameter is expressed in seconds.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.storage.blob.BlobProperties]
 
         .. admonition:: Example:
 
@@ -865,16 +871,16 @@
         Note that in order to delete a blob, you must delete all of its
         snapshots. You can delete both at the same time with the delete_blob
         operation.
 
         If a delete retention policy is enabled for the service, then this operation soft deletes the blob or snapshot
         and retains the blob or snapshot for specified number of days.
         After specified number of days, blob's data is removed from the service during garbage collection.
-        Soft deleted blob or snapshot is accessible through :func:`list_blobs()` specifying `include=["deleted"]`
-        option. Soft-deleted blob or snapshot can be restored using :func:`~BlobClient.undelete()`
+        Soft deleted blobs or snapshots are accessible through :func:`list_blobs()` specifying `include=["deleted"]`
+        Soft-deleted blob or snapshot can be restored using :func:`~azure.storage.blob.aio.BlobClient.undelete()`
 
         :param blob: The blob with which to interact. If specified, this value will override
             a blob value specified in the blob URL.
         :type blob: str or ~azure.storage.blob.BlobProperties
         :param str delete_snapshots:
             Required if the blob has associated snapshots. Values include:
              - "only": Deletes only the blobs snapshots.
@@ -921,17 +927,42 @@
         kwargs.setdefault('merge_span', True)
         timeout = kwargs.pop('timeout', None)
         await blob.delete_blob( # type: ignore
             delete_snapshots=delete_snapshots,
             timeout=timeout,
             **kwargs)
 
+    @overload
+    async def download_blob(
+            self, blob: Union[str, BlobProperties],
+            offset: int = None,
+            length: int = None,
+            *,
+            encoding: str,
+            **kwargs) -> StorageStreamDownloader[str]:
+        ...
+
+    @overload
+    async def download_blob(
+            self, blob: Union[str, BlobProperties],
+            offset: int = None,
+            length: int = None,
+            *,
+            encoding: None = None,
+            **kwargs) -> StorageStreamDownloader[bytes]:
+        ...
+
     @distributed_trace_async
-    async def download_blob(self, blob, offset=None, length=None, **kwargs):
-        # type: (Union[str, BlobProperties], Optional[int], Optional[int], Any) -> StorageStreamDownloader
+    async def download_blob(
+            self, blob: Union[str, BlobProperties],
+            offset: int = None,
+            length: int = None,
+            *,
+            encoding: Optional[str] = None,
+            **kwargs) -> StorageStreamDownloader:
         """Downloads a blob to the StorageStreamDownloader. The readall() method must
         be used to read all the content or readinto() must be used to download the blob into
         a stream. Using chunks() returns an async iterator which allows the user to iterate over the content in chunks.
 
         :param blob: The blob with which to interact. If specified, this value will override
             a blob value specified in the blob URL.
         :type blob: str or ~azure.storage.blob.BlobProperties
@@ -1007,32 +1038,33 @@
         :rtype: ~azure.storage.blob.aio.StorageStreamDownloader
         """
         blob_client = self.get_blob_client(blob) # type: ignore
         kwargs.setdefault('merge_span', True)
         return await blob_client.download_blob(
             offset=offset,
             length=length,
+            encoding=encoding,
             **kwargs)
 
     @distributed_trace_async
-    async def delete_blobs(  # pylint: disable=arguments-differ
-            self, *blobs: List[Union[str, BlobProperties, dict]],
-            **kwargs
+    async def delete_blobs(
+        self, *blobs: Union[str, Dict[str, Any], BlobProperties],
+        **kwargs: Any
     ) -> AsyncIterator[AsyncHttpResponse]:
         """Marks the specified blobs or snapshots for deletion.
 
         The blobs are later deleted during garbage collection.
         Note that in order to delete blobs, you must delete all of their
         snapshots. You can delete both at the same time with the delete_blobs operation.
 
         If a delete retention policy is enabled for the service, then this operation soft deletes the blobs or snapshots
         and retains the blobs or snapshots for specified number of days.
         After specified number of days, blobs' data is removed from the service during garbage collection.
         Soft deleted blobs or snapshots are accessible through :func:`list_blobs()` specifying `include=["deleted"]`
-        Soft-deleted blobs or snapshots can be restored using :func:`~BlobClient.undelete()`
+        Soft-deleted blobs or snapshots can be restored using :func:`~azure.storage.blob.aio.BlobClient.undelete()`
 
         The maximum number of blobs that can be deleted in a single request is 256.
 
         :param blobs:
             The blobs to delete. This can be a single blob, or multiple values can
             be supplied, where each value is either the name of the blob (str) or BlobProperties.
 
@@ -1054,15 +1086,15 @@
                 tags match condition:
                     key: 'if_tags_match_condition', value type: str
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
-        :type blobs: list[str], list[dict], or list[~azure.storage.blob.BlobProperties]
+        :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword str delete_snapshots:
             Required if a blob has associated snapshots. Values include:
              - "only": Deletes only the blobs snapshots.
              - "include": Deletes the blob along with all snapshots.
         :keyword ~datetime.datetime if_modified_since:
             A DateTime value. Azure expects the date value passed in to be UTC.
             If timezone is included, any non-UTC datetimes will be converted to UTC.
@@ -1102,20 +1134,19 @@
         if len(blobs) == 0:
             return iter(list())
 
         reqs, options = self._generate_delete_blobs_options(*blobs, **kwargs)
 
         return await self._batch_send(*reqs, **options)
 
-    @distributed_trace
+    @distributed_trace_async
     async def set_standard_blob_tier_blobs(
-        self,
-        standard_blob_tier: Union[str, 'StandardBlobTier'],
-        *blobs: List[Union[str, BlobProperties, dict]],
-        **kwargs
+        self, standard_blob_tier: Union[str, 'StandardBlobTier'],
+        *blobs: Union[str, Dict[str, Any], BlobProperties],
+        **kwargs: Any
     ) -> AsyncIterator[AsyncHttpResponse]:
         """This operation sets the tier on block blobs.
 
         A block blob's tier determines Hot/Cool/Archive storage type.
         This operation does not update the blob's ETag.
 
         The maximum number of blobs that can be updated in a single request is 256.
@@ -1148,15 +1179,15 @@
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 tags match condition:
                     key: 'if_tags_match_condition', value type: str
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
-        :type blobs: list[str], list[dict], or list[~azure.storage.blob.BlobProperties]
+        :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword ~azure.storage.blob.RehydratePriority rehydrate_priority:
             Indicates the priority with which to rehydrate an archived blob
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
@@ -1170,20 +1201,19 @@
         :return: An async iterator of responses, one for each blob in order
         :rtype: asynciterator[~azure.core.pipeline.transport.AsyncHttpResponse]
         """
         reqs, options = self._generate_set_tiers_options(standard_blob_tier, *blobs, **kwargs)
 
         return await self._batch_send(*reqs, **options)
 
-    @distributed_trace
+    @distributed_trace_async
     async def set_premium_page_blob_tier_blobs(
-        self,
-        premium_page_blob_tier: Union[str, 'PremiumPageBlobTier'],
-        *blobs: List[Union[str, BlobProperties, dict]],
-        **kwargs
+        self, premium_page_blob_tier: Union[str, 'PremiumPageBlobTier'],
+        *blobs: Union[str, Dict[str, Any], BlobProperties],
+        **kwargs: Any
     ) -> AsyncIterator[AsyncHttpResponse]:
         """Sets the page blob tiers on the blobs. This API is only supported for page blobs on premium accounts.
 
         The maximum number of blobs that can be updated in a single request is 256.
 
         :param premium_page_blob_tier:
             A page blob tier value to set on all blobs to. The tier correlates to the size of the
@@ -1206,15 +1236,15 @@
                 premium blob tier:
                     key: 'blob_tier', value type: PremiumPageBlobTier
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
-        :type blobs: list[str], list[dict], or list[~azure.storage.blob.BlobProperties]
+        :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword int timeout:
             The timeout parameter is expressed in seconds. This method may make
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure. For optimal performance,
@@ -1258,9 +1288,9 @@
             transport=AsyncTransportWrapper(self._pipeline._transport), # pylint: disable = protected-access
             policies=self._pipeline._impl_policies # pylint: disable = protected-access
         )
         return BlobClient(
             self.url, container_name=self.container_name, blob_name=blob_name, snapshot=snapshot,
             credential=self.credential, api_version=self.api_version, _configuration=self._config,
             _pipeline=_pipeline, _location_mode=self._location_mode, _hosts=self._hosts,
-            require_encryption=self.require_encryption, key_encryption_key=self.key_encryption_key,
-            key_resolver_function=self.key_resolver_function)
+            require_encryption=self.require_encryption, encryption_version=self.encryption_version,
+            key_encryption_key=self.key_encryption_key, key_resolver_function=self.key_resolver_function)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_download_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_download_async.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
-# pylint: disable=invalid-overridden-method
 
 import asyncio
 import sys
 from io import BytesIO
 from itertools import islice
 import warnings
-from typing import AsyncIterator
 
-from aiohttp import ClientPayloadError
-from azure.core.exceptions import HttpResponseError, ServiceResponseError
+from azure.core.exceptions import HttpResponseError
 from .._shared.encryption import decrypt_blob
 from .._shared.request_handlers import validate_and_format_range_headers
 from .._shared.response_handlers import process_storage_error, parse_length_from_content_range
-from .._deserialize import get_page_ranges_result
 from .._download import process_range_and_offset, _ChunkDownloader
 
+
 async def process_content(data, start_offset, end_offset, encryption):
     if data is None:
         raise ValueError("Response cannot be None.")
-    content = data.response.body()
+    try:
+        content = data.response.body()
+    except Exception as error:
+        raise HttpResponseError(message="Download stream interrupted.", response=data.response, error=error)
     if encryption.get('key') is not None or encryption.get('resolver') is not None:
         try:
             return decrypt_blob(
                 encryption.get('required'),
                 encryption.get('key'),
                 encryption.get('resolver'),
                 content,
@@ -63,78 +63,52 @@
     async def _update_progress(self, length):
         if self.progress_lock:
             async with self.progress_lock:  # pylint: disable=not-async-context-manager
                 self.progress_total += length
         else:
             self.progress_total += length
 
-        if self.progress_hook:
-            await self.progress_hook(self.progress_total, self.total_size)
-
     async def _write_to_stream(self, chunk_data, chunk_start):
         if self.stream_lock:
             async with self.stream_lock:  # pylint: disable=not-async-context-manager
                 self.stream.seek(self.stream_start + (chunk_start - self.start_index))
                 self.stream.write(chunk_data)
         else:
             self.stream.write(chunk_data)
 
     async def _download_chunk(self, chunk_start, chunk_end):
         download_range, offset = process_range_and_offset(
-            chunk_start, chunk_end, chunk_end, self.encryption_options)
-
-        # No need to download the empty chunk from server if there's no data in the chunk to be downloaded.
-        # Do optimize and create empty chunk locally if condition is met.
-        if self._do_optimize(download_range[0], download_range[1]):
-            chunk_data = b"\x00" * self.chunk_size
-        else:
-            range_header, range_validation = validate_and_format_range_headers(
-                download_range[0],
-                download_range[1],
-                check_content_md5=self.validate_content
+            chunk_start, chunk_end, chunk_end, self.encryption_options
+        )
+        range_header, range_validation = validate_and_format_range_headers(
+            download_range[0],
+            download_range[1],
+            check_content_md5=self.validate_content
+        )
+        try:
+            _, response = await self.client.download(
+                range=range_header,
+                range_get_content_md5=range_validation,
+                validate_content=self.validate_content,
+                data_stream_total=self.total_size,
+                download_stream_current=self.progress_total,
+                **self.request_options
             )
-            retry_active = True
-            retry_total = 3
-            while retry_active:
-                try:
-                    _, response = await self.client.download(
-                        range=range_header,
-                        range_get_content_md5=range_validation,
-                        validate_content=self.validate_content,
-                        data_stream_total=self.total_size,
-                        download_stream_current=self.progress_total,
-                        **self.request_options
-                    )
-                    retry_active = False
-
-                except HttpResponseError as error:
-                    process_storage_error(error)
-                except ClientPayloadError as error:
-                    retry_total -= 1
-                    if retry_total <= 0:
-                        raise ServiceResponseError(error, error=error)
-                    await asyncio.sleep(1)
-
-            chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)
-
-
-            # This makes sure that if_match is set so that we can validate
-            # that subsequent downloads are to an unmodified blob
-            if self.request_options.get('modified_access_conditions'):
-                self.request_options['modified_access_conditions'].if_match = response.properties.etag
+        except HttpResponseError as error:
+            process_storage_error(error)
 
+        chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)
         return chunk_data
 
 
 class _AsyncChunkIterator(object):
-    """Async iterator for chunks in blob download stream."""
+    """Async iterator for chunks in file download stream."""
 
-    def __init__(self, size, content, downloader, chunk_size):
+    def __init__(self, size, content, downloader):
         self.size = size
-        self._chunk_size = chunk_size
         self._current_content = content
         self._iter_downloader = downloader
         self._iter_chunks = None
         self._complete = (size == 0)
 
     def __len__(self):
         return self.size
@@ -146,94 +120,82 @@
         return self
 
     async def __anext__(self):
         """Iterate through responses."""
         if self._complete:
             raise StopAsyncIteration("Download complete")
         if not self._iter_downloader:
-            # cut the data obtained from initial GET into chunks
-            if len(self._current_content) > self._chunk_size:
-                return self._get_chunk_data()
+            # If no iterator was supplied, the download completed with
+            # the initial GET, so we just return that data
             self._complete = True
             return self._current_content
 
         if not self._iter_chunks:
             self._iter_chunks = self._iter_downloader.get_chunk_offsets()
+        else:
+            try:
+                chunk = next(self._iter_chunks)
+            except StopIteration:
+                raise StopAsyncIteration("Download complete")
+            self._current_content = await self._iter_downloader.yield_chunk(chunk)
 
-        # initial GET result still has more than _chunk_size bytes of data
-        if len(self._current_content) >= self._chunk_size:
-            return self._get_chunk_data()
-
-        try:
-            chunk = next(self._iter_chunks)
-            self._current_content += await self._iter_downloader.yield_chunk(chunk)
-        except StopIteration:
-            self._complete = True
-            # it's likely that there some data left in self._current_content
-            if self._current_content:
-                return self._current_content
-            raise StopAsyncIteration("Download complete")
-
-        return self._get_chunk_data()
-
-    def _get_chunk_data(self):
-        chunk_data = self._current_content[: self._chunk_size]
-        self._current_content = self._current_content[self._chunk_size:]
-        return chunk_data
+        return self._current_content
 
 
 class StorageStreamDownloader(object):  # pylint: disable=too-many-instance-attributes
     """A streaming object to download from Azure Storage.
 
     :ivar str name:
-        The name of the blob being downloaded.
-    :ivar str container:
-        The name of the container where the blob is.
-    :ivar ~azure.storage.blob.BlobProperties properties:
-        The properties of the blob being downloaded. If only a range of the data is being
+        The name of the file being downloaded.
+    :ivar: str path:
+        The full path of the file.
+    :ivar str share:
+        The name of the share where the file is.
+    :ivar ~azure.storage.fileshare.FileProperties properties:
+        The properties of the file being downloaded. If only a range of the data is being
         downloaded, this will be reflected in the properties.
     :ivar int size:
         The size of the total data in the stream. This will be the byte range if speficied,
-        otherwise the total size of the blob.
+        otherwise the total size of the file.
     """
 
     def __init__(
             self,
-            clients=None,
+            client=None,
             config=None,
             start_range=None,
             end_range=None,
             validate_content=None,
             encryption_options=None,
             max_concurrency=1,
             name=None,
-            container=None,
+            path=None,
+            share=None,
             encoding=None,
             **kwargs
     ):
         self.name = name
-        self.container = container
+        self.path = path
+        self.share = share
         self.properties = None
         self.size = None
 
-        self._clients = clients
+        self._client = client
         self._config = config
         self._start_range = start_range
         self._end_range = end_range
         self._max_concurrency = max_concurrency
         self._encoding = encoding
         self._validate_content = validate_content
         self._encryption_options = encryption_options or {}
-        self._progress_hook = kwargs.pop('progress_hook', None)
         self._request_options = kwargs
         self._location_mode = None
         self._download_complete = False
         self._current_content = None
         self._file_size = None
-        self._non_empty_ranges = None
         self._response = None
 
         # The service only provides transactional MD5s for chunks under 4MB.
         # If validate_content is on, get only self.MAX_CHUNK_GET_SIZE for the first
         # chunk so a transactional MD5 can be retrieved.
         self._first_get_size = self._config.max_single_get_size if not self._validate_content \
             else self._config.max_chunk_get_size
@@ -250,15 +212,16 @@
     def __len__(self):
         return self.size
 
     async def _setup(self):
         self._response = await self._initial_request()
         self.properties = self._response.properties
         self.properties.name = self.name
-        self.properties.container = self.container
+        self.properties.path = self.path
+        self.properties.share = self.share
 
         # Set the content length to the download size instead of the size of
         # the last range
         self.properties.size = self.size
 
         # Overwrite the content range to the user requested range
         self.properties.content_range = 'bytes {0}-{1}/{2}'.format(
@@ -286,130 +249,96 @@
         range_header, range_validation = validate_and_format_range_headers(
             self._initial_range[0],
             self._initial_range[1],
             start_range_required=False,
             end_range_required=False,
             check_content_md5=self._validate_content)
 
-        retry_active = True
-        retry_total = 3
-        while retry_active:
-            try:
-                location_mode, response = await self._clients.blob.download(
-                    range=range_header,
-                    range_get_content_md5=range_validation,
-                    validate_content=self._validate_content,
-                    data_stream_total=None,
-                    download_stream_current=0,
-                    **self._request_options)
-
-                # Check the location we read from to ensure we use the same one
-                # for subsequent requests.
-                self._location_mode = location_mode
-
-                # Parse the total file size and adjust the download size if ranges
-                # were specified
-                self._file_size = parse_length_from_content_range(response.properties.content_range)
-                if self._end_range is not None:
-                    # Use the length unless it is over the end of the file
-                    self.size = min(self._file_size, self._end_range - self._start_range + 1)
-                elif self._start_range is not None:
-                    self.size = self._file_size - self._start_range
-                else:
-                    self.size = self._file_size
-                retry_active = False
-
-            except HttpResponseError as error:
-                if self._start_range is None and error.response.status_code == 416:
-                    # Get range will fail on an empty file. If the user did not
-                    # request a range, do a regular get request in order to get
-                    # any properties.
-                    try:
-                        _, response = await self._clients.blob.download(
-                            validate_content=self._validate_content,
-                            data_stream_total=0,
-                            download_stream_current=0,
-                            **self._request_options)
-                        retry_active = False
-                    except HttpResponseError as error:
-                        process_storage_error(error)
-
-                    # Set the download size to empty
-                    self.size = 0
-                    self._file_size = 0
-                else:
-                    process_storage_error(error)
+        try:
+            location_mode, response = await self._client.download(
+                range=range_header,
+                range_get_content_md5=range_validation,
+                validate_content=self._validate_content,
+                data_stream_total=None,
+                download_stream_current=0,
+                **self._request_options)
 
-            except ClientPayloadError as error:
-                retry_total -= 1
-                if retry_total <= 0:
-                    raise ServiceResponseError(error, error=error)
-                await asyncio.sleep(1)
+            # Check the location we read from to ensure we use the same one
+            # for subsequent requests.
+            self._location_mode = location_mode
+
+            # Parse the total file size and adjust the download size if ranges
+            # were specified
+            self._file_size = parse_length_from_content_range(response.properties.content_range)
+            if self._end_range is not None:
+                # Use the length unless it is over the end of the file
+                self.size = min(self._file_size, self._end_range - self._start_range + 1)
+            elif self._start_range is not None:
+                self.size = self._file_size - self._start_range
+            else:
+                self.size = self._file_size
 
-        # get page ranges to optimize downloading sparse page blob
-        if response.properties.blob_type == 'PageBlob':
-            try:
-                page_ranges = await self._clients.page_blob.get_page_ranges()
-                self._non_empty_ranges = get_page_ranges_result(page_ranges)[0]
-            except HttpResponseError:
-                pass
+        except HttpResponseError as error:
+            if self._start_range is None and error.response.status_code == 416:
+                # Get range will fail on an empty file. If the user did not
+                # request a range, do a regular get request in order to get
+                # any properties.
+                try:
+                    _, response = await self._client.download(
+                        validate_content=self._validate_content,
+                        data_stream_total=0,
+                        download_stream_current=0,
+                        **self._request_options)
+                except HttpResponseError as error:
+                    process_storage_error(error)
+
+                # Set the download size to empty
+                self.size = 0
+                self._file_size = 0
+            else:
+                process_storage_error(error)
 
         # If the file is small, the download is complete at this point.
         # If file size is large, download the rest of the file in chunks.
-        if response.properties.size != self.size:
-            if self._request_options.get('modified_access_conditions'):
-                self._request_options['modified_access_conditions'].if_match = response.properties.etag
-        else:
+        if response.properties.size == self.size:
             self._download_complete = True
         return response
 
     def chunks(self):
-        # type: () -> AsyncIterator[bytes]
         """Iterate over chunks in the download stream.
 
-        :rtype: AsyncIterator[bytes]
-
-        .. admonition:: Example:
-
-            .. literalinclude:: ../samples/blob_samples_hello_world_async.py
-                :start-after: [START download_a_blob_in_chunk]
-                :end-before: [END download_a_blob_in_chunk]
-                :language: python
-                :dedent: 16
-                :caption: Download a blob using chunks().
+        :rtype: Iterable[bytes]
         """
         if self.size == 0 or self._download_complete:
             iter_downloader = None
         else:
             data_end = self._file_size
             if self._end_range is not None:
                 # Use the length unless it is over the end of the file
                 data_end = min(self._file_size, self._end_range + 1)
             iter_downloader = _AsyncChunkDownloader(
-                client=self._clients.blob,
-                non_empty_ranges=self._non_empty_ranges,
+                client=self._client,
                 total_size=self.size,
                 chunk_size=self._config.max_chunk_get_size,
                 current_progress=self._first_get_size,
                 start_range=self._initial_range[1] + 1,  # Start where the first download ended
                 end_range=data_end,
                 stream=None,
                 parallel=False,
                 validate_content=self._validate_content,
                 encryption_options=self._encryption_options,
                 use_location=self._location_mode,
                 **self._request_options)
         return _AsyncChunkIterator(
             size=self.size,
             content=self._current_content,
-            downloader=iter_downloader,
-            chunk_size=self._config.max_chunk_get_size)
+            downloader=iter_downloader)
 
     async def readall(self):
-        """Download the contents of this blob.
+        """Download the contents of this file.
 
         This operation is blocking until all data is downloaded.
         :rtype: bytes or str
         """
         stream = BytesIO()
         await self.readinto(stream)
         data = stream.getvalue()
@@ -430,34 +359,34 @@
             "content_as_bytes is deprecated, use readall instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
         return await self.readall()
 
     async def content_as_text(self, max_concurrency=1, encoding="UTF-8"):
-        """Download the contents of this blob, and decode as text.
+        """Download the contents of this file, and decode as text.
 
         This operation is blocking until all data is downloaded.
 
-        :param int max_concurrency:
+        :keyword int max_concurrency:
             The number of parallel connections with which to download.
         :param str encoding:
             Test encoding to decode the downloaded bytes. Default is UTF-8.
         :rtype: str
         """
         warnings.warn(
             "content_as_text is deprecated, use readall instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
         self._encoding = encoding
         return await self.readall()
 
     async def readinto(self, stream):
-        """Download the contents of this blob to a stream.
+        """Download the contents of this file to a stream.
 
         :param stream:
             The stream to download to. This can be an open file-handle,
             or any writable stream. The stream must be seekable if the download
             uses more than one parallel connection.
         :returns: The number of bytes read.
         :rtype: int
@@ -472,82 +401,65 @@
             try:
                 stream.seek(stream.tell())
             except (NotImplementedError, AttributeError):
                 raise ValueError(error_message)
 
         # Write the content to the user stream
         stream.write(self._current_content)
-        if self._progress_hook:
-            await self._progress_hook(len(self._current_content), self.size)
-
         if self._download_complete:
             return self.size
 
         data_end = self._file_size
         if self._end_range is not None:
             # Use the length unless it is over the end of the file
             data_end = min(self._file_size, self._end_range + 1)
 
         downloader = _AsyncChunkDownloader(
-            client=self._clients.blob,
-            non_empty_ranges=self._non_empty_ranges,
+            client=self._client,
             total_size=self.size,
             chunk_size=self._config.max_chunk_get_size,
             current_progress=self._first_get_size,
             start_range=self._initial_range[1] + 1,  # start where the first download ended
             end_range=data_end,
             stream=stream,
             parallel=parallel,
             validate_content=self._validate_content,
             encryption_options=self._encryption_options,
             use_location=self._location_mode,
-            progress_hook=self._progress_hook,
             **self._request_options)
 
         dl_tasks = downloader.get_chunk_offsets()
         running_futures = [
             asyncio.ensure_future(downloader.process_chunk(d))
             for d in islice(dl_tasks, 0, self._max_concurrency)
         ]
         while running_futures:
             # Wait for some download to finish before adding a new one
-            done, running_futures = await asyncio.wait(
+            _done, running_futures = await asyncio.wait(
                 running_futures, return_when=asyncio.FIRST_COMPLETED)
             try:
-                for task in done:
-                    task.result()
-            except HttpResponseError as error:
-                process_storage_error(error)
-            try:
                 next_chunk = next(dl_tasks)
             except StopIteration:
                 break
             else:
                 running_futures.add(asyncio.ensure_future(downloader.process_chunk(next_chunk)))
 
         if running_futures:
             # Wait for the remaining downloads to finish
-            done, _running_futures = await asyncio.wait(running_futures)
-            try:
-                for task in done:
-                    task.result()
-            except HttpResponseError as error:
-                process_storage_error(error)
+            await asyncio.wait(running_futures)
         return self.size
 
     async def download_to_stream(self, stream, max_concurrency=1):
-        """Download the contents of this blob to a stream.
+        """Download the contents of this file to a stream.
 
         :param stream:
             The stream to download to. This can be an open file-handle,
             or any writable stream. The stream must be seekable if the download
             uses more than one parallel connection.
-        :param int max_concurrency:
-            The number of parallel connections with which to download.
-        :returns: The properties of the downloaded blob.
+        :returns: The properties of the downloaded file.
         :rtype: Any
         """
         warnings.warn(
             "download_to_stream is deprecated, use readinto instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_lease_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_list_blobs_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_list_blobs_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -83,15 +83,14 @@
     :ivar int results_per_page: The maximum number of results retrieved per API call.
     :ivar str continuation_token: The continuation token to retrieve the next page of results.
     :ivar str location_mode: The location mode being used to list results. The available
         options include "primary" and "secondary".
     :ivar current_page: The current page of listed results.
     :vartype current_page: list(~azure.storage.blob.BlobProperties)
     :ivar str container: The container that the blobs are listed from.
-
     :param callable command: Function to retrieve the next page of items.
     :param str container: The name of the container.
     :param int results_per_page: The maximum number of blobs to retrieve per
         call.
     :param str continuation_token: An opaque continuation token.
     :param location_mode: Specifies the location the request should be sent to.
         This mode only applies for RA-GRS accounts which allow secondary read access.
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_06_08/aio/_upload_helpers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_upload_helpers.py`

 * *Files 14% similar despite different names*

```diff
@@ -2,42 +2,72 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=no-self-use
 
 from io import SEEK_SET, UnsupportedOperation
-from typing import Optional, Union, Any, TypeVar, TYPE_CHECKING # pylint: disable=unused-import
+from typing import TypeVar, TYPE_CHECKING
 
-import six
-from azure.core.exceptions import ResourceModifiedError, HttpResponseError
+from azure.core.exceptions import ResourceExistsError, ResourceModifiedError, HttpResponseError
 
-from .._shared.response_handlers import (
-    process_storage_error,
-    return_response_headers)
-from .._shared.uploads_async import (
+from ._shared.response_handlers import process_storage_error, return_response_headers
+from ._shared.models import StorageErrorCode
+from ._shared.uploads import (
     upload_data_chunks,
     upload_substream_blocks,
     BlockBlobChunkUploader,
     PageBlobChunkUploader,
-    AppendBlobChunkUploader)
-from .._shared.encryption import generate_blob_encryption_data, encrypt_blob
-from .._generated.models import (
+    AppendBlobChunkUploader
+)
+from ._generated.models import (
     BlockLookupList,
     AppendPositionAccessConditions,
     ModifiedAccessConditions,
 )
-from .._upload_helpers import _convert_mod_error, _any_conditions
+from ._encryption import (
+    GCMBlobEncryptionStream,
+    encrypt_blob,
+    get_adjusted_upload_size,
+    get_blob_encryptor_and_padder,
+    generate_blob_encryption_data,
+    _ENCRYPTION_PROTOCOL_V1,
+    _ENCRYPTION_PROTOCOL_V2
+)
 
 if TYPE_CHECKING:
-    from datetime import datetime # pylint: disable=unused-import
     BlobLeaseClient = TypeVar("BlobLeaseClient")
 
+_LARGE_BLOB_UPLOAD_MAX_READ_BUFFER_SIZE = 4 * 1024 * 1024
+_ERROR_VALUE_SHOULD_BE_SEEKABLE_STREAM = '{0} should be a seekable file-like/io.IOBase type stream object.'
+
+
+def _convert_mod_error(error):
+    message = error.message.replace(
+        "The condition specified using HTTP conditional header(s) is not met.",
+        "The specified blob already exists.")
+    message = message.replace("ConditionNotMet", "BlobAlreadyExists")
+    overwrite_error = ResourceExistsError(
+        message=message,
+        response=error.response,
+        error=error)
+    overwrite_error.error_code = StorageErrorCode.blob_already_exists
+    raise overwrite_error
+
+
+def _any_conditions(modified_access_conditions=None, **kwargs):  # pylint: disable=unused-argument
+    return any([
+        modified_access_conditions.if_modified_since,
+        modified_access_conditions.if_unmodified_since,
+        modified_access_conditions.if_none_match,
+        modified_access_conditions.if_match
+    ])
 
-async def upload_block_blob(  # pylint: disable=too-many-locals
+
+def upload_block_blob(  # pylint: disable=too-many-locals, too-many-statements
         client=None,
         data=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
@@ -46,37 +76,38 @@
         encryption_options=None,
         **kwargs):
     try:
         if not overwrite and not _any_conditions(**kwargs):
             kwargs['modified_access_conditions'].if_none_match = '*'
         adjusted_count = length
         if (encryption_options.get('key') is not None) and (adjusted_count is not None):
-            adjusted_count += (16 - (length % 16))
+            adjusted_count = get_adjusted_upload_size(adjusted_count, encryption_options['version'])
         blob_headers = kwargs.pop('blob_headers', None)
         tier = kwargs.pop('standard_blob_tier', None)
         blob_tags_string = kwargs.pop('blob_tags_string', None)
 
         immutability_policy = kwargs.pop('immutability_policy', None)
         immutability_policy_expiry = None if immutability_policy is None else immutability_policy.expiry_time
         immutability_policy_mode = None if immutability_policy is None else immutability_policy.policy_mode
         legal_hold = kwargs.pop('legal_hold', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
-        # Do single put if the size is smaller than config.max_single_put_size
+        # Do single put if the size is smaller than or equal config.max_single_put_size
         if adjusted_count is not None and (adjusted_count <= blob_settings.max_single_put_size):
             try:
                 data = data.read(length)
-                if not isinstance(data, six.binary_type):
+                if not isinstance(data, bytes):
                     raise TypeError('Blob data should be of type bytes.')
             except AttributeError:
                 pass
             if encryption_options.get('key'):
-                encryption_data, data = encrypt_blob(data, encryption_options['key'])
+                encryption_data, data = encrypt_blob(data, encryption_options['key'], encryption_options['version'])
                 headers['x-ms-meta-encryptiondata'] = encryption_data
-            response = await client.upload(
+
+            response = client.upload(
                 body=data,
                 content_length=adjusted_count,
                 blob_http_headers=blob_headers,
                 headers=headers,
                 cls=return_response_headers,
                 validate_content=validate_content,
                 data_stream_total=adjusted_count,
@@ -85,60 +116,74 @@
                 blob_tags_string=blob_tags_string,
                 immutability_policy_expiry=immutability_policy_expiry,
                 immutability_policy_mode=immutability_policy_mode,
                 legal_hold=legal_hold,
                 **kwargs)
 
             if progress_hook:
-                await progress_hook(adjusted_count, adjusted_count)
+                progress_hook(adjusted_count, adjusted_count)
 
             return response
 
         use_original_upload_path = blob_settings.use_byte_buffer or \
             validate_content or encryption_options.get('required') or \
             blob_settings.max_block_size < blob_settings.min_large_block_upload_threshold or \
             hasattr(stream, 'seekable') and not stream.seekable() or \
             not hasattr(stream, 'seek') or not hasattr(stream, 'tell')
 
         if use_original_upload_path:
-            if encryption_options.get('key'):
-                cek, iv, encryption_data = generate_blob_encryption_data(encryption_options['key'])
+            total_size = length
+            encryptor, padder = None, None
+            if encryption_options and encryption_options.get('key'):
+                cek, iv, encryption_data = generate_blob_encryption_data(
+                    encryption_options['key'],
+                    encryption_options['version'])
                 headers['x-ms-meta-encryptiondata'] = encryption_data
-                encryption_options['cek'] = cek
-                encryption_options['vector'] = iv
-            block_ids = await upload_data_chunks(
+
+                if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V1:
+                    encryptor, padder = get_blob_encryptor_and_padder(cek, iv, True)
+
+                # Adjust total_size for encryption V2
+                if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V2:
+                    # Adjust total_size for encryption V2
+                    total_size = adjusted_count
+                    # V2 wraps the data stream with an encryption stream
+                    stream = GCMBlobEncryptionStream(cek, stream)
+
+            block_ids = upload_data_chunks(
                 service=client,
                 uploader_class=BlockBlobChunkUploader,
-                total_size=length,
+                total_size=total_size,
                 chunk_size=blob_settings.max_block_size,
                 max_concurrency=max_concurrency,
                 stream=stream,
                 validate_content=validate_content,
-                encryption_options=encryption_options,
                 progress_hook=progress_hook,
+                encryptor=encryptor,
+                padder=padder,
                 headers=headers,
                 **kwargs
             )
         else:
-            block_ids = await upload_substream_blocks(
+            block_ids = upload_substream_blocks(
                 service=client,
                 uploader_class=BlockBlobChunkUploader,
                 total_size=length,
                 chunk_size=blob_settings.max_block_size,
                 max_concurrency=max_concurrency,
                 stream=stream,
                 validate_content=validate_content,
                 progress_hook=progress_hook,
                 headers=headers,
                 **kwargs
             )
 
         block_lookup = BlockLookupList(committed=[], uncommitted=[], latest=[])
         block_lookup.latest = block_ids
-        return await client.commit_block_list(
+        return client.commit_block_list(
             block_lookup,
             blob_http_headers=blob_headers,
             cls=return_response_headers,
             validate_content=validate_content,
             headers=headers,
             tier=tier.value if tier else None,
             blob_tags_string=blob_tags_string,
@@ -151,15 +196,15 @@
             process_storage_error(error)
         except ResourceModifiedError as mod_error:
             if not overwrite:
                 _convert_mod_error(mod_error)
             raise
 
 
-async def upload_page_blob(
+def upload_page_blob(
         client=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
         max_concurrency=None,
@@ -170,61 +215,73 @@
         if not overwrite and not _any_conditions(**kwargs):
             kwargs['modified_access_conditions'].if_none_match = '*'
         if length is None or length < 0:
             raise ValueError("A content length must be specified for a Page Blob.")
         if length % 512 != 0:
             raise ValueError("Invalid page blob size: {0}. "
                              "The size must be aligned to a 512-byte boundary.".format(length))
+        tier = None
         if kwargs.get('premium_page_blob_tier'):
             premium_page_blob_tier = kwargs.pop('premium_page_blob_tier')
             try:
-                headers['x-ms-access-tier'] = premium_page_blob_tier.value
+                tier = premium_page_blob_tier.value
             except AttributeError:
-                headers['x-ms-access-tier'] = premium_page_blob_tier
-        if encryption_options and encryption_options.get('data'):
-            headers['x-ms-meta-encryptiondata'] = encryption_options['data']
+                tier = premium_page_blob_tier
+
+        if encryption_options and encryption_options.get('key'):
+            cek, iv, encryption_data = generate_blob_encryption_data(
+                encryption_options['key'],
+                encryption_options['version'])
+            headers['x-ms-meta-encryptiondata'] = encryption_data
+
         blob_tags_string = kwargs.pop('blob_tags_string', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
-        response = await client.create(
+        response = client.create(
             content_length=0,
             blob_content_length=length,
             blob_sequence_number=None,
             blob_http_headers=kwargs.pop('blob_headers', None),
             blob_tags_string=blob_tags_string,
+            tier=tier,
             cls=return_response_headers,
             headers=headers,
             **kwargs)
         if length == 0:
             return response
 
+        if encryption_options and encryption_options.get('key'):
+            if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V1:
+                encryptor, padder = get_blob_encryptor_and_padder(cek, iv, False)
+                kwargs['encryptor'] = encryptor
+                kwargs['padder'] = padder
+
         kwargs['modified_access_conditions'] = ModifiedAccessConditions(if_match=response['etag'])
-        return await upload_data_chunks(
+        return upload_data_chunks(
             service=client,
             uploader_class=PageBlobChunkUploader,
             total_size=length,
             chunk_size=blob_settings.max_page_size,
             stream=stream,
             max_concurrency=max_concurrency,
             validate_content=validate_content,
-            encryption_options=encryption_options,
             progress_hook=progress_hook,
             headers=headers,
             **kwargs)
 
     except HttpResponseError as error:
         try:
             process_storage_error(error)
         except ResourceModifiedError as mod_error:
             if not overwrite:
                 _convert_mod_error(mod_error)
             raise
 
 
-async def upload_append_blob(  # pylint: disable=unused-argument
+def upload_append_blob(  # pylint: disable=unused-argument
         client=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
         max_concurrency=None,
@@ -239,21 +296,21 @@
             max_size=kwargs.pop('maxsize_condition', None),
             append_position=None)
         blob_tags_string = kwargs.pop('blob_tags_string', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
         try:
             if overwrite:
-                await client.create(
+                client.create(
                     content_length=0,
                     blob_http_headers=blob_headers,
                     headers=headers,
                     blob_tags_string=blob_tags_string,
                     **kwargs)
-            return await upload_data_chunks(
+            return upload_data_chunks(
                 service=client,
                 uploader_class=AppendBlobChunkUploader,
                 total_size=length,
                 chunk_size=blob_settings.max_block_size,
                 stream=stream,
                 max_concurrency=max_concurrency,
                 validate_content=validate_content,
@@ -268,21 +325,21 @@
             if hasattr(stream, 'read'):
                 try:
                     # attempt to rewind the body to the initial position
                     stream.seek(0, SEEK_SET)
                 except UnsupportedOperation:
                     # if body is not seekable, then retry would not work
                     raise error
-            await client.create(
+            client.create(
                 content_length=0,
                 blob_http_headers=blob_headers,
                 headers=headers,
                 blob_tags_string=blob_tags_string,
                 **kwargs)
-            return await upload_data_chunks(
+            return upload_data_chunks(
                 service=client,
                 uploader_class=AppendBlobChunkUploader,
                 total_size=length,
                 chunk_size=blob_settings.max_block_size,
                 stream=stream,
                 max_concurrency=max_concurrency,
                 validate_content=validate_content,
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_blob_client.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,29 +4,30 @@
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-lines,no-self-use
 
 from functools import partial
 from io import BytesIO
 from typing import (
-    Any, AnyStr, Dict, IO, Iterable, List, Optional, overload, Tuple, Type, TypeVar, Union,
+    Any, AnyStr, AsyncIterable, Dict, IO, Iterable, List, Optional, overload, Tuple, Union,
     TYPE_CHECKING
 )
 from urllib.parse import urlparse, quote, unquote
 import warnings
 
-import six
+from typing_extensions import Self
+
 from azure.core.exceptions import ResourceNotFoundError, HttpResponseError, ResourceExistsError
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import Pipeline
 from azure.core.tracing.decorator import distributed_trace
-
 from ._shared import encode_base64
 from ._shared.base_client import StorageAccountHostsMixin, parse_connection_str, parse_query, TransportWrapper
 from ._shared.uploads import IterStreamer
+from ._shared.uploads_async import AsyncIterStreamer
 from ._shared.request_handlers import (
     add_metadata_headers, get_length, read_length,
     validate_and_format_range_headers)
 from ._shared.response_handlers import return_response_headers, process_storage_error, return_headers_and_deserialized
 from ._generated import AzureBlobStorage
 from ._generated.models import (
     DeleteSnapshotsOptionType,
@@ -62,30 +63,29 @@
     upload_block_blob,
     upload_append_blob,
     upload_page_blob,
     _any_conditions
 )
 
 if TYPE_CHECKING:
+    from azure.core.credentials import AzureNamedKeyCredential, AzureSasCredential, TokenCredential
     from datetime import datetime
     from ._generated.models import BlockList
     from ._models import (
         ContentSettings,
         ImmutabilityPolicy,
         PremiumPageBlobTier,
         StandardBlobTier,
         SequenceNumberAction
     )
 
 _ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION = (
     'The require_encryption flag is set, but encryption is not supported'
     ' for this method.')
 
-ClassType = TypeVar("ClassType")
-
 
 class BlobClient(StorageAccountHostsMixin, StorageEncryptionMixin):  # pylint: disable=too-many-public-methods
     """A client to interact with a specific blob, although that blob may not yet exist.
 
     For more optional configuration, please click
     `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
     #optional-configuration>`_.
@@ -145,22 +145,21 @@
             :start-after: [START create_blob_client_sas_url]
             :end-before: [END create_blob_client_sas_url]
             :language: python
             :dedent: 8
             :caption: Creating the BlobClient from a SAS URL to a blob.
     """
     def __init__(
-            self, account_url,  # type: str
-            container_name,  # type: str
-            blob_name,  # type: str
-            snapshot=None,  # type: Optional[Union[str, Dict[str, Any]]]
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):
-        # type: (...) -> None
+            self, account_url: str,
+            container_name: str,
+            blob_name: str,
+            snapshot: Optional[Union[str, Dict[str, Any]]] = None,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> None:
         try:
             if not account_url.lower().startswith('http'):
                 account_url = "https://" + account_url
         except AttributeError:
             raise ValueError("Account URL must be a string.")
         parsed_url = urlparse(account_url.rstrip('/'))
 
@@ -187,15 +186,15 @@
         super(BlobClient, self).__init__(parsed_url, service='blob', credential=credential, **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
         self._configure_encryption(kwargs)
 
     def _format_url(self, hostname):
         container_name = self.container_name
-        if isinstance(container_name, six.text_type):
+        if isinstance(container_name, str):
             container_name = container_name.encode('UTF-8')
         return "{}://{}/{}/{}{}".format(
             self.scheme,
             hostname,
             quote(container_name),
             quote(self.blob_name, safe='~/'),
             self._query_str)
@@ -209,20 +208,19 @@
         result = ["{}://{}{}".format(source_scheme, source_hostname, quote(source_path, safe='~/'))]
         if source_query:
             result.append(source_query)
         return '?'.join(result)
 
     @classmethod
     def from_blob_url(
-            cls,  # type: Type[ClassType]
-            blob_url,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            snapshot=None,  # type: Optional[Union[str, Dict[str, Any]]]
-            **kwargs  # type: Any
-        ):  # type: (...) -> ClassType
+            cls, blob_url: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            snapshot: Optional[Union[str, Dict[str, Any]]] = None,
+            **kwargs: Any
+        ) -> Self:
         """Create BlobClient from a blob url. This doesn't support customized blob url with '/' in blob name.
 
         :param str blob_url:
             The full endpoint URL to the Blob, including SAS token and snapshot if used. This could be
             either the primary endpoint, or the secondary endpoint depending on the current `location_mode`.
         :type blob_url: str
         :param credential:
@@ -291,22 +289,21 @@
         return cls(
             account_url, container_name=container_name, blob_name=blob_name,
             snapshot=path_snapshot, credential=credential, **kwargs
         )
 
     @classmethod
     def from_connection_string(
-            cls,  # type: Type[ClassType]
-            conn_str,  # type: str
-            container_name,  # type: str
-            blob_name,  # type: str
-            snapshot=None,  # type: Optional[str]
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):  # type: (...) -> ClassType
+            cls, conn_str: str,
+            container_name: str,
+            blob_name: str,
+            snapshot: Optional[Union[str, Dict[str, Any]]] = None,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> Self:
         """Create BlobClient from a Connection String.
 
         :param str conn_str:
             A connection string to an Azure Storage account.
         :param container_name: The container name for the blob.
         :type container_name: str
         :param blob_name: The name of the blob with which to interact.
@@ -356,44 +353,45 @@
         """
         try:
             return self._client.blob.get_account_info(cls=return_response_headers, **kwargs) # type: ignore
         except HttpResponseError as error:
             process_storage_error(error)
 
     def _upload_blob_options(  # pylint:disable=too-many-statements
-            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
-            blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
-            length=None,  # type: Optional[int]
-            metadata=None,  # type: Optional[Dict[str, str]]
+            self, data: Union[bytes, str, Iterable[AnyStr], AsyncIterable[AnyStr], IO[AnyStr]],
+            blob_type: Union[str, BlobType] = BlobType.BlockBlob,
+            length: Optional[int] = None,
+            metadata: Optional[Dict[str, str]] = None,
             **kwargs
-        ):
-        # type: (...) -> Dict[str, Any]
+        ) -> Dict[str, Any]:
         if self.require_encryption and not self.key_encryption_key:
             raise ValueError("Encryption required but no key was provided.")
         encryption_options = {
             'required': self.require_encryption,
             'version': self.encryption_version,
             'key': self.key_encryption_key,
             'resolver': self.key_resolver_function,
         }
 
         encoding = kwargs.pop('encoding', 'UTF-8')
-        if isinstance(data, six.text_type):
-            data = data.encode(encoding) # type: ignore
+        if isinstance(data, str):
+            data = data.encode(encoding)
         if length is None:
             length = get_length(data)
         if isinstance(data, bytes):
             data = data[:length]
 
         if isinstance(data, bytes):
             stream = BytesIO(data)
         elif hasattr(data, 'read'):
             stream = data
         elif hasattr(data, '__iter__') and not isinstance(data, (list, tuple, set, dict)):
             stream = IterStreamer(data, encoding=encoding)
+        elif hasattr(data, '__aiter__'):
+            stream = AsyncIterStreamer(data, encoding=encoding)
         else:
             raise TypeError("Unsupported data type: {}".format(type(data)))
 
         validate_content = kwargs.pop('validate_content', False)
         content_settings = kwargs.pop('content_settings', None)
         overwrite = kwargs.pop('overwrite', False)
         max_concurrency = kwargs.pop('max_concurrency', 1)
@@ -557,15 +555,19 @@
             The destination match condition to use upon the etag.
         :keyword destination_lease:
             The lease ID specified for this header must match the lease ID of the
             destination blob. If the request does not include the lease ID or it is not
             valid, the operation fails with status code 412 (Precondition Failed).
         :paramtype destination_lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword ~azure.storage.blob.ContentSettings content_settings:
             ContentSettings object used to set blob properties. Used to set content type, encoding,
             language, disposition, md5, and cache control.
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
@@ -587,22 +589,21 @@
             **kwargs)
         try:
             return self._client.block_blob.put_blob_from_url(**options)
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace
-    def upload_blob(  # pylint: disable=too-many-locals
-            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
-            blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
-            length=None,  # type: Optional[int]
-            metadata=None,  # type: Optional[Dict[str, str]]
+    def upload_blob(
+            self, data: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]],
+            blob_type: Union[str, BlobType] = BlobType.BlockBlob,
+            length: Optional[int] = None,
+            metadata: Optional[Dict[str, str]] = None,
             **kwargs
-        ):
-        # type: (...) -> Any
+        ) -> Dict[str, Any]:
         """Creates a new blob from a data source with automatic chunking.
 
         :param data: The blob data to upload.
         :param ~azure.storage.blob.BlobType blob_type: The type of the blob. This can be
             either BlockBlob, PageBlob or AppendBlob. The default value is BlockBlob.
         :param int length:
             Number of bytes to read from the stream. This is optional, but
@@ -713,17 +714,20 @@
             Defaults to UTF-8.
         :keyword progress_hook:
             A callback to track the progress of a long running upload. The signature is
             function(current: int, total: Optional[int]) where current is the number of bytes transfered
             so far, and total is the size of the blob or None if the size is unknown.
         :paramtype progress_hook: Callable[[int, Optional[int]], None]
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
-            multiple calls to the Azure service and the timeout will apply to
-            each call individually.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
         :returns: Blob-updated property dict (Etag and last modified)
         :rtype: dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_hello_world.py
                 :start-after: [START upload_a_blob]
@@ -878,15 +882,20 @@
             Encoding to decode the downloaded bytes. Default is None, i.e. no decoding.
         :keyword progress_hook:
             A callback to track the progress of a long running download. The signature is
             function(current: int, total: int) where current is the number of bytes transfered
             so far, and total is the total size of the download.
         :paramtype progress_hook: Callable[[int, int], None]
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :returns: A streaming object (StorageStreamDownloader)
         :rtype: ~azure.storage.blob.StorageStreamDownloader
 
         .. admonition:: Example:
 
@@ -1024,15 +1033,19 @@
 
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
             a secure connection must be established to transfer the key.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A streaming object (BlobQueryReader)
         :rtype: ~azure.storage.blob.BlobQueryReader
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_query.py
                 :start-after: [START query]
@@ -1137,15 +1150,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_hello_world.py
                 :start-after: [START delete_blob]
                 :end-before: [END delete_blob]
@@ -1163,16 +1180,24 @@
     def undelete_blob(self, **kwargs):
         # type: (**Any) -> None
         """Restores soft-deleted blobs or snapshots.
 
         Operation will only be successful if used within the specified number of days
         set in the delete retention policy.
 
+        If blob versioning is enabled, the base blob cannot be restored using this
+        method. Instead use :func:`start_copy_from_url` with the URL of the blob version
+        you wish to promote to the current version.
+
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common.py
                 :start-after: [START undelete_blob]
                 :end-before: [END undelete_blob]
@@ -1188,19 +1213,23 @@
     @distributed_trace()
     def exists(self, **kwargs):
         # type: (**Any) -> bool
         """
         Returns True if a blob exists with the defined parameters, and returns
         False otherwise.
 
-        :kwarg str version_id:
+        :keyword str version_id:
             The version id parameter is an opaque DateTime
             value that, when present, specifies the version of the blob to check if it exists.
-        :kwarg int timeout:
-            The timeout parameter is expressed in seconds.
+        :keyword int timeout:
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: boolean
         """
         try:
             self._client.blob.get_properties(
                 snapshot=self.snapshot,
                 **kwargs)
             return True
@@ -1255,15 +1284,19 @@
 
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
             a secure connection must be established to transfer the key.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: BlobProperties
         :rtype: ~azure.storage.blob.BlobProperties
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common.py
                 :start-after: [START get_blob_properties]
@@ -1360,15 +1393,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified)
         :rtype: Dict[str, Any]
         """
         options = self._set_http_headers_options(content_settings=content_settings, **kwargs)
         try:
             return self._client.blob.set_http_headers(**options) # type: ignore
         except HttpResponseError as error:
@@ -1447,15 +1484,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified)
         """
         options = self._set_blob_metadata_options(metadata=metadata, **kwargs)
         try:
             return self._client.blob.set_metadata(**options)  # type: ignore
         except HttpResponseError as error:
             process_storage_error(error)
@@ -1471,15 +1512,19 @@
         :param ~azure.storage.blob.ImmutabilityPolicy immutability_policy:
             Specifies the immutability policy of a blob, blob snapshot or blob version.
 
             .. versionadded:: 12.10.0
                 This was introduced in API version '2020-10-02'.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, str]
         """
 
         kwargs['immutability_policy_expiry'] = immutability_policy.expiry_time
         kwargs['immutability_policy_mode'] = immutability_policy.policy_mode
         return self._client.blob.set_immutability_policy(cls=return_response_headers, **kwargs)
@@ -1489,15 +1534,19 @@
         # type: (**Any) -> None
         """The Delete Immutability Policy operation deletes the immutability policy on the blob.
 
         .. versionadded:: 12.10.0
             This operation was introduced in API version '2020-10-02'.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, str]
         """
 
         self._client.blob.delete_immutability_policy(**kwargs)
 
     @distributed_trace
@@ -1507,15 +1556,19 @@
 
         .. versionadded:: 12.10.0
             This operation was introduced in API version '2020-10-02'.
 
         :param bool legal_hold:
             Specified if a legal hold should be set on the blob.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, Union[str, datetime, bool]]
         """
 
         return self._client.blob.set_legal_hold(legal_hold, cls=return_response_headers, **kwargs)
 
     def _create_page_blob_options(  # type: ignore
@@ -1665,15 +1718,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict[str, Any]
         """
         options = self._create_page_blob_options(
             size,
             content_settings=content_settings,
             metadata=metadata,
@@ -1797,15 +1854,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict[str, Any]
         """
         options = self._create_append_blob_options(
             content_settings=content_settings,
             metadata=metadata,
             **kwargs)
@@ -1892,15 +1953,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Snapshot ID, Etag, and last modified).
         :rtype: dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common.py
                 :start-after: [START create_blob_snapshot]
@@ -2119,15 +2184,19 @@
             valid, the operation fails with status code 412 (Precondition Failed).
         :paramtype destination_lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword source_lease:
             Specify this to perform the Copy Blob operation only if
             the lease ID given matches the active lease ID of the source blob.
         :paramtype source_lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword ~azure.storage.blob.PremiumPageBlobTier premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
             premium storage accounts.
         :keyword ~azure.storage.blob.StandardBlobTier standard_blob_tier:
             A standard blob tier value to set the blob to. For this version of the library,
             this is only applicable to block blobs on standard storage accounts.
@@ -2262,15 +2331,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A BlobLeaseClient object.
         :rtype: ~azure.storage.blob.BlobLeaseClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common.py
                 :start-after: [START acquire_lease_on_blob]
@@ -2309,15 +2382,19 @@
             This keyword argument was introduced in API version '2019-12-12'.
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :rtype: None
         """
         access_conditions = get_access_conditions(kwargs.pop('lease', None))
@@ -2343,15 +2420,15 @@
             length=None,  # type: Optional[int]
             **kwargs
         ):
         # type: (...) -> Dict[str, Any]
         if self.require_encryption or (self.key_encryption_key is not None):
             raise ValueError(_ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION)
         block_id = encode_base64(str(block_id))
-        if isinstance(data, six.text_type):
+        if isinstance(data, str):
             data = data.encode(kwargs.pop('encoding', 'UTF-8'))  # type: ignore
         access_conditions = get_access_conditions(kwargs.pop('lease', None))
         if length is None:
             length = get_length(data)
             if length is None:
                 length, data = read_length(data)
         if isinstance(data, bytes):
@@ -2422,15 +2499,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob property dict.
         :rtype: dict[str, Any]
         """
         options = self._stage_block_options(
             block_id,
             data,
             length=length,
@@ -2522,15 +2603,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword str source_authorization:
             Authenticate as a service principal using a client secret to access a source blob. Ensure "bearer " is
             the prefix of the source_authorization string.
         :returns: Blob property dict.
         :rtype: dict[str, Any]
         """
         options = self._stage_block_from_url_options(
@@ -2571,15 +2656,19 @@
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on destination blob with a matching value.
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A tuple of two lists - committed and uncommitted blocks
         :rtype: tuple(list(~azure.storage.blob.BlobBlock), list(~azure.storage.blob.BlobBlock))
         """
         access_conditions = get_access_conditions(kwargs.pop('lease', None))
         mod_conditions = get_modify_conditions(kwargs)
         try:
             blocks = self._client.block_blob.get_block_list(
@@ -2750,15 +2839,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._commit_block_list_options(
             block_list,
             content_settings=content_settings,
             metadata=metadata,
@@ -2781,17 +2874,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
-            multiple calls to the Azure service and the timeout will apply to
-            each call individually.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :rtype: None
         """
         access_conditions = get_access_conditions(kwargs.pop('lease', None))
@@ -2853,15 +2948,19 @@
             Specify a SQL where clause on blob tags to operate only on destination blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified)
         :rtype: Dict[str, Any]
         """
         options = self._set_blob_tags_options(tags=tags, **kwargs)
         try:
             return self._client.blob.set_tags(**options)
         except HttpResponseError as error:
@@ -2896,15 +2995,19 @@
             Specify a SQL where clause on blob tags to operate only on destination blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, str]
         """
         options = self._get_blob_tags_options(**kwargs)
         try:
             _, tags = self._client.blob.get_tags(**options)
             return parse_tags(tags) # pylint: disable=protected-access
@@ -2997,15 +3100,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns:
             A tuple of two lists of page ranges as dictionaries with 'start' and 'end' keys.
             The first element are filled page ranges, the 2nd element is cleared page ranges.
         :rtype: tuple(list(dict(str, str), list(dict(str, str))
         """
         warnings.warn(
             "get_page_ranges is deprecated, use list_page_ranges instead",
@@ -3085,15 +3192,19 @@
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int results_per_page:
             The maximum number of page ranges to retrieve per API call.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) of PageRange.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.PageRange]
         """
         results_per_page = kwargs.pop('results_per_page', None)
         options = self._get_page_ranges_options(
             offset=offset,
             length=length,
@@ -3164,15 +3275,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns:
             A tuple of two lists of page ranges as dictionaries with 'start' and 'end' keys.
             The first element are filled page ranges, the 2nd element is cleared page ranges.
         :rtype: tuple(list(dict(str, str), list(dict(str, str))
         """
         options = self._get_page_ranges_options(
             offset=offset,
@@ -3237,15 +3352,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._set_sequence_number_options(
             sequence_number_action, sequence_number=sequence_number, **kwargs)
         try:
             return self._client.page_blob.update_sequence_number(**options) # type: ignore
@@ -3315,15 +3434,19 @@
             .. versionadded:: 12.4.0
 
         :keyword ~azure.storage.blob.PremiumPageBlobTier premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
             premium storage accounts.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._resize_blob_options(size, **kwargs)
         try:
             return self._client.page_blob.resize(**options) # type: ignore
         except HttpResponseError as error:
@@ -3332,15 +3455,15 @@
     def _upload_page_options( # type: ignore
             self, page,  # type: bytes
             offset,  # type: int
             length,  # type: int
             **kwargs
         ):
         # type: (...) -> Dict[str, Any]
-        if isinstance(page, six.text_type):
+        if isinstance(page, str):
             page = page.encode(kwargs.pop('encoding', 'UTF-8'))
         if self.require_encryption or (self.key_encryption_key is not None):
             raise ValueError(_ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION)
 
         if offset is None or offset % 512 != 0:
             raise ValueError("offset must be an integer that aligns with 512 page size")
         if length is None or length % 512 != 0:
@@ -3456,15 +3579,19 @@
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword str encoding:
             Defaults to UTF-8.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._upload_page_options(
             page=page,
             offset=offset,
             length=length,
@@ -3628,15 +3755,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword str source_authorization:
             Authenticate as a service principal using a client secret to access a source blob. Ensure "bearer " is
             the prefix of the source_authorization string.
         """
         options = self._upload_pages_from_url_options(
             source_url=self._encode_source_url(source_url),
             offset=offset,
@@ -3740,15 +3871,19 @@
 
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
             a secure connection must be established to transfer the key.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._clear_page_options(offset, length, **kwargs)
         try:
             return self._client.page_blob.clear_pages(**options)  # type: ignore
         except HttpResponseError as error:
@@ -3759,15 +3894,15 @@
             length=None,  # type: Optional[int]
             **kwargs
         ):
         # type: (...) -> Dict[str, Any]
         if self.require_encryption or (self.key_encryption_key is not None):
             raise ValueError(_ERROR_UNSUPPORTED_METHOD_FOR_ENCRYPTION)
 
-        if isinstance(data, six.text_type):
+        if isinstance(data, str):
             data = data.encode(kwargs.pop('encoding', 'UTF-8')) # type: ignore
         if length is None:
             length = get_length(data)
             if length is None:
                 length, data = read_length(data)
         if length == 0:
             return {}
@@ -3880,15 +4015,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag, last modified, append offset, committed block count).
         :rtype: dict(str, Any)
         """
         options = self._append_block_options(
             data,
             length=length,
             **kwargs
@@ -4044,15 +4183,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword str source_authorization:
             Authenticate as a service principal using a client secret to access a source blob. Ensure "bearer " is
             the prefix of the source_authorization string.
         """
         options = self._append_block_from_url_options(
             copy_source_url=self._encode_source_url(copy_source_url),
             source_offset=source_offset,
@@ -4118,15 +4261,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag, last modified, append offset, committed block count).
         :rtype: dict(str, Any)
         """
         options = self._seal_append_blob_options(**kwargs)
         try:
             return self._client.append_blob.seal(**options) # type: ignore
         except HttpResponseError as error:
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_blob_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_blob_service_client.py`

 * *Files 12% similar despite different names*

```diff
@@ -2,25 +2,26 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
 import functools
 import warnings
-from typing import (  # pylint: disable=unused-import
-    Any, Dict, List, Optional, TypeVar, Union,
+from typing import (
+    Any, Dict, List, Optional, Union,
     TYPE_CHECKING
 )
 from urllib.parse import urlparse
 
+from typing_extensions import Self
+
 from azure.core.exceptions import HttpResponseError
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import Pipeline
 from azure.core.tracing.decorator import distributed_trace
-
 from ._shared.base_client import StorageAccountHostsMixin, TransportWrapper, parse_connection_str, parse_query
 from ._shared.models import LocationMode
 from ._shared.parser import _to_utc_datetime
 from ._shared.response_handlers import (
     return_response_headers,
     process_storage_error,
     parse_to_internal_user_delegation_key
@@ -32,14 +33,15 @@
 from ._deserialize import service_stats_deserialize, service_properties_deserialize
 from ._encryption import StorageEncryptionMixin
 from ._list_blobs_helper import FilteredBlobPaged
 from ._models import ContainerPropertiesPaged
 from ._serialize import get_api_version
 
 if TYPE_CHECKING:
+    from azure.core.credentials import AzureNamedKeyCredential, AzureSasCredential, TokenCredential
     from datetime import datetime
     from ._shared.models import UserDelegationKey
     from ._lease import BlobLeaseClient
     from ._models import (
         ContainerProperties,
         BlobProperties,
         PublicAccess,
@@ -47,16 +49,14 @@
         Metrics,
         CorsRule,
         RetentionPolicy,
         StaticWebsite,
         FilteredBlob
     )
 
-ClassType = TypeVar("ClassType")
-
 
 class BlobServiceClient(StorageAccountHostsMixin, StorageEncryptionMixin):
     """A client to interact with the Blob Service at the account level.
 
     This client provides operations to retrieve and configure the account properties
     as well as list, create and delete containers within the account.
     For operations relating to a specific container or blob, clients for those entities
@@ -115,19 +115,18 @@
             :end-before: [END create_blob_service_client_oauth]
             :language: python
             :dedent: 8
             :caption: Creating the BlobServiceClient with Azure Identity credentials.
     """
 
     def __init__(
-            self, account_url,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):
-        # type: (...) -> None
+            self, account_url: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> None:
         try:
             if not account_url.lower().startswith('http'):
                 account_url = "https://" + account_url
         except AttributeError:
             raise ValueError("Account URL must be a string.")
         parsed_url = urlparse(account_url.rstrip('/'))
         if not parsed_url.netloc:
@@ -144,19 +143,18 @@
         """Format the endpoint URL according to the current location
         mode hostname.
         """
         return "{}://{}/{}".format(self.scheme, hostname, self._query_str)
 
     @classmethod
     def from_connection_string(
-            cls,  # type: Type[ClassType]
-            conn_str,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):  # type: (...) -> ClassType
+            cls, conn_str: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> Self:
         """Create BlobServiceClient from a Connection String.
 
         :param str conn_str:
             A connection string to an Azure Storage account.
         :param credential:
             The credentials with which to authenticate. This is optional if the
             account URL already has a SAS token, or the connection string already has shared
@@ -194,15 +192,19 @@
         A token credential must be present on the service object for this request to succeed.
 
         :param ~datetime.datetime key_start_time:
             A DateTime value. Indicates when the key becomes valid.
         :param ~datetime.datetime key_expiry_time:
             A DateTime value. Indicates when the key stops being valid.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: The user delegation key.
         :rtype: ~azure.storage.blob.UserDelegationKey
         """
         key_info = KeyInfo(start=_to_utc_datetime(key_start_time), expiry=_to_utc_datetime(key_expiry_time))
         timeout = kwargs.pop('timeout', None)
         try:
             user_delegation_key = self._client.service.get_user_delegation_key(key_info=key_info,
@@ -256,15 +258,19 @@
         is the secondary location. The secondary location is automatically
         determined based on the location of the primary; it is in a second data
         center that resides in the same region as the primary location. Read-only
         access is available from the secondary location, if read-access geo-redundant
         replication is enabled for your storage account.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: The blob service stats.
         :rtype: Dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service.py
                 :start-after: [START get_blob_service_stats]
@@ -284,15 +290,19 @@
     @distributed_trace
     def get_service_properties(self, **kwargs):
         # type: (Any) -> Dict[str, Any]
         """Gets the properties of a storage account's Blob service, including
         Azure Storage Analytics.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An object containing blob service properties such as
             analytics logging, hour/minute metrics, cors rules, etc.
         :rtype: Dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service.py
@@ -351,15 +361,19 @@
             It also specifies the number of days and versions of blob to keep.
         :type delete_retention_policy: ~azure.storage.blob.RetentionPolicy
         :param static_website:
             Specifies whether the static website feature is enabled,
             and if yes, indicates the index document and 404 error document to use.
         :type static_website: ~azure.storage.blob.StaticWebsite
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service.py
                 :start-after: [START set_blob_service_properties]
                 :end-before: [END set_blob_service_properties]
@@ -412,15 +426,19 @@
         :keyword bool include_system:
             Flag specifying that system containers should be included.
             .. versionadded:: 12.10.0
         :keyword int results_per_page:
             The maximum number of container names to retrieve per API
             call. If the request does not specify the server will return up to 5,000 items.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) of ContainerProperties.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.ContainerProperties]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service.py
                 :start-after: [START bsc_list_containers]
@@ -463,15 +481,19 @@
         :param str filter_expression:
             The expression to find blobs whose tags matches the specified condition.
             eg. "\"yourtagname\"='firsttag' and \"yourtagname2\"='secondtag'"
             To specify a container, eg. "@container='containerName' and \"Name\"='C'"
         :keyword int results_per_page:
             The max result per page when paginating.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.FilteredBlob]
         """
 
         results_per_page = kwargs.pop('results_per_page', None)
         timeout = kwargs.pop('timeout', None)
         command = functools.partial(
@@ -509,15 +531,19 @@
             Specifies the default encryption scope to set on the container and use for
             all future writes.
 
             .. versionadded:: 12.2.0
 
         :paramtype container_encryption_scope: dict or ~azure.storage.blob.ContainerEncryptionScope
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.ContainerClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service.py
                 :start-after: [START bsc_create_container]
                 :end-before: [END bsc_create_container]
@@ -567,15 +593,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service.py
                 :start-after: [START bsc_delete_container]
                 :end-before: [END bsc_delete_container]
@@ -603,15 +633,19 @@
         :param str new_name:
             The new container name the user wants to rename to.
         :keyword lease:
             Specify this to perform only if the lease ID given
             matches the active lease ID of the source container.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         renamed_container = self.get_container_client(new_name)
         lease = kwargs.pop('lease', None)
         try:
             kwargs['source_lease_id'] = lease.id  # type: str
         except AttributeError:
@@ -634,15 +668,19 @@
             This operation was introduced in API version '2019-12-12'.
 
         :param str deleted_container_name:
             Specifies the name of the deleted container to restore.
         :param str deleted_container_version:
             Specifies the version of the deleted container to restore.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         new_name = kwargs.pop('new_name', None)
         if new_name:
             warnings.warn("`new_name` is no longer supported.", DeprecationWarning)
         container = self.get_container_client(new_name or deleted_container_name)
         try:
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_container_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_container_client.py`

 * *Files 15% similar despite different names*

```diff
@@ -2,52 +2,59 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
 import functools
-from typing import (  # pylint: disable=unused-import
-    Any, AnyStr, Dict, List, IO, Iterable, Iterator, Optional, overload, TypeVar, Union,
+from typing import (
+    Any, AnyStr, Dict, List, IO, Iterable, Iterator, Optional, overload, Union,
     TYPE_CHECKING
 )
 from urllib.parse import urlparse, quote, unquote
 
-import six
+from typing_extensions import Self
+
 from azure.core import MatchConditions
 from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
 from azure.core.paging import ItemPaged
 from azure.core.pipeline import Pipeline
 from azure.core.pipeline.transport import HttpRequest, HttpResponse
 from azure.core.tracing.decorator import distributed_trace
-
 from ._shared.base_client import StorageAccountHostsMixin, TransportWrapper, parse_connection_str, parse_query
 from ._shared.request_handlers import add_metadata_headers, serialize_iso
 from ._shared.response_handlers import (
     process_storage_error,
     return_response_headers,
     return_headers_and_deserialized
 )
 from ._generated import AzureBlobStorage
 from ._generated.models import SignedIdentifier
 from ._blob_client import BlobClient
 from ._deserialize import deserialize_container_properties
 from ._download import StorageStreamDownloader
 from ._encryption import StorageEncryptionMixin
 from ._lease import BlobLeaseClient
-from ._list_blobs_helper import BlobPrefix, BlobPropertiesPaged, FilteredBlobPaged
+from ._list_blobs_helper import (
+    BlobNamesPaged,
+    BlobPrefix,
+    BlobPropertiesPaged,
+    FilteredBlobPaged,
+    IgnoreListBlobsDeserializer
+)
 from ._models import (
     ContainerProperties,
     BlobProperties,
     BlobType,
     FilteredBlob
 )
 from ._serialize import get_modify_conditions, get_container_cpk_scope_info, get_api_version, get_access_conditions
 
 if TYPE_CHECKING:
+    from azure.core.credentials import AzureNamedKeyCredential, AzureSasCredential, TokenCredential
     from datetime import datetime
     from ._models import (  # pylint: disable=unused-import
         PublicAccess,
         AccessPolicy,
         StandardBlobTier,
         PremiumPageBlobTier)
 
@@ -60,17 +67,14 @@
     """
     try:
         return blob.get('name')
     except AttributeError:
         return blob
 
 
-ClassType = TypeVar("ClassType")
-
-
 class ContainerClient(StorageAccountHostsMixin, StorageEncryptionMixin):    # pylint: disable=too-many-public-methods
     """A client to interact with a specific container, although that container
     may not yet exist.
 
     For operations relating to a specific blob within this container, a blob client can be
     retrieved using the :func:`~get_blob_client` function.
 
@@ -128,20 +132,19 @@
             :start-after: [START create_container_client_sasurl]
             :end-before: [END create_container_client_sasurl]
             :language: python
             :dedent: 8
             :caption: Creating the container client directly.
     """
     def __init__(
-            self, account_url,  # type: str
-            container_name,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):
-        # type: (...) -> None
+            self, account_url: str,
+            container_name: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> None:
         try:
             if not account_url.lower().startswith('http'):
                 account_url = "https://" + account_url
         except AttributeError:
             raise ValueError("Container URL must be a string.")
         parsed_url = urlparse(account_url.rstrip('/'))
         if not container_name:
@@ -151,35 +154,39 @@
 
         _, sas_token = parse_query(parsed_url.query)
         self.container_name = container_name
         # This parameter is used for the hierarchy traversal. Give precedence to credential.
         self._raw_credential = credential if credential else sas_token
         self._query_str, credential = self._format_query_string(sas_token, credential)
         super(ContainerClient, self).__init__(parsed_url, service='blob', credential=credential, **kwargs)
-        self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
-        self._client._config.version = get_api_version(kwargs) # pylint: disable=protected-access
+        self._api_version = get_api_version(kwargs)
+        self._client = self._build_generated_client()
         self._configure_encryption(kwargs)
 
+    def _build_generated_client(self):
+        client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
+        client._config.version = self._api_version # pylint: disable=protected-access
+        return client
+
     def _format_url(self, hostname):
         container_name = self.container_name
-        if isinstance(container_name, six.text_type):
+        if isinstance(container_name, str):
             container_name = container_name.encode('UTF-8')
         return "{}://{}/{}{}".format(
             self.scheme,
             hostname,
             quote(container_name),
             self._query_str)
 
     @classmethod
     def from_container_url(
-            cls,  # type: Type[ClassType]
-            container_url,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):  # type: (...) -> ClassType
+            cls, container_url: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> Self:
         """Create ContainerClient from a container url.
 
         :param str container_url:
             The full endpoint URL to the Container, including SAS token if used. This could be
             either the primary endpoint, or the secondary endpoint depending on the current `location_mode`.
         :type container_url: str
         :param credential:
@@ -196,19 +203,19 @@
         :rtype: ~azure.storage.blob.ContainerClient
         """
         try:
             if not container_url.lower().startswith('http'):
                 container_url = "https://" + container_url
         except AttributeError:
             raise ValueError("Container URL must be a string.")
-        parsed_url = urlparse(container_url.rstrip('/'))
+        parsed_url = urlparse(container_url)
         if not parsed_url.netloc:
             raise ValueError("Invalid URL: {}".format(container_url))
 
-        container_path = parsed_url.path.lstrip('/').split('/')
+        container_path = parsed_url.path.strip('/').split('/')
         account_path = ""
         if len(container_path) > 1:
             account_path = "/" + "/".join(container_path[:-1])
         account_url = "{}://{}{}?{}".format(
             parsed_url.scheme,
             parsed_url.netloc.rstrip('/'),
             account_path,
@@ -216,20 +223,19 @@
         container_name = unquote(container_path[-1])
         if not container_name:
             raise ValueError("Invalid URL. Please provide a URL with a valid container name")
         return cls(account_url, container_name=container_name, credential=credential, **kwargs)
 
     @classmethod
     def from_connection_string(
-            cls,  # type: Type[ClassType]
-            conn_str,  # type: str
-            container_name,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):  # type: (...) -> ClassType
+            cls, conn_str: str,
+            container_name: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> Self:
         """Create ContainerClient from a Connection String.
 
         :param str conn_str:
             A connection string to an Azure Storage account.
         :param container_name:
             The container name for the blob.
         :type container_name: str
@@ -277,15 +283,19 @@
             Specifies the default encryption scope to set on the container and use for
             all future writes.
 
             .. versionadded:: 12.2.0
 
         :paramtype container_encryption_scope: dict or ~azure.storage.blob.ContainerEncryptionScope
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A dictionary of response headers.
         :rtype: Dict[str, Union[str, datetime]]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START create_container]
@@ -319,15 +329,19 @@
         :param str new_name:
             The new container name the user wants to rename to.
         :keyword lease:
             Specify this to perform only if the lease ID given
             matches the active lease ID of the source container.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         lease = kwargs.pop('lease', None)
         try:
             kwargs['source_lease_id'] = lease.id
         except AttributeError:
             kwargs['source_lease_id'] = lease
@@ -370,15 +384,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START delete_container]
                 :end-before: [END delete_container]
@@ -432,15 +450,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A BlobLeaseClient object, that can be run in a context manager.
         :rtype: ~azure.storage.blob.BlobLeaseClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START acquire_lease_on_container]
@@ -478,15 +500,19 @@
         container. The data returned does not include the container's list of blobs.
 
         :keyword lease:
             If specified, get_container_properties only succeeds if the
             container's lease is active and matches this ID.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: Properties for the specified container within a container object.
         :rtype: ~azure.storage.blob.ContainerProperties
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START get_container_properties]
@@ -512,15 +538,19 @@
     @distributed_trace
     def exists(self, **kwargs):
         # type: (**Any) -> bool
         """
         Returns True if a container exists and returns False otherwise.
 
         :kwarg int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: boolean
         """
         try:
             self._client.container.get_properties(**kwargs)
             return True
         except HttpResponseError as error:
             try:
@@ -559,15 +589,19 @@
             If a date is passed in without timezone info, it is assumed to be UTC.
             Specify this header to perform the operation only if
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Container-updated property dict (Etag and last modified).
         :rtype: dict[str, str or datetime]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START set_container_metadata]
@@ -634,15 +668,19 @@
         The permissions indicate whether container data may be accessed publicly.
 
         :keyword lease:
             If specified, get_container_access_policy only succeeds if the
             container's lease is active and matches this ID.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Access policy information in a dict.
         :rtype: dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START get_container_access_policy]
@@ -697,15 +735,19 @@
         :keyword ~datetime.datetime if_unmodified_since:
             A datetime value. Azure expects the date value passed in to be UTC.
             If timezone is included, any non-UTC datetimes will be converted to UTC.
             If a date is passed in without timezone info, it is assumed to be UTC.
             Specify this header to perform the operation only if
             the resource has not been modified since the specified date/time.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Container-updated property dict (Etag and last modified).
         :rtype: dict[str, str or ~datetime.datetime]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START set_container_access_policy]
@@ -751,17 +793,21 @@
         :param str name_starts_with:
             Filters the results to return only blobs whose names
             begin with the specified prefix.
         :param include:
             Specifies one or more additional datasets to include in the response.
             Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted', 'deletedwithversions',
             'tags', 'versions', 'immutabilitypolicy', 'legalhold'.
-        :paramtype include: list[str] or str
+        :type include: list[str] or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.BlobProperties]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers.py
                 :start-after: [START list_blobs_in_container]
@@ -781,39 +827,86 @@
             timeout=timeout,
             **kwargs)
         return ItemPaged(
             command, prefix=name_starts_with, results_per_page=results_per_page,
             page_iterator_class=BlobPropertiesPaged)
 
     @distributed_trace
+    def list_blob_names(self, **kwargs: Any) -> ItemPaged[str]:
+        """Returns a generator to list the names of blobs under the specified container.
+        The generator will lazily follow the continuation tokens returned by
+        the service.
+
+        Note that no additional properties or metadata will be returned when using this API.
+        Additionally, this API does not have an option to include additional blobs such as snapshots,
+        versions, soft-deleted blobs, etc. To get any of this data, use :func:`list_blobs()`.
+
+        :keyword str name_starts_with:
+            Filters the results to return only blobs whose names
+            begin with the specified prefix.
+        :keyword int timeout:
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
+        :returns: An iterable (auto-paging) response of blob names as strings.
+        :rtype: ~azure.core.paging.ItemPaged[str]
+        """
+        name_starts_with = kwargs.pop('name_starts_with', None)
+        results_per_page = kwargs.pop('results_per_page', None)
+        timeout = kwargs.pop('timeout', None)
+
+        # For listing only names we need to create a one-off generated client and
+        # override its deserializer to prevent deserialization of the full response.
+        client = self._build_generated_client()
+        client.container._deserialize = IgnoreListBlobsDeserializer()  # pylint: disable=protected-access
+
+        command = functools.partial(
+            client.container.list_blob_flat_segment,
+            timeout=timeout,
+            **kwargs)
+        return ItemPaged(
+            command,
+            prefix=name_starts_with,
+            results_per_page=results_per_page,
+            page_iterator_class=BlobNamesPaged)
+
+    @distributed_trace
     def walk_blobs(
             self, name_starts_with=None, # type: Optional[str]
-            include=None, # type: Optional[Any]
+            include=None, # type: Optional[Union[List[str], str]]
             delimiter="/", # type: str
             **kwargs # type: Optional[Any]
         ):
         # type: (...) -> ItemPaged[BlobProperties]
         """Returns a generator to list the blobs under the specified container.
         The generator will lazily follow the continuation tokens returned by
         the service. This operation will list blobs in accordance with a hierarchy,
         as delimited by the specified delimiter character.
 
         :param str name_starts_with:
             Filters the results to return only blobs whose names
             begin with the specified prefix.
-        :param list[str] include:
+        :param include:
             Specifies one or more additional datasets to include in the response.
-            Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted'.
+            Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted', 'deletedwithversions',
+            'tags', 'versions', 'immutabilitypolicy', 'legalhold'.
+        :type include: list[str] or str
         :param str delimiter:
             When the request includes this parameter, the operation returns a BlobPrefix
             element in the response body that acts as a placeholder for all blobs whose
             names begin with the same substring up to the appearance of the delimiter
             character. The delimiter may be a single character or a string.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.BlobProperties]
         """
         if include and not isinstance(include, list):
             include = [include]
 
         results_per_page = kwargs.pop('results_per_page', None)
@@ -843,15 +936,19 @@
 
         :param str filter_expression:
             The expression to find blobs whose tags matches the specified condition.
             eg. "\"yourtagname\"='firsttag' and \"yourtagname2\"='secondtag'"
         :keyword int results_per_page:
             The max result per page when paginating.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of FilteredBlob.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.BlobProperties]
         """
         results_per_page = kwargs.pop('results_per_page', None)
         timeout = kwargs.pop('timeout', None)
         command = functools.partial(
             self._client.container.filter_blobs,
@@ -860,22 +957,21 @@
             **kwargs)
         return ItemPaged(
             command, results_per_page=results_per_page,
             page_iterator_class=FilteredBlobPaged)
 
     @distributed_trace
     def upload_blob(
-            self, name,  # type: Union[str, BlobProperties]
-            data,  # type: Union[Iterable[AnyStr], IO[AnyStr]]
-            blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
-            length=None,  # type: Optional[int]
-            metadata=None,  # type: Optional[Dict[str, str]]
+            self, name: Union[str, BlobProperties],
+            data: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]],
+            blob_type: Union[str, BlobType] = BlobType.BlockBlob,
+            length: Optional[int] = None,
+            metadata: Optional[Dict[str, str]] = None,
             **kwargs
-        ):
-        # type: (...) -> BlobClient
+        ) -> BlobClient:
         """Creates a new blob from a data source with automatic chunking.
 
         :param name: The blob with which to interact. If specified, this value will override
             a blob value specified in the blob URL.
         :type name: str or ~azure.storage.blob.BlobProperties
         :param data: The blob data to upload.
         :param ~azure.storage.blob.BlobType blob_type: The type of the blob. This can be
@@ -928,17 +1024,20 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
-            multiple calls to the Azure service and the timeout will apply to
-            each call individually.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
         :keyword ~azure.storage.blob.PremiumPageBlobTier premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
             premium storage accounts.
         :keyword ~azure.storage.blob.StandardBlobTier standard_blob_tier:
             A standard blob tier value to set the blob to. For this version of the library,
             this is only applicable to block blobs on standard storage accounts.
@@ -1056,15 +1155,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
         """
         blob_client = self.get_blob_client(blob) # type: ignore
         kwargs.setdefault('merge_span', True)
         timeout = kwargs.pop('timeout', None)
         blob_client.delete_blob( # type: ignore
             delete_snapshots=delete_snapshots,
@@ -1167,15 +1270,20 @@
             Encoding to decode the downloaded bytes. Default is None, i.e. no decoding.
         :keyword progress_hook:
             A callback to track the progress of a long running download. The signature is
             function(current: int, total: int) where current is the number of bytes transfered
             so far, and total is the total size of the download.
         :paramtype progress_hook: Callable[[int, int], None]
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :returns: A streaming object (StorageStreamDownloader)
         :rtype: ~azure.storage.blob.StorageStreamDownloader
         """
         blob_client = self.get_blob_client(blob) # type: ignore
         kwargs.setdefault('merge_span', True)
@@ -1377,15 +1485,19 @@
 
             .. versionadded:: 12.4.0
 
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: An iterator of responses, one for each blob in order
         :rtype: Iterator[~azure.core.pipeline.transport.HttpResponse]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common.py
                 :start-after: [START delete_multiple_blobs]
@@ -1545,15 +1657,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure.
         :return: An iterator of responses, one for each blob in order
         :rtype: Iterator[~azure.core.pipeline.transport.HttpResponse]
         """
         reqs, options = self._generate_set_tiers_options(standard_blob_tier, *blobs, **kwargs)
@@ -1594,17 +1710,19 @@
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
         :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
-            multiple calls to the Azure service and the timeout will apply to
-            each call individually.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure.
         :return: An iterator of responses, one for each blob in order
         :rtype: iterator[~azure.core.pipeline.transport.HttpResponse]
         """
         reqs, options = self._generate_set_tiers_options(premium_page_blob_tier, *blobs, **kwargs)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_deserialize.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,29 +1,42 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=no-self-use
-from typing import (  # pylint: disable=unused-import
-    Tuple, Dict, List,
+
+from typing import (
+    Dict, List, Optional, Tuple, Union,
     TYPE_CHECKING
 )
-try:
-    from urllib.parse import unquote
-except ImportError:
-    from urllib import unquote
-from ._models import BlobType, CopyProperties, ContentSettings, LeaseProperties, BlobProperties, ImmutabilityPolicy
+from urllib.parse import unquote
+from xml.etree.ElementTree import Element
+
+from ._models import (
+    BlobAnalyticsLogging,
+    BlobProperties,
+    BlobType,
+    ContainerProperties,
+    ContentSettings,
+    CopyProperties,
+    CorsRule,
+    ImmutabilityPolicy,
+    LeaseProperties,
+    Metrics,
+    ObjectReplicationPolicy,
+    ObjectReplicationRule,
+    RetentionPolicy,
+    StaticWebsite,
+)
 from ._shared.models import get_enum_value
 from ._shared.response_handlers import deserialize_metadata
-from ._models import ContainerProperties, BlobAnalyticsLogging, Metrics, CorsRule, RetentionPolicy, \
-    StaticWebsite, ObjectReplicationPolicy, ObjectReplicationRule
 
 if TYPE_CHECKING:
-    from ._generated.models import PageList
+    from ._generated.models import BlobTag, PageList
 
 
 def deserialize_pipeline_response_into_cls(cls_method, response, obj, headers):
     try:
         deserialized_response = response.http_response
     except AttributeError:
         deserialized_response = response
@@ -168,7 +181,31 @@
     # type: (Optional[List[BlobTag]]) -> Union[Dict[str, str], None]
     """Deserialize a list of BlobTag objects into a dict.
     """
     if generated_tags:
         tag_dict = {t.key: t.value for t in generated_tags.blob_tag_set}
         return tag_dict
     return None
+
+
+def load_single_xml_node(element: Element, name: str) -> Union[Element, None]:
+    return element.find(name)
+
+
+def load_many_xml_nodes(element: Element, name: str, wrapper: Element = None) -> List[Union[Element, None]]:
+    if wrapper:
+        element = load_single_xml_node(element, wrapper)
+    return list(element.findall(name))
+
+
+def load_xml_string(element: Element, name: str) -> str:
+    node = element.find(name)
+    if node is None or not node.text:
+        return None
+    return node.text
+
+
+def load_xml_int(element: Element, name: str) -> int:
+    node = element.find(name)
+    if node is None or not node.text:
+        return None
+    return int(node.text)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_download.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_download.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_azure_blob_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_azure_blob_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_vendor.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/_vendor.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_azure_blob_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_azure_blob_storage.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,98 +3,101 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from copy import deepcopy
-from typing import Any, Awaitable
+from typing import Any
 
-from azure.core import AsyncPipelineClient
-from azure.core.rest import AsyncHttpResponse, HttpRequest
+from azure.core import PipelineClient
+from azure.core.rest import HttpRequest, HttpResponse
 
-from .. import models
-from .._serialization import Deserializer, Serializer
+from . import models
 from ._configuration import AzureBlobStorageConfiguration
+from ._serialization import Deserializer, Serializer
 from .operations import (
     AppendBlobOperations,
     BlobOperations,
     BlockBlobOperations,
     ContainerOperations,
     PageBlobOperations,
     ServiceOperations,
 )
 
 
 class AzureBlobStorage:  # pylint: disable=client-accepts-api-version-keyword
     """AzureBlobStorage.
 
     :ivar service: ServiceOperations operations
-    :vartype service: azure.storage.blob.aio.operations.ServiceOperations
+    :vartype service: azure.storage.blob.operations.ServiceOperations
     :ivar container: ContainerOperations operations
-    :vartype container: azure.storage.blob.aio.operations.ContainerOperations
+    :vartype container: azure.storage.blob.operations.ContainerOperations
     :ivar blob: BlobOperations operations
-    :vartype blob: azure.storage.blob.aio.operations.BlobOperations
+    :vartype blob: azure.storage.blob.operations.BlobOperations
     :ivar page_blob: PageBlobOperations operations
-    :vartype page_blob: azure.storage.blob.aio.operations.PageBlobOperations
+    :vartype page_blob: azure.storage.blob.operations.PageBlobOperations
     :ivar append_blob: AppendBlobOperations operations
-    :vartype append_blob: azure.storage.blob.aio.operations.AppendBlobOperations
+    :vartype append_blob: azure.storage.blob.operations.AppendBlobOperations
     :ivar block_blob: BlockBlobOperations operations
-    :vartype block_blob: azure.storage.blob.aio.operations.BlockBlobOperations
+    :vartype block_blob: azure.storage.blob.operations.BlockBlobOperations
     :param url: The URL of the service account, container, or blob that is the target of the
      desired operation. Required.
     :type url: str
     :param base_url: Service URL. Required. Default value is "".
     :type base_url: str
     :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2021-08-06". Note that overriding this default value may result in unsupported behavior.
+     is "2021-12-02". Note that overriding this default value may result in unsupported behavior.
     :paramtype version: str
     """
 
     def __init__(  # pylint: disable=missing-client-constructor-parameter-credential
         self, url: str, base_url: str = "", **kwargs: Any
     ) -> None:
         self._config = AzureBlobStorageConfiguration(url=url, **kwargs)
-        self._client = AsyncPipelineClient(base_url=base_url, config=self._config, **kwargs)
+        self._client = PipelineClient(base_url=base_url, config=self._config, **kwargs)
 
         client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
         self._serialize = Serializer(client_models)
         self._deserialize = Deserializer(client_models)
         self._serialize.client_side_validation = False
         self.service = ServiceOperations(self._client, self._config, self._serialize, self._deserialize)
         self.container = ContainerOperations(self._client, self._config, self._serialize, self._deserialize)
         self.blob = BlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.page_blob = PageBlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.append_blob = AppendBlobOperations(self._client, self._config, self._serialize, self._deserialize)
         self.block_blob = BlockBlobOperations(self._client, self._config, self._serialize, self._deserialize)
 
-    def _send_request(self, request: HttpRequest, **kwargs: Any) -> Awaitable[AsyncHttpResponse]:
+    def _send_request(self, request: HttpRequest, **kwargs: Any) -> HttpResponse:
         """Runs the network request through the client's chained policies.
 
         >>> from azure.core.rest import HttpRequest
         >>> request = HttpRequest("GET", "https://www.example.org/")
         <HttpRequest [GET], url: 'https://www.example.org/'>
-        >>> response = await client._send_request(request)
-        <AsyncHttpResponse: 200 OK>
+        >>> response = client._send_request(request)
+        <HttpResponse: 200 OK>
 
         For more information on this code flow, see https://aka.ms/azsdk/dpcodegen/python/send_request
 
         :param request: The network request you want to make. Required.
         :type request: ~azure.core.rest.HttpRequest
         :keyword bool stream: Whether the response payload will be streamed. Defaults to False.
         :return: The response of your network call. Does not do error handling on your response.
-        :rtype: ~azure.core.rest.AsyncHttpResponse
+        :rtype: ~azure.core.rest.HttpResponse
         """
 
         request_copy = deepcopy(request)
         request_copy.url = self._client.format_url(request_copy.url)
         return self._client.send_request(request_copy, **kwargs)
 
-    async def close(self) -> None:
-        await self._client.close()
-
-    async def __aenter__(self) -> "AzureBlobStorage":
-        await self._client.__aenter__()
+    def close(self):
+        # type: () -> None
+        self._client.close()
+
+    def __enter__(self):
+        # type: () -> AzureBlobStorage
+        self._client.__enter__()
         return self
 
-    async def __aexit__(self, *exc_details) -> None:
-        await self._client.__aexit__(*exc_details)
+    def __exit__(self, *exc_details):
+        # type: (Any) -> None
+        self._client.__exit__(*exc_details)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_configuration.py`

 * *Files 5% similar despite different names*

```diff
@@ -20,21 +20,21 @@
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
     :param url: The URL of the service account, container, or blob that is the target of the
      desired operation. Required.
     :type url: str
     :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2021-08-06". Note that overriding this default value may result in unsupported behavior.
+     is "2021-12-02". Note that overriding this default value may result in unsupported behavior.
     :paramtype version: str
     """
 
     def __init__(self, url: str, **kwargs: Any) -> None:
         super(AzureBlobStorageConfiguration, self).__init__(**kwargs)
-        version = kwargs.pop("version", "2021-08-06")  # type: str
+        version = kwargs.pop("version", "2021-12-02")  # type: str
 
         if url is None:
             raise ValueError("Parameter 'url' must not be None.")
 
         self.url = url
         self.version = version
         kwargs.setdefault("sdk_moniker", "azureblobstorage/{}".format(VERSION))
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_append_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_append_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_blob_operations.py`

 * *Files 1% similar despite different names*

```diff
@@ -198,14 +198,17 @@
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
             response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-creation-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-creation-time")
+            )
             response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
             response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
             response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
             response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
             response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
             response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
             response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
@@ -276,14 +279,17 @@
             )
             response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
 
             deserialized = response.stream_download(self._client._pipeline)
 
         if response.status_code == 206:
             response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-creation-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-creation-time")
+            )
             response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
             response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
             response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
             response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
             response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
             response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
             response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
@@ -2073,16 +2079,16 @@
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
-         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
-         Default value is None.
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param rehydrate_priority: Optional: Indicates the priority with which to rehydrate an archived
          blob. Known values are: "High" and "Standard". Default value is None.
         :type rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
@@ -2247,16 +2253,16 @@
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
-         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
-         Default value is None.
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
@@ -2512,15 +2518,16 @@
         """The Set Tier operation sets the tier on a blob. The operation is allowed on a page blob in a
         premium storage account and on a block blob in a blob storage account (locally redundant
         storage only). A premium page blob's tier determines the allowed size, IOPS, and bandwidth of
         the blob. A block blob's tier determines Hot/Cool/Archive storage type. This operation does not
         update the blob's ETag.
 
         :param tier: Indicates the tier to be set on the blob. Known values are: "P4", "P6", "P10",
-         "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive". Required.
+         "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and "Cold".
+         Required.
         :type tier: str or ~azure.storage.blob.models.AccessTierRequired
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
          a Snapshot of a Blob.</a>`. Default value is None.
         :type snapshot: str
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_block_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_block_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_container_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_container_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_page_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_page_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/aio/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_azure_blob_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_azure_blob_storage_enums.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,14 +24,15 @@
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
     HOT = "Hot"
     COOL = "Cool"
     ARCHIVE = "Archive"
     PREMIUM = "Premium"
+    COLD = "Cold"
 
 
 class AccessTierOptional(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """AccessTierOptional."""
 
     P4 = "P4"
     P6 = "P6"
@@ -43,14 +44,15 @@
     P50 = "P50"
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
     HOT = "Hot"
     COOL = "Cool"
     ARCHIVE = "Archive"
+    COLD = "Cold"
 
 
 class AccessTierRequired(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """AccessTierRequired."""
 
     P4 = "P4"
     P6 = "P6"
@@ -62,14 +64,15 @@
     P50 = "P50"
     P60 = "P60"
     P70 = "P70"
     P80 = "P80"
     HOT = "Hot"
     COOL = "Cool"
     ARCHIVE = "Archive"
+    COLD = "Cold"
 
 
 class AccountKind(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """AccountKind."""
 
     STORAGE = "Storage"
     BLOB_STORAGE = "BlobStorage"
@@ -330,15 +333,15 @@
     CONTAINER_DISABLED = "ContainerDisabled"
     CONTAINER_NOT_FOUND = "ContainerNotFound"
     CONTENT_LENGTH_LARGER_THAN_TIER_LIMIT = "ContentLengthLargerThanTierLimit"
     COPY_ACROSS_ACCOUNTS_NOT_SUPPORTED = "CopyAcrossAccountsNotSupported"
     COPY_ID_MISMATCH = "CopyIdMismatch"
     FEATURE_VERSION_MISMATCH = "FeatureVersionMismatch"
     INCREMENTAL_COPY_BLOB_MISMATCH = "IncrementalCopyBlobMismatch"
-    INCREMENTAL_COPY_OF_ERALIER_VERSION_SNAPSHOT_NOT_ALLOWED = "IncrementalCopyOfEralierVersionSnapshotNotAllowed"
+    INCREMENTAL_COPY_OF_EARLIER_VERSION_SNAPSHOT_NOT_ALLOWED = "IncrementalCopyOfEarlierVersionSnapshotNotAllowed"
     INCREMENTAL_COPY_SOURCE_MUST_BE_SNAPSHOT = "IncrementalCopySourceMustBeSnapshot"
     INFINITE_LEASE_DURATION_REQUIRED = "InfiniteLeaseDurationRequired"
     INVALID_BLOB_OR_BLOCK = "InvalidBlobOrBlock"
     INVALID_BLOB_TIER = "InvalidBlobTier"
     INVALID_BLOB_TYPE = "InvalidBlobType"
     INVALID_BLOCK_ID = "InvalidBlockId"
     INVALID_BLOCK_LIST = "InvalidBlockList"
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/models/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_append_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_append_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_blob_operations.py`

 * *Files 1% similar despite different names*

```diff
@@ -53,15 +53,15 @@
     if_tags: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -132,15 +132,15 @@
     if_tags: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -200,15 +200,15 @@
     request_id_parameter: Optional[str] = None,
     blob_delete_type: str = "Permanent",
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -251,15 +251,15 @@
 def build_undelete_request(
     url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -289,15 +289,15 @@
     expires_on: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -340,15 +340,15 @@
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -409,15 +409,15 @@
     immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -451,15 +451,15 @@
 def build_delete_immutability_policy_request(
     url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "immutabilityPolicies"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -488,15 +488,15 @@
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "legalhold"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -536,15 +536,15 @@
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -604,15 +604,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
     action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -662,15 +662,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
     action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -717,15 +717,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
     action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -773,15 +773,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
     action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -829,15 +829,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
     action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -889,15 +889,15 @@
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "snapshot"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -968,15 +968,15 @@
     immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
     legal_hold: Optional[bool] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1071,15 +1071,15 @@
     copy_source_tags: Optional[Union[str, "_models.BlobCopySourceTags"]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     x_ms_requires_sync = kwargs.pop("x_ms_requires_sync", _headers.pop("x-ms-requires-sync", "true"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1163,15 +1163,15 @@
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "copy"))  # type: str
     copy_action_abort_constant = kwargs.pop(
         "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
     )  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1209,15 +1209,15 @@
     if_tags: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "tier"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1251,15 +1251,15 @@
 
 def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
     comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1296,15 +1296,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "query"))  # type: str
     content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1360,15 +1360,15 @@
     lease_id: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1411,15 +1411,15 @@
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "tags"))  # type: str
     content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -1599,14 +1599,17 @@
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         if response.status_code == 200:
             response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-creation-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-creation-time")
+            )
             response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
             response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
             response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
             response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
             response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
             response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
             response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
@@ -1677,14 +1680,17 @@
             )
             response_headers["x-ms-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-legal-hold"))
 
             deserialized = response.stream_download(self._client._pipeline)
 
         if response.status_code == 206:
             response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-creation-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-creation-time")
+            )
             response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
             response_headers["x-ms-or-policy-id"] = self._deserialize("str", response.headers.get("x-ms-or-policy-id"))
             response_headers["x-ms-or"] = self._deserialize("{str}", response.headers.get("x-ms-or"))
             response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
             response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
             response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
             response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
@@ -3474,16 +3480,16 @@
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
-         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
-         Default value is None.
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param rehydrate_priority: Optional: Indicates the priority with which to rehydrate an archived
          blob. Known values are: "High" and "Standard". Default value is None.
         :type rehydrate_priority: str or ~azure.storage.blob.models.RehydratePriority
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
@@ -3648,16 +3654,16 @@
          or file to the destination blob. If one or more name-value pairs are specified, the destination
          blob is created with the specified metadata, and metadata is not copied from the source blob or
          file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
          rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
          information. Default value is None.
         :type metadata: dict[str, str]
         :param tier: Optional. Indicates the tier to be set on the blob. Known values are: "P4", "P6",
-         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive".
-         Default value is None.
+         "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and
+         "Cold". Default value is None.
         :type tier: str or ~azure.storage.blob.models.AccessTierOptional
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
          from the copy source. Default value is None.
@@ -3913,15 +3919,16 @@
         """The Set Tier operation sets the tier on a blob. The operation is allowed on a page blob in a
         premium storage account and on a block blob in a blob storage account (locally redundant
         storage only). A premium page blob's tier determines the allowed size, IOPS, and bandwidth of
         the blob. A block blob's tier determines Hot/Cool/Archive storage type. This operation does not
         update the blob's ETag.
 
         :param tier: Indicates the tier to be set on the blob. Known values are: "P4", "P6", "P10",
-         "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", and "Archive". Required.
+         "P15", "P20", "P30", "P40", "P50", "P60", "P70", "P80", "Hot", "Cool", "Archive", and "Cold".
+         Required.
         :type tier: str or ~azure.storage.blob.models.AccessTierRequired
         :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
          see :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
          a Snapshot of a Blob.</a>`. Default value is None.
         :type snapshot: str
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_block_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_block_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_container_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_path_operations.py`

 * *Files 11% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import datetime
-from typing import Any, Callable, Dict, IO, Iterator, List, Optional, TypeVar, Union
+from typing import Any, Callable, Dict, IO, Iterator, Optional, TypeVar, Union
 
 from azure.core.exceptions import (
     ClientAuthenticationError,
     HttpResponseError,
     ResourceExistsError,
     ResourceNotFoundError,
     map_error,
@@ -32,1450 +32,1801 @@
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 
 
 def build_create_request(
     url: str,
     *,
-    timeout: Optional[int] = None,
-    metadata: Optional[Dict[str, str]] = None,
-    access: Optional[Union[str, "_models.PublicAccessType"]] = None,
     request_id_parameter: Optional[str] = None,
-    default_encryption_scope: Optional[str] = None,
-    prevent_encryption_scope_override: Optional[bool] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url = _format_url_section(_url, **path_format_arguments)
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    if metadata is not None:
-        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    if access is not None:
-        _headers["x-ms-blob-public-access"] = _SERIALIZER.header("access", access, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if default_encryption_scope is not None:
-        _headers["x-ms-default-encryption-scope"] = _SERIALIZER.header(
-            "default_encryption_scope", default_encryption_scope, "str"
-        )
-    if prevent_encryption_scope_override is not None:
-        _headers["x-ms-deny-encryption-scope-override"] = _SERIALIZER.header(
-            "prevent_encryption_scope_override", prevent_encryption_scope_override, "bool"
-        )
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_get_properties_request(
-    url: str,
-    *,
     timeout: Optional[int] = None,
+    resource: Optional[Union[str, "_models.PathResourceType"]] = None,
+    continuation: Optional[str] = None,
+    mode: Optional[Union[str, "_models.PathRenameMode"]] = None,
+    cache_control: Optional[str] = None,
+    content_encoding: Optional[str] = None,
+    content_language: Optional[str] = None,
+    content_disposition: Optional[str] = None,
+    content_type_parameter: Optional[str] = None,
+    rename_source: Optional[str] = None,
     lease_id: Optional[str] = None,
-    request_id_parameter: Optional[str] = None,
+    source_lease_id: Optional[str] = None,
+    properties: Optional[str] = None,
+    permissions: Optional[str] = None,
+    umask: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    source_if_match: Optional[str] = None,
+    source_if_none_match: Optional[str] = None,
+    source_if_modified_since: Optional[datetime.datetime] = None,
+    source_if_unmodified_since: Optional[datetime.datetime] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: str = "AES256",
+    owner: Optional[str] = None,
+    group: Optional[str] = None,
+    acl: Optional[str] = None,
+    proposed_lease_id: Optional[str] = None,
+    lease_duration: Optional[int] = None,
+    expiry_options: Optional[Union[str, "_models.PathExpiryOptions"]] = None,
+    expires_on: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if resource is not None:
+        _params["resource"] = _SERIALIZER.query("resource", resource, "str")
+    if continuation is not None:
+        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
+    if mode is not None:
+        _params["mode"] = _SERIALIZER.query("mode", mode, "str")
 
     # Construct headers
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if cache_control is not None:
+        _headers["x-ms-cache-control"] = _SERIALIZER.header("cache_control", cache_control, "str")
+    if content_encoding is not None:
+        _headers["x-ms-content-encoding"] = _SERIALIZER.header("content_encoding", content_encoding, "str")
+    if content_language is not None:
+        _headers["x-ms-content-language"] = _SERIALIZER.header("content_language", content_language, "str")
+    if content_disposition is not None:
+        _headers["x-ms-content-disposition"] = _SERIALIZER.header("content_disposition", content_disposition, "str")
+    if content_type_parameter is not None:
+        _headers["x-ms-content-type"] = _SERIALIZER.header("content_type_parameter", content_type_parameter, "str")
+    if rename_source is not None:
+        _headers["x-ms-rename-source"] = _SERIALIZER.header("rename_source", rename_source, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if source_lease_id is not None:
+        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
+    if properties is not None:
+        _headers["x-ms-properties"] = _SERIALIZER.header("properties", properties, "str")
+    if permissions is not None:
+        _headers["x-ms-permissions"] = _SERIALIZER.header("permissions", permissions, "str")
+    if umask is not None:
+        _headers["x-ms-umask"] = _SERIALIZER.header("umask", umask, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if source_if_match is not None:
+        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
+    if source_if_none_match is not None:
+        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
+    if source_if_modified_since is not None:
+        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
+            "source_if_modified_since", source_if_modified_since, "rfc-1123"
+        )
+    if source_if_unmodified_since is not None:
+        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
+            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
+        )
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if owner is not None:
+        _headers["x-ms-owner"] = _SERIALIZER.header("owner", owner, "str")
+    if group is not None:
+        _headers["x-ms-group"] = _SERIALIZER.header("group", group, "str")
+    if acl is not None:
+        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
+    if proposed_lease_id is not None:
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    if lease_duration is not None:
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("lease_duration", lease_duration, "int")
+    if expiry_options is not None:
+        _headers["x-ms-expiry-option"] = _SERIALIZER.header("expiry_options", expiry_options, "str")
+    if expires_on is not None:
+        _headers["x-ms-expiry-time"] = _SERIALIZER.header("expires_on", expires_on, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_delete_request(
+def build_update_request(
     url: str,
     *,
+    action: Union[str, "_models.PathUpdateAction"],
+    mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
+    content: IO,
+    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
+    max_records: Optional[int] = None,
+    continuation: Optional[str] = None,
+    force_flag: Optional[bool] = None,
+    position: Optional[int] = None,
+    retain_uncommitted_data: Optional[bool] = None,
+    close: Optional[bool] = None,
+    content_length: Optional[int] = None,
+    content_md5: Optional[bytes] = None,
     lease_id: Optional[str] = None,
+    cache_control: Optional[str] = None,
+    content_type_parameter: Optional[str] = None,
+    content_disposition: Optional[str] = None,
+    content_encoding: Optional[str] = None,
+    content_language: Optional[str] = None,
+    properties: Optional[str] = None,
+    owner: Optional[str] = None,
+    group: Optional[str] = None,
+    permissions: Optional[str] = None,
+    acl: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
     if_modified_since: Optional[datetime.datetime] = None,
     if_unmodified_since: Optional[datetime.datetime] = None,
-    request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    _params["action"] = _SERIALIZER.query("action", action, "str")
+    if max_records is not None:
+        _params["maxRecords"] = _SERIALIZER.query("max_records", max_records, "int", minimum=1)
+    if continuation is not None:
+        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
+    _params["mode"] = _SERIALIZER.query("mode", mode, "str")
+    if force_flag is not None:
+        _params["forceFlag"] = _SERIALIZER.query("force_flag", force_flag, "bool")
+    if position is not None:
+        _params["position"] = _SERIALIZER.query("position", position, "int")
+    if retain_uncommitted_data is not None:
+        _params["retainUncommittedData"] = _SERIALIZER.query("retain_uncommitted_data", retain_uncommitted_data, "bool")
+    if close is not None:
+        _params["close"] = _SERIALIZER.query("close", close, "bool")
 
     # Construct headers
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if content_length is not None:
+        _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int", minimum=0)
+    if content_md5 is not None:
+        _headers["x-ms-content-md5"] = _SERIALIZER.header("content_md5", content_md5, "bytearray")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if cache_control is not None:
+        _headers["x-ms-cache-control"] = _SERIALIZER.header("cache_control", cache_control, "str")
+    if content_type_parameter is not None:
+        _headers["x-ms-content-type"] = _SERIALIZER.header("content_type_parameter", content_type_parameter, "str")
+    if content_disposition is not None:
+        _headers["x-ms-content-disposition"] = _SERIALIZER.header("content_disposition", content_disposition, "str")
+    if content_encoding is not None:
+        _headers["x-ms-content-encoding"] = _SERIALIZER.header("content_encoding", content_encoding, "str")
+    if content_language is not None:
+        _headers["x-ms-content-language"] = _SERIALIZER.header("content_language", content_language, "str")
+    if properties is not None:
+        _headers["x-ms-properties"] = _SERIALIZER.header("properties", properties, "str")
+    if owner is not None:
+        _headers["x-ms-owner"] = _SERIALIZER.header("owner", owner, "str")
+    if group is not None:
+        _headers["x-ms-group"] = _SERIALIZER.header("group", group, "str")
+    if permissions is not None:
+        _headers["x-ms-permissions"] = _SERIALIZER.header("permissions", permissions, "str")
+    if acl is not None:
+        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_modified_since is not None:
         _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
         _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
-def build_set_metadata_request(
+def build_lease_request(
     url: str,
     *,
+    x_ms_lease_action: Union[str, "_models.PathLeaseAction"],
+    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
+    x_ms_lease_break_period: Optional[int] = None,
     lease_id: Optional[str] = None,
-    metadata: Optional[Dict[str, str]] = None,
+    proposed_lease_id: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
     if_modified_since: Optional[datetime.datetime] = None,
-    request_id_parameter: Optional[str] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    x_ms_lease_duration: Optional[int] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("x_ms_lease_action", x_ms_lease_action, "str")
+    if x_ms_lease_duration is not None:
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("x_ms_lease_duration", x_ms_lease_duration, "int")
+    if x_ms_lease_break_period is not None:
+        _headers["x-ms-lease-break-period"] = _SERIALIZER.header(
+            "x_ms_lease_break_period", x_ms_lease_break_period, "int"
+        )
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if metadata is not None:
-        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
+    if proposed_lease_id is not None:
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_modified_since is not None:
         _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_get_access_policy_request(
+def build_read_request(
     url: str,
     *,
-    timeout: Optional[int] = None,
-    lease_id: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url = _format_url_section(_url, **path_format_arguments)
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_set_access_policy_request(
-    url: str,
-    *,
     timeout: Optional[int] = None,
+    range: Optional[str] = None,
     lease_id: Optional[str] = None,
-    access: Optional[Union[str, "_models.PublicAccessType"]] = None,
+    x_ms_range_get_content_md5: Optional[bool] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
     if_modified_since: Optional[datetime.datetime] = None,
     if_unmodified_since: Optional[datetime.datetime] = None,
-    request_id_parameter: Optional[str] = None,
-    content: Any = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: str = "AES256",
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
-    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if range is not None:
+        _headers["Range"] = _SERIALIZER.header("range", range, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if access is not None:
-        _headers["x-ms-blob-public-access"] = _SERIALIZER.header("access", access, "str")
+    if x_ms_range_get_content_md5 is not None:
+        _headers["x-ms-range-get-content-md5"] = _SERIALIZER.header(
+            "x_ms_range_get_content_md5", x_ms_range_get_content_md5, "bool"
+        )
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_modified_since is not None:
         _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
         _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if content_type is not None:
-        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
-
-
-def build_restore_request(
-    url: str,
-    *,
-    timeout: Optional[int] = None,
-    request_id_parameter: Optional[str] = None,
-    deleted_container_name: Optional[str] = None,
-    deleted_container_version: Optional[str] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url = _format_url_section(_url, **path_format_arguments)
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if deleted_container_name is not None:
-        _headers["x-ms-deleted-container-name"] = _SERIALIZER.header(
-            "deleted_container_name", deleted_container_name, "str"
-        )
-    if deleted_container_version is not None:
-        _headers["x-ms-deleted-container-version"] = _SERIALIZER.header(
-            "deleted_container_version", deleted_container_version, "str"
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
         )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_rename_request(
+def build_get_properties_request(
     url: str,
     *,
-    source_container_name: str,
-    timeout: Optional[int] = None,
     request_id_parameter: Optional[str] = None,
-    source_lease_id: Optional[str] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url = _format_url_section(_url, **path_format_arguments)
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    _headers["x-ms-source-container-name"] = _SERIALIZER.header("source_container_name", source_container_name, "str")
-    if source_lease_id is not None:
-        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_submit_batch_request(
-    url: str,
-    *,
-    content_length: int,
-    content: IO,
     timeout: Optional[int] = None,
-    request_id_parameter: Optional[str] = None,
+    action: Optional[Union[str, "_models.PathGetPropertiesAction"]] = None,
+    upn: Optional[bool] = None,
+    lease_id: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
-    multipart_content_type = kwargs.pop(
-        "multipart_content_type", _headers.pop("Content-Type", None)
-    )  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if action is not None:
+        _params["action"] = _SERIALIZER.query("action", action, "str")
+    if upn is not None:
+        _params["upn"] = _SERIALIZER.query("upn", upn, "bool")
 
     # Construct headers
-    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
-    if multipart_content_type is not None:
-        _headers["Content-Type"] = _SERIALIZER.header("multipart_content_type", multipart_content_type, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, content=content, **kwargs)
-
-
-def build_filter_blobs_request(
-    url: str,
-    *,
-    timeout: Optional[int] = None,
-    request_id_parameter: Optional[str] = None,
-    where: Optional[str] = None,
-    marker: Optional[str] = None,
-    maxresults: Optional[int] = None,
-    include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url = _format_url_section(_url, **path_format_arguments)
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if where is not None:
-        _params["where"] = _SERIALIZER.query("where", where, "str")
-    if marker is not None:
-        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
-    if maxresults is not None:
-        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
-    if include is not None:
-        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
-
-    # Construct headers
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="HEAD", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_acquire_lease_request(
+def build_delete_request(
     url: str,
     *,
+    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
-    duration: Optional[int] = None,
-    proposed_lease_id: Optional[str] = None,
+    recursive: Optional[bool] = None,
+    continuation: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
     if_modified_since: Optional[datetime.datetime] = None,
     if_unmodified_since: Optional[datetime.datetime] = None,
-    request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if recursive is not None:
+        _params["recursive"] = _SERIALIZER.query("recursive", recursive, "bool")
+    if continuation is not None:
+        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    if duration is not None:
-        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
-    if proposed_lease_id is not None:
-        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_modified_since is not None:
         _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
         _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_release_lease_request(
+def build_set_access_control_request(
     url: str,
     *,
-    lease_id: str,
     timeout: Optional[int] = None,
+    lease_id: Optional[str] = None,
+    owner: Optional[str] = None,
+    group: Optional[str] = None,
+    permissions: Optional[str] = None,
+    acl: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
     if_modified_since: Optional[datetime.datetime] = None,
     if_unmodified_since: Optional[datetime.datetime] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    action = kwargs.pop("action", _params.pop("action", "setAccessControl"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["action"] = _SERIALIZER.query("action", action, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if owner is not None:
+        _headers["x-ms-owner"] = _SERIALIZER.header("owner", owner, "str")
+    if group is not None:
+        _headers["x-ms-group"] = _SERIALIZER.header("group", group, "str")
+    if permissions is not None:
+        _headers["x-ms-permissions"] = _SERIALIZER.header("permissions", permissions, "str")
+    if acl is not None:
+        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_modified_since is not None:
         _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
         _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_renew_lease_request(
+def build_set_access_control_recursive_request(
     url: str,
     *,
-    lease_id: str,
+    mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
     timeout: Optional[int] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
+    continuation: Optional[str] = None,
+    force_flag: Optional[bool] = None,
+    max_records: Optional[int] = None,
+    acl: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    action = kwargs.pop("action", _params.pop("action", "setAccessControlRecursive"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["action"] = _SERIALIZER.query("action", action, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if continuation is not None:
+        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
+    _params["mode"] = _SERIALIZER.query("mode", mode, "str")
+    if force_flag is not None:
+        _params["forceFlag"] = _SERIALIZER.query("force_flag", force_flag, "bool")
+    if max_records is not None:
+        _params["maxRecords"] = _SERIALIZER.query("max_records", max_records, "int", minimum=1)
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if acl is not None:
+        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_break_lease_request(
+def build_flush_data_request(
     url: str,
     *,
     timeout: Optional[int] = None,
-    break_period: Optional[int] = None,
+    position: Optional[int] = None,
+    retain_uncommitted_data: Optional[bool] = None,
+    close: Optional[bool] = None,
+    content_length: Optional[int] = None,
+    content_md5: Optional[bytes] = None,
+    lease_id: Optional[str] = None,
+    cache_control: Optional[str] = None,
+    content_type_parameter: Optional[str] = None,
+    content_disposition: Optional[str] = None,
+    content_encoding: Optional[str] = None,
+    content_language: Optional[str] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
     if_modified_since: Optional[datetime.datetime] = None,
     if_unmodified_since: Optional[datetime.datetime] = None,
     request_id_parameter: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: str = "AES256",
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    action = kwargs.pop("action", _params.pop("action", "flush"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["action"] = _SERIALIZER.query("action", action, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if position is not None:
+        _params["position"] = _SERIALIZER.query("position", position, "int")
+    if retain_uncommitted_data is not None:
+        _params["retainUncommittedData"] = _SERIALIZER.query("retain_uncommitted_data", retain_uncommitted_data, "bool")
+    if close is not None:
+        _params["close"] = _SERIALIZER.query("close", close, "bool")
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    if break_period is not None:
-        _headers["x-ms-lease-break-period"] = _SERIALIZER.header("break_period", break_period, "int")
+    if content_length is not None:
+        _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int", minimum=0)
+    if content_md5 is not None:
+        _headers["x-ms-content-md5"] = _SERIALIZER.header("content_md5", content_md5, "bytearray")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if cache_control is not None:
+        _headers["x-ms-cache-control"] = _SERIALIZER.header("cache_control", cache_control, "str")
+    if content_type_parameter is not None:
+        _headers["x-ms-content-type"] = _SERIALIZER.header("content_type_parameter", content_type_parameter, "str")
+    if content_disposition is not None:
+        _headers["x-ms-content-disposition"] = _SERIALIZER.header("content_disposition", content_disposition, "str")
+    if content_encoding is not None:
+        _headers["x-ms-content-encoding"] = _SERIALIZER.header("content_encoding", content_encoding, "str")
+    if content_language is not None:
+        _headers["x-ms-content-language"] = _SERIALIZER.header("content_language", content_language, "str")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
     if if_modified_since is not None:
         _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
     if if_unmodified_since is not None:
         _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_change_lease_request(
+def build_append_data_request(
     url: str,
     *,
-    lease_id: str,
-    proposed_lease_id: str,
+    content: IO,
+    position: Optional[int] = None,
     timeout: Optional[int] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
+    content_length: Optional[int] = None,
+    transactional_content_hash: Optional[bytes] = None,
+    transactional_content_crc64: Optional[bytes] = None,
+    lease_id: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: str = "AES256",
+    flush: Optional[bool] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    action = kwargs.pop("action", _params.pop("action", "append"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["action"] = _SERIALIZER.query("action", action, "str")
+    if position is not None:
+        _params["position"] = _SERIALIZER.query("position", position, "int")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if flush is not None:
+        _params["flush"] = _SERIALIZER.query("flush", flush, "bool")
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if content_length is not None:
+        _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int", minimum=0)
+    if transactional_content_hash is not None:
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_hash", transactional_content_hash, "bytearray"
+        )
+    if transactional_content_crc64 is not None:
+        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
+            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+        )
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
-def build_list_blob_flat_segment_request(
+def build_set_expiry_request(
     url: str,
     *,
-    prefix: Optional[str] = None,
-    marker: Optional[str] = None,
-    maxresults: Optional[int] = None,
-    include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+    expiry_options: Union[str, "_models.PathExpiryOptions"],
     timeout: Optional[int] = None,
     request_id_parameter: Optional[str] = None,
+    expires_on: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if prefix is not None:
-        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
-    if marker is not None:
-        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
-    if maxresults is not None:
-        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
-    if include is not None:
-        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    _headers["x-ms-expiry-option"] = _SERIALIZER.header("expiry_options", expiry_options, "str")
+    if expires_on is not None:
+        _headers["x-ms-expiry-time"] = _SERIALIZER.header("expires_on", expires_on, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_list_blob_hierarchy_segment_request(
+def build_undelete_request(
     url: str,
     *,
-    delimiter: str,
-    prefix: Optional[str] = None,
-    marker: Optional[str] = None,
-    maxresults: Optional[int] = None,
-    include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
     timeout: Optional[int] = None,
+    undelete_source: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
+    comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
+    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if prefix is not None:
-        _params["prefix"] = _SERIALIZER.query("prefix", prefix, "str")
-    _params["delimiter"] = _SERIALIZER.query("delimiter", delimiter, "str")
-    if marker is not None:
-        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
-    if maxresults is not None:
-        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
-    if include is not None:
-        _params["include"] = _SERIALIZER.query("include", include, "[str]", div=",")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
+    if undelete_source is not None:
+        _headers["x-ms-undelete-source"] = _SERIALIZER.header("undelete_source", undelete_source, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
-    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{containerName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url = _format_url_section(_url, **path_format_arguments)
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-class ContainerOperations:
+class PathOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
-        :class:`~azure.storage.blob.AzureBlobStorage`'s
-        :attr:`container` attribute.
+        :class:`~azure.storage.filedatalake.AzureDataLakeStorageRESTAPI`'s
+        :attr:`path` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
         input_args = list(args)
         self._client = input_args.pop(0) if input_args else kwargs.pop("client")
         self._config = input_args.pop(0) if input_args else kwargs.pop("config")
         self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
         self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def create(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout: Optional[int] = None,
-        metadata: Optional[Dict[str, str]] = None,
-        access: Optional[Union[str, "_models.PublicAccessType"]] = None,
         request_id_parameter: Optional[str] = None,
-        container_cpk_scope_info: Optional[_models.ContainerCpkScopeInfo] = None,
+        timeout: Optional[int] = None,
+        resource: Optional[Union[str, "_models.PathResourceType"]] = None,
+        continuation: Optional[str] = None,
+        mode: Optional[Union[str, "_models.PathRenameMode"]] = None,
+        rename_source: Optional[str] = None,
+        source_lease_id: Optional[str] = None,
+        properties: Optional[str] = None,
+        permissions: Optional[str] = None,
+        umask: Optional[str] = None,
+        owner: Optional[str] = None,
+        group: Optional[str] = None,
+        acl: Optional[str] = None,
+        proposed_lease_id: Optional[str] = None,
+        lease_duration: Optional[int] = None,
+        expiry_options: Optional[Union[str, "_models.PathExpiryOptions"]] = None,
+        expires_on: Optional[str] = None,
+        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
     ) -> None:
-        """creates a new container under the specified account. If the container with the same name
-        already exists, the operation fails.
+        """Create File | Create Directory | Rename File | Rename Directory.
+
+        Create or rename a file or directory.    By default, the destination is overwritten and if the
+        destination already exists and has a lease the lease is broken.  This operation supports
+        conditional HTTP requests.  For more information, see `Specifying Conditional Headers for Blob
+        Service Operations
+        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+        To fail if the destination already exists, use a conditional request with If-None-Match: "*".
 
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
-         If no name-value pairs are specified, the operation will copy the metadata from the source blob
-         or file to the destination blob. If one or more name-value pairs are specified, the destination
-         blob is created with the specified metadata, and metadata is not copied from the source blob or
-         file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
-         rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
-         information. Default value is None.
-        :type metadata: dict[str, str]
-        :param access: Specifies whether data in the container may be accessed publicly and the level
-         of access. Known values are: "container" and "blob". Default value is None.
-        :type access: str or ~azure.storage.blob.models.PublicAccessType
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param container_cpk_scope_info: Parameter group. Default value is None.
-        :type container_cpk_scope_info: ~azure.storage.blob.models.ContainerCpkScopeInfo
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-
-        _default_encryption_scope = None
-        _prevent_encryption_scope_override = None
-        if container_cpk_scope_info is not None:
-            _default_encryption_scope = container_cpk_scope_info.default_encryption_scope
-            _prevent_encryption_scope_override = container_cpk_scope_info.prevent_encryption_scope_override
-
-        request = build_create_request(
-            url=self._config.url,
-            timeout=timeout,
-            metadata=metadata,
-            access=access,
-            request_id_parameter=request_id_parameter,
-            default_encryption_scope=_default_encryption_scope,
-            prevent_encryption_scope_override=_prevent_encryption_scope_override,
-            restype=restype,
-            version=self._config.version,
-            template_url=self.create.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
-
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [201]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    create.metadata = {"url": "{url}/{containerName}"}  # type: ignore
-
-    @distributed_trace
-    def get_properties(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        **kwargs: Any
-    ) -> None:
-        """returns all user-defined metadata and system properties for the specified container. The data
-        returned does not include the container's list of blobs.
-
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param resource: Required only for Create File and Create Directory. The value must be "file"
+         or "directory". Known values are: "directory" and "file". Default value is None.
+        :type resource: str or ~azure.storage.filedatalake.models.PathResourceType
+        :param continuation: Optional.  When deleting a directory, the number of paths that are deleted
+         with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a
+         continuation token is returned in this response header.  When a continuation token is returned
+         in the response, it must be specified in a subsequent invocation of the delete operation to
+         continue deleting the directory. Default value is None.
+        :type continuation: str
+        :param mode: Optional. Valid only when namespace is enabled. This parameter determines the
+         behavior of the rename operation. The value must be "legacy" or "posix", and the default value
+         will be "posix". Known values are: "legacy" and "posix". Default value is None.
+        :type mode: str or ~azure.storage.filedatalake.models.PathRenameMode
+        :param rename_source: An optional file or directory to be renamed.  The value must have the
+         following format: "/{filesystem}/{path}".  If "x-ms-properties" is specified, the properties
+         will overwrite the existing properties; otherwise, the existing properties will be preserved.
+         This value must be a URL percent-encoded string. Note that the string may only contain ASCII
+         characters in the ISO-8859-1 character set. Default value is None.
+        :type rename_source: str
+        :param source_lease_id: A lease ID for the source path. If specified, the source path must have
+         an active lease and the lease ID must match. Default value is None.
+        :type source_lease_id: str
+        :param properties: Optional. User-defined properties to be stored with the filesystem, in the
+         format of a comma-separated list of name and value pairs "n1=v1, n2=v2, ...", where each value
+         is a base64 encoded string. Note that the string may only contain ASCII characters in the
+         ISO-8859-1 character set.  If the filesystem exists, any properties not included in the list
+         will be removed.  All properties are removed if the header is omitted.  To merge new and
+         existing properties, first get all existing properties and the current E-Tag, then make a
+         conditional request with the E-Tag and include values for all properties. Default value is
+         None.
+        :type properties: str
+        :param permissions: Optional and only valid if Hierarchical Namespace is enabled for the
+         account. Sets POSIX access permissions for the file owner, the file owning group, and others.
+         Each class may be granted read, write, or execute permission.  The sticky bit is also
+         supported.  Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
+         Default value is None.
+        :type permissions: str
+        :param umask: Optional and only valid if Hierarchical Namespace is enabled for the account.
+         When creating a file or directory and the parent folder does not have a default ACL, the umask
+         restricts the permissions of the file or directory to be created.  The resulting permission is
+         given by p bitwise and not u, where p is the permission and u is the umask.  For example, if p
+         is 0777 and u is 0057, then the resulting permission is 0720.  The default permission is 0777
+         for a directory and 0666 for a file.  The default umask is 0027.  The umask must be specified
+         in 4-digit octal notation (e.g. 0766). Default value is None.
+        :type umask: str
+        :param owner: Optional. The owner of the blob or directory. Default value is None.
+        :type owner: str
+        :param group: Optional. The owning group of the blob or directory. Default value is None.
+        :type group: str
+        :param acl: Sets POSIX access control rights on files and directories. The value is a
+         comma-separated list of access control entries. Each access control entry (ACE) consists of a
+         scope, a type, a user or group identifier, and permissions in the format
+         "[scope:][type]:[id]:[permissions]". Default value is None.
+        :type acl: str
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Default value is None.
+        :type proposed_lease_id: str
+        :param lease_duration: The lease duration is required to acquire a lease, and specifies the
+         duration of the lease in seconds.  The lease duration must be between 15 and 60 seconds or -1
+         for infinite lease. Default value is None.
+        :type lease_duration: int
+        :param expiry_options: Required. Indicates mode of the expiry time. Known values are:
+         "NeverExpire", "RelativeToCreation", "RelativeToNow", and "Absolute". Default value is None.
+        :type expiry_options: str or ~azure.storage.filedatalake.models.PathExpiryOptions
+        :param expires_on: The time to set the blob to expiry. Default value is None.
+        :type expires_on: str
+        :param path_http_headers: Parameter group. Default value is None.
+        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :param source_modified_access_conditions: Parameter group. Default value is None.
+        :type source_modified_access_conditions:
+         ~azure.storage.filedatalake.models.SourceModifiedAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
+        _cache_control = None
+        _content_encoding = None
+        _content_language = None
+        _content_disposition = None
+        _content_type_parameter = None
         _lease_id = None
+        _if_match = None
+        _if_none_match = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _source_if_match = None
+        _source_if_none_match = None
+        _source_if_modified_since = None
+        _source_if_unmodified_since = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        if path_http_headers is not None:
+            _cache_control = path_http_headers.cache_control
+            _content_disposition = path_http_headers.content_disposition
+            _content_encoding = path_http_headers.content_encoding
+            _content_language = path_http_headers.content_language
+            _content_type_parameter = path_http_headers.content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        if source_modified_access_conditions is not None:
+            _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
+            _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
 
-        request = build_get_properties_request(
+        request = build_create_request(
             url=self._config.url,
+            request_id_parameter=request_id_parameter,
             timeout=timeout,
+            resource=resource,
+            continuation=continuation,
+            mode=mode,
+            cache_control=_cache_control,
+            content_encoding=_content_encoding,
+            content_language=_content_language,
+            content_disposition=_content_disposition,
+            content_type_parameter=_content_type_parameter,
+            rename_source=rename_source,
             lease_id=_lease_id,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
+            source_lease_id=source_lease_id,
+            properties=properties,
+            permissions=permissions,
+            umask=umask,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            source_if_match=_source_if_match,
+            source_if_none_match=_source_if_none_match,
+            source_if_modified_since=_source_if_modified_since,
+            source_if_unmodified_since=_source_if_unmodified_since,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            owner=owner,
+            group=group,
+            acl=acl,
+            proposed_lease_id=proposed_lease_id,
+            lease_duration=lease_duration,
+            expiry_options=expiry_options,
+            expires_on=expires_on,
             version=self._config.version,
-            template_url=self.get_properties.metadata["url"],
+            template_url=self.create.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
-        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-blob-public-access"] = self._deserialize(
-            "str", response.headers.get("x-ms-blob-public-access")
-        )
-        response_headers["x-ms-has-immutability-policy"] = self._deserialize(
-            "bool", response.headers.get("x-ms-has-immutability-policy")
+        response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
+        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
         )
-        response_headers["x-ms-has-legal-hold"] = self._deserialize("bool", response.headers.get("x-ms-has-legal-hold"))
-        response_headers["x-ms-default-encryption-scope"] = self._deserialize(
-            "str", response.headers.get("x-ms-default-encryption-scope")
-        )
-        response_headers["x-ms-deny-encryption-scope-override"] = self._deserialize(
-            "bool", response.headers.get("x-ms-deny-encryption-scope-override")
-        )
-        response_headers["x-ms-immutable-storage-with-versioning-enabled"] = self._deserialize(
-            "bool", response.headers.get("x-ms-immutable-storage-with-versioning-enabled")
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
         )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    create.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def update(
         self,
-        timeout: Optional[int] = None,
+        action: Union[str, "_models.PathUpdateAction"],
+        mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
+        body: IO,
         request_id_parameter: Optional[str] = None,
+        timeout: Optional[int] = None,
+        max_records: Optional[int] = None,
+        continuation: Optional[str] = None,
+        force_flag: Optional[bool] = None,
+        position: Optional[int] = None,
+        retain_uncommitted_data: Optional[bool] = None,
+        close: Optional[bool] = None,
+        content_length: Optional[int] = None,
+        properties: Optional[str] = None,
+        owner: Optional[str] = None,
+        group: Optional[str] = None,
+        permissions: Optional[str] = None,
+        acl: Optional[str] = None,
+        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """operation marks the specified container for deletion. The container and any blobs contained
-        within it are later deleted during garbage collection.
+    ) -> Optional[_models.SetAccessControlRecursiveResponse]:
+        """Append Data | Flush Data | Set Properties | Set Access Control.
 
+        Uploads data to be appended to a file, flushes (writes) previously uploaded data to a file,
+        sets properties for a file or directory, or sets access control for a file or directory. Data
+        can only be appended to a file. Concurrent writes to the same file using multiple clients are
+        not supported. This operation supports conditional HTTP requests. For more information, see
+        `Specifying Conditional Headers for Blob Service Operations
+        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+
+        :param action: The action must be "append" to upload data to be appended to a file, "flush" to
+         flush previously uploaded data to a file, "setProperties" to set the properties of a file or
+         directory, "setAccessControl" to set the owner, group, permissions, or access control list for
+         a file or directory, or  "setAccessControlRecursive" to set the access control list for a
+         directory recursively. Note that Hierarchical Namespace must be enabled for the account in
+         order to use access control.  Also note that the Access Control List (ACL) includes permissions
+         for the owner, owning group, and others, so the x-ms-permissions and x-ms-acl request headers
+         are mutually exclusive. Known values are: "append", "flush", "setProperties",
+         "setAccessControl", and "setAccessControlRecursive". Required.
+        :type action: str or ~azure.storage.filedatalake.models.PathUpdateAction
+        :param mode: Mode "set" sets POSIX access control rights on files and directories, "modify"
+         modifies one or more POSIX access control rights  that pre-exist on files and directories,
+         "remove" removes one or more POSIX access control rights  that were present earlier on files
+         and directories. Known values are: "set", "modify", and "remove". Required.
+        :type mode: str or ~azure.storage.filedatalake.models.PathSetAccessControlRecursiveMode
+        :param body: Initial data. Required.
+        :type body: IO
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param max_records: Optional. Valid for "SetAccessControlRecursive" operation. It specifies the
+         maximum number of files or directories on which the acl change will be applied. If omitted or
+         greater than 2,000, the request will process up to 2,000 items. Default value is None.
+        :type max_records: int
+        :param continuation: Optional. The number of paths processed with each invocation is limited.
+         If the number of paths to be processed exceeds this limit, a continuation token is returned in
+         the response header x-ms-continuation. When a continuation token is  returned in the response,
+         it must be percent-encoded and specified in a subsequent invocation of
+         setAccessControlRecursive operation. Default value is None.
+        :type continuation: str
+        :param force_flag: Optional. Valid for "SetAccessControlRecursive" operation. If set to false,
+         the operation will terminate quickly on encountering user errors (4XX). If true, the operation
+         will ignore user errors and proceed with the operation on other sub-entities of the directory.
+         Continuation token will only be returned when forceFlag is true in case of user errors. If not
+         set the default value is false for this. Default value is None.
+        :type force_flag: bool
+        :param position: This parameter allows the caller to upload data in parallel and control the
+         order in which it is appended to the file.  It is required when uploading data to be appended
+         to the file and when flushing previously uploaded data to the file.  The value must be the
+         position where the data is to be appended.  Uploaded data is not immediately flushed, or
+         written, to the file.  To flush, the previously uploaded data must be contiguous, the position
+         parameter must be specified and equal to the length of the file after all data has been
+         written, and there must not be a request entity body included with the request. Default value
+         is None.
+        :type position: int
+        :param retain_uncommitted_data: Valid only for flush operations.  If "true", uncommitted data
+         is retained after the flush operation completes; otherwise, the uncommitted data is deleted
+         after the flush operation.  The default is false.  Data at offsets less than the specified
+         position are written to the file when flush succeeds, but this optional parameter allows data
+         after the flush position to be retained for a future flush operation. Default value is None.
+        :type retain_uncommitted_data: bool
+        :param close: Azure Storage Events allow applications to receive notifications when files
+         change. When Azure Storage Events are enabled, a file changed event is raised. This event has a
+         property indicating whether this is the final change to distinguish the difference between an
+         intermediate flush to a file stream and the final close of a file stream. The close query
+         parameter is valid only when the action is "flush" and change notifications are enabled. If the
+         value of close is "true" and the flush operation completes successfully, the service raises a
+         file change notification with a property indicating that this is the final update (the file
+         stream has been closed). If "false" a change notification is raised indicating the file has
+         changed. The default is false. This query parameter is set to true by the Hadoop ABFS driver to
+         indicate that the file stream has been closed.". Default value is None.
+        :type close: bool
+        :param content_length: Required for "Append Data" and "Flush Data".  Must be 0 for "Flush
+         Data".  Must be the length of the request content in bytes for "Append Data". Default value is
+         None.
+        :type content_length: int
+        :param properties: Optional. User-defined properties to be stored with the filesystem, in the
+         format of a comma-separated list of name and value pairs "n1=v1, n2=v2, ...", where each value
+         is a base64 encoded string. Note that the string may only contain ASCII characters in the
+         ISO-8859-1 character set.  If the filesystem exists, any properties not included in the list
+         will be removed.  All properties are removed if the header is omitted.  To merge new and
+         existing properties, first get all existing properties and the current E-Tag, then make a
+         conditional request with the E-Tag and include values for all properties. Default value is
+         None.
+        :type properties: str
+        :param owner: Optional. The owner of the blob or directory. Default value is None.
+        :type owner: str
+        :param group: Optional. The owning group of the blob or directory. Default value is None.
+        :type group: str
+        :param permissions: Optional and only valid if Hierarchical Namespace is enabled for the
+         account. Sets POSIX access permissions for the file owner, the file owning group, and others.
+         Each class may be granted read, write, or execute permission.  The sticky bit is also
+         supported.  Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
+         Default value is None.
+        :type permissions: str
+        :param acl: Sets POSIX access control rights on files and directories. The value is a
+         comma-separated list of access control entries. Each access control entry (ACE) consists of a
+         scope, a type, a user or group identifier, and permissions in the format
+         "[scope:][type]:[id]:[permissions]". Default value is None.
+        :type acl: str
+        :param path_http_headers: Parameter group. Default value is None.
+        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: SetAccessControlRecursiveResponse or None or the result of cls(response)
+        :rtype: ~azure.storage.filedatalake.models.SetAccessControlRecursiveResponse or None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[Optional[_models.SetAccessControlRecursiveResponse]]
 
+        _content_md5 = None
         _lease_id = None
+        _cache_control = None
+        _content_type_parameter = None
+        _content_disposition = None
+        _content_encoding = None
+        _content_language = None
+        _if_match = None
+        _if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
+        if path_http_headers is not None:
+            _cache_control = path_http_headers.cache_control
+            _content_disposition = path_http_headers.content_disposition
+            _content_encoding = path_http_headers.content_encoding
+            _content_language = path_http_headers.content_language
+            _content_md5 = path_http_headers.content_md5
+            _content_type_parameter = path_http_headers.content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
             _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        _content = body
 
-        request = build_delete_request(
+        request = build_update_request(
             url=self._config.url,
+            action=action,
+            mode=mode,
+            request_id_parameter=request_id_parameter,
             timeout=timeout,
+            max_records=max_records,
+            continuation=continuation,
+            force_flag=force_flag,
+            position=position,
+            retain_uncommitted_data=retain_uncommitted_data,
+            close=close,
+            content_length=content_length,
+            content_md5=_content_md5,
             lease_id=_lease_id,
+            cache_control=_cache_control,
+            content_type_parameter=_content_type_parameter,
+            content_disposition=_content_disposition,
+            content_encoding=_content_encoding,
+            content_language=_content_language,
+            properties=properties,
+            owner=owner,
+            group=group,
+            permissions=permissions,
+            acl=acl,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
+            content_type=content_type,
             version=self._config.version,
-            template_url=self.delete.metadata["url"],
+            content=_content,
+            template_url=self.update.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [200, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
+        deserialized = None
         response_headers = {}
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        if response.status_code == 200:
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
+            response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
+            response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+
+            deserialized = self._deserialize("SetAccessControlRecursiveResponse", pipeline_response)
+
+        if response.status_code == 202:
+            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    delete.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+        return deserialized
+
+    update.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def set_metadata(  # pylint: disable=inconsistent-return-statements
+    def lease(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout: Optional[int] = None,
-        metadata: Optional[Dict[str, str]] = None,
+        x_ms_lease_action: Union[str, "_models.PathLeaseAction"],
         request_id_parameter: Optional[str] = None,
+        timeout: Optional[int] = None,
+        x_ms_lease_break_period: Optional[int] = None,
+        proposed_lease_id: Optional[str] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """operation sets one or more user-defined name-value pairs for the specified container.
+        """Lease Path.
 
+        Create and manage a lease to restrict write and delete access to the path. This operation
+        supports conditional HTTP requests.  For more information, see `Specifying Conditional Headers
+        for Blob Service Operations
+        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+
+        :param x_ms_lease_action: There are five lease actions: "acquire", "break", "change", "renew",
+         and "release". Use "acquire" and specify the "x-ms-proposed-lease-id" and "x-ms-lease-duration"
+         to acquire a new lease. Use "break" to break an existing lease. When a lease is broken, the
+         lease break period is allowed to elapse, during which time no lease operation except break and
+         release can be performed on the file. When a lease is successfully broken, the response
+         indicates the interval in seconds until a new lease can be acquired. Use "change" and specify
+         the current lease ID in "x-ms-lease-id" and the new lease ID in "x-ms-proposed-lease-id" to
+         change the lease ID of an active lease. Use "renew" and specify the "x-ms-lease-id" to renew an
+         existing lease. Use "release" and specify the "x-ms-lease-id" to release a lease. Known values
+         are: "acquire", "break", "change", "renew", and "release". Required.
+        :type x_ms_lease_action: str or ~azure.storage.filedatalake.models.PathLeaseAction
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
-         If no name-value pairs are specified, the operation will copy the metadata from the source blob
-         or file to the destination blob. If one or more name-value pairs are specified, the destination
-         blob is created with the specified metadata, and metadata is not copied from the source blob or
-         file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
-         rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
-         information. Default value is None.
-        :type metadata: dict[str, str]
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param x_ms_lease_break_period: The lease break period duration is optional to break a lease,
+         and  specifies the break period of the lease in seconds.  The lease break  duration must be
+         between 0 and 60 seconds. Default value is None.
+        :type x_ms_lease_break_period: int
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Default value is None.
+        :type proposed_lease_id: str
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "metadata"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
+        _if_match = None
+        _if_none_match = None
         _if_modified_since = None
+        _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
             _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_set_metadata_request(
+        request = build_lease_request(
             url=self._config.url,
+            x_ms_lease_action=x_ms_lease_action,
+            request_id_parameter=request_id_parameter,
             timeout=timeout,
+            x_ms_lease_break_period=x_ms_lease_break_period,
             lease_id=_lease_id,
-            metadata=metadata,
+            proposed_lease_id=proposed_lease_id,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
             if_modified_since=_if_modified_since,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
-            comp=comp,
+            if_unmodified_since=_if_unmodified_since,
+            x_ms_lease_duration=self._config.x_ms_lease_duration,
             version=self._config.version,
-            template_url=self.set_metadata.metadata["url"],
+            template_url=self.lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [200, 201, 202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        if response.status_code == 200:
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+
+        if response.status_code == 201:
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+
+        if response.status_code == 202:
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-lease-time"] = self._deserialize("str", response.headers.get("x-ms-lease-time"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_metadata.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    lease.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def get_access_policy(
+    def read(
         self,
-        timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
+        timeout: Optional[int] = None,
+        range: Optional[str] = None,
+        x_ms_range_get_content_md5: Optional[bool] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
-    ) -> List[_models.SignedIdentifier]:
-        """gets the permissions for the specified container. The permissions indicate whether container
-        data may be accessed publicly.
+    ) -> Iterator[bytes]:
+        """Read File.
 
+        Read the contents of a file.  For read operations, range requests are supported. This operation
+        supports conditional HTTP requests.  For more information, see `Specifying Conditional Headers
+        for Blob Service Operations
+        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+        :param range: The HTTP Range request header specifies one or more byte ranges of the resource
+         to be retrieved. Default value is None.
+        :type range: str
+        :param x_ms_range_get_content_md5: Optional. When this header is set to "true" and specified
+         together with the Range header, the service returns the MD5 hash for the range, as long as the
+         range is less than or equal to 4MB in size. If this header is specified without the Range
+         header, the service returns status code 400 (Bad Request). If this header is set to true when
+         the range exceeds 4 MB in size, the service returns status code 400 (Bad Request). Default
          value is None.
-        :type request_id_parameter: str
+        :type x_ms_range_get_content_md5: bool
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
-         in unsupported behavior.
-        :paramtype comp: str
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: list of SignedIdentifier or the result of cls(response)
-        :rtype: list[~azure.storage.blob.models.SignedIdentifier]
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[List[_models.SignedIdentifier]]
+        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
 
         _lease_id = None
+        _if_match = None
+        _if_none_match = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
 
-        request = build_get_access_policy_request(
+        request = build_read_request(
             url=self._config.url,
+            request_id_parameter=request_id_parameter,
             timeout=timeout,
+            range=range,
             lease_id=_lease_id,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
-            comp=comp,
+            x_ms_range_get_content_md5=x_ms_range_get_content_md5,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
             version=self._config.version,
-            template_url=self.get_access_policy.metadata["url"],
+            template_url=self.read.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
+            request, stream=True, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [200, 206]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["x-ms-blob-public-access"] = self._deserialize(
-            "str", response.headers.get("x-ms-blob-public-access")
-        )
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        if response.status_code == 200:
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-resource-type"] = self._deserialize(
+                "str", response.headers.get("x-ms-resource-type")
+            )
+            response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-request-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
 
-        deserialized = self._deserialize("[SignedIdentifier]", pipeline_response)
+            deserialized = response.stream_download(self._client._pipeline)
+
+        if response.status_code == 206:
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
+            response_headers["x-ms-content-md5"] = self._deserialize("str", response.headers.get("x-ms-content-md5"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["x-ms-resource-type"] = self._deserialize(
+                "str", response.headers.get("x-ms-resource-type")
+            )
+            response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+            response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-request-server-encrypted")
+            )
+            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+                "str", response.headers.get("x-ms-encryption-key-sha256")
+            )
+
+            deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    read.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def set_access_policy(  # pylint: disable=inconsistent-return-statements
+    def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout: Optional[int] = None,
-        access: Optional[Union[str, "_models.PublicAccessType"]] = None,
         request_id_parameter: Optional[str] = None,
+        timeout: Optional[int] = None,
+        action: Optional[Union[str, "_models.PathGetPropertiesAction"]] = None,
+        upn: Optional[bool] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
-        container_acl: Optional[List[_models.SignedIdentifier]] = None,
         **kwargs: Any
     ) -> None:
-        """sets the permissions for the specified container. The permissions indicate whether blobs in a
-        container may be accessed publicly.
+        """Get Properties | Get Status | Get Access Control List.
 
+        Get Properties returns all system and user defined properties for a path. Get Status returns
+        all system defined properties for a path. Get Access Control List returns the access control
+        list for a path. This operation supports conditional HTTP requests.  For more information, see
+        `Specifying Conditional Headers for Blob Service Operations
+        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param access: Specifies whether data in the container may be accessed publicly and the level
-         of access. Known values are: "container" and "blob". Default value is None.
-        :type access: str or ~azure.storage.blob.models.PublicAccessType
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param action: Optional. If the value is "getStatus" only the system defined properties for the
+         path are returned. If the value is "getAccessControl" the access control list is returned in
+         the response headers (Hierarchical Namespace must be enabled for the account), otherwise the
+         properties are returned. Known values are: "getAccessControl" and "getStatus". Default value is
+         None.
+        :type action: str or ~azure.storage.filedatalake.models.PathGetPropertiesAction
+        :param upn: Optional. Valid only when Hierarchical Namespace is enabled for the account. If
+         "true", the user identity values returned in the x-ms-owner, x-ms-group, and x-ms-acl response
+         headers will be transformed from Azure Active Directory Object IDs to User Principal Names.  If
+         "false", the values will be returned as Azure Active Directory Object IDs. The default value is
+         false. Note that group and application Object IDs are not translated because they do not have
+         unique friendly names. Default value is None.
+        :type upn: bool
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :param container_acl: the acls for the container. Default value is None.
-        :type container_acl: list[~azure.storage.blob.models.SignedIdentifier]
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
-         in unsupported behavior.
-        :paramtype comp: str
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
 
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "acl"))  # type: str
-        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
+        _if_match = None
+        _if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
             _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        serialization_ctxt = {"xml": {"name": "SignedIdentifiers", "wrapped": True, "itemsName": "SignedIdentifier"}}
-        if container_acl is not None:
-            _content = self._serialize.body(
-                container_acl, "[SignedIdentifier]", is_xml=True, serialization_ctxt=serialization_ctxt
-            )
-        else:
-            _content = None
 
-        request = build_set_access_policy_request(
+        request = build_get_properties_request(
             url=self._config.url,
+            request_id_parameter=request_id_parameter,
             timeout=timeout,
+            action=action,
+            upn=upn,
             lease_id=_lease_id,
-            access=access,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
-            comp=comp,
-            content_type=content_type,
             version=self._config.version,
-            content=_content,
-            template_url=self.set_access_policy.metadata["url"],
+            template_url=self.get_properties.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
@@ -1486,581 +1837,238 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
+        response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+        response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+        response_headers["Content-Disposition"] = self._deserialize("str", response.headers.get("Content-Disposition"))
+        response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+        response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-resource-type"] = self._deserialize("str", response.headers.get("x-ms-resource-type"))
+        response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
+        response_headers["x-ms-owner"] = self._deserialize("str", response.headers.get("x-ms-owner"))
+        response_headers["x-ms-group"] = self._deserialize("str", response.headers.get("x-ms-group"))
+        response_headers["x-ms-permissions"] = self._deserialize("str", response.headers.get("x-ms-permissions"))
+        response_headers["x-ms-acl"] = self._deserialize("str", response.headers.get("x-ms-acl"))
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_access_policy.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    get_properties.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def restore(  # pylint: disable=inconsistent-return-statements
+    def delete(  # pylint: disable=inconsistent-return-statements
         self,
-        timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        deleted_container_name: Optional[str] = None,
-        deleted_container_version: Optional[str] = None,
-        **kwargs: Any
-    ) -> None:
-        """Restores a previously-deleted container.
-
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :param deleted_container_name: Optional.  Version 2019-12-12 and later.  Specifies the name of
-         the deleted container to restore. Default value is None.
-        :type deleted_container_name: str
-        :param deleted_container_version: Optional.  Version 2019-12-12 and later.  Specifies the
-         version of the deleted container to restore. Default value is None.
-        :type deleted_container_version: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-
-        request = build_restore_request(
-            url=self._config.url,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            deleted_container_name=deleted_container_name,
-            deleted_container_version=deleted_container_version,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            template_url=self.restore.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
-
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [201]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    restore.metadata = {"url": "{url}/{containerName}"}  # type: ignore
-
-    @distributed_trace
-    def rename(  # pylint: disable=inconsistent-return-statements
-        self,
-        source_container_name: str,
         timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        source_lease_id: Optional[str] = None,
+        recursive: Optional[bool] = None,
+        continuation: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Renames an existing container.
-
-        :param source_container_name: Required.  Specifies the name of the container to rename.
-         Required.
-        :type source_container_name: str
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :param source_lease_id: A lease ID for the source path. If specified, the source path must have
-         an active lease and the lease ID must match. Default value is None.
-        :type source_lease_id: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "rename". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}) or {})
+        """Delete File | Delete Directory.
 
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "rename"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        Delete the file or directory. This operation supports conditional HTTP requests.  For more
+        information, see `Specifying Conditional Headers for Blob Service Operations
+        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
 
-        request = build_rename_request(
-            url=self._config.url,
-            source_container_name=source_container_name,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            source_lease_id=source_lease_id,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            template_url=self.rename.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
-
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    rename.metadata = {"url": "{url}/{containerName}"}  # type: ignore
-
-    @distributed_trace
-    def submit_batch(
-        self,
-        content_length: int,
-        body: IO,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
-    ) -> Iterator[bytes]:
-        """The Batch operation allows multiple API calls to be embedded into a single HTTP request.
-
-        :param content_length: The length of the request. Required.
-        :type content_length: int
-        :param body: Initial data. Required.
-        :type body: IO
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
-        :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "batch". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: Iterator of the response bytes or the result of cls(response)
-        :rtype: Iterator[bytes]
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
-        multipart_content_type = kwargs.pop(
-            "multipart_content_type", _headers.pop("Content-Type", "application/xml")
-        )  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
-
-        _content = body
-
-        request = build_submit_batch_request(
-            url=self._config.url,
-            content_length=content_length,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
-            comp=comp,
-            multipart_content_type=multipart_content_type,
-            version=self._config.version,
-            content=_content,
-            template_url=self.submit_batch.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
-
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=True, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [202]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-
-        deserialized = response.stream_download(self._client._pipeline)
-
-        if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
-
-    submit_batch.metadata = {"url": "{url}/{containerName}"}  # type: ignore
-
-    @distributed_trace
-    def filter_blobs(
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        where: Optional[str] = None,
-        marker: Optional[str] = None,
-        maxresults: Optional[int] = None,
-        include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
-        **kwargs: Any
-    ) -> _models.FilterBlobSegment:
-        """The Filter Blobs operation enables callers to list blobs in a container whose tags match a
-        given search expression.  Filter blobs searches within the given container.
-
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :param where: Filters the results to return only to return only blobs whose tags match the
-         specified expression. Default value is None.
-        :type where: str
-        :param marker: A string value that identifies the portion of the list of containers to be
-         returned with the next listing operation. The operation returns the NextMarker value within the
-         response body if the listing operation did not return all containers remaining to be listed
-         with the current page. The NextMarker value can be used as the value for the marker parameter
-         in a subsequent call to request the next page of list items. The marker value is opaque to the
-         client. Default value is None.
-        :type marker: str
-        :param maxresults: Specifies the maximum number of containers to return. If the request does
-         not specify maxresults, or specifies a value greater than 5000, the server will return up to
-         5000 items. Note that if the listing operation crosses a partition boundary, then the service
-         will return a continuation token for retrieving the remainder of the results. For this reason,
-         it is possible that the service will return fewer results than specified by maxresults, or than
-         the default of 5000. Default value is None.
-        :type maxresults: int
-        :param include: Include this parameter to specify one or more datasets to include in the
-         response. Default value is None.
-        :type include: list[str or ~azure.storage.blob.models.FilterBlobsIncludeItem]
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "blobs". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: FilterBlobSegment or the result of cls(response)
-        :rtype: ~azure.storage.blob.models.FilterBlobSegment
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[_models.FilterBlobSegment]
-
-        request = build_filter_blobs_request(
-            url=self._config.url,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            where=where,
-            marker=marker,
-            maxresults=maxresults,
-            include=include,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            template_url=self.filter_blobs.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
-
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        deserialized = self._deserialize("FilterBlobSegment", pipeline_response)
-
-        if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
-
-    filter_blobs.metadata = {"url": "{url}/{containerName}"}  # type: ignore
-
-    @distributed_trace
-    def acquire_lease(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout: Optional[int] = None,
-        duration: Optional[int] = None,
-        proposed_lease_id: Optional[str] = None,
-        request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
-        **kwargs: Any
-    ) -> None:
-        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
-        can be 15 to 60 seconds, or can be infinite.
-
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param duration: Specifies the duration of the lease, in seconds, or negative one (-1) for a
-         lease that never expires. A non-infinite lease can be between 15 and 60 seconds. A lease
-         duration cannot be changed using renew or change. Default value is None.
-        :type duration: int
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Default value is None.
-        :type proposed_lease_id: str
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param recursive: Required. Default value is None.
+        :type recursive: bool
+        :param continuation: Optional.  When deleting a directory, the number of paths that are deleted
+         with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a
+         continuation token is returned in this response header.  When a continuation token is returned
+         in the response, it must be specified in a subsequent invocation of the delete operation to
+         continue deleting the directory. Default value is None.
+        :type continuation: str
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword action: Describes what lease action to take. Default value is "acquire". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype action: str
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
 
-        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
+        _lease_id = None
+        _if_match = None
+        _if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
             _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_acquire_lease_request(
+        request = build_delete_request(
             url=self._config.url,
+            request_id_parameter=request_id_parameter,
             timeout=timeout,
-            duration=duration,
-            proposed_lease_id=proposed_lease_id,
+            recursive=recursive,
+            continuation=continuation,
+            lease_id=_lease_id,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
-            request_id_parameter=request_id_parameter,
-            comp=comp,
-            restype=restype,
-            action=action,
             version=self._config.version,
-            template_url=self.acquire_lease.metadata["url"],
+            template_url=self.delete.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
+        response_headers["x-ms-deletion-id"] = self._deserialize("str", response.headers.get("x-ms-deletion-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    acquire_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    delete.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def release_lease(  # pylint: disable=inconsistent-return-statements
+    def set_access_control(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id: str,
         timeout: Optional[int] = None,
+        owner: Optional[str] = None,
+        group: Optional[str] = None,
+        permissions: Optional[str] = None,
+        acl: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
-        can be 15 to 60 seconds, or can be infinite.
+        """Set the owner, group, permissions, or access control list for a path.
 
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param owner: Optional. The owner of the blob or directory. Default value is None.
+        :type owner: str
+        :param group: Optional. The owning group of the blob or directory. Default value is None.
+        :type group: str
+        :param permissions: Optional and only valid if Hierarchical Namespace is enabled for the
+         account. Sets POSIX access permissions for the file owner, the file owning group, and others.
+         Each class may be granted read, write, or execute permission.  The sticky bit is also
+         supported.  Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
+         Default value is None.
+        :type permissions: str
+        :param acl: Sets POSIX access control rights on files and directories. The value is a
+         comma-separated list of access control entries. Each access control entry (ACE) consists of a
+         scope, a type, a user or group identifier, and permissions in the format
+         "[scope:][type]:[id]:[permissions]". Default value is None.
+        :type acl: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :keyword action: action. Default value is "setAccessControl". Note that overriding this default
          value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword action: Describes what lease action to take. Default value is "release". Note that
-         overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))  # type: str
+        action = kwargs.pop("action", _params.pop("action", "setAccessControl"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
+        _lease_id = None
+        _if_match = None
+        _if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
             _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_release_lease_request(
+        request = build_set_access_control_request(
             url=self._config.url,
-            lease_id=lease_id,
             timeout=timeout,
+            lease_id=_lease_id,
+            owner=owner,
+            group=group,
+            permissions=permissions,
+            acl=acl,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            comp=comp,
-            restype=restype,
             action=action,
             version=self._config.version,
-            template_url=self.release_lease.metadata["url"],
+            template_url=self.set_access_control.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
@@ -2071,96 +2079,106 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    release_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    set_access_control.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def renew_lease(  # pylint: disable=inconsistent-return-statements
+    def set_access_control_recursive(
         self,
-        lease_id: str,
+        mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
         timeout: Optional[int] = None,
+        continuation: Optional[str] = None,
+        force_flag: Optional[bool] = None,
+        max_records: Optional[int] = None,
+        acl: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
-        can be 15 to 60 seconds, or can be infinite.
+    ) -> _models.SetAccessControlRecursiveResponse:
+        """Set the access control list for a path and sub-paths.
 
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
+        :param mode: Mode "set" sets POSIX access control rights on files and directories, "modify"
+         modifies one or more POSIX access control rights  that pre-exist on files and directories,
+         "remove" removes one or more POSIX access control rights  that were present earlier on files
+         and directories. Known values are: "set", "modify", and "remove". Required.
+        :type mode: str or ~azure.storage.filedatalake.models.PathSetAccessControlRecursiveMode
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param continuation: Optional.  When deleting a directory, the number of paths that are deleted
+         with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a
+         continuation token is returned in this response header.  When a continuation token is returned
+         in the response, it must be specified in a subsequent invocation of the delete operation to
+         continue deleting the directory. Default value is None.
+        :type continuation: str
+        :param force_flag: Optional. Valid for "SetAccessControlRecursive" operation. If set to false,
+         the operation will terminate quickly on encountering user errors (4XX). If true, the operation
+         will ignore user errors and proceed with the operation on other sub-entities of the directory.
+         Continuation token will only be returned when forceFlag is true in case of user errors. If not
+         set the default value is false for this. Default value is None.
+        :type force_flag: bool
+        :param max_records: Optional. It specifies the maximum number of files or directories on which
+         the acl change will be applied. If omitted or greater than 2,000, the request will process up
+         to 2,000 items. Default value is None.
+        :type max_records: int
+        :param acl: Sets POSIX access control rights on files and directories. The value is a
+         comma-separated list of access control entries. Each access control entry (ACE) consists of a
+         scope, a type, a user or group identifier, and permissions in the format
+         "[scope:][type]:[id]:[permissions]". Default value is None.
+        :type acl: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword action: Describes what lease action to take. Default value is "renew". Note that
-         overriding this default value may result in unsupported behavior.
+        :keyword action: action. Default value is "setAccessControlRecursive". Note that overriding
+         this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: SetAccessControlRecursiveResponse or the result of cls(response)
+        :rtype: ~azure.storage.filedatalake.models.SetAccessControlRecursiveResponse
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
-
-        _if_modified_since = None
-        _if_unmodified_since = None
-        if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        action = kwargs.pop("action", _params.pop("action", "setAccessControlRecursive"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.SetAccessControlRecursiveResponse]
 
-        request = build_renew_lease_request(
+        request = build_set_access_control_recursive_request(
             url=self._config.url,
-            lease_id=lease_id,
+            mode=mode,
             timeout=timeout,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
+            continuation=continuation,
+            force_flag=force_flag,
+            max_records=max_records,
+            acl=acl,
             request_id_parameter=request_id_parameter,
-            comp=comp,
-            restype=restype,
             action=action,
             version=self._config.version,
-            template_url=self.renew_lease.metadata["url"],
+            template_url=self.set_access_control_recursive.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
@@ -2171,318 +2189,404 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
+        response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        deserialized = self._deserialize("SetAccessControlRecursiveResponse", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    renew_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+        return deserialized
+
+    set_access_control_recursive.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def break_lease(  # pylint: disable=inconsistent-return-statements
+    def flush_data(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
-        break_period: Optional[int] = None,
+        position: Optional[int] = None,
+        retain_uncommitted_data: Optional[bool] = None,
+        close: Optional[bool] = None,
+        content_length: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
+        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
     ) -> None:
-        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
-        can be 15 to 60 seconds, or can be infinite.
+        """Set the owner, group, permissions, or access control list for a path.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param break_period: For a break operation, proposed duration the lease should continue before
-         it is broken, in seconds, between 0 and 60. This break period is only used if it is shorter
-         than the time remaining on the lease. If longer, the time remaining on the lease is used. A new
-         lease will not be available before the break period has expired, but the lease may be held for
-         longer than the break period. If this header does not appear with a break operation, a
-         fixed-duration lease breaks after the remaining lease period elapses, and an infinite lease
-         breaks immediately. Default value is None.
-        :type break_period: int
+        :param position: This parameter allows the caller to upload data in parallel and control the
+         order in which it is appended to the file.  It is required when uploading data to be appended
+         to the file and when flushing previously uploaded data to the file.  The value must be the
+         position where the data is to be appended.  Uploaded data is not immediately flushed, or
+         written, to the file.  To flush, the previously uploaded data must be contiguous, the position
+         parameter must be specified and equal to the length of the file after all data has been
+         written, and there must not be a request entity body included with the request. Default value
+         is None.
+        :type position: int
+        :param retain_uncommitted_data: Valid only for flush operations.  If "true", uncommitted data
+         is retained after the flush operation completes; otherwise, the uncommitted data is deleted
+         after the flush operation.  The default is false.  Data at offsets less than the specified
+         position are written to the file when flush succeeds, but this optional parameter allows data
+         after the flush position to be retained for a future flush operation. Default value is None.
+        :type retain_uncommitted_data: bool
+        :param close: Azure Storage Events allow applications to receive notifications when files
+         change. When Azure Storage Events are enabled, a file changed event is raised. This event has a
+         property indicating whether this is the final change to distinguish the difference between an
+         intermediate flush to a file stream and the final close of a file stream. The close query
+         parameter is valid only when the action is "flush" and change notifications are enabled. If the
+         value of close is "true" and the flush operation completes successfully, the service raises a
+         file change notification with a property indicating that this is the final update (the file
+         stream has been closed). If "false" a change notification is raised indicating the file has
+         changed. The default is false. This query parameter is set to true by the Hadoop ABFS driver to
+         indicate that the file stream has been closed.". Default value is None.
+        :type close: bool
+        :param content_length: Required for "Append Data" and "Flush Data".  Must be 0 for "Flush
+         Data".  Must be the length of the request content in bytes for "Append Data". Default value is
+         None.
+        :type content_length: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
+        :param path_http_headers: Parameter group. Default value is None.
+        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
         :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
+        :keyword action: action. Default value is "flush". Note that overriding this default value may
          result in unsupported behavior.
-        :paramtype comp: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword action: Describes what lease action to take. Default value is "break". Note that
-         overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))  # type: str
+        action = kwargs.pop("action", _params.pop("action", "flush"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
+        _content_md5 = None
+        _lease_id = None
+        _cache_control = None
+        _content_type_parameter = None
+        _content_disposition = None
+        _content_encoding = None
+        _content_language = None
+        _if_match = None
+        _if_none_match = None
         _if_modified_since = None
         _if_unmodified_since = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        if path_http_headers is not None:
+            _cache_control = path_http_headers.cache_control
+            _content_disposition = path_http_headers.content_disposition
+            _content_encoding = path_http_headers.content_encoding
+            _content_language = path_http_headers.content_language
+            _content_md5 = path_http_headers.content_md5
+            _content_type_parameter = path_http_headers.content_type
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
         if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
             _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
             _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
 
-        request = build_break_lease_request(
+        request = build_flush_data_request(
             url=self._config.url,
             timeout=timeout,
-            break_period=break_period,
+            position=position,
+            retain_uncommitted_data=retain_uncommitted_data,
+            close=close,
+            content_length=content_length,
+            content_md5=_content_md5,
+            lease_id=_lease_id,
+            cache_control=_cache_control,
+            content_type_parameter=_content_type_parameter,
+            content_disposition=_content_disposition,
+            content_encoding=_content_encoding,
+            content_language=_content_language,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
             if_modified_since=_if_modified_since,
             if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            comp=comp,
-            restype=restype,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
             action=action,
             version=self._config.version,
-            template_url=self.break_lease.metadata["url"],
+            template_url=self.flush_data.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
+        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    break_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    flush_data.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def change_lease(  # pylint: disable=inconsistent-return-statements
+    def append_data(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id: str,
-        proposed_lease_id: str,
+        body: IO,
+        position: Optional[int] = None,
         timeout: Optional[int] = None,
+        content_length: Optional[int] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         request_id_parameter: Optional[str] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        flush: Optional[bool] = None,
+        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
     ) -> None:
-        """[Update] establishes and manages a lock on a container for delete operations. The lock duration
-        can be 15 to 60 seconds, or can be infinite.
+        """Append data to the file.
 
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Required.
-        :type proposed_lease_id: str
+        :param body: Initial data. Required.
+        :type body: IO
+        :param position: This parameter allows the caller to upload data in parallel and control the
+         order in which it is appended to the file.  It is required when uploading data to be appended
+         to the file and when flushing previously uploaded data to the file.  The value must be the
+         position where the data is to be appended.  Uploaded data is not immediately flushed, or
+         written, to the file.  To flush, the previously uploaded data must be contiguous, the position
+         parameter must be specified and equal to the length of the file after all data has been
+         written, and there must not be a request entity body included with the request. Default value
+         is None.
+        :type position: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param content_length: Required for "Append Data" and "Flush Data".  Must be 0 for "Flush
+         Data".  Must be the length of the request content in bytes for "Append Data". Default value is
+         None.
+        :type content_length: int
+        :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
+         validated by the service. Default value is None.
+        :type transactional_content_crc64: bytes
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+        :param flush: If file should be flushed after the append. Default value is None.
+        :type flush: bool
+        :param path_http_headers: Parameter group. Default value is None.
+        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
+        :keyword action: action. Default value is "append". Note that overriding this default value may
          result in unsupported behavior.
-        :paramtype comp: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword action: Describes what lease action to take. Default value is "change". Note that
-         overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop("comp", _params.pop("comp", "lease"))  # type: str
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        action = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))  # type: str
+        action = kwargs.pop("action", _params.pop("action", "append"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/json"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        _if_modified_since = None
-        _if_unmodified_since = None
-        if modified_access_conditions is not None:
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        _transactional_content_hash = None
+        _lease_id = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        if path_http_headers is not None:
+            _transactional_content_hash = path_http_headers.transactional_content_hash
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
+        _content = body
 
-        request = build_change_lease_request(
+        request = build_append_data_request(
             url=self._config.url,
-            lease_id=lease_id,
-            proposed_lease_id=proposed_lease_id,
+            position=position,
             timeout=timeout,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
+            content_length=content_length,
+            transactional_content_hash=_transactional_content_hash,
+            transactional_content_crc64=transactional_content_crc64,
+            lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            comp=comp,
-            restype=restype,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            flush=flush,
             action=action,
+            content_type=content_type,
             version=self._config.version,
-            template_url=self.change_lease.metadata["url"],
+            content=_content,
+            template_url=self.append_data.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    append_data.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def list_blob_flat_segment(
+    def set_expiry(  # pylint: disable=inconsistent-return-statements
         self,
-        prefix: Optional[str] = None,
-        marker: Optional[str] = None,
-        maxresults: Optional[int] = None,
-        include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
+        expiry_options: Union[str, "_models.PathExpiryOptions"],
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
+        expires_on: Optional[str] = None,
         **kwargs: Any
-    ) -> _models.ListBlobsFlatSegmentResponse:
-        """[Update] The List Blobs operation returns a list of the blobs under the specified container.
+    ) -> None:
+        """Sets the time a blob will expire and be deleted.
 
-        :param prefix: Filters the results to return only containers whose name begins with the
-         specified prefix. Default value is None.
-        :type prefix: str
-        :param marker: A string value that identifies the portion of the list of containers to be
-         returned with the next listing operation. The operation returns the NextMarker value within the
-         response body if the listing operation did not return all containers remaining to be listed
-         with the current page. The NextMarker value can be used as the value for the marker parameter
-         in a subsequent call to request the next page of list items. The marker value is opaque to the
-         client. Default value is None.
-        :type marker: str
-        :param maxresults: Specifies the maximum number of containers to return. If the request does
-         not specify maxresults, or specifies a value greater than 5000, the server will return up to
-         5000 items. Note that if the listing operation crosses a partition boundary, then the service
-         will return a continuation token for retrieving the remainder of the results. For this reason,
-         it is possible that the service will return fewer results than specified by maxresults, or than
-         the default of 5000. Default value is None.
-        :type maxresults: int
-        :param include: Include this parameter to specify one or more datasets to include in the
-         response. Default value is None.
-        :type include: list[str or ~azure.storage.blob.models.ListBlobsIncludeItem]
+        :param expiry_options: Required. Indicates mode of the expiry time. Known values are:
+         "NeverExpire", "RelativeToCreation", "RelativeToNow", and "Absolute". Required.
+        :type expiry_options: str or ~azure.storage.filedatalake.models.PathExpiryOptions
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "list". Note that overriding this default value may
+        :param expires_on: The time to set the blob to expiry. Default value is None.
+        :type expires_on: str
+        :keyword comp: comp. Default value is "expiry". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListBlobsFlatSegmentResponse or the result of cls(response)
-        :rtype: ~azure.storage.blob.models.ListBlobsFlatSegmentResponse
+        :return: None or the result of cls(response)
+        :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsFlatSegmentResponse]
+        comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        request = build_list_blob_flat_segment_request(
+        request = build_set_expiry_request(
             url=self._config.url,
-            prefix=prefix,
-            marker=marker,
-            maxresults=maxresults,
-            include=include,
+            expiry_options=expiry_options,
             timeout=timeout,
             request_id_parameter=request_id_parameter,
-            restype=restype,
+            expires_on=expires_on,
             comp=comp,
             version=self._config.version,
-            template_url=self.list_blob_flat_segment.metadata["url"],
+            template_url=self.set_expiry.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
@@ -2493,179 +2597,75 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize("ListBlobsFlatSegmentResponse", pipeline_response)
-
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    list_blob_flat_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    set_expiry.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
 
     @distributed_trace
-    def list_blob_hierarchy_segment(
+    def undelete(  # pylint: disable=inconsistent-return-statements
         self,
-        delimiter: str,
-        prefix: Optional[str] = None,
-        marker: Optional[str] = None,
-        maxresults: Optional[int] = None,
-        include: Optional[List[Union[str, "_models.ListBlobsIncludeItem"]]] = None,
         timeout: Optional[int] = None,
+        undelete_source: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> _models.ListBlobsHierarchySegmentResponse:
-        """[Update] The List Blobs operation returns a list of the blobs under the specified container.
+    ) -> None:
+        """Undelete a path that was previously soft deleted.
 
-        :param delimiter: When the request includes this parameter, the operation returns a BlobPrefix
-         element in the response body that acts as a placeholder for all blobs whose names begin with
-         the same substring up to the appearance of the delimiter character. The delimiter may be a
-         single character or a string. Required.
-        :type delimiter: str
-        :param prefix: Filters the results to return only containers whose name begins with the
-         specified prefix. Default value is None.
-        :type prefix: str
-        :param marker: A string value that identifies the portion of the list of containers to be
-         returned with the next listing operation. The operation returns the NextMarker value within the
-         response body if the listing operation did not return all containers remaining to be listed
-         with the current page. The NextMarker value can be used as the value for the marker parameter
-         in a subsequent call to request the next page of list items. The marker value is opaque to the
-         client. Default value is None.
-        :type marker: str
-        :param maxresults: Specifies the maximum number of containers to return. If the request does
-         not specify maxresults, or specifies a value greater than 5000, the server will return up to
-         5000 items. Note that if the listing operation crosses a partition boundary, then the service
-         will return a continuation token for retrieving the remainder of the results. For this reason,
-         it is possible that the service will return fewer results than specified by maxresults, or than
-         the default of 5000. Default value is None.
-        :type maxresults: int
-        :param include: Include this parameter to specify one or more datasets to include in the
-         response. Default value is None.
-        :type include: list[str or ~azure.storage.blob.models.ListBlobsIncludeItem]
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
          Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param undelete_source: Only for hierarchical namespace enabled accounts. Optional. The path of
+         the soft deleted blob to undelete. Default value is None.
+        :type undelete_source: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword restype: restype. Default value is "container". Note that overriding this default
-         value may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "list". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListBlobsHierarchySegmentResponse or the result of cls(response)
-        :rtype: ~azure.storage.blob.models.ListBlobsHierarchySegmentResponse
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype = kwargs.pop("restype", _params.pop("restype", "container"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[_models.ListBlobsHierarchySegmentResponse]
-
-        request = build_list_blob_hierarchy_segment_request(
-            url=self._config.url,
-            delimiter=delimiter,
-            prefix=prefix,
-            marker=marker,
-            maxresults=maxresults,
-            include=include,
-            timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            template_url=self.list_blob_hierarchy_segment.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
-
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        deserialized = self._deserialize("ListBlobsHierarchySegmentResponse", pipeline_response)
-
-        if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
-
-    list_blob_hierarchy_segment.metadata = {"url": "{url}/{containerName}"}  # type: ignore
-
-    @distributed_trace
-    def get_account_info(self, **kwargs: Any) -> None:  # pylint: disable=inconsistent-return-statements
-        """Returns the sku name and account kind.
-
-        :keyword restype: restype. Default value is "account". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+        :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
-        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
         cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        request = build_get_account_info_request(
+        request = build_undelete_request(
             url=self._config.url,
-            restype=restype,
+            timeout=timeout,
+            undelete_source=undelete_source,
+            request_id_parameter=request_id_parameter,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_account_info.metadata["url"],
+            template_url=self.undelete.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)  # type: ignore
 
         pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
@@ -2680,16 +2680,15 @@
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-resource-type"] = self._deserialize("str", response.headers.get("x-ms-resource-type"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-sku-name"] = self._deserialize("str", response.headers.get("x-ms-sku-name"))
-        response_headers["x-ms-account-kind"] = self._deserialize("str", response.headers.get("x-ms-account-kind"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_account_info.metadata = {"url": "{url}/{containerName}"}  # type: ignore
+    undelete.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_page_blob_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_page_blob_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_service_operations.py`

 * *Files 0% similar despite different names*

```diff
@@ -37,15 +37,15 @@
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
     comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
     content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -73,15 +73,15 @@
     url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
     comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -107,15 +107,15 @@
     url: str, *, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
     comp = kwargs.pop("comp", _params.pop("comp", "stats"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -148,15 +148,15 @@
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "list"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -190,15 +190,15 @@
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     restype = kwargs.pop("restype", _params.pop("restype", "service"))  # type: str
     comp = kwargs.pop("comp", _params.pop("comp", "userdelegationkey"))  # type: str
     content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -224,15 +224,15 @@
 
 def build_get_account_info_request(url: str, **kwargs: Any) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     restype = kwargs.pop("restype", _params.pop("restype", "account"))  # type: str
     comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -262,15 +262,15 @@
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "batch"))  # type: str
     multipart_content_type = kwargs.pop(
         "multipart_content_type", _headers.pop("Content-Type", None)
     )  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
@@ -305,15 +305,15 @@
     include: Optional[List[Union[str, "_models.FilterBlobsIncludeItem"]]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp = kwargs.pop("comp", _params.pop("comp", "blobs"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-08-06"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
     _url = kwargs.pop("template_url", "{url}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_lease.py`

 * *Files 7% similar despite different names*

```diff
@@ -99,15 +99,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = self._client.acquire_lease(
                 timeout=kwargs.pop('timeout', None),
                 duration=lease_duration,
@@ -152,15 +156,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = self._client.renew_lease(
                 lease_id=self.id,
                 timeout=kwargs.pop('timeout', None),
@@ -202,15 +210,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = self._client.release_lease(
                 lease_id=self.id,
                 timeout=kwargs.pop('timeout', None),
@@ -251,15 +263,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = self._client.change_lease(
                 lease_id=self.id,
                 proposed_lease_id=proposed_lease_id,
@@ -310,15 +326,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: Approximate time remaining in the lease period, in seconds.
         :rtype: int
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = self._client.break_lease(
                 timeout=kwargs.pop('timeout', None),
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_list_blobs_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_list_blobs_helper.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,42 @@
 # pylint: disable=too-many-lines
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
-try:
-    from urllib.parse import unquote
-except ImportError:
-    from urllib import unquote
+from urllib.parse import unquote
+
 from azure.core.paging import PageIterator, ItemPaged
 from azure.core.exceptions import HttpResponseError
-from ._deserialize import get_blob_properties_from_generated_code, parse_tags
+
+from ._deserialize import (
+    get_blob_properties_from_generated_code,
+    load_many_xml_nodes,
+    load_xml_int,
+    load_xml_string,
+    parse_tags,
+)
 from ._generated.models import BlobItemInternal, BlobPrefix as GenBlobPrefix, FilterBlobItem
+from ._generated._serialization import Deserializer
 from ._models import BlobProperties, FilteredBlob
 from ._shared.models import DictMixin
-from ._shared.response_handlers import return_context_and_deserialized, process_storage_error
+from ._shared.response_handlers import (
+    return_context_and_deserialized,
+    return_raw_deserialized,
+    process_storage_error,
+)
+
+
+class IgnoreListBlobsDeserializer(Deserializer):
+    def __call__(self, target_obj, response_data, content_type=None):
+        if target_obj == "ListBlobsFlatSegmentResponse":
+            return None
+        super().__call__(target_obj, response_data, content_type)
 
 
 class BlobPropertiesPaged(PageIterator):
     """An Iterable of Blob properties.
 
     :ivar str service_endpoint: The service URL.
     :ivar str prefix: A blob name prefix being used to filter the list.
@@ -99,14 +116,87 @@
         if isinstance(item, BlobItemInternal):
             blob = get_blob_properties_from_generated_code(item)  # pylint: disable=protected-access
             blob.container = self.container
             return blob
         return item
 
 
+class BlobNamesPaged(PageIterator):
+    """An Iterable of Blob names.
+
+    :ivar str service_endpoint: The service URL.
+    :ivar str prefix: A blob name prefix being used to filter the list.
+    :ivar str marker: The continuation token of the current page of results.
+    :ivar int results_per_page: The maximum number of results retrieved per API call.
+    :ivar str continuation_token: The continuation token to retrieve the next page of results.
+    :ivar str location_mode: The location mode being used to list results. The available
+        options include "primary" and "secondary".
+    :ivar current_page: The current page of listed results.
+    :vartype current_page: list(str)
+    :ivar str container: The container that the blobs are listed from.
+    :ivar str delimiter: A delimiting character used for hierarchy listing.
+
+    :param callable command: Function to retrieve the next page of items.
+    :param str container: The name of the container.
+    :param str prefix: Filters the results to return only blobs whose names
+        begin with the specified prefix.
+    :param int results_per_page: The maximum number of blobs to retrieve per
+        call.
+    :param str continuation_token: An opaque continuation token.
+    :param location_mode: Specifies the location the request should be sent to.
+        This mode only applies for RA-GRS accounts which allow secondary read access.
+        Options include 'primary' or 'secondary'.
+    """
+    def __init__(
+            self, command,
+            container=None,
+            prefix=None,
+            results_per_page=None,
+            continuation_token=None,
+            location_mode=None):
+        super(BlobNamesPaged, self).__init__(
+            get_next=self._get_next_cb,
+            extract_data=self._extract_data_cb,
+            continuation_token=continuation_token or ""
+        )
+        self._command = command
+        self.service_endpoint = None
+        self.prefix = prefix
+        self.marker = None
+        self.results_per_page = results_per_page
+        self.container = container
+        self.current_page = None
+        self.location_mode = location_mode
+
+    def _get_next_cb(self, continuation_token):
+        try:
+            return self._command(
+                prefix=self.prefix,
+                marker=continuation_token or None,
+                maxresults=self.results_per_page,
+                cls=return_raw_deserialized,
+                use_location=self.location_mode)
+        except HttpResponseError as error:
+            process_storage_error(error)
+
+    def _extract_data_cb(self, get_next_return):
+        self.location_mode, self._response = get_next_return
+        self.service_endpoint = self._response.get('ServiceEndpoint')
+        self.prefix = load_xml_string(self._response, 'Prefix')
+        self.marker = load_xml_string(self._response, 'Marker')
+        self.results_per_page = load_xml_int(self._response, 'MaxResults')
+        self.container = self._response.get('ContainerName')
+
+        blobs = load_many_xml_nodes(self._response, 'Blob', wrapper='Blobs')
+        self.current_page = [load_xml_string(blob, 'Name') for blob in blobs]
+
+        next_marker = load_xml_string(self._response, 'NextMarker')
+        return next_marker or None, self.current_page
+
+
 class BlobPrefixPaged(BlobPropertiesPaged):
     def __init__(self, *args, **kwargs):
         super(BlobPrefixPaged, self).__init__(*args, **kwargs)
         self.name = self.prefix
 
     def _extract_data_cb(self, get_next_return):
         continuation_token, _ = super(BlobPrefixPaged, self)._extract_data_cb(get_next_return)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -74,14 +74,15 @@
     """
     Specifies the blob tier to set the blob to. This is only applicable for
     block blobs on standard storage accounts.
     """
 
     ARCHIVE = 'Archive'  #: Archive
     COOL = 'Cool'  #: Cool
+    COLD = 'Cold'  #: Cold
     HOT = 'Hot'  #: Hot
 
 
 class PremiumPageBlobTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
     """
     Specifies the page blob tier to set the blob to. This is only applicable to page
     blobs on premium storage accounts. Please take a look at:
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_quick_query_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_quick_query_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_serialize.py`

 * *Files 1% similar despite different names*

```diff
@@ -47,15 +47,17 @@
     '2020-06-12',
     '2020-08-04',
     '2020-10-02',
     '2020-12-06',
     '2021-02-12',
     '2021-04-10',
     '2021-06-08',
-    '2021-08-06'
+    '2021-08-06',
+    '2021-12-02',
+    '2022-11-02'
 ]
 
 
 def _get_match_headers(kwargs, match_param, etag_param):
     # type: (Dict[str, Any], str, str) -> Tuple(Dict[str, Any], Optional[str], Optional[str])
     if_match = None
     if_none_match = None
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/authentication.py`

 * *Files 19% similar despite different names*

```diff
@@ -2,21 +2,16 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 
 import logging
 import re
-import sys
-
-try:
-    from urllib.parse import urlparse, unquote
-except ImportError:
-    from urlparse import urlparse # type: ignore
-    from urllib2 import unquote # type: ignore
+from typing import List, Tuple
+from urllib.parse import unquote, urlparse
 
 try:
     from yarl import URL
 except ImportError:
     pass
 
 try:
@@ -25,32 +20,47 @@
     AioHttpTransport = None
 
 from azure.core.exceptions import ClientAuthenticationError
 from azure.core.pipeline.policies import SansIOHTTPPolicy
 
 from . import sign_string
 
-
 logger = logging.getLogger(__name__)
 
 
-
 # wraps a given exception with the desired exception type
 def _wrap_exception(ex, desired_type):
     msg = ""
     if ex.args:
         msg = ex.args[0]
-    if sys.version_info >= (3,):
-        # Automatic chaining in Python 3 means we keep the trace
-        return desired_type(msg)
-    # There isn't a good solution in 2 for keeping the stack trace
-    # in general, or that will not result in an error in 3
-    # However, we can keep the previous error type and message
-    # TODO: In the future we will log the trace
-    return desired_type('{}: {}'.format(ex.__class__.__name__, msg))
+    return desired_type(msg)
+
+# This method attempts to emulate the sorting done by the service
+def _storage_header_sort(input_headers: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
+    # Define the custom alphabet for weights
+    custom_weights = "-!#$%&*.^_|~+\"\'(),/`~0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{}"
+
+    # Build dict of tuples and list of keys
+    header_dict = dict()
+    header_keys = []
+    for k, v in input_headers:
+        header_dict[k] = v
+        header_keys.append(k)
+
+    # Sort according to custom defined weights
+    try:
+        header_keys = sorted(header_keys, key=lambda word: [custom_weights.index(c) for c in word])
+    except ValueError:
+        raise ValueError("Illegal character encountered when sorting headers.")
+
+    # Build list of sorted tuples
+    sorted_headers = []
+    for key in header_keys:
+        sorted_headers.append((key, header_dict.get(key)))
+    return sorted_headers
 
 
 class AzureSigningError(ClientAuthenticationError):
     """
     Represents a fatal error when attempting to sign a request.
     In general, the cause of this exception is user error. For example, the given account key is not valid.
     Please visit https://docs.microsoft.com/en-us/azure/storage/common/storage-create-storage-account for more info.
@@ -92,15 +102,15 @@
     @staticmethod
     def _get_canonicalized_headers(request):
         string_to_sign = ''
         x_ms_headers = []
         for name, value in request.http_request.headers.items():
             if name.startswith('x-ms-'):
                 x_ms_headers.append((name.lower(), value))
-        x_ms_headers.sort()
+        x_ms_headers = _storage_header_sort(x_ms_headers)
         for name, value in x_ms_headers:
             if value is not None:
                 string_to_sign += ''.join([name, ':', value, '\n'])
         return string_to_sign
 
     @staticmethod
     def _get_canonicalized_resource_query(request):
@@ -136,15 +146,15 @@
                 ]
             ) + \
             self._get_canonicalized_headers(request) + \
             self._get_canonicalized_resource(request) + \
             self._get_canonicalized_resource_query(request)
 
         self._add_authorization_header(request, string_to_sign)
-        #logger.debug("String_to_sign=%s", string_to_sign)
+        # logger.debug("String_to_sign=%s", string_to_sign)
 
 
 class StorageHttpChallenge(object):
     def __init__(self, challenge):
         """ Parses an HTTP WWW-Authentication Bearer challenge from the Storage service. """
         if not challenge:
             raise ValueError("Challenge cannot be empty")
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/avro_io.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/avro_io_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/avro_io_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/datafile.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/datafile_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/datafile_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/avro/schema.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/schema.py`

 * *Files 0% similar despite different names*

```diff
@@ -255,15 +255,15 @@
             self._fullname = (self._name
                               if (not self._namespace) else
                               '%s.%s' % (self._namespace, self._name))
 
             # Validate the fullname:
             if _RE_FULL_NAME.match(self._fullname) is None:
                 raise SchemaParseException(
-                    'Invalid schema name %r infered from name %r and namespace %r.'
+                    'Invalid schema name %r inferred from name %r and namespace %r.'
                     % (self._fullname, self._name, self._namespace))
 
     def __eq__(self, other):
         if not isinstance(other, Name):
             return NotImplemented
         return self.fullname == other.fullname
 
@@ -435,17 +435,17 @@
     def fullname(self):
         return self._avro_name.fullname
 
     def name_ref(self, names):
         """Reports this schema name relative to the specified name tracker.
 
         Args:
-          names: Avro name tracker to relativise this schema name against.
+          names: Avro name tracker to relativize this schema name against.
         Returns:
-          This schema name, relativised against the specified name tracker.
+          This schema name, relativized against the specified name tracker.
         """
         if self.namespace == names.default_namespace:
             return self.name
         return self.fullname
 
     @abc.abstractmethod
     def to_json(self, names):
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/base_client_async.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,19 @@
 )
 from azure.core.pipeline.transport import AsyncHttpTransport
 
 from .constants import CONNECTION_TIMEOUT, READ_TIMEOUT
 from .authentication import SharedKeyCredentialPolicy
 from .base_client import create_configuration
 from .policies import (
+    QueueMessagePolicy,
     StorageContentValidation,
     StorageHeadersPolicy,
     StorageHosts,
     StorageRequestHook,
-    QueueMessagePolicy
 )
 from .policies_async import AsyncStorageBearerTokenCredentialPolicy, AsyncStorageResponseHook
 
 from .response_handlers import process_storage_error, PartialBatchErrorException
 
 if TYPE_CHECKING:
     from azure.core.pipeline import Pipeline
@@ -71,15 +71,15 @@
         if hasattr(credential, 'get_token'):
             self._credential_policy = AsyncStorageBearerTokenCredentialPolicy(credential)
         elif isinstance(credential, SharedKeyCredentialPolicy):
             self._credential_policy = credential
         elif isinstance(credential, AzureSasCredential):
             self._credential_policy = AzureSasCredentialPolicy(credential)
         elif credential is not None:
-            raise TypeError("Unsupported credential: {}".format(credential))
+            raise TypeError(f"Unsupported credential: {credential}")
         config = kwargs.get('_configuration') or create_configuration(**kwargs)
         if kwargs.get('_pipeline'):
             return config, kwargs['_pipeline']
         config.transport = kwargs.get('transport')  # type: ignore
         kwargs.setdefault("connection_timeout", CONNECTION_TIMEOUT)
         kwargs.setdefault("read_timeout", READ_TIMEOUT)
         if not config.transport:
@@ -115,21 +115,18 @@
         **kwargs
     ):
         """Given a series of request, do a Storage batch call.
         """
         # Pop it here, so requests doesn't feel bad about additional kwarg
         raise_on_any_failure = kwargs.pop("raise_on_any_failure", True)
         request = self._client._client.post(  # pylint: disable=protected-access
-            url='{}://{}/{}?{}comp=batch{}{}'.format(
-                self.scheme,
-                self.primary_hostname,
-                kwargs.pop('path', ""),
-                kwargs.pop('restype', ""),
-                kwargs.pop('sas', ""),
-                kwargs.pop('timeout', "")
+            url=(
+                f'{self.scheme}://{self.primary_hostname}/'
+                f"{kwargs.pop('path', '')}?{kwargs.pop('restype', '')}"
+                f"comp=batch{kwargs.pop('sas', '')}{kwargs.pop('timeout', '')}"
             ),
             headers={
                 'x-ms-version': self.api_version
             }
         )
 
         policies = [StorageHeadersPolicy()]
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/constants.py`

 * *Files 27% similar despite different names*

```diff
@@ -7,13 +7,13 @@
 from .._serialize import _SUPPORTED_API_VERSIONS
 
 
 X_MS_VERSION = _SUPPORTED_API_VERSIONS[-1]
 
 # Default socket timeouts, in seconds
 CONNECTION_TIMEOUT = 20
-READ_TIMEOUT = 80000  # 4000MB (max block size) / 50KB/s (an arbitrarily chosen minimum upload speed)
+READ_TIMEOUT = 60
 
 DEFAULT_OAUTH_SCOPE = "/.default"
 STORAGE_OAUTH_SCOPE = "https://storage.azure.com/.default"
 
 SERVICE_HOST_BASE = 'core.windows.net'
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/models.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-instance-attributes
+
 from enum import Enum
 
 from azure.core import CaseInsensitiveEnumMeta
 
 
 def get_enum_value(value):
     if value is None or value in ["None", ""]:
@@ -280,15 +281,15 @@
         To specify service, container, or object you need only to
         include the first letter of the word in the string. E.g. service and container,
         you would provide a string "sc".
 
         :param str string: Specify service, container, or object in
             in the string with the first letter of the word.
         :return: A ResourceTypes object
-        :rtype: ~azure.storage.blob.ResourceTypes
+        :rtype: ~azure.storage.queue.ResourceTypes
         """
         res_service = 's' in string
         res_container = 'c' in string
         res_object = 'o' in string
 
         parsed = cls(res_service, res_container, res_object)
         parsed._str = string  # pylint: disable = protected-access
@@ -378,15 +379,15 @@
         To specify read, write, delete, etc. permissions you need only to
         include the first letter of the word in the string. E.g. for read and write
         permissions you would provide a string "rw".
 
         :param str permission: Specify permissions in
             the string with the first letter of the word.
         :return: An AccountSasPermissions object
-        :rtype: ~azure.storage.blob.AccountSasPermissions
+        :rtype: ~azure.storage.queue.AccountSasPermissions
         """
         p_read = 'r' in permission
         p_write = 'w' in permission
         p_delete = 'd' in permission
         p_delete_previous_version = 'x' in permission
         p_permanent_delete = 'y' in permission
         p_list = 'l' in permission
@@ -434,15 +435,15 @@
         To specify blob, queue, or file you need only to
         include the first letter of the word in the string. E.g. for blob and queue
         you would provide a string "bq".
 
         :param str string: Specify blob, queue, or file in
             in the string with the first letter of the word.
         :return: A Services object
-        :rtype: ~azure.storage.blob.Services
+        :rtype: ~azure.storage.queue.Services
         """
         res_blob = 'b' in string
         res_queue = 'q' in string
         res_file = 'f' in string
 
         parsed = cls(res_blob, res_queue, res_file)
         parsed._str = string  # pylint: disable = protected-access
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/policies.py`

 * *Files 0% similar despite different names*

```diff
@@ -82,15 +82,15 @@
     variables such as the number of total retries to allow, whether to
     respect the Retry-After header, whether this header is present, and
     whether the returned status code is on the list of status codes to
     be retried upon on the presence of the aforementioned header)
     """
     status = response.http_response.status_code
     if 300 <= status < 500:
-        # An exception occured, but in most cases it was expected. Examples could
+        # An exception occurred, but in most cases it was expected. Examples could
         # include a 309 Conflict or 412 Precondition Failed.
         if status == 404 and mode == LocationMode.SECONDARY:
             # Response code 404 should be retried if secondary was used.
             return True
         if status == 408:
             # Response code 408 is a timeout and should be retried.
             return True
@@ -173,15 +173,15 @@
 
         # See if a specific location mode has been specified, and if so, redirect
         use_location = request.context.options.pop('use_location', None)
         if use_location:
             # Lock retries to the specific location
             request.context.options['retry_to_secondary'] = False
             if use_location not in self.hosts:
-                raise ValueError("Attempting to use undefined host location {}".format(use_location))
+                raise ValueError(f"Attempting to use undefined host location {use_location}")
             if use_location != location_mode:
                 # Update request URL to use the specified location
                 updated = parsed_url._replace(netloc=self.hosts[use_location])
                 request.http_request.url = updated.geturl()
                 location_mode = use_location
 
         request.context.options['location_mode'] = location_mode
@@ -383,17 +383,17 @@
         request.context['validate_content'] = validate_content
 
     def on_response(self, request, response):
         if response.context.get('validate_content', False) and response.http_response.headers.get('content-md5'):
             computed_md5 = request.context.get('validate_content_md5') or \
                 encode_base64(StorageContentValidation.get_content_md5(response.http_response.body()))
             if response.http_response.headers['content-md5'] != computed_md5:
-                raise AzureError(
-                    'MD5 mismatch. Expected value is \'{0}\', computed value is \'{1}\'.'.format(
-                        response.http_response.headers['content-md5'], computed_md5),
+                raise AzureError((
+                    f"MD5 mismatch. Expected value is '{response.http_response.headers['content-md5']}', "
+                    f"computed value is '{computed_md5}'."),
                     response=response.http_response
                 )
 
 
 class StorageRetryPolicy(HTTPPolicy):
     """
     The base class for Exponential and Linear retries containing shared code.
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/request_handlers.py`

 * *Files 2% similar despite different names*

```diff
@@ -118,45 +118,45 @@
         raise ValueError("start_range value cannot be None.")
     if end_range_required and end_range is None:
         raise ValueError("end_range value cannot be None.")
 
     # Page ranges must be 512 aligned
     if align_to_page:
         if start_range is not None and start_range % 512 != 0:
-            raise ValueError("Invalid page blob start_range: {0}. "
-                             "The size must be aligned to a 512-byte boundary.".format(start_range))
+            raise ValueError(f"Invalid page blob start_range: {start_range}. "
+                             "The size must be aligned to a 512-byte boundary.")
         if end_range is not None and end_range % 512 != 511:
-            raise ValueError("Invalid page blob end_range: {0}. "
-                             "The size must be aligned to a 512-byte boundary.".format(end_range))
+            raise ValueError(f"Invalid page blob end_range: {end_range}. "
+                             "The size must be aligned to a 512-byte boundary.")
 
     # Format based on whether end_range is present
     range_header = None
     if end_range is not None:
-        range_header = 'bytes={0}-{1}'.format(start_range, end_range)
+        range_header = f'bytes={start_range}-{end_range}'
     elif start_range is not None:
-        range_header = "bytes={0}-".format(start_range)
+        range_header = f"bytes={start_range}-"
 
     # Content MD5 can only be provided for a complete range less than 4MB in size
     range_validation = None
     if check_content_md5:
         if start_range is None or end_range is None:
-            raise ValueError("Both start and end range requied for MD5 content validation.")
+            raise ValueError("Both start and end range required for MD5 content validation.")
         if end_range - start_range > 4 * 1024 * 1024:
             raise ValueError("Getting content MD5 for a range greater than 4MB is not supported.")
         range_validation = 'true'
 
     return range_header, range_validation
 
 
 def add_metadata_headers(metadata=None):
     # type: (Optional[Dict[str, str]]) -> Dict[str, str]
     headers = {}
     if metadata:
         for key, value in metadata.items():
-            headers['x-ms-meta-{}'.format(key.strip())] = value.strip() if value else value
+            headers[f'x-ms-meta-{key.strip()}'] = value.strip() if value else value
     return headers
 
 
 def serialize_batch_body(requests, batch_id):
     """
     --<delimiter>
     <subrequest>
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/response_handlers.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,14 +18,15 @@
     ResourceExistsError,
     ClientAuthenticationError,
     DecodeError)
 
 from .parser import _to_utc_datetime
 from .models import StorageErrorCode, UserDelegationKey, get_enum_value
 
+
 if TYPE_CHECKING:
     from datetime import datetime
     from azure.core.exceptions import AzureError
 
 
 _LOGGER = logging.getLogger(__name__)
 
@@ -62,15 +63,15 @@
         if key.startswith('x-ms-'):
             key = key[5:]
         normalized[key.lower().replace('-', '_')] = get_enum_value(value)
     return normalized
 
 
 def deserialize_metadata(response, obj, headers):  # pylint: disable=unused-argument
-    raw_metadata = {k: v for k, v in response.http_response.headers.items() if k.startswith("x-ms-meta-")}
+    raw_metadata = {k: v for k, v in response.headers.items() if k.startswith("x-ms-meta-")}
     return {k[10:]: v for k, v in raw_metadata.items()}
 
 
 def return_response_headers(response, deserialized, response_headers):  # pylint: disable=unused-argument
     return normalize_headers(response_headers)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/shared_access_signature.py`

 * *Files 2% similar despite different names*

```diff
@@ -34,16 +34,14 @@
     SIGNED_SERVICES = 'ss'
     SIGNED_OID = 'skoid'
     SIGNED_TID = 'sktid'
     SIGNED_KEY_START = 'skt'
     SIGNED_KEY_EXPIRY = 'ske'
     SIGNED_KEY_SERVICE = 'sks'
     SIGNED_KEY_VERSION = 'skv'
-
-    # for blob only
     SIGNED_ENCRYPTION_SCOPE = 'ses'
 
     # for ADLS
     SIGNED_AUTHORIZED_OID = 'saoid'
     SIGNED_UNAUTHORIZED_OID = 'suoid'
     SIGNED_CORRELATION_ID = 'scid'
     SIGNED_DIRECTORY_DEPTH = 'sdd'
@@ -73,15 +71,14 @@
             QueryStringConstants.SIGNED_SERVICES,
             QueryStringConstants.SIGNED_OID,
             QueryStringConstants.SIGNED_TID,
             QueryStringConstants.SIGNED_KEY_START,
             QueryStringConstants.SIGNED_KEY_EXPIRY,
             QueryStringConstants.SIGNED_KEY_SERVICE,
             QueryStringConstants.SIGNED_KEY_VERSION,
-            # for blob only
             QueryStringConstants.SIGNED_ENCRYPTION_SCOPE,
             # for ADLS
             QueryStringConstants.SIGNED_AUTHORIZED_OID,
             QueryStringConstants.SIGNED_UNAUTHORIZED_OID,
             QueryStringConstants.SIGNED_CORRELATION_ID,
             QueryStringConstants.SIGNED_DIRECTORY_DEPTH,
         ]
@@ -146,14 +143,17 @@
             If the IP address from which the request originates does not match the IP address
             or address range specified on the SAS token, the request is not authenticated.
             For example, specifying sip=168.1.5.65 or sip=168.1.5.60-168.1.5.70 on the SAS
             restricts the request to those IP addresses.
         :param str protocol:
             Specifies the protocol permitted for a request made. The default value
             is https,http. See :class:`~azure.storage.common.models.Protocol` for possible values.
+        :keyword str encryption_scope:
+            Optional. If specified, this is the encryption scope to use when sending requests
+            authorized with this SAS URI.
         '''
         sas = _SharedAccessHelper()
         sas.add_base(permission, expiry, start, ip, protocol, self.x_ms_version)
         sas.add_account(services, resource_types)
         sas.add_encryption_scope(**kwargs)
         sas.add_account_signature(self.account_name, self.account_key)
 
@@ -164,17 +164,14 @@
     def __init__(self):
         self.query_dict = {}
 
     def _add_query(self, name, val):
         if val:
             self.query_dict[name] = _str(val) if val is not None else None
 
-    def add_encryption_scope(self, **kwargs):
-        self._add_query(QueryStringConstants.SIGNED_ENCRYPTION_SCOPE, kwargs.pop('encryption_scope', None))
-
     def add_base(self, permission, expiry, start, ip, protocol, x_ms_version):
         if isinstance(start, date):
             start = _to_utc_datetime(start)
 
         if isinstance(expiry, date):
             expiry = _to_utc_datetime(expiry)
 
@@ -191,14 +188,17 @@
     def add_id(self, policy_id):
         self._add_query(QueryStringConstants.SIGNED_IDENTIFIER, policy_id)
 
     def add_account(self, services, resource_types):
         self._add_query(QueryStringConstants.SIGNED_SERVICES, services)
         self._add_query(QueryStringConstants.SIGNED_RESOURCE_TYPES, resource_types)
 
+    def add_encryption_scope(self, **kwargs):
+        self._add_query(QueryStringConstants.SIGNED_ENCRYPTION_SCOPE, kwargs.pop('encryption_scope', None))
+
     def add_override_response_headers(self, cache_control,
                                       content_disposition,
                                       content_encoding,
                                       content_language,
                                       content_type):
         self._add_query(QueryStringConstants.SIGNED_CACHE_CONTROL, cache_control)
         self._add_query(QueryStringConstants.SIGNED_CONTENT_DISPOSITION, content_disposition)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared_access_signature.py`

 * *Files 2% similar despite different names*

```diff
@@ -453,14 +453,17 @@
         Response header value for Content-Language when resource is accessed
         using this shared access signature.
     :keyword str content_type:
         Response header value for Content-Type when resource is accessed
         using this shared access signature.
     :keyword str encryption_scope:
         Specifies the encryption scope for a request made so that all write operations will be service encrypted.
+    :keyword str correlation_id:
+        The correlation id to correlate the storage audit logs with the audit logs used by the principal
+        generating and distributing the SAS. This can only be used when generating a SAS with delegation key.
     :return: A Shared Access Signature (sas) token.
     :rtype: str
 
     .. admonition:: Example:
 
         .. literalinclude:: ../samples/blob_samples_containers.py
             :start-after: [START generate_sas_token]
@@ -554,15 +557,18 @@
     :param str ip:
         Specifies an IP address or a range of IP addresses from which to accept requests.
         If the IP address from which the request originates does not match the IP address
         or address range specified on the SAS token, the request is not authenticated.
         For example, specifying ip=168.1.5.65 or ip=168.1.5.60-168.1.5.70 on the SAS
         restricts the request to those IP addresses.
     :keyword str version_id:
-        An optional blob version ID. This parameter is only for versioning enabled account
+        An optional blob version ID. This parameter is only applicable for versioning-enabled
+        Storage accounts. Note that the 'versionid' query parameter is not included in the output
+        SAS. Therefore, please provide the 'version_id' parameter to any APIs when using the output
+        SAS to operate on a specific version.
 
         .. versionadded:: 12.4.0
             This keyword argument was introduced in API version '2019-12-12'.
     :keyword str protocol:
         Specifies the protocol permitted for a request made. The default value is https.
     :keyword str cache_control:
         Response header value for Cache-Control when resource is accessed
@@ -577,14 +583,17 @@
         Response header value for Content-Language when resource is accessed
         using this shared access signature.
     :keyword str content_type:
         Response header value for Content-Type when resource is accessed
         using this shared access signature.
     :keyword str encryption_scope:
         Specifies the encryption scope for a request made so that all write operations will be service encrypted.
+    :keyword str correlation_id:
+        The correlation id to correlate the storage audit logs with the audit logs used by the principal
+        generating and distributing the SAS. This can only be used when generating a SAS with delegation key.
     :return: A Shared Access Signature (sas) token.
     :rtype: str
     """
     if not user_delegation_key and not account_key:
         raise ValueError("Either user_delegation_key or account_key must be provided.")
     if isinstance(account_key, UserDelegationKey):
         user_delegation_key = account_key
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/_upload_helpers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_upload_helpers.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,74 +1,49 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=no-self-use
 
+import inspect
 from io import SEEK_SET, UnsupportedOperation
 from typing import TypeVar, TYPE_CHECKING
 
-import six
-from azure.core.exceptions import ResourceExistsError, ResourceModifiedError, HttpResponseError
+from azure.core.exceptions import ResourceModifiedError, HttpResponseError
 
-from ._shared.response_handlers import process_storage_error, return_response_headers
-from ._shared.models import StorageErrorCode
-from ._shared.uploads import (
+from .._shared.response_handlers import process_storage_error, return_response_headers
+from .._shared.uploads_async import (
     upload_data_chunks,
     upload_substream_blocks,
     BlockBlobChunkUploader,
     PageBlobChunkUploader,
     AppendBlobChunkUploader
 )
-from ._generated.models import (
+from .._generated.models import (
     BlockLookupList,
     AppendPositionAccessConditions,
     ModifiedAccessConditions,
 )
-from ._encryption import (
+from .._encryption import (
     GCMBlobEncryptionStream,
     encrypt_blob,
     get_adjusted_upload_size,
     get_blob_encryptor_and_padder,
     generate_blob_encryption_data,
     _ENCRYPTION_PROTOCOL_V1,
     _ENCRYPTION_PROTOCOL_V2
 )
+from .._upload_helpers import _convert_mod_error, _any_conditions
 
 if TYPE_CHECKING:
     BlobLeaseClient = TypeVar("BlobLeaseClient")
 
-_LARGE_BLOB_UPLOAD_MAX_READ_BUFFER_SIZE = 4 * 1024 * 1024
-_ERROR_VALUE_SHOULD_BE_SEEKABLE_STREAM = '{0} should be a seekable file-like/io.IOBase type stream object.'
 
-
-def _convert_mod_error(error):
-    message = error.message.replace(
-        "The condition specified using HTTP conditional header(s) is not met.",
-        "The specified blob already exists.")
-    message = message.replace("ConditionNotMet", "BlobAlreadyExists")
-    overwrite_error = ResourceExistsError(
-        message=message,
-        response=error.response,
-        error=error)
-    overwrite_error.error_code = StorageErrorCode.blob_already_exists
-    raise overwrite_error
-
-
-def _any_conditions(modified_access_conditions=None, **kwargs):  # pylint: disable=unused-argument
-    return any([
-        modified_access_conditions.if_modified_since,
-        modified_access_conditions.if_unmodified_since,
-        modified_access_conditions.if_none_match,
-        modified_access_conditions.if_match
-    ])
-
-
-def upload_block_blob(  # pylint: disable=too-many-locals, too-many-statements
+async def upload_block_blob(  # pylint: disable=too-many-locals, too-many-statements
         client=None,
         data=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
@@ -88,27 +63,28 @@
 
         immutability_policy = kwargs.pop('immutability_policy', None)
         immutability_policy_expiry = None if immutability_policy is None else immutability_policy.expiry_time
         immutability_policy_mode = None if immutability_policy is None else immutability_policy.policy_mode
         legal_hold = kwargs.pop('legal_hold', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
-        # Do single put if the size is smaller than or equal config.max_single_put_size
+        # Do single put if the size is smaller than config.max_single_put_size
         if adjusted_count is not None and (adjusted_count <= blob_settings.max_single_put_size):
             try:
                 data = data.read(length)
-                if not isinstance(data, six.binary_type):
+                if inspect.isawaitable(data):
+                    data = await data
+                if not isinstance(data, bytes):
                     raise TypeError('Blob data should be of type bytes.')
             except AttributeError:
                 pass
             if encryption_options.get('key'):
                 encryption_data, data = encrypt_blob(data, encryption_options['key'], encryption_options['version'])
                 headers['x-ms-meta-encryptiondata'] = encryption_data
-
-            response = client.upload(
+            response = await client.upload(
                 body=data,
                 content_length=adjusted_count,
                 blob_http_headers=blob_headers,
                 headers=headers,
                 cls=return_response_headers,
                 validate_content=validate_content,
                 data_stream_total=adjusted_count,
@@ -117,15 +93,15 @@
                 blob_tags_string=blob_tags_string,
                 immutability_policy_expiry=immutability_policy_expiry,
                 immutability_policy_mode=immutability_policy_mode,
                 legal_hold=legal_hold,
                 **kwargs)
 
             if progress_hook:
-                progress_hook(adjusted_count, adjusted_count)
+                await progress_hook(adjusted_count, adjusted_count)
 
             return response
 
         use_original_upload_path = blob_settings.use_byte_buffer or \
             validate_content or encryption_options.get('required') or \
             blob_settings.max_block_size < blob_settings.min_large_block_upload_threshold or \
             hasattr(stream, 'seekable') and not stream.seekable() or \
@@ -146,45 +122,45 @@
                 # Adjust total_size for encryption V2
                 if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V2:
                     # Adjust total_size for encryption V2
                     total_size = adjusted_count
                     # V2 wraps the data stream with an encryption stream
                     stream = GCMBlobEncryptionStream(cek, stream)
 
-            block_ids = upload_data_chunks(
+            block_ids = await upload_data_chunks(
                 service=client,
                 uploader_class=BlockBlobChunkUploader,
                 total_size=total_size,
                 chunk_size=blob_settings.max_block_size,
                 max_concurrency=max_concurrency,
                 stream=stream,
                 validate_content=validate_content,
                 progress_hook=progress_hook,
                 encryptor=encryptor,
                 padder=padder,
                 headers=headers,
                 **kwargs
             )
         else:
-            block_ids = upload_substream_blocks(
+            block_ids = await upload_substream_blocks(
                 service=client,
                 uploader_class=BlockBlobChunkUploader,
                 total_size=length,
                 chunk_size=blob_settings.max_block_size,
                 max_concurrency=max_concurrency,
                 stream=stream,
                 validate_content=validate_content,
                 progress_hook=progress_hook,
                 headers=headers,
                 **kwargs
             )
 
         block_lookup = BlockLookupList(committed=[], uncommitted=[], latest=[])
         block_lookup.latest = block_ids
-        return client.commit_block_list(
+        return await client.commit_block_list(
             block_lookup,
             blob_http_headers=blob_headers,
             cls=return_response_headers,
             validate_content=validate_content,
             headers=headers,
             tier=tier.value if tier else None,
             blob_tags_string=blob_tags_string,
@@ -197,15 +173,15 @@
             process_storage_error(error)
         except ResourceModifiedError as mod_error:
             if not overwrite:
                 _convert_mod_error(mod_error)
             raise
 
 
-def upload_page_blob(
+async def upload_page_blob(
         client=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
         max_concurrency=None,
@@ -233,15 +209,15 @@
                 encryption_options['key'],
                 encryption_options['version'])
             headers['x-ms-meta-encryptiondata'] = encryption_data
 
         blob_tags_string = kwargs.pop('blob_tags_string', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
-        response = client.create(
+        response = await client.create(
             content_length=0,
             blob_content_length=length,
             blob_sequence_number=None,
             blob_http_headers=kwargs.pop('blob_headers', None),
             blob_tags_string=blob_tags_string,
             tier=tier,
             cls=return_response_headers,
@@ -253,15 +229,15 @@
         if encryption_options and encryption_options.get('key'):
             if encryption_options['version'] == _ENCRYPTION_PROTOCOL_V1:
                 encryptor, padder = get_blob_encryptor_and_padder(cek, iv, False)
                 kwargs['encryptor'] = encryptor
                 kwargs['padder'] = padder
 
         kwargs['modified_access_conditions'] = ModifiedAccessConditions(if_match=response['etag'])
-        return upload_data_chunks(
+        return await upload_data_chunks(
             service=client,
             uploader_class=PageBlobChunkUploader,
             total_size=length,
             chunk_size=blob_settings.max_page_size,
             stream=stream,
             max_concurrency=max_concurrency,
             validate_content=validate_content,
@@ -274,15 +250,15 @@
             process_storage_error(error)
         except ResourceModifiedError as mod_error:
             if not overwrite:
                 _convert_mod_error(mod_error)
             raise
 
 
-def upload_append_blob(  # pylint: disable=unused-argument
+async def upload_append_blob(  # pylint: disable=unused-argument
         client=None,
         stream=None,
         length=None,
         overwrite=None,
         headers=None,
         validate_content=None,
         max_concurrency=None,
@@ -297,21 +273,21 @@
             max_size=kwargs.pop('maxsize_condition', None),
             append_position=None)
         blob_tags_string = kwargs.pop('blob_tags_string', None)
         progress_hook = kwargs.pop('progress_hook', None)
 
         try:
             if overwrite:
-                client.create(
+                await client.create(
                     content_length=0,
                     blob_http_headers=blob_headers,
                     headers=headers,
                     blob_tags_string=blob_tags_string,
                     **kwargs)
-            return upload_data_chunks(
+            return await upload_data_chunks(
                 service=client,
                 uploader_class=AppendBlobChunkUploader,
                 total_size=length,
                 chunk_size=blob_settings.max_block_size,
                 stream=stream,
                 max_concurrency=max_concurrency,
                 validate_content=validate_content,
@@ -326,21 +302,21 @@
             if hasattr(stream, 'read'):
                 try:
                     # attempt to rewind the body to the initial position
                     stream.seek(0, SEEK_SET)
                 except UnsupportedOperation:
                     # if body is not seekable, then retry would not work
                     raise error
-            client.create(
+            await client.create(
                 content_length=0,
                 blob_http_headers=blob_headers,
                 headers=headers,
                 blob_tags_string=blob_tags_string,
                 **kwargs)
-            return upload_data_chunks(
+            return await upload_data_chunks(
                 service=client,
                 uploader_class=AppendBlobChunkUploader,
                 total_size=length,
                 chunk_size=blob_settings.max_block_size,
                 stream=stream,
                 max_concurrency=max_concurrency,
                 validate_content=validate_content,
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_blob_client_async.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-lines, invalid-overridden-method
 
 import warnings
 from functools import partial
 from typing import (  # pylint: disable=unused-import
-    Any, AnyStr, Dict, IO, Iterable, List, Optional, overload, Tuple, Union,
+    Any, AnyStr, AsyncIterable, Dict, IO, Iterable, List, Optional, overload, Tuple, Union,
     TYPE_CHECKING
 )
 
 from azure.core.async_paging import AsyncItemPaged
 from azure.core.exceptions import ResourceNotFoundError, HttpResponseError, ResourceExistsError
 from azure.core.pipeline import AsyncPipeline
 from azure.core.tracing.decorator import distributed_trace
@@ -39,14 +39,15 @@
 from ._upload_helpers import (
     upload_block_blob,
     upload_append_blob,
     upload_page_blob
 )
 
 if TYPE_CHECKING:
+    from azure.core.credentials import AzureNamedKeyCredential, AzureSasCredential, TokenCredential
     from datetime import datetime
     from .._models import (  # pylint: disable=unused-import
         ContentSettings,
         ImmutabilityPolicy,
         PremiumPageBlobTier,
         StandardBlobTier,
         SequenceNumberAction
@@ -111,22 +112,21 @@
             :start-after: [START create_blob_client_sas_url]
             :end-before: [END create_blob_client_sas_url]
             :language: python
             :dedent: 8
             :caption: Creating the BlobClient from a SAS URL to a blob.
     """
     def __init__(
-            self, account_url,  # type: str
-            container_name,  # type: str
-            blob_name,  # type: str
-            snapshot=None,  # type: Optional[Union[str, Dict[str, Any]]]
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):
-        # type: (...) -> None
+            self, account_url: str,
+            container_name: str,
+            blob_name: str,
+            snapshot: Optional[Union[str, Dict[str, Any]]] = None,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> None:
         kwargs['retry_policy'] = kwargs.get('retry_policy') or ExponentialRetry(**kwargs)
         super(BlobClient, self).__init__(
             account_url,
             container_name=container_name,
             blob_name=blob_name,
             snapshot=snapshot,
             credential=credential,
@@ -220,15 +220,19 @@
             The destination match condition to use upon the etag.
         :keyword destination_lease:
             The lease ID specified for this header must match the lease ID of the
             destination blob. If the request does not include the lease ID or it is not
             valid, the operation fails with status code 412 (Precondition Failed).
         :paramtype destination_lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword ~azure.storage.blob.ContentSettings content_settings:
             ContentSettings object used to set blob properties. Used to set content type, encoding,
             language, disposition, md5, and cache control.
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
@@ -251,21 +255,20 @@
         try:
             return await self._client.block_blob.put_blob_from_url(**options)
         except HttpResponseError as error:
             process_storage_error(error)
 
     @distributed_trace_async
     async def upload_blob(
-            self, data,  # type: Union[bytes, str, Iterable[AnyStr], IO[AnyStr]]
-            blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
-            length=None,  # type: Optional[int]
-            metadata=None,  # type: Optional[Dict[str, str]]
+            self, data: Union[bytes, str, Iterable[AnyStr], AsyncIterable[AnyStr], IO[AnyStr]],
+            blob_type: Union[str, BlobType] = BlobType.BlockBlob,
+            length: Optional[int] = None,
+            metadata: Optional[Dict[str, str]] = None,
             **kwargs
-        ):
-        # type: (...) -> Any
+        ) -> Dict[str, Any]:
         """Creates a new blob from a data source with automatic chunking.
 
         :param data: The blob data to upload.
         :param ~azure.storage.blob.BlobType blob_type: The type of the blob. This can be
             either BlockBlob, PageBlob or AppendBlob. The default value is BlockBlob.
         :param int length:
             Number of bytes to read from the stream. This is optional, but
@@ -376,15 +379,20 @@
             Defaults to UTF-8.
         :keyword progress_hook:
             An async callback to track the progress of a long running upload. The signature is
             function(current: int, total: Optional[int]) where current is the number of bytes transfered
             so far, and total is the size of the blob or None if the size is unknown.
         :paramtype progress_hook: Callable[[int, Optional[int]], Awaitable[None]]
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :returns: Blob-updated property dict (Etag and last modified)
         :rtype: dict[str, Any]
 
         .. admonition:: Example:
 
@@ -497,15 +505,20 @@
             Encoding to decode the downloaded bytes. Default is None, i.e. no decoding.
         :keyword progress_hook:
             An async callback to track the progress of a long running download. The signature is
             function(current: int, total: int) where current is the number of bytes transfered
             so far, and total is the total size of the download.
         :paramtype progress_hook: Callable[[int, int], Awaitable[None]]
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :returns: A streaming object (StorageStreamDownloader)
         :rtype: ~azure.storage.blob.aio.StorageStreamDownloader
 
         .. admonition:: Example:
 
@@ -577,15 +590,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_hello_world_async.py
                 :start-after: [START delete_blob]
                 :end-before: [END delete_blob]
@@ -603,16 +620,24 @@
     async def undelete_blob(self, **kwargs):
         # type: (Any) -> None
         """Restores soft-deleted blobs or snapshots.
 
         Operation will only be successful if used within the specified number of days
         set in the delete retention policy.
 
+        If blob versioning is enabled, the base blob cannot be restored using this
+        method. Instead use :func:`start_copy_from_url` with the URL of the blob version
+        you wish to promote to the current version.
+
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common_async.py
                 :start-after: [START undelete_blob]
                 :end-before: [END undelete_blob]
@@ -628,19 +653,23 @@
     @distributed_trace_async
     async def exists(self, **kwargs):
         # type: (**Any) -> bool
         """
         Returns True if a blob exists with the defined parameters, and returns
         False otherwise.
 
-        :kwarg str version_id:
+        :keyword str version_id:
             The version id parameter is an opaque DateTime
             value that, when present, specifies the version of the blob to check if it exists.
-        :kwarg int timeout:
-            The timeout parameter is expressed in seconds.
+        :keyword int timeout:
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: boolean
         """
         try:
             await self._client.blob.get_properties(
                 snapshot=self.snapshot,
                 **kwargs)
             return True
@@ -695,15 +724,19 @@
 
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
             a secure connection must be established to transfer the key.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: BlobProperties
         :rtype: ~azure.storage.blob.BlobProperties
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common_async.py
                 :start-after: [START get_blob_properties]
@@ -776,15 +809,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified)
         :rtype: Dict[str, Any]
         """
         options = self._set_http_headers_options(content_settings=content_settings, **kwargs)
         try:
             return await self._client.blob.set_http_headers(**options) # type: ignore
         except HttpResponseError as error:
@@ -837,15 +874,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified)
         """
         options = self._set_blob_metadata_options(metadata=metadata, **kwargs)
         try:
             return await self._client.blob.set_metadata(**options)  # type: ignore
         except HttpResponseError as error:
             process_storage_error(error)
@@ -861,15 +902,19 @@
         :param ~azure.storage.blob.ImmutabilityPolicy immutability_policy:
             Specifies the immutability policy of a blob, blob snapshot or blob version.
 
             .. versionadded:: 12.10.0
                 This was introduced in API version '2020-10-02'.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, str]
         """
 
         kwargs['immutability_policy_expiry'] = immutability_policy.expiry_time
         kwargs['immutability_policy_mode'] = immutability_policy.policy_mode
         return await self._client.blob.set_immutability_policy(cls=return_response_headers, **kwargs)
@@ -879,15 +924,19 @@
         # type: (**Any) -> None
         """The Delete Immutability Policy operation deletes the immutability policy on the blob.
 
         .. versionadded:: 12.10.0
             This operation was introduced in API version '2020-10-02'.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, str]
         """
 
         await self._client.blob.delete_immutability_policy(**kwargs)
 
     @distributed_trace_async
@@ -897,15 +946,19 @@
 
         .. versionadded:: 12.10.0
             This operation was introduced in API version '2020-10-02'.
 
         :param bool legal_hold:
             Specified if a legal hold should be set on the blob.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, Union[str, datetime, bool]]
         """
 
         return await self._client.blob.set_legal_hold(legal_hold, cls=return_response_headers, **kwargs)
 
     @distributed_trace_async
@@ -989,15 +1042,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict[str, Any]
         """
         options = self._create_page_blob_options(
             size,
             content_settings=content_settings,
             metadata=metadata,
@@ -1072,15 +1129,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict[str, Any]
         """
         options = self._create_append_blob_options(
             content_settings=content_settings,
             metadata=metadata,
             **kwargs)
@@ -1142,15 +1203,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Snapshot ID, Etag, and last modified).
         :rtype: dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common_async.py
                 :start-after: [START create_blob_snapshot]
@@ -1298,15 +1363,19 @@
             valid, the operation fails with status code 412 (Precondition Failed).
         :paramtype destination_lease: ~azure.storage.blob.aio.BlobLeaseClient or str
         :keyword source_lease:
             Specify this to perform the Copy Blob operation only if
             the lease ID given matches the active lease ID of the source blob.
         :paramtype source_lease: ~azure.storage.blob.aio.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword ~azure.storage.blob.PremiumPageBlobTier premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
             premium storage accounts.
         :keyword ~azure.storage.blob.StandardBlobTier standard_blob_tier:
             A standard blob tier value to set the blob to. For this version of the library,
             this is only applicable to block blobs on standard storage accounts.
@@ -1424,15 +1493,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A BlobLeaseClient object.
         :rtype: ~azure.storage.blob.aio.BlobLeaseClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common_async.py
                 :start-after: [START acquire_lease_on_blob]
@@ -1466,15 +1539,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.aio.BlobLeaseClient or str
         :rtype: None
         """
         access_conditions = get_access_conditions(kwargs.pop('lease', None))
@@ -1531,15 +1608,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
         """
         options = self._stage_block_options(
             block_id,
             data,
             length=length,
             **kwargs)
@@ -1586,15 +1667,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword str source_authorization:
             Authenticate as a service principal using a client secret to access a source blob. Ensure "bearer " is
             the prefix of the source_authorization string.
         :rtype: None
         """
         options = self._stage_block_from_url_options(
             block_id,
@@ -1625,19 +1710,23 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A tuple of two lists - committed and uncommitted blocks
         :rtype: tuple(list(~azure.storage.blob.BlobBlock), list(~azure.storage.blob.BlobBlock))
         """
-        access_conditions = get_access_conditions(kwargs.pop('kease', None))
+        access_conditions = get_access_conditions(kwargs.pop('lease', None))
         mod_conditions = get_modify_conditions(kwargs)
         try:
             blocks = await self._client.block_blob.get_block_list(
                 list_type=block_list_type,
                 snapshot=self.snapshot,
                 timeout=kwargs.pop('timeout', None),
                 lease_access_conditions=access_conditions,
@@ -1735,15 +1824,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._commit_block_list_options(
             block_list,
             content_settings=content_settings,
             metadata=metadata,
@@ -1766,17 +1859,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
-            multiple calls to the Azure service and the timeout will apply to
-            each call individually.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.aio.BlobLeaseClient or str
         :rtype: None
         """
         access_conditions = get_access_conditions(kwargs.pop('lease', None))
@@ -1824,15 +1919,19 @@
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified)
         :rtype: Dict[str, Any]
         """
         options = self._set_blob_tags_options(tags=tags, **kwargs)
         try:
             return await self._client.blob.set_tags(**options)
         except HttpResponseError as error:
@@ -1853,15 +1952,19 @@
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
         :keyword lease:
             Required if the blob has an active lease. Value can be a BlobLeaseClient object
             or the lease ID as a string.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Key value pairs of blob tags.
         :rtype: Dict[str, str]
         """
         options = self._get_blob_tags_options(**kwargs)
         try:
             _, tags = await self._client.blob.get_tags(**options)
             return parse_tags(tags)  # pylint: disable=protected-access
@@ -1921,15 +2024,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns:
             A tuple of two lists of page ranges as dictionaries with 'start' and 'end' keys.
             The first element are filled page ranges, the 2nd element is cleared page ranges.
         :rtype: tuple(list(dict(str, str), list(dict(str, str))
         """
         warnings.warn(
             "get_page_ranges is deprecated, use list_page_ranges instead",
@@ -2009,15 +2116,19 @@
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int results_per_page:
             The maximum number of page ranges to retrieve per API call.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) of PageRange.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.PageRange]
         """
         results_per_page = kwargs.pop('results_per_page', None)
         options = self._get_page_ranges_options(
             offset=offset,
             length=length,
@@ -2088,15 +2199,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns:
             A tuple of two lists of page ranges as dictionaries with 'start' and 'end' keys.
             The first element are filled page ranges, the 2nd element is cleared page ranges.
         :rtype: tuple(list(dict(str, str), list(dict(str, str))
         """
         options = self._get_page_ranges_options(
             offset=offset,
@@ -2149,15 +2264,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._set_sequence_number_options(
             sequence_number_action, sequence_number=sequence_number, **kwargs)
         try:
             return await self._client.page_blob.update_sequence_number(**options) # type: ignore
@@ -2203,15 +2322,19 @@
             .. versionadded:: 12.4.0
 
         :keyword ~azure.storage.blob.PremiumPageBlobTier premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
             premium storage accounts.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._resize_blob_options(size, **kwargs)
         try:
             return await self._client.page_blob.resize(**options) # type: ignore
         except HttpResponseError as error:
@@ -2294,15 +2417,19 @@
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword str encoding:
             Defaults to UTF-8.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._upload_page_options(
             page=page,
             offset=offset,
             length=length,
@@ -2405,15 +2532,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword str source_authorization:
             Authenticate as a service principal using a client secret to access a source blob. Ensure "bearer " is
             the prefix of the source_authorization string.
         """
 
         options = self._upload_pages_from_url_options(
             source_url=self._encode_source_url(source_url),
@@ -2480,15 +2611,19 @@
 
         :keyword ~azure.storage.blob.CustomerProvidedEncryptionKey cpk:
             Encrypts the data on the service-side with the given key.
             Use of customer-provided keys must be done over HTTPS.
             As the encryption key itself is provided in the request,
             a secure connection must be established to transfer the key.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag and last modified).
         :rtype: dict(str, Any)
         """
         options = self._clear_page_options(offset, length, **kwargs)
         try:
             return await self._client.page_blob.clear_pages(**options)  # type: ignore
         except HttpResponseError as error:
@@ -2565,15 +2700,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag, last modified, append offset, committed block count).
         :rtype: dict(str, Any)
         """
         options = self._append_block_options(
             data,
             length=length,
             **kwargs
@@ -2668,15 +2807,19 @@
             scope can be created using the Management API and referenced here by name. If a default
             encryption scope has been defined at the container, this value will override it if the
             container-level scope is configured to allow overrides. Otherwise an error will be raised.
 
             .. versionadded:: 12.2.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword str source_authorization:
             Authenticate as a service principal using a client secret to access a source blob. Ensure "bearer " is
             the prefix of the source_authorization string.
         """
         options = self._append_block_from_url_options(
             copy_source_url=self._encode_source_url(copy_source_url),
             source_offset=source_offset,
@@ -2719,15 +2862,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Blob-updated property dict (Etag, last modified, append offset, committed block count).
         :rtype: dict(str, Any)
         """
         options = self._seal_append_blob_options(**kwargs)
         try:
             return await self._client.append_blob.seal(**options) # type: ignore
         except HttpResponseError as error:
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_blob_service_client_async.py`

 * *Files 13% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=invalid-overridden-method
 
 import functools
 import warnings
-from typing import (  # pylint: disable=unused-import
+from typing import (
     Any, Dict, List, Optional, Union,
     TYPE_CHECKING
 )
 
 from azure.core.async_paging import AsyncItemPaged
 from azure.core.exceptions import HttpResponseError
 from azure.core.pipeline import AsyncPipeline
@@ -36,14 +36,15 @@
 from .._models import ContainerProperties
 from .._serialize import get_api_version
 from ._blob_client_async import BlobClient
 from ._container_client_async import ContainerClient
 from ._models import ContainerPropertiesPaged, FilteredBlobPaged
 
 if TYPE_CHECKING:
+    from azure.core.credentials import AzureNamedKeyCredential, AzureSasCredential, TokenCredential
     from datetime import datetime
     from .._shared.models import UserDelegationKey
     from ._lease_async import BlobLeaseClient
     from .._models import (
         BlobProperties,
         PublicAccess,
         BlobAnalyticsLogging,
@@ -111,19 +112,18 @@
             :end-before: [END create_blob_service_client_oauth]
             :language: python
             :dedent: 8
             :caption: Creating the BlobServiceClient with Azure Identity credentials.
     """
 
     def __init__(
-            self, account_url,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):
-        # type: (...) -> None
+            self, account_url: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> None:
         kwargs['retry_policy'] = kwargs.get('retry_policy') or ExponentialRetry(**kwargs)
         super(BlobServiceClient, self).__init__(
             account_url,
             credential=credential,
             **kwargs)
         self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
         self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
@@ -140,15 +140,19 @@
         A token credential must be present on the service object for this request to succeed.
 
         :param ~datetime.datetime key_start_time:
             A DateTime value. Indicates when the key becomes valid.
         :param ~datetime.datetime key_expiry_time:
             A DateTime value. Indicates when the key stops being valid.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: The user delegation key.
         :rtype: ~azure.storage.blob.UserDelegationKey
         """
         key_info = KeyInfo(start=_to_utc_datetime(key_start_time), expiry=_to_utc_datetime(key_expiry_time))
         timeout = kwargs.pop('timeout', None)
         try:
             user_delegation_key = await self._client.service.get_user_delegation_key(key_info=key_info,
@@ -202,15 +206,19 @@
         is the secondary location. The secondary location is automatically
         determined based on the location of the primary; it is in a second data
         center that resides in the same region as the primary location. Read-only
         access is available from the secondary location, if read-access geo-redundant
         replication is enabled for your storage account.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: The blob service stats.
         :rtype: Dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service_async.py
                 :start-after: [START get_blob_service_stats]
@@ -230,15 +238,19 @@
     @distributed_trace_async
     async def get_service_properties(self, **kwargs):
         # type: (Any) -> Dict[str, Any]
         """Gets the properties of a storage account's Blob service, including
         Azure Storage Analytics.
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An object containing blob service properties such as
             analytics logging, hour/minute metrics, cors rules, etc.
         :rtype: Dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service_async.py
@@ -297,15 +309,19 @@
             It also specifies the number of days and versions of blob to keep.
         :type delete_retention_policy: ~azure.storage.blob.RetentionPolicy
         :param static_website:
             Specifies whether the static website feature is enabled,
             and if yes, indicates the index document and 404 error document to use.
         :type static_website: ~azure.storage.blob.StaticWebsite
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service_async.py
                 :start-after: [START set_blob_service_properties]
                 :end-before: [END set_blob_service_properties]
@@ -358,15 +374,19 @@
         :keyword bool include_system:
             Flag specifying that system containers should be included.
             .. versionadded:: 12.10.0
         :keyword int results_per_page:
             The maximum number of container names to retrieve per API
             call. If the request does not specify the server will return up to 5,000 items.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) of ContainerProperties.
         :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.storage.blob.ContainerProperties]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service_async.py
                 :start-after: [START bsc_list_containers]
@@ -408,15 +428,19 @@
         :param str filter_expression:
             The expression to find blobs whose tags matches the specified condition.
             eg. "\"yourtagname\"='firsttag' and \"yourtagname2\"='secondtag'"
             To specify a container, eg. "@container='containerName' and \"Name\"='C'"
         :keyword int results_per_page:
             The max result per page when paginating.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.storage.blob.FilteredBlob]
         """
 
         results_per_page = kwargs.pop('results_per_page', None)
         timeout = kwargs.pop('timeout', None)
         command = functools.partial(
@@ -454,15 +478,19 @@
             Specifies the default encryption scope to set on the container and use for
             all future writes.
 
             .. versionadded:: 12.2.0
 
         :paramtype container_encryption_scope: dict or ~azure.storage.blob.ContainerEncryptionScope
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.aio.ContainerClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service_async.py
                 :start-after: [START bsc_create_container]
                 :end-before: [END bsc_create_container]
@@ -512,15 +540,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_service_async.py
                 :start-after: [START bsc_delete_container]
                 :end-before: [END bsc_delete_container]
@@ -548,15 +580,19 @@
         :param str new_name:
             The new container name the user wants to rename to.
         :keyword lease:
             Specify this to perform only if the lease ID given
             matches the active lease ID of the source container.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         renamed_container = self.get_container_client(new_name)
         lease = kwargs.pop('lease', None)
         try:
             kwargs['source_lease_id'] = lease.id  # type: str
         except AttributeError:
@@ -579,15 +615,19 @@
             This operation was introduced in API version '2019-12-12'.
 
         :param str deleted_container_name:
             Specifies the name of the deleted container to restore.
         :param str deleted_container_version:
             Specifies the version of the deleted container to restore.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.aio.ContainerClient
         """
         new_name = kwargs.pop('new_name', None)
         if new_name:
             warnings.warn("`new_name` is no longer supported.", DeprecationWarning)
         container = self.get_container_client(new_name or deleted_container_name)
         try:
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_container_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_container_client_async.py`

 * *Files 16% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-lines, invalid-overridden-method
 
 import functools
 from typing import (  # pylint: disable=unused-import
-    Any, AnyStr, AsyncIterator, Dict, List, IO, Iterable, Optional, overload, Union,
+    Any, AnyStr, AsyncIterable, AsyncIterator, Dict, List, IO, Iterable, Optional, overload, Union,
     TYPE_CHECKING
 )
 
 from azure.core.async_paging import AsyncItemPaged
 from azure.core.exceptions import HttpResponseError, ResourceNotFoundError
 from azure.core.pipeline import AsyncPipeline
 from azure.core.pipeline.transport import AsyncHttpResponse
@@ -32,18 +32,20 @@
 from .._deserialize import deserialize_container_properties
 from ._download_async import StorageStreamDownloader
 from .._encryption import StorageEncryptionMixin
 from .._models import ContainerProperties, BlobType, BlobProperties, FilteredBlob
 from .._serialize import get_modify_conditions, get_container_cpk_scope_info, get_api_version, get_access_conditions
 from ._blob_client_async import BlobClient
 from ._lease_async import BlobLeaseClient
-from ._list_blobs_helper import BlobPropertiesPaged, BlobPrefix
+from ._list_blobs_helper import BlobNamesPaged, BlobPropertiesPaged, BlobPrefix
+from .._list_blobs_helper import IgnoreListBlobsDeserializer
 from ._models import FilteredBlobPaged
 
 if TYPE_CHECKING:
+    from azure.core.credentials import AzureNamedKeyCredential, AzureSasCredential, TokenCredential
     from datetime import datetime
     from .._models import ( # pylint: disable=unused-import
         AccessPolicy,
         StandardBlobTier,
         PremiumPageBlobTier,
         PublicAccess)
 
@@ -105,30 +107,34 @@
             :start-after: [START create_container_client_sasurl]
             :end-before: [END create_container_client_sasurl]
             :language: python
             :dedent: 12
             :caption: Creating the container client directly.
     """
     def __init__(
-            self, account_url,  # type: str
-            container_name,  # type: str
-            credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
-            **kwargs  # type: Any
-        ):
-        # type: (...) -> None
+            self, account_url: str,
+            container_name: str,
+            credential: Optional[Union[str, Dict[str, str], "AzureNamedKeyCredential", "AzureSasCredential", "TokenCredential"]] = None,  # pylint: disable=line-too-long
+            **kwargs: Any
+        ) -> None:
         kwargs['retry_policy'] = kwargs.get('retry_policy') or ExponentialRetry(**kwargs)
         super(ContainerClient, self).__init__(
             account_url,
             container_name=container_name,
             credential=credential,
             **kwargs)
-        self._client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
-        self._client._config.version = get_api_version(kwargs)  # pylint: disable=protected-access
+        self._api_version = get_api_version(kwargs)
+        self._client = self._build_generated_client()
         self._configure_encryption(kwargs)
 
+    def _build_generated_client(self):
+        client = AzureBlobStorage(self.url, base_url=self.url, pipeline=self._pipeline)
+        client._config.version = self._api_version # pylint: disable=protected-access
+        return client
+
     @distributed_trace_async
     async def create_container(self, metadata=None, public_access=None, **kwargs):
         # type: (Optional[Dict[str, str]], Optional[Union[PublicAccess, str]], **Any) -> Dict[str, Union[str, datetime]]
         """
         Creates a new container under the specified account. If the container
         with the same name already exists, the operation fails.
 
@@ -142,15 +148,19 @@
             Specifies the default encryption scope to set on the container and use for
             all future writes.
 
             .. versionadded:: 12.2.0
 
         :paramtype container_encryption_scope: dict or ~azure.storage.blob.ContainerEncryptionScope
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A dictionary of response headers.
         :rtype: Dict[str, Union[str, datetime]]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START create_container]
@@ -184,15 +194,19 @@
         :param str new_name:
             The new container name the user wants to rename to.
         :keyword lease:
             Specify this to perform only if the lease ID given
             matches the active lease ID of the source container.
         :paramtype lease: ~azure.storage.blob.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: ~azure.storage.blob.ContainerClient
         """
         lease = kwargs.pop('lease', None)
         try:
             kwargs['source_lease_id'] = lease.id
         except AttributeError:
             kwargs['source_lease_id'] = lease
@@ -235,15 +249,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START delete_container]
                 :end-before: [END delete_container]
@@ -297,15 +315,19 @@
             the resource has not been modified since the specified date/time.
         :keyword str etag:
             An ETag value, or the wildcard character (*). Used to check if the resource has changed,
             and act according to the condition specified by the `match_condition` parameter.
         :keyword ~azure.core.MatchConditions match_condition:
             The match condition to use upon the etag.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: A BlobLeaseClient object, that can be run in a context manager.
         :rtype: ~azure.storage.blob.aio.BlobLeaseClient
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START acquire_lease_on_container]
@@ -343,15 +365,19 @@
         container. The data returned does not include the container's list of blobs.
 
         :keyword lease:
             If specified, get_container_properties only succeeds if the
             container's lease is active and matches this ID.
         :paramtype lease: ~azure.storage.blob.aio.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: Properties for the specified container within a container object.
         :rtype: ~azure.storage.blob.ContainerProperties
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START get_container_properties]
@@ -377,15 +403,19 @@
     @distributed_trace_async
     async def exists(self, **kwargs):
         # type: (**Any) -> bool
         """
         Returns True if a container exists and returns False otherwise.
 
         :kwarg int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: boolean
         """
         try:
             await self._client.container.get_properties(**kwargs)
             return True
         except HttpResponseError as error:
             try:
@@ -415,15 +445,19 @@
         :keyword ~datetime.datetime if_modified_since:
             A DateTime value. Azure expects the date value passed in to be UTC.
             If timezone is included, any non-UTC datetimes will be converted to UTC.
             If a date is passed in without timezone info, it is assumed to be UTC.
             Specify this header to perform the operation only
             if the resource has been modified since the specified time.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Container-updated property dict (Etag and last modified).
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START set_container_metadata]
                 :end-before: [END set_container_metadata]
@@ -490,15 +524,19 @@
         The permissions indicate whether container data may be accessed publicly.
 
         :keyword lease:
             If specified, get_container_access_policy only succeeds if the
             container's lease is active and matches this ID.
         :paramtype lease: ~azure.storage.blob.aio.BlobLeaseClient or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Access policy information in a dict.
         :rtype: dict[str, Any]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START get_container_access_policy]
@@ -553,15 +591,19 @@
         :keyword ~datetime.datetime if_unmodified_since:
             A datetime value. Azure expects the date value passed in to be UTC.
             If timezone is included, any non-UTC datetimes will be converted to UTC.
             If a date is passed in without timezone info, it is assumed to be UTC.
             Specify this header to perform the operation only if
             the resource has not been modified since the specified date/time.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: Container-updated property dict (Etag and last modified).
         :rtype: dict[str, str or ~datetime.datetime]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START set_container_access_policy]
@@ -607,18 +649,22 @@
 
         :param str name_starts_with:
             Filters the results to return only blobs whose names
             begin with the specified prefix.
         :param include:
             Specifies one or more additional datasets to include in the response.
             Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted', 'deletedwithversions',
-            'tags', 'versions'.
-        :paramtype include: list[str] or str
+            'tags', 'versions', 'immutabilitypolicy', 'legalhold'.
+        :type include: list[str] or str
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.storage.blob.BlobProperties]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_containers_async.py
                 :start-after: [START list_blobs_in_container]
@@ -641,39 +687,86 @@
             command,
             prefix=name_starts_with,
             results_per_page=results_per_page,
             page_iterator_class=BlobPropertiesPaged
         )
 
     @distributed_trace
+    def list_blob_names(self, **kwargs: Any) -> AsyncItemPaged[str]:
+        """Returns a generator to list the names of blobs under the specified container.
+        The generator will lazily follow the continuation tokens returned by
+        the service.
+
+        Note that no additional properties or metadata will be returned when using this API.
+        Additionally this API does not have an option to include additional blobs such as snapshots,
+        versions, soft-deleted blobs, etc. To get any of this data, use :func:`list_blobs()`.
+
+        :keyword str name_starts_with:
+            Filters the results to return only blobs whose names
+            begin with the specified prefix.
+        :keyword int timeout:
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
+        :returns: An iterable (auto-paging) response of blob names as strings.
+        :rtype: ~azure.core.async_paging.AsyncItemPaged[str]
+        """
+        name_starts_with = kwargs.pop('name_starts_with', None)
+        results_per_page = kwargs.pop('results_per_page', None)
+        timeout = kwargs.pop('timeout', None)
+
+        # For listing only names we need to create a one-off generated client and
+        # override its deserializer to prevent deserialization of the full response.
+        client = self._build_generated_client()
+        client.container._deserialize = IgnoreListBlobsDeserializer()  # pylint: disable=protected-access
+
+        command = functools.partial(
+            client.container.list_blob_flat_segment,
+            timeout=timeout,
+            **kwargs)
+        return AsyncItemPaged(
+            command,
+            prefix=name_starts_with,
+            results_per_page=results_per_page,
+            page_iterator_class=BlobNamesPaged)
+
+    @distributed_trace
     def walk_blobs(
             self, name_starts_with=None, # type: Optional[str]
-            include=None, # type: Optional[Any]
+            include=None, # type: Optional[Union[List[str], str]]
             delimiter="/", # type: str
             **kwargs # type: Optional[Any]
         ):
         # type: (...) -> AsyncItemPaged[BlobProperties]
         """Returns a generator to list the blobs under the specified container.
         The generator will lazily follow the continuation tokens returned by
         the service. This operation will list blobs in accordance with a hierarchy,
         as delimited by the specified delimiter character.
 
         :param str name_starts_with:
             Filters the results to return only blobs whose names
             begin with the specified prefix.
-        :param list[str] include:
+        :param include:
             Specifies one or more additional datasets to include in the response.
-            Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted'.
+            Options include: 'snapshots', 'metadata', 'uncommittedblobs', 'copy', 'deleted', 'deletedwithversions',
+            'tags', 'versions', 'immutabilitypolicy', 'legalhold'.
+        :type include: list[str] or str
         :param str delimiter:
             When the request includes this parameter, the operation returns a BlobPrefix
             element in the response body that acts as a placeholder for all blobs whose
             names begin with the same substring up to the appearance of the delimiter
             character. The delimiter may be a single character or a string.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of BlobProperties.
         :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.storage.blob.BlobProperties]
         """
         if include and not isinstance(include, list):
             include = [include]
 
         results_per_page = kwargs.pop('results_per_page', None)
@@ -703,15 +796,19 @@
 
         :param str filter_expression:
             The expression to find blobs whose tags matches the specified condition.
             eg. "\"yourtagname\"='firsttag' and \"yourtagname2\"='secondtag'"
         :keyword int results_per_page:
             The max result per page when paginating.
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :returns: An iterable (auto-paging) response of FilteredBlob.
         :rtype: ~azure.core.paging.ItemPaged[~azure.storage.blob.BlobProperties]
         """
         results_per_page = kwargs.pop('results_per_page', None)
         timeout = kwargs.pop('timeout', None)
         command = functools.partial(
             self._client.container.filter_blobs,
@@ -720,22 +817,21 @@
             **kwargs)
         return AsyncItemPaged(
             command, results_per_page=results_per_page,
             page_iterator_class=FilteredBlobPaged)
 
     @distributed_trace_async
     async def upload_blob(
-            self, name,  # type: Union[str, BlobProperties]
-            data,  # type: Union[Iterable[AnyStr], IO[AnyStr]]
-            blob_type=BlobType.BlockBlob,  # type: Union[str, BlobType]
-            length=None,  # type: Optional[int]
-            metadata=None,  # type: Optional[Dict[str, str]]
+            self, name: Union[str, BlobProperties],
+            data: Union[bytes, str, Iterable[AnyStr], AsyncIterable[AnyStr], IO[AnyStr]],
+            blob_type: Union[str, BlobType] = BlobType.BlockBlob,
+            length: Optional[int] = None,
+            metadata: Optional[Dict[str, str]] = None,
             **kwargs
-        ):
-        # type: (...) -> BlobClient
+        ) -> BlobClient:
         """Creates a new blob from a data source with automatic chunking.
 
         :param name: The blob with which to interact. If specified, this value will override
             a blob value specified in the blob URL.
         :type name: str or ~azure.storage.blob.BlobProperties
         :param data: The blob data to upload.
         :param ~azure.storage.blob.BlobType blob_type: The type of the blob. This can be
@@ -788,15 +884,20 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :keyword ~azure.storage.blob.PremiumPageBlobTier premium_page_blob_tier:
             A page blob tier value to set the blob to. The tier correlates to the size of the
             blob and number of allowed IOPS. This is only applicable to page blobs on
             premium storage accounts.
         :keyword ~azure.storage.blob.StandardBlobTier standard_blob_tier:
@@ -916,15 +1017,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
         """
         blob = self.get_blob_client(blob) # type: ignore
         kwargs.setdefault('merge_span', True)
         timeout = kwargs.pop('timeout', None)
         await blob.delete_blob( # type: ignore
             delete_snapshots=delete_snapshots,
@@ -1027,15 +1132,20 @@
             Encoding to decode the downloaded bytes. Default is None, i.e. no decoding.
         :keyword progress_hook:
             An async callback to track the progress of a long running download. The signature is
             function(current: int, total: int) where current is the number of bytes transfered
             so far, and total is the total size of the download.
         :paramtype progress_hook: Callable[[int, int], Awaitable[None]]
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_. This method may make multiple calls to the service and
+            the timeout will apply to each call individually.
             multiple calls to the Azure service and the timeout will apply to
             each call individually.
         :returns: A streaming object. (StorageStreamDownloader)
         :rtype: ~azure.storage.blob.aio.StorageStreamDownloader
         """
         blob_client = self.get_blob_client(blob) # type: ignore
         kwargs.setdefault('merge_span', True)
@@ -1114,15 +1224,19 @@
             .. versionadded:: 12.4.0
 
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure. For optimal performance,
             this should be set to False
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: An async iterator of responses, one for each blob in order
         :rtype: asynciterator[~azure.core.pipeline.transport.AsyncHttpResponse]
 
         .. admonition:: Example:
 
             .. literalinclude:: ../samples/blob_samples_common_async.py
                 :start-after: [START delete_multiple_blobs]
@@ -1189,15 +1303,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure. For optimal performance,
             this should be set to False.
         :return: An async iterator of responses, one for each blob in order
         :rtype: asynciterator[~azure.core.pipeline.transport.AsyncHttpResponse]
         """
@@ -1238,17 +1356,19 @@
                 lease:
                     key: 'lease_id', value type: Union[str, LeaseClient]
                 timeout for subrequest:
                     key: 'timeout', value type: int
 
         :type blobs: str or dict(str, Any) or ~azure.storage.blob.BlobProperties
         :keyword int timeout:
-            The timeout parameter is expressed in seconds. This method may make
-            multiple calls to the Azure service and the timeout will apply to
-            each call individually.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :keyword bool raise_on_any_failure:
             This is a boolean param which defaults to True. When this is set, an exception
             is raised even if there is a single operation failure. For optimal performance,
             this should be set to False.
         :return: An async iterator of responses, one for each blob in order
         :rtype: asynciterator[~azure.core.pipeline.transport.AsyncHttpResponse]
         """
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_download_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_download_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_lease_async.py`

 * *Files 7% similar despite different names*

```diff
@@ -93,15 +93,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :rtype: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = await self._client.acquire_lease(
                 timeout=kwargs.pop('timeout', None),
                 duration=lease_duration,
@@ -146,15 +150,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = await self._client.renew_lease(
                 lease_id=self.id,
                 timeout=kwargs.pop('timeout', None),
@@ -196,15 +204,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = await self._client.release_lease(
                 lease_id=self.id,
                 timeout=kwargs.pop('timeout', None),
@@ -245,15 +257,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: None
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = await self._client.change_lease(
                 lease_id=self.id,
                 proposed_lease_id=proposed_lease_id,
@@ -304,15 +320,19 @@
         :keyword str if_tags_match_condition:
             Specify a SQL where clause on blob tags to operate only on blob with a matching value.
             eg. ``\"\\\"tagname\\\"='my tag'\"``
 
             .. versionadded:: 12.4.0
 
         :keyword int timeout:
-            The timeout parameter is expressed in seconds.
+            Sets the server-side timeout for the operation in seconds. For more details see
+            https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations.
+            This value is not tracked or validated on the client. To configure client-side network timesouts
+            see `here <https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-blob
+            #other-client--per-operation-configuration>`_.
         :return: Approximate time remaining in the lease period, in seconds.
         :rtype: int
         """
         mod_conditions = get_modify_conditions(kwargs)
         try:
             response = await self._client.break_lease(
                 timeout=kwargs.pop('timeout', None),
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_list_blobs_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_list_paths_helper.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,65 +1,53 @@
-# pylint: disable=too-many-lines
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
-
-try:
-    from urllib.parse import unquote
-except ImportError:
-    from urllib import unquote
-from azure.core.async_paging import AsyncPageIterator, AsyncItemPaged
+# pylint: disable=too-few-public-methods, too-many-instance-attributes
+# pylint: disable=super-init-not-called, too-many-lines
 from azure.core.exceptions import HttpResponseError
-from .._deserialize import get_blob_properties_from_generated_code
-from .._models import BlobProperties
+from azure.core.async_paging import AsyncPageIterator
+
+from .._deserialize import process_storage_error, get_deleted_path_properties_from_generated_code, \
+    return_headers_and_deserialized_path_list
 from .._generated.models import BlobItemInternal, BlobPrefix as GenBlobPrefix
+
 from .._shared.models import DictMixin
-from .._shared.response_handlers import return_context_and_deserialized, process_storage_error
+from .._shared.response_handlers import return_context_and_deserialized
+from .._generated.models import Path
+from .._models import PathProperties
 
 
-class BlobPropertiesPaged(AsyncPageIterator):
-    """An Iterable of Blob properties.
+class DeletedPathPropertiesPaged(AsyncPageIterator):
+    """An Iterable of deleted path properties.
 
     :ivar str service_endpoint: The service URL.
-    :ivar str prefix: A blob name prefix being used to filter the list.
+    :ivar str prefix: A path name prefix being used to filter the list.
     :ivar str marker: The continuation token of the current page of results.
     :ivar int results_per_page: The maximum number of results retrieved per API call.
+    :ivar str continuation_token: The continuation token to retrieve the next page of results.
     :ivar str location_mode: The location mode being used to list results. The available
         options include "primary" and "secondary".
     :ivar current_page: The current page of listed results.
-    :vartype current_page: list(~azure.storage.blob.models.BlobProperties)
-    :ivar str container: The container that the blobs are listed from.
+    :vartype current_page: list(~azure.storage.filedatalake.DeletedPathProperties)
+    :ivar str container: The container that the paths are listed from.
     :ivar str delimiter: A delimiting character used for hierarchy listing.
 
     :param callable command: Function to retrieve the next page of items.
-    :param str container: The container that the blobs are listed from.
-    :param str prefix: Filters the results to return only blobs whose names
-        begin with the specified prefix.
-    :param int results_per_page: The maximum number of blobs to retrieve per
-        call.
-    :param str continuation_token: An opaque continuation token.
-    :param str delimiter:
-        Used to capture blobs whose names begin with the same substring up to
-        the appearance of the delimiter character. The delimiter may be a single
-        character or a string.
-    :param location_mode: Specifies the location the request should be sent to.
-        This mode only applies for RA-GRS accounts which allow secondary read access.
-        Options include 'primary' or 'secondary'.
     """
     def __init__(
             self, command,
             container=None,
             prefix=None,
             results_per_page=None,
             continuation_token=None,
             delimiter=None,
             location_mode=None):
-        super(BlobPropertiesPaged, self).__init__(
+        super(DeletedPathPropertiesPaged, self).__init__(
             get_next=self._get_next_cb,
             extract_data=self._extract_data_cb,
             continuation_token=continuation_token or ""
         )
         self._command = command
         self.service_endpoint = None
         self.prefix = prefix
@@ -71,101 +59,119 @@
         self.location_mode = location_mode
 
     async def _get_next_cb(self, continuation_token):
         try:
             return await self._command(
                 prefix=self.prefix,
                 marker=continuation_token or None,
-                maxresults=self.results_per_page,
+                max_results=self.results_per_page,
                 cls=return_context_and_deserialized,
                 use_location=self.location_mode)
         except HttpResponseError as error:
             process_storage_error(error)
 
     async def _extract_data_cb(self, get_next_return):
         self.location_mode, self._response = get_next_return
         self.service_endpoint = self._response.service_endpoint
         self.prefix = self._response.prefix
         self.marker = self._response.marker
         self.results_per_page = self._response.max_results
         self.container = self._response.container_name
-        self.current_page = [self._build_item(item) for item in self._response.segment.blob_items]
+        self.current_page = self._response.segment.blob_prefixes  + self._response.segment.blob_items
+        self.current_page = [self._build_item(item) for item in self.current_page]
+        self.delimiter = self._response.delimiter
 
         return self._response.next_marker or None, self.current_page
 
     def _build_item(self, item):
-        if isinstance(item, BlobProperties):
-            return item
         if isinstance(item, BlobItemInternal):
-            blob = get_blob_properties_from_generated_code(item)  # pylint: disable=protected-access
-            blob.container = self.container
-            return blob
+            file_props = get_deleted_path_properties_from_generated_code(item)
+            file_props.file_system = self.container
+            return file_props
+        if isinstance(item, GenBlobPrefix):
+            return DirectoryPrefix(
+                container=self.container,
+                prefix=item.name,
+                results_per_page=self.results_per_page,
+                location_mode=self.location_mode)
         return item
 
 
-class BlobPrefix(AsyncItemPaged, DictMixin):
-    """An Iterable of Blob properties.
+class DirectoryPrefix(DictMixin):
+    """Directory prefix.
 
-    Returned from walk_blobs when a delimiter is used.
-    Can be thought of as a virtual blob directory.
-
-    :ivar str name: The prefix, or "directory name" of the blob.
-    :ivar str prefix: A blob name prefix being used to filter the list.
+    :ivar str name: Name of the deleted directory.
     :ivar int results_per_page: The maximum number of results retrieved per API call.
-    :ivar str marker: The continuation token of the current page of results.
     :ivar str location_mode: The location mode being used to list results. The available
         options include "primary" and "secondary".
-    :ivar current_page: The current page of listed results.
-    :vartype current_page: list(~azure.storage.blob.models.BlobProperties)
-    :ivar str container: The container that the blobs are listed from.
+    :ivar str file_system: The file system that the deleted paths are listed from.
     :ivar str delimiter: A delimiting character used for hierarchy listing.
-    :param callable command: Function to retrieve the next page of items.
-    :param str prefix: Filters the results to return only blobs whose names
-        begin with the specified prefix.
-    :param int results_per_page: The maximum number of blobs to retrieve per
-        call.
-    :param str marker: An opaque continuation token.
-    :param str delimiter:
-        Used to capture blobs whose names begin with the same substring up to
-        the appearance of the delimiter character. The delimiter may be a single
-        character or a string.
-    :param location_mode: Specifies the location the request should be sent to.
-        This mode only applies for RA-GRS accounts which allow secondary read access.
-        Options include 'primary' or 'secondary'.
     """
-    def __init__(self, *args, **kwargs):
-        super(BlobPrefix, self).__init__(*args, page_iterator_class=BlobPrefixPaged, **kwargs)
+    def __init__(self, **kwargs):
         self.name = kwargs.get('prefix')
-        self.prefix = kwargs.get('prefix')
         self.results_per_page = kwargs.get('results_per_page')
-        self.container = kwargs.get('container')
+        self.file_system = kwargs.get('container')
         self.delimiter = kwargs.get('delimiter')
         self.location_mode = kwargs.get('location_mode')
 
 
-class BlobPrefixPaged(BlobPropertiesPaged):
-    def __init__(self, *args, **kwargs):
-        super(BlobPrefixPaged, self).__init__(*args, **kwargs)
-        self.name = self.prefix
+class PathPropertiesPaged(AsyncPageIterator):
+    """An Iterable of Path properties.
+
+    :ivar str path: Filters the results to return only paths under the specified path.
+    :ivar int results_per_page: The maximum number of results retrieved per API call.
+    :ivar str continuation_token: The continuation token to retrieve the next page of results.
+    :ivar list(~azure.storage.filedatalake.PathProperties) current_page: The current page of listed results.
+
+    :param callable command: Function to retrieve the next page of items.
+    :param str path: Filters the results to return only paths under the specified path.
+    :param int max_results: The maximum number of psths to retrieve per
+        call.
+    :param str continuation_token: An opaque continuation token.
+    """
+
+    def __init__(
+            self, command,
+            recursive,
+            path=None,
+            max_results=None,
+            continuation_token=None,
+            upn=None):
+        super(PathPropertiesPaged, self).__init__(
+            get_next=self._get_next_cb,
+            extract_data=self._extract_data_cb,
+            continuation_token=continuation_token or ""
+        )
+        self._command = command
+        self.recursive = recursive
+        self.results_per_page = max_results
+        self.path = path
+        self.upn = upn
+        self.current_page = None
+        self.path_list = None
+
+    async def _get_next_cb(self, continuation_token):
+        try:
+            return await self._command(
+                self.recursive,
+                continuation=continuation_token or None,
+                path=self.path,
+                max_results=self.results_per_page,
+                upn=self.upn,
+                cls=return_headers_and_deserialized_path_list)
+        except HttpResponseError as error:
+            process_storage_error(error)
 
     async def _extract_data_cb(self, get_next_return):
-        continuation_token, _ = await super(BlobPrefixPaged, self)._extract_data_cb(get_next_return)
-        self.current_page = self._response.segment.blob_prefixes + self._response.segment.blob_items
-        self.current_page = [self._build_item(item) for item in self.current_page]
-        self.delimiter = self._response.delimiter
+        self.path_list, self._response = get_next_return
+        self.current_page = [self._build_item(item) for item in self.path_list]
 
-        return continuation_token, self.current_page
+        return self._response['continuation'] or None, self.current_page
 
-    def _build_item(self, item):
-        item = super(BlobPrefixPaged, self)._build_item(item)
-        if isinstance(item, GenBlobPrefix):
-            if item.name.encoded:
-                name = unquote(item.name.content)
-            else:
-                name = item.name.content
-            return BlobPrefix(
-                self._command,
-                container=self.container,
-                prefix=name,
-                results_per_page=self.results_per_page,
-                location_mode=self.location_mode)
+    @staticmethod
+    def _build_item(item):
+        if isinstance(item, PathProperties):
+            return item
+        if isinstance(item, Path):
+            path = PathProperties._from_generated(item)  # pylint: disable=protected-access
+            return path
         return item
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_upload_helpers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2021_08_06/aio/_upload_helpers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_directory_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_directory_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_file_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_file_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_lease.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_file_system_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_file_system_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_data_lake_storage_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/_data_lake_storage_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_configuration_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_configuration_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_data_lake_storage_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/_data_lake_storage_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_file_system_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_file_system_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_path_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_path_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_data_lake_storage_client_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_data_lake_storage_client_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_file_system_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_file_system_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_path_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_path_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_path_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_path_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_serialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/response_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_directory_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_directory_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_file_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_file_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_lease_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_data_lake_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_file_system_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_file_system_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_path_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2019_07_07/aio/_path_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_directory_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_directory_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_file_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_file_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_lease.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_data_lake_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_download.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_download.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_file_system_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_file_system_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_azure_data_lake_storage_restapi.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_azure_data_lake_storage_restapi.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_vendor.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_vendor.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_azure_data_lake_storage_restapi.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_azure_data_lake_storage_restapi.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_file_system_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_file_system_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_path_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_path_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_azure_data_lake_storage_restapi_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_azure_data_lake_storage_restapi_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/models/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_file_system_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_file_system_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_path_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_file_operations.py`

 * *Files 11% similar despite different names*

```diff
@@ -2,2693 +2,3244 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-import datetime
+import sys
 from typing import Any, Callable, Dict, IO, Iterator, Optional, TypeVar, Union
 
 from azure.core.exceptions import (
     ClientAuthenticationError,
     HttpResponseError,
     ResourceExistsError,
     ResourceNotFoundError,
+    ResourceNotModifiedError,
     map_error,
 )
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
 from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
+if sys.version_info >= (3, 8):
+    from typing import Literal  # pylint: disable=no-name-in-module, ungrouped-imports
+else:
+    from typing_extensions import Literal  # type: ignore  # pylint: disable=ungrouped-imports
 T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 
 
 def build_create_request(
     url: str,
     *,
-    request_id_parameter: Optional[str] = None,
+    file_content_length: int,
     timeout: Optional[int] = None,
-    resource: Optional[Union[str, "_models.PathResourceType"]] = None,
-    continuation: Optional[str] = None,
-    mode: Optional[Union[str, "_models.PathRenameMode"]] = None,
-    cache_control: Optional[str] = None,
-    content_encoding: Optional[str] = None,
-    content_language: Optional[str] = None,
-    content_disposition: Optional[str] = None,
-    content_type_parameter: Optional[str] = None,
-    rename_source: Optional[str] = None,
+    file_content_type: Optional[str] = None,
+    file_content_encoding: Optional[str] = None,
+    file_content_language: Optional[str] = None,
+    file_cache_control: Optional[str] = None,
+    file_content_md5: Optional[bytes] = None,
+    file_content_disposition: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    file_permission: str = "inherit",
+    file_permission_key: Optional[str] = None,
+    file_attributes: str = "none",
+    file_creation_time: str = "now",
+    file_last_write_time: str = "now",
+    file_change_time: Optional[str] = None,
     lease_id: Optional[str] = None,
-    source_lease_id: Optional[str] = None,
-    properties: Optional[str] = None,
-    permissions: Optional[str] = None,
-    umask: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
-    source_if_match: Optional[str] = None,
-    source_if_none_match: Optional[str] = None,
-    source_if_modified_since: Optional[datetime.datetime] = None,
-    source_if_unmodified_since: Optional[datetime.datetime] = None,
-    encryption_key: Optional[str] = None,
-    encryption_key_sha256: Optional[str] = None,
-    encryption_algorithm: str = "AES256",
-    owner: Optional[str] = None,
-    group: Optional[str] = None,
-    acl: Optional[str] = None,
-    proposed_lease_id: Optional[str] = None,
-    lease_duration: Optional[int] = None,
-    expiry_options: Optional[Union[str, "_models.PathExpiryOptions"]] = None,
-    expires_on: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    file_type_constant: Literal["file"] = kwargs.pop("file_type_constant", _headers.pop("x-ms-type", "file"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if resource is not None:
-        _params["resource"] = _SERIALIZER.query("resource", resource, "str")
-    if continuation is not None:
-        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
-    if mode is not None:
-        _params["mode"] = _SERIALIZER.query("mode", mode, "str")
 
     # Construct headers
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if cache_control is not None:
-        _headers["x-ms-cache-control"] = _SERIALIZER.header("cache_control", cache_control, "str")
-    if content_encoding is not None:
-        _headers["x-ms-content-encoding"] = _SERIALIZER.header("content_encoding", content_encoding, "str")
-    if content_language is not None:
-        _headers["x-ms-content-language"] = _SERIALIZER.header("content_language", content_language, "str")
-    if content_disposition is not None:
-        _headers["x-ms-content-disposition"] = _SERIALIZER.header("content_disposition", content_disposition, "str")
-    if content_type_parameter is not None:
-        _headers["x-ms-content-type"] = _SERIALIZER.header("content_type_parameter", content_type_parameter, "str")
-    if rename_source is not None:
-        _headers["x-ms-rename-source"] = _SERIALIZER.header("rename_source", rename_source, "str")
+    _headers["x-ms-content-length"] = _SERIALIZER.header("file_content_length", file_content_length, "int")
+    _headers["x-ms-type"] = _SERIALIZER.header("file_type_constant", file_type_constant, "str")
+    if file_content_type is not None:
+        _headers["x-ms-content-type"] = _SERIALIZER.header("file_content_type", file_content_type, "str")
+    if file_content_encoding is not None:
+        _headers["x-ms-content-encoding"] = _SERIALIZER.header("file_content_encoding", file_content_encoding, "str")
+    if file_content_language is not None:
+        _headers["x-ms-content-language"] = _SERIALIZER.header("file_content_language", file_content_language, "str")
+    if file_cache_control is not None:
+        _headers["x-ms-cache-control"] = _SERIALIZER.header("file_cache_control", file_cache_control, "str")
+    if file_content_md5 is not None:
+        _headers["x-ms-content-md5"] = _SERIALIZER.header("file_content_md5", file_content_md5, "bytearray")
+    if file_content_disposition is not None:
+        _headers["x-ms-content-disposition"] = _SERIALIZER.header(
+            "file_content_disposition", file_content_disposition, "str"
+        )
+    if metadata is not None:
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
+    if file_permission is not None:
+        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
+    if file_permission_key is not None:
+        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
+    _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
+    if file_creation_time is not None:
+        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
+    if file_last_write_time is not None:
+        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
+    if file_change_time is not None:
+        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if source_lease_id is not None:
-        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
-    if properties is not None:
-        _headers["x-ms-properties"] = _SERIALIZER.header("properties", properties, "str")
-    if permissions is not None:
-        _headers["x-ms-permissions"] = _SERIALIZER.header("permissions", permissions, "str")
-    if umask is not None:
-        _headers["x-ms-umask"] = _SERIALIZER.header("umask", umask, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    if source_if_match is not None:
-        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
-    if source_if_none_match is not None:
-        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
-    if source_if_modified_since is not None:
-        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
-            "source_if_modified_since", source_if_modified_since, "rfc-1123"
-        )
-    if source_if_unmodified_since is not None:
-        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
-            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
-        )
-    if encryption_key is not None:
-        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
-    if encryption_key_sha256 is not None:
-        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
-            "encryption_key_sha256", encryption_key_sha256, "str"
-        )
-    if encryption_algorithm is not None:
-        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
-    if owner is not None:
-        _headers["x-ms-owner"] = _SERIALIZER.header("owner", owner, "str")
-    if group is not None:
-        _headers["x-ms-group"] = _SERIALIZER.header("group", group, "str")
-    if acl is not None:
-        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
-    if proposed_lease_id is not None:
-        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
-    if lease_duration is not None:
-        _headers["x-ms-lease-duration"] = _SERIALIZER.header("lease_duration", lease_duration, "int")
-    if expiry_options is not None:
-        _headers["x-ms-expiry-option"] = _SERIALIZER.header("expiry_options", expiry_options, "str")
-    if expires_on is not None:
-        _headers["x-ms-expiry-time"] = _SERIALIZER.header("expires_on", expires_on, "str")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_update_request(
+def build_download_request(
     url: str,
     *,
-    action: Union[str, "_models.PathUpdateAction"],
-    mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
-    content: IO,
-    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
-    max_records: Optional[int] = None,
-    continuation: Optional[str] = None,
-    force_flag: Optional[bool] = None,
-    position: Optional[int] = None,
-    retain_uncommitted_data: Optional[bool] = None,
-    close: Optional[bool] = None,
-    content_length: Optional[int] = None,
-    content_md5: Optional[bytes] = None,
+    range: Optional[str] = None,
+    range_get_content_md5: Optional[bool] = None,
     lease_id: Optional[str] = None,
-    cache_control: Optional[str] = None,
-    content_type_parameter: Optional[str] = None,
-    content_disposition: Optional[str] = None,
-    content_encoding: Optional[str] = None,
-    content_language: Optional[str] = None,
-    properties: Optional[str] = None,
-    owner: Optional[str] = None,
-    group: Optional[str] = None,
-    permissions: Optional[str] = None,
-    acl: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    _params["action"] = _SERIALIZER.query("action", action, "str")
-    if max_records is not None:
-        _params["maxRecords"] = _SERIALIZER.query("max_records", max_records, "int", minimum=1)
-    if continuation is not None:
-        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
-    _params["mode"] = _SERIALIZER.query("mode", mode, "str")
-    if force_flag is not None:
-        _params["forceFlag"] = _SERIALIZER.query("force_flag", force_flag, "bool")
-    if position is not None:
-        _params["position"] = _SERIALIZER.query("position", position, "int")
-    if retain_uncommitted_data is not None:
-        _params["retainUncommittedData"] = _SERIALIZER.query("retain_uncommitted_data", retain_uncommitted_data, "bool")
-    if close is not None:
-        _params["close"] = _SERIALIZER.query("close", close, "bool")
 
     # Construct headers
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if content_length is not None:
-        _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int", minimum=0)
-    if content_md5 is not None:
-        _headers["x-ms-content-md5"] = _SERIALIZER.header("content_md5", content_md5, "bytearray")
+    if range is not None:
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if range_get_content_md5 is not None:
+        _headers["x-ms-range-get-content-md5"] = _SERIALIZER.header(
+            "range_get_content_md5", range_get_content_md5, "bool"
+        )
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if cache_control is not None:
-        _headers["x-ms-cache-control"] = _SERIALIZER.header("cache_control", cache_control, "str")
-    if content_type_parameter is not None:
-        _headers["x-ms-content-type"] = _SERIALIZER.header("content_type_parameter", content_type_parameter, "str")
-    if content_disposition is not None:
-        _headers["x-ms-content-disposition"] = _SERIALIZER.header("content_disposition", content_disposition, "str")
-    if content_encoding is not None:
-        _headers["x-ms-content-encoding"] = _SERIALIZER.header("content_encoding", content_encoding, "str")
-    if content_language is not None:
-        _headers["x-ms-content-language"] = _SERIALIZER.header("content_language", content_language, "str")
-    if properties is not None:
-        _headers["x-ms-properties"] = _SERIALIZER.header("properties", properties, "str")
-    if owner is not None:
-        _headers["x-ms-owner"] = _SERIALIZER.header("owner", owner, "str")
-    if group is not None:
-        _headers["x-ms-group"] = _SERIALIZER.header("group", group, "str")
-    if permissions is not None:
-        _headers["x-ms-permissions"] = _SERIALIZER.header("permissions", permissions, "str")
-    if acl is not None:
-        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    if content_type is not None:
-        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, content=content, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_lease_request(
+def build_get_properties_request(
     url: str,
     *,
-    x_ms_lease_action: Union[str, "_models.PathLeaseAction"],
-    request_id_parameter: Optional[str] = None,
+    sharesnapshot: Optional[str] = None,
     timeout: Optional[int] = None,
-    x_ms_lease_break_period: Optional[int] = None,
     lease_id: Optional[str] = None,
-    proposed_lease_id: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
-    x_ms_lease_duration: Optional[int] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("x_ms_lease_action", x_ms_lease_action, "str")
-    if x_ms_lease_duration is not None:
-        _headers["x-ms-lease-duration"] = _SERIALIZER.header("x_ms_lease_duration", x_ms_lease_duration, "int")
-    if x_ms_lease_break_period is not None:
-        _headers["x-ms-lease-break-period"] = _SERIALIZER.header(
-            "x_ms_lease_break_period", x_ms_lease_break_period, "int"
-        )
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if proposed_lease_id is not None:
-        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="HEAD", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_read_request(
+def build_delete_request(
     url: str,
     *,
-    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
-    range: Optional[str] = None,
     lease_id: Optional[str] = None,
-    x_ms_range_get_content_md5: Optional[bool] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
-    encryption_key: Optional[str] = None,
-    encryption_key_sha256: Optional[str] = None,
-    encryption_algorithm: str = "AES256",
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if range is not None:
-        _headers["Range"] = _SERIALIZER.header("range", range, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if x_ms_range_get_content_md5 is not None:
-        _headers["x-ms-range-get-content-md5"] = _SERIALIZER.header(
-            "x_ms_range_get_content_md5", x_ms_range_get_content_md5, "bool"
-        )
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
-    if encryption_key is not None:
-        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
-    if encryption_key_sha256 is not None:
-        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
-            "encryption_key_sha256", encryption_key_sha256, "str"
-        )
-    if encryption_algorithm is not None:
-        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_get_properties_request(
+def build_set_http_headers_request(
     url: str,
     *,
-    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
-    action: Optional[Union[str, "_models.PathGetPropertiesAction"]] = None,
-    upn: Optional[bool] = None,
+    file_content_length: Optional[int] = None,
+    file_content_type: Optional[str] = None,
+    file_content_encoding: Optional[str] = None,
+    file_content_language: Optional[str] = None,
+    file_cache_control: Optional[str] = None,
+    file_content_md5: Optional[bytes] = None,
+    file_content_disposition: Optional[str] = None,
+    file_permission: str = "inherit",
+    file_permission_key: Optional[str] = None,
+    file_attributes: str = "none",
+    file_creation_time: str = "now",
+    file_last_write_time: str = "now",
+    file_change_time: Optional[str] = None,
     lease_id: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if action is not None:
-        _params["action"] = _SERIALIZER.query("action", action, "str")
-    if upn is not None:
-        _params["upn"] = _SERIALIZER.query("upn", upn, "bool")
 
     # Construct headers
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if file_content_length is not None:
+        _headers["x-ms-content-length"] = _SERIALIZER.header("file_content_length", file_content_length, "int")
+    if file_content_type is not None:
+        _headers["x-ms-content-type"] = _SERIALIZER.header("file_content_type", file_content_type, "str")
+    if file_content_encoding is not None:
+        _headers["x-ms-content-encoding"] = _SERIALIZER.header("file_content_encoding", file_content_encoding, "str")
+    if file_content_language is not None:
+        _headers["x-ms-content-language"] = _SERIALIZER.header("file_content_language", file_content_language, "str")
+    if file_cache_control is not None:
+        _headers["x-ms-cache-control"] = _SERIALIZER.header("file_cache_control", file_cache_control, "str")
+    if file_content_md5 is not None:
+        _headers["x-ms-content-md5"] = _SERIALIZER.header("file_content_md5", file_content_md5, "bytearray")
+    if file_content_disposition is not None:
+        _headers["x-ms-content-disposition"] = _SERIALIZER.header(
+            "file_content_disposition", file_content_disposition, "str"
+        )
+    if file_permission is not None:
+        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
+    if file_permission_key is not None:
+        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
+    _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
+    if file_creation_time is not None:
+        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
+    if file_last_write_time is not None:
+        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
+    if file_change_time is not None:
+        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="HEAD", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_delete_request(
+def build_set_metadata_request(
     url: str,
     *,
-    request_id_parameter: Optional[str] = None,
     timeout: Optional[int] = None,
-    recursive: Optional[bool] = None,
-    continuation: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
     lease_id: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if recursive is not None:
-        _params["recursive"] = _SERIALIZER.query("recursive", recursive, "bool")
-    if continuation is not None:
-        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
 
     # Construct headers
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if metadata is not None:
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_access_control_request(
+def build_acquire_lease_request(
     url: str,
     *,
     timeout: Optional[int] = None,
-    lease_id: Optional[str] = None,
-    owner: Optional[str] = None,
-    group: Optional[str] = None,
-    permissions: Optional[str] = None,
-    acl: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
+    duration: Optional[int] = None,
+    proposed_lease_id: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    action = kwargs.pop("action", _params.pop("action", "setAccessControl"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+    action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
-    _params["action"] = _SERIALIZER.query("action", action, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if owner is not None:
-        _headers["x-ms-owner"] = _SERIALIZER.header("owner", owner, "str")
-    if group is not None:
-        _headers["x-ms-group"] = _SERIALIZER.header("group", group, "str")
-    if permissions is not None:
-        _headers["x-ms-permissions"] = _SERIALIZER.header("permissions", permissions, "str")
-    if acl is not None:
-        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    if duration is not None:
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
+    if proposed_lease_id is not None:
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_access_control_recursive_request(
+def build_release_lease_request(
     url: str,
     *,
-    mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
+    lease_id: str,
     timeout: Optional[int] = None,
-    continuation: Optional[str] = None,
-    force_flag: Optional[bool] = None,
-    max_records: Optional[int] = None,
-    acl: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    action = kwargs.pop("action", _params.pop("action", "setAccessControlRecursive"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+    action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
-    _params["action"] = _SERIALIZER.query("action", action, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if continuation is not None:
-        _params["continuation"] = _SERIALIZER.query("continuation", continuation, "str")
-    _params["mode"] = _SERIALIZER.query("mode", mode, "str")
-    if force_flag is not None:
-        _params["forceFlag"] = _SERIALIZER.query("force_flag", force_flag, "bool")
-    if max_records is not None:
-        _params["maxRecords"] = _SERIALIZER.query("max_records", max_records, "int", minimum=1)
 
     # Construct headers
-    if acl is not None:
-        _headers["x-ms-acl"] = _SERIALIZER.header("acl", acl, "str")
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_change_lease_request(
+    url: str,
+    *,
+    lease_id: str,
+    timeout: Optional[int] = None,
+    proposed_lease_id: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+    action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+
+    # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if proposed_lease_id is not None:
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_flush_data_request(
+def build_break_lease_request(
     url: str,
     *,
     timeout: Optional[int] = None,
-    position: Optional[int] = None,
-    retain_uncommitted_data: Optional[bool] = None,
-    close: Optional[bool] = None,
-    content_length: Optional[int] = None,
-    content_md5: Optional[bytes] = None,
     lease_id: Optional[str] = None,
-    cache_control: Optional[str] = None,
-    content_type_parameter: Optional[str] = None,
-    content_disposition: Optional[str] = None,
-    content_encoding: Optional[str] = None,
-    content_language: Optional[str] = None,
-    if_match: Optional[str] = None,
-    if_none_match: Optional[str] = None,
-    if_modified_since: Optional[datetime.datetime] = None,
-    if_unmodified_since: Optional[datetime.datetime] = None,
     request_id_parameter: Optional[str] = None,
-    encryption_key: Optional[str] = None,
-    encryption_key_sha256: Optional[str] = None,
-    encryption_algorithm: str = "AES256",
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    action = kwargs.pop("action", _params.pop("action", "flush"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+    action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
-    _params["action"] = _SERIALIZER.query("action", action, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if position is not None:
-        _params["position"] = _SERIALIZER.query("position", position, "int")
-    if retain_uncommitted_data is not None:
-        _params["retainUncommittedData"] = _SERIALIZER.query("retain_uncommitted_data", retain_uncommitted_data, "bool")
-    if close is not None:
-        _params["close"] = _SERIALIZER.query("close", close, "bool")
 
     # Construct headers
-    if content_length is not None:
-        _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int", minimum=0)
-    if content_md5 is not None:
-        _headers["x-ms-content-md5"] = _SERIALIZER.header("content_md5", content_md5, "bytearray")
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if cache_control is not None:
-        _headers["x-ms-cache-control"] = _SERIALIZER.header("cache_control", cache_control, "str")
-    if content_type_parameter is not None:
-        _headers["x-ms-content-type"] = _SERIALIZER.header("content_type_parameter", content_type_parameter, "str")
-    if content_disposition is not None:
-        _headers["x-ms-content-disposition"] = _SERIALIZER.header("content_disposition", content_disposition, "str")
-    if content_encoding is not None:
-        _headers["x-ms-content-encoding"] = _SERIALIZER.header("content_encoding", content_encoding, "str")
-    if content_language is not None:
-        _headers["x-ms-content-language"] = _SERIALIZER.header("content_language", content_language, "str")
-    if if_match is not None:
-        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
-    if if_none_match is not None:
-        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
-    if if_modified_since is not None:
-        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
-    if if_unmodified_since is not None:
-        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_upload_range_request(
+    url: str,
+    *,
+    range: str,
+    content_length: int,
+    timeout: Optional[int] = None,
+    file_range_write: Union[str, _models.FileRangeWriteType] = "update",
+    content_md5: Optional[bytes] = None,
+    lease_id: Optional[str] = None,
+    file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
+    content: Optional[IO] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
+    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+
+    # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    _headers["x-ms-write"] = _SERIALIZER.header("file_range_write", file_range_write, "str")
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if content_md5 is not None:
+        _headers["Content-MD5"] = _SERIALIZER.header("content_md5", content_md5, "bytearray")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if encryption_key is not None:
-        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
-    if encryption_key_sha256 is not None:
-        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
-            "encryption_key_sha256", encryption_key_sha256, "str"
-        )
-    if encryption_algorithm is not None:
-        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if file_last_written_mode is not None:
+        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header(
+            "file_last_written_mode", file_last_written_mode, "str"
+        )
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
-def build_append_data_request(
+def build_upload_range_from_url_request(
     url: str,
     *,
-    content: IO,
-    position: Optional[int] = None,
+    range: str,
+    copy_source: str,
+    content_length: int,
     timeout: Optional[int] = None,
-    content_length: Optional[int] = None,
-    transactional_content_hash: Optional[bytes] = None,
-    transactional_content_crc64: Optional[bytes] = None,
+    source_range: Optional[str] = None,
+    source_content_crc64: Optional[bytes] = None,
+    source_if_match_crc64: Optional[bytes] = None,
+    source_if_none_match_crc64: Optional[bytes] = None,
     lease_id: Optional[str] = None,
-    request_id_parameter: Optional[str] = None,
-    encryption_key: Optional[str] = None,
-    encryption_key_sha256: Optional[str] = None,
-    encryption_algorithm: str = "AES256",
-    flush: Optional[bool] = None,
+    copy_source_authorization: Optional[str] = None,
+    file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    allow_source_trailing_dot: Optional[bool] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    action = kwargs.pop("action", _params.pop("action", "append"))  # type: str
-    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
+    file_range_write_from_url: Literal["update"] = kwargs.pop(
+        "file_range_write_from_url", _headers.pop("x-ms-write", "update")
+    )
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
-    _params["action"] = _SERIALIZER.query("action", action, "str")
-    if position is not None:
-        _params["position"] = _SERIALIZER.query("position", position, "int")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if flush is not None:
-        _params["flush"] = _SERIALIZER.query("flush", flush, "bool")
 
     # Construct headers
-    if content_length is not None:
-        _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int", minimum=0)
-    if transactional_content_hash is not None:
-        _headers["Content-MD5"] = _SERIALIZER.header(
-            "transactional_content_hash", transactional_content_hash, "bytearray"
-        )
-    if transactional_content_crc64 is not None:
-        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
-            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+    _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
+    if source_range is not None:
+        _headers["x-ms-source-range"] = _SERIALIZER.header("source_range", source_range, "str")
+    _headers["x-ms-write"] = _SERIALIZER.header("file_range_write_from_url", file_range_write_from_url, "str")
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if source_content_crc64 is not None:
+        _headers["x-ms-source-content-crc64"] = _SERIALIZER.header(
+            "source_content_crc64", source_content_crc64, "bytearray"
+        )
+    if source_if_match_crc64 is not None:
+        _headers["x-ms-source-if-match-crc64"] = _SERIALIZER.header(
+            "source_if_match_crc64", source_if_match_crc64, "bytearray"
+        )
+    if source_if_none_match_crc64 is not None:
+        _headers["x-ms-source-if-none-match-crc64"] = _SERIALIZER.header(
+            "source_if_none_match_crc64", source_if_none_match_crc64, "bytearray"
         )
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if copy_source_authorization is not None:
+        _headers["x-ms-copy-source-authorization"] = _SERIALIZER.header(
+            "copy_source_authorization", copy_source_authorization, "str"
+        )
+    if file_last_written_mode is not None:
+        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header(
+            "file_last_written_mode", file_last_written_mode, "str"
+        )
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if allow_source_trailing_dot is not None:
+        _headers["x-ms-source-allow-trailing-dot"] = _SERIALIZER.header(
+            "allow_source_trailing_dot", allow_source_trailing_dot, "bool"
+        )
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_get_range_list_request(
+    url: str,
+    *,
+    sharesnapshot: Optional[str] = None,
+    prevsharesnapshot: Optional[str] = None,
+    timeout: Optional[int] = None,
+    range: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp: Literal["rangelist"] = kwargs.pop("comp", _params.pop("comp", "rangelist"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+
+    # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
+    if prevsharesnapshot is not None:
+        _params["prevsharesnapshot"] = _SERIALIZER.query("prevsharesnapshot", prevsharesnapshot, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if range is not None:
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_start_copy_request(
+    url: str,
+    *,
+    copy_source: str,
+    timeout: Optional[int] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    file_permission: str = "inherit",
+    file_permission_key: Optional[str] = None,
+    file_permission_copy_mode: Optional[Union[str, _models.PermissionCopyModeType]] = None,
+    ignore_read_only: Optional[bool] = None,
+    file_attributes: Optional[str] = None,
+    file_creation_time: Optional[str] = None,
+    file_last_write_time: Optional[str] = None,
+    file_change_time: Optional[str] = None,
+    set_archive_attribute: Optional[bool] = None,
+    lease_id: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    allow_source_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+
+    # Construct parameters
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if encryption_key is not None:
-        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
-    if encryption_key_sha256 is not None:
-        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
-            "encryption_key_sha256", encryption_key_sha256, "str"
+    if metadata is not None:
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
+    if file_permission is not None:
+        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
+    if file_permission_key is not None:
+        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
+    if file_permission_copy_mode is not None:
+        _headers["x-ms-file-permission-copy-mode"] = _SERIALIZER.header(
+            "file_permission_copy_mode", file_permission_copy_mode, "str"
+        )
+    if ignore_read_only is not None:
+        _headers["x-ms-file-copy-ignore-readonly"] = _SERIALIZER.header("ignore_read_only", ignore_read_only, "bool")
+    if file_attributes is not None:
+        _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
+    if file_creation_time is not None:
+        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
+    if file_last_write_time is not None:
+        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
+    if file_change_time is not None:
+        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
+    if set_archive_attribute is not None:
+        _headers["x-ms-file-copy-set-archive"] = _SERIALIZER.header(
+            "set_archive_attribute", set_archive_attribute, "bool"
         )
-    if encryption_algorithm is not None:
-        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
-    if content_type is not None:
-        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if allow_source_trailing_dot is not None:
+        _headers["x-ms-source-allow-trailing-dot"] = _SERIALIZER.header(
+            "allow_source_trailing_dot", allow_source_trailing_dot, "bool"
+        )
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PATCH", url=_url, params=_params, headers=_headers, content=content, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_expiry_request(
+def build_abort_copy_request(
     url: str,
     *,
-    expiry_options: Union[str, "_models.PathExpiryOptions"],
+    copy_id: str,
     timeout: Optional[int] = None,
-    request_id_parameter: Optional[str] = None,
-    expires_on: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["copy"] = kwargs.pop("comp", _params.pop("comp", "copy"))
+    copy_action_abort_constant: Literal["abort"] = kwargs.pop(
+        "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
+    )
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["copyid"] = _SERIALIZER.query("copy_id", copy_id, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
+    _headers["x-ms-copy-action"] = _SERIALIZER.header("copy_action_abort_constant", copy_action_abort_constant, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    _headers["x-ms-expiry-option"] = _SERIALIZER.header("expiry_options", expiry_options, "str")
-    if expires_on is not None:
-        _headers["x-ms-expiry-time"] = _SERIALIZER.header("expires_on", expires_on, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_undelete_request(
+def build_list_handles_request(
     url: str,
     *,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
     timeout: Optional[int] = None,
-    undelete_source: Optional[str] = None,
-    request_id_parameter: Optional[str] = None,
+    sharesnapshot: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
-    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-06-08"))  # type: str
-    accept = _headers.pop("Accept", "application/json")
+    comp: Literal["listhandles"] = kwargs.pop("comp", _params.pop("comp", "listhandles"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{filesystem}/{path}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url = _format_url_section(_url, **path_format_arguments)
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if marker is not None:
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
+    if maxresults is not None:
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
-    if undelete_source is not None:
-        _headers["x-ms-undelete-source"] = _SERIALIZER.header("undelete_source", undelete_source, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+def build_force_close_handles_request(
+    url: str,
+    *,
+    handle_id: str,
+    timeout: Optional[int] = None,
+    marker: Optional[str] = None,
+    sharesnapshot: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp: Literal["forceclosehandles"] = kwargs.pop("comp", _params.pop("comp", "forceclosehandles"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+
+    # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if marker is not None:
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
+
+    # Construct headers
+    _headers["x-ms-handle-id"] = _SERIALIZER.header("handle_id", handle_id, "str")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-class PathOperations:
+def build_rename_request(
+    url: str,
+    *,
+    rename_source: str,
+    timeout: Optional[int] = None,
+    replace_if_exists: Optional[bool] = None,
+    ignore_read_only: Optional[bool] = None,
+    source_lease_id: Optional[str] = None,
+    destination_lease_id: Optional[str] = None,
+    file_attributes: Optional[str] = None,
+    file_creation_time: Optional[str] = None,
+    file_last_write_time: Optional[str] = None,
+    file_change_time: Optional[str] = None,
+    file_permission: str = "inherit",
+    file_permission_key: Optional[str] = None,
+    metadata: Optional[Dict[str, str]] = None,
+    file_content_type: Optional[str] = None,
+    allow_trailing_dot: Optional[bool] = None,
+    allow_source_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    **kwargs: Any
+) -> HttpRequest:
+    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+    comp: Literal["rename"] = kwargs.pop("comp", _params.pop("comp", "rename"))
+    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    accept = _headers.pop("Accept", "application/xml")
+
+    # Construct URL
+    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    path_format_arguments = {
+        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
+    }
+
+    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+
+    # Construct parameters
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if timeout is not None:
+        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+
+    # Construct headers
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    _headers["x-ms-file-rename-source"] = _SERIALIZER.header("rename_source", rename_source, "str")
+    if replace_if_exists is not None:
+        _headers["x-ms-file-rename-replace-if-exists"] = _SERIALIZER.header(
+            "replace_if_exists", replace_if_exists, "bool"
+        )
+    if ignore_read_only is not None:
+        _headers["x-ms-file-rename-ignore-readonly"] = _SERIALIZER.header("ignore_read_only", ignore_read_only, "bool")
+    if source_lease_id is not None:
+        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
+    if destination_lease_id is not None:
+        _headers["x-ms-destination-lease-id"] = _SERIALIZER.header("destination_lease_id", destination_lease_id, "str")
+    if file_attributes is not None:
+        _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
+    if file_creation_time is not None:
+        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
+    if file_last_write_time is not None:
+        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
+    if file_change_time is not None:
+        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
+    if file_permission is not None:
+        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
+    if file_permission_key is not None:
+        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
+    if metadata is not None:
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
+    if file_content_type is not None:
+        _headers["x-ms-content-type"] = _SERIALIZER.header("file_content_type", file_content_type, "str")
+    if allow_trailing_dot is not None:
+        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if allow_source_trailing_dot is not None:
+        _headers["x-ms-source-allow-trailing-dot"] = _SERIALIZER.header(
+            "allow_source_trailing_dot", allow_source_trailing_dot, "bool"
+        )
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
+
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+
+
+class FileOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
-        :class:`~azure.storage.filedatalake.AzureDataLakeStorageRESTAPI`'s
-        :attr:`path` attribute.
+        :class:`~azure.storage.fileshare.AzureFileStorage`'s
+        :attr:`file` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
         input_args = list(args)
         self._client = input_args.pop(0) if input_args else kwargs.pop("client")
         self._config = input_args.pop(0) if input_args else kwargs.pop("config")
         self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
         self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def create(  # pylint: disable=inconsistent-return-statements
         self,
-        request_id_parameter: Optional[str] = None,
+        file_content_length: int,
         timeout: Optional[int] = None,
-        resource: Optional[Union[str, "_models.PathResourceType"]] = None,
-        continuation: Optional[str] = None,
-        mode: Optional[Union[str, "_models.PathRenameMode"]] = None,
-        rename_source: Optional[str] = None,
-        source_lease_id: Optional[str] = None,
-        properties: Optional[str] = None,
-        permissions: Optional[str] = None,
-        umask: Optional[str] = None,
-        owner: Optional[str] = None,
-        group: Optional[str] = None,
-        acl: Optional[str] = None,
-        proposed_lease_id: Optional[str] = None,
-        lease_duration: Optional[int] = None,
-        expiry_options: Optional[Union[str, "_models.PathExpiryOptions"]] = None,
-        expires_on: Optional[str] = None,
-        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        file_permission: str = "inherit",
+        file_permission_key: Optional[str] = None,
+        file_attributes: str = "none",
+        file_creation_time: str = "now",
+        file_last_write_time: str = "now",
+        file_change_time: Optional[str] = None,
+        file_http_headers: Optional[_models.FileHTTPHeaders] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
-        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
-        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
     ) -> None:
-        """Create File | Create Directory | Rename File | Rename Directory.
-
-        Create or rename a file or directory.    By default, the destination is overwritten and if the
-        destination already exists and has a lease the lease is broken.  This operation supports
-        conditional HTTP requests.  For more information, see `Specifying Conditional Headers for Blob
-        Service Operations
-        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
-        To fail if the destination already exists, use a conditional request with If-None-Match: "*".
+        """Creates a new file or replaces a file. Note it only initializes the file with no content.
 
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param file_content_length: Specifies the maximum size for the file, up to 4 TB. Required.
+        :type file_content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param resource: Required only for Create File and Create Directory. The value must be "file"
-         or "directory". Known values are: "directory" and "file". Default value is None.
-        :type resource: str or ~azure.storage.filedatalake.models.PathResourceType
-        :param continuation: Optional.  When deleting a directory, the number of paths that are deleted
-         with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a
-         continuation token is returned in this response header.  When a continuation token is returned
-         in the response, it must be specified in a subsequent invocation of the delete operation to
-         continue deleting the directory. Default value is None.
-        :type continuation: str
-        :param mode: Optional. Valid only when namespace is enabled. This parameter determines the
-         behavior of the rename operation. The value must be "legacy" or "posix", and the default value
-         will be "posix". Known values are: "legacy" and "posix". Default value is None.
-        :type mode: str or ~azure.storage.filedatalake.models.PathRenameMode
-        :param rename_source: An optional file or directory to be renamed.  The value must have the
-         following format: "/{filesystem}/{path}".  If "x-ms-properties" is specified, the properties
-         will overwrite the existing properties; otherwise, the existing properties will be preserved.
-         This value must be a URL percent-encoded string. Note that the string may only contain ASCII
-         characters in the ISO-8859-1 character set. Default value is None.
-        :type rename_source: str
-        :param source_lease_id: A lease ID for the source path. If specified, the source path must have
-         an active lease and the lease ID must match. Default value is None.
-        :type source_lease_id: str
-        :param properties: Optional. User-defined properties to be stored with the filesystem, in the
-         format of a comma-separated list of name and value pairs "n1=v1, n2=v2, ...", where each value
-         is a base64 encoded string. Note that the string may only contain ASCII characters in the
-         ISO-8859-1 character set.  If the filesystem exists, any properties not included in the list
-         will be removed.  All properties are removed if the header is omitted.  To merge new and
-         existing properties, first get all existing properties and the current E-Tag, then make a
-         conditional request with the E-Tag and include values for all properties. Default value is
+        :param metadata: A name-value pair to associate with a file storage object. Default value is
          None.
-        :type properties: str
-        :param permissions: Optional and only valid if Hierarchical Namespace is enabled for the
-         account. Sets POSIX access permissions for the file owner, the file owning group, and others.
-         Each class may be granted read, write, or execute permission.  The sticky bit is also
-         supported.  Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
-         Default value is None.
-        :type permissions: str
-        :param umask: Optional and only valid if Hierarchical Namespace is enabled for the account.
-         When creating a file or directory and the parent folder does not have a default ACL, the umask
-         restricts the permissions of the file or directory to be created.  The resulting permission is
-         given by p bitwise and not u, where p is the permission and u is the umask.  For example, if p
-         is 0777 and u is 0057, then the resulting permission is 0720.  The default permission is 0777
-         for a directory and 0666 for a file.  The default umask is 0027.  The umask must be specified
-         in 4-digit octal notation (e.g. 0766). Default value is None.
-        :type umask: str
-        :param owner: Optional. The owner of the blob or directory. Default value is None.
-        :type owner: str
-        :param group: Optional. The owning group of the blob or directory. Default value is None.
-        :type group: str
-        :param acl: Sets POSIX access control rights on files and directories. The value is a
-         comma-separated list of access control entries. Each access control entry (ACE) consists of a
-         scope, a type, a user or group identifier, and permissions in the format
-         "[scope:][type]:[id]:[permissions]". Default value is None.
-        :type acl: str
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Default value is None.
-        :type proposed_lease_id: str
-        :param lease_duration: The lease duration is required to acquire a lease, and specifies the
-         duration of the lease in seconds.  The lease duration must be between 15 and 60 seconds or -1
-         for infinite lease. Default value is None.
-        :type lease_duration: int
-        :param expiry_options: Required. Indicates mode of the expiry time. Known values are:
-         "NeverExpire", "RelativeToCreation", "RelativeToNow", and "Absolute". Default value is None.
-        :type expiry_options: str or ~azure.storage.filedatalake.models.PathExpiryOptions
-        :param expires_on: The time to set the blob to expiry. Default value is None.
-        :type expires_on: str
-        :param path_http_headers: Parameter group. Default value is None.
-        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
+        :type metadata: dict[str, str]
+        :param file_permission: If specified the permission (security descriptor) shall be set for the
+         directory/file. This header can be used if Permission size is <= 8KB, else
+         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
+         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
+         x-ms-file-permission-key should be specified. Default value is "inherit".
+        :type file_permission: str
+        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
+         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
+         is None.
+        :type file_permission_key: str
+        :param file_attributes: If specified, the provided file attributes shall be set. Default value:
+         Archive for file and Directory for directory. None can also be specified as default.
+         Default value is "none".
+        :type file_attributes: str
+        :param file_creation_time: Creation time for the file/directory. Default value: Now. Default
+         value is "now".
+        :type file_creation_time: str
+        :param file_last_write_time: Last write time for the file/directory. Default value: Now.
+         Default value is "now".
+        :type file_last_write_time: str
+        :param file_change_time: Change time for the file/directory. Default value: Now. Default value
+         is None.
+        :type file_change_time: str
+        :param file_http_headers: Parameter group. Default value is None.
+        :type file_http_headers: ~azure.storage.fileshare.models.FileHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
-        :param source_modified_access_conditions: Parameter group. Default value is None.
-        :type source_modified_access_conditions:
-         ~azure.storage.filedatalake.models.SourceModifiedAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword file_type_constant: Dummy constant parameter, file type can only be file. Default
+         value is "file". Note that overriding this default value may result in unsupported behavior.
+        :paramtype file_type_constant: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = kwargs.pop("params", {}) or {}
 
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        file_type_constant: Literal["file"] = kwargs.pop("file_type_constant", _headers.pop("x-ms-type", "file"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _cache_control = None
-        _content_encoding = None
-        _content_language = None
-        _content_disposition = None
-        _content_type_parameter = None
+        _file_content_type = None
+        _file_content_encoding = None
+        _file_content_language = None
+        _file_cache_control = None
+        _file_content_md5 = None
+        _file_content_disposition = None
         _lease_id = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        _source_if_match = None
-        _source_if_none_match = None
-        _source_if_modified_since = None
-        _source_if_unmodified_since = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        if path_http_headers is not None:
-            _cache_control = path_http_headers.cache_control
-            _content_disposition = path_http_headers.content_disposition
-            _content_encoding = path_http_headers.content_encoding
-            _content_language = path_http_headers.content_language
-            _content_type_parameter = path_http_headers.content_type
+        if file_http_headers is not None:
+            _file_cache_control = file_http_headers.file_cache_control
+            _file_content_disposition = file_http_headers.file_content_disposition
+            _file_content_encoding = file_http_headers.file_content_encoding
+            _file_content_language = file_http_headers.file_content_language
+            _file_content_md5 = file_http_headers.file_content_md5
+            _file_content_type = file_http_headers.file_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        if source_modified_access_conditions is not None:
-            _source_if_match = source_modified_access_conditions.source_if_match
-            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
-            _source_if_none_match = source_modified_access_conditions.source_if_none_match
-            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
-        if cpk_info is not None:
-            _encryption_algorithm = cpk_info.encryption_algorithm
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
 
         request = build_create_request(
             url=self._config.url,
-            request_id_parameter=request_id_parameter,
+            file_content_length=file_content_length,
             timeout=timeout,
-            resource=resource,
-            continuation=continuation,
-            mode=mode,
-            cache_control=_cache_control,
-            content_encoding=_content_encoding,
-            content_language=_content_language,
-            content_disposition=_content_disposition,
-            content_type_parameter=_content_type_parameter,
-            rename_source=rename_source,
+            file_content_type=_file_content_type,
+            file_content_encoding=_file_content_encoding,
+            file_content_language=_file_content_language,
+            file_cache_control=_file_cache_control,
+            file_content_md5=_file_content_md5,
+            file_content_disposition=_file_content_disposition,
+            metadata=metadata,
+            file_permission=file_permission,
+            file_permission_key=file_permission_key,
+            file_attributes=file_attributes,
+            file_creation_time=file_creation_time,
+            file_last_write_time=file_last_write_time,
+            file_change_time=file_change_time,
             lease_id=_lease_id,
-            source_lease_id=source_lease_id,
-            properties=properties,
-            permissions=permissions,
-            umask=umask,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            source_if_match=_source_if_match,
-            source_if_none_match=_source_if_none_match,
-            source_if_modified_since=_source_if_modified_since,
-            source_if_unmodified_since=_source_if_unmodified_since,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            owner=owner,
-            group=group,
-            acl=acl,
-            proposed_lease_id=proposed_lease_id,
-            lease_duration=lease_duration,
-            expiry_options=expiry_options,
-            expires_on=expires_on,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            file_type_constant=file_type_constant,
             version=self._config.version,
             template_url=self.create.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
-        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["x-ms-request-server-encrypted"] = self._deserialize(
             "bool", response.headers.get("x-ms-request-server-encrypted")
         )
-        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
-            "str", response.headers.get("x-ms-encryption-key-sha256")
+        response_headers["x-ms-file-permission-key"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-permission-key")
+        )
+        response_headers["x-ms-file-attributes"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-attributes")
+        )
+        response_headers["x-ms-file-creation-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-creation-time")
         )
+        response_headers["x-ms-file-last-write-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-last-write-time")
+        )
+        response_headers["x-ms-file-change-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-change-time")
+        )
+        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
+        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    create.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def update(
+    def download(
         self,
-        action: Union[str, "_models.PathUpdateAction"],
-        mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
-        body: IO,
-        request_id_parameter: Optional[str] = None,
         timeout: Optional[int] = None,
-        max_records: Optional[int] = None,
-        continuation: Optional[str] = None,
-        force_flag: Optional[bool] = None,
-        position: Optional[int] = None,
-        retain_uncommitted_data: Optional[bool] = None,
-        close: Optional[bool] = None,
-        content_length: Optional[int] = None,
-        properties: Optional[str] = None,
-        owner: Optional[str] = None,
-        group: Optional[str] = None,
-        permissions: Optional[str] = None,
-        acl: Optional[str] = None,
-        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
+        range: Optional[str] = None,
+        range_get_content_md5: Optional[bool] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> Optional[_models.SetAccessControlRecursiveResponse]:
-        """Append Data | Flush Data | Set Properties | Set Access Control.
+    ) -> Iterator[bytes]:
+        """Reads or downloads a file from the system, including its metadata and properties.
 
-        Uploads data to be appended to a file, flushes (writes) previously uploaded data to a file,
-        sets properties for a file or directory, or sets access control for a file or directory. Data
-        can only be appended to a file. Concurrent writes to the same file using multiple clients are
-        not supported. This operation supports conditional HTTP requests. For more information, see
-        `Specifying Conditional Headers for Blob Service Operations
-        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
-
-        :param action: The action must be "append" to upload data to be appended to a file, "flush" to
-         flush previously uploaded data to a file, "setProperties" to set the properties of a file or
-         directory, "setAccessControl" to set the owner, group, permissions, or access control list for
-         a file or directory, or  "setAccessControlRecursive" to set the access control list for a
-         directory recursively. Note that Hierarchical Namespace must be enabled for the account in
-         order to use access control.  Also note that the Access Control List (ACL) includes permissions
-         for the owner, owning group, and others, so the x-ms-permissions and x-ms-acl request headers
-         are mutually exclusive. Known values are: "append", "flush", "setProperties",
-         "setAccessControl", and "setAccessControlRecursive". Required.
-        :type action: str or ~azure.storage.filedatalake.models.PathUpdateAction
-        :param mode: Mode "set" sets POSIX access control rights on files and directories, "modify"
-         modifies one or more POSIX access control rights  that pre-exist on files and directories,
-         "remove" removes one or more POSIX access control rights  that were present earlier on files
-         and directories. Known values are: "set", "modify", and "remove". Required.
-        :type mode: str or ~azure.storage.filedatalake.models.PathSetAccessControlRecursiveMode
-        :param body: Initial data. Required.
-        :type body: IO
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param max_records: Optional. Valid for "SetAccessControlRecursive" operation. It specifies the
-         maximum number of files or directories on which the acl change will be applied. If omitted or
-         greater than 2,000, the request will process up to 2,000 items. Default value is None.
-        :type max_records: int
-        :param continuation: Optional. The number of paths processed with each invocation is limited.
-         If the number of paths to be processed exceeds this limit, a continuation token is returned in
-         the response header x-ms-continuation. When a continuation token is  returned in the response,
-         it must be percent-encoded and specified in a subsequent invocation of
-         setAccessControlRecursive operation. Default value is None.
-        :type continuation: str
-        :param force_flag: Optional. Valid for "SetAccessControlRecursive" operation. If set to false,
-         the operation will terminate quickly on encountering user errors (4XX). If true, the operation
-         will ignore user errors and proceed with the operation on other sub-entities of the directory.
-         Continuation token will only be returned when forceFlag is true in case of user errors. If not
-         set the default value is false for this. Default value is None.
-        :type force_flag: bool
-        :param position: This parameter allows the caller to upload data in parallel and control the
-         order in which it is appended to the file.  It is required when uploading data to be appended
-         to the file and when flushing previously uploaded data to the file.  The value must be the
-         position where the data is to be appended.  Uploaded data is not immediately flushed, or
-         written, to the file.  To flush, the previously uploaded data must be contiguous, the position
-         parameter must be specified and equal to the length of the file after all data has been
-         written, and there must not be a request entity body included with the request. Default value
-         is None.
-        :type position: int
-        :param retain_uncommitted_data: Valid only for flush operations.  If "true", uncommitted data
-         is retained after the flush operation completes; otherwise, the uncommitted data is deleted
-         after the flush operation.  The default is false.  Data at offsets less than the specified
-         position are written to the file when flush succeeds, but this optional parameter allows data
-         after the flush position to be retained for a future flush operation. Default value is None.
-        :type retain_uncommitted_data: bool
-        :param close: Azure Storage Events allow applications to receive notifications when files
-         change. When Azure Storage Events are enabled, a file changed event is raised. This event has a
-         property indicating whether this is the final change to distinguish the difference between an
-         intermediate flush to a file stream and the final close of a file stream. The close query
-         parameter is valid only when the action is "flush" and change notifications are enabled. If the
-         value of close is "true" and the flush operation completes successfully, the service raises a
-         file change notification with a property indicating that this is the final update (the file
-         stream has been closed). If "false" a change notification is raised indicating the file has
-         changed. The default is false. This query parameter is set to true by the Hadoop ABFS driver to
-         indicate that the file stream has been closed.". Default value is None.
-        :type close: bool
-        :param content_length: Required for "Append Data" and "Flush Data".  Must be 0 for "Flush
-         Data".  Must be the length of the request content in bytes for "Append Data". Default value is
-         None.
-        :type content_length: int
-        :param properties: Optional. User-defined properties to be stored with the filesystem, in the
-         format of a comma-separated list of name and value pairs "n1=v1, n2=v2, ...", where each value
-         is a base64 encoded string. Note that the string may only contain ASCII characters in the
-         ISO-8859-1 character set.  If the filesystem exists, any properties not included in the list
-         will be removed.  All properties are removed if the header is omitted.  To merge new and
-         existing properties, first get all existing properties and the current E-Tag, then make a
-         conditional request with the E-Tag and include values for all properties. Default value is
-         None.
-        :type properties: str
-        :param owner: Optional. The owner of the blob or directory. Default value is None.
-        :type owner: str
-        :param group: Optional. The owning group of the blob or directory. Default value is None.
-        :type group: str
-        :param permissions: Optional and only valid if Hierarchical Namespace is enabled for the
-         account. Sets POSIX access permissions for the file owner, the file owning group, and others.
-         Each class may be granted read, write, or execute permission.  The sticky bit is also
-         supported.  Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
-         Default value is None.
-        :type permissions: str
-        :param acl: Sets POSIX access control rights on files and directories. The value is a
-         comma-separated list of access control entries. Each access control entry (ACE) consists of a
-         scope, a type, a user or group identifier, and permissions in the format
-         "[scope:][type]:[id]:[permissions]". Default value is None.
-        :type acl: str
-        :param path_http_headers: Parameter group. Default value is None.
-        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
+        :param range: Return file data only from the specified byte range. Default value is None.
+        :type range: str
+        :param range_get_content_md5: When this header is set to true and specified together with the
+         Range header, the service returns the MD5 hash for the range, as long as the range is less than
+         or equal to 4 MB in size. Default value is None.
+        :type range_get_content_md5: bool
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: SetAccessControlRecursiveResponse or None or the result of cls(response)
-        :rtype: ~azure.storage.filedatalake.models.SetAccessControlRecursiveResponse or None
+        :return: Iterator of the response bytes or the result of cls(response)
+        :rtype: Iterator[bytes]
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = kwargs.pop("params", {}) or {}
 
-        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[Optional[_models.SetAccessControlRecursiveResponse]]
+        cls: ClsType[Iterator[bytes]] = kwargs.pop("cls", None)
 
-        _content_md5 = None
         _lease_id = None
-        _cache_control = None
-        _content_type_parameter = None
-        _content_disposition = None
-        _content_encoding = None
-        _content_language = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        if path_http_headers is not None:
-            _cache_control = path_http_headers.cache_control
-            _content_disposition = path_http_headers.content_disposition
-            _content_encoding = path_http_headers.content_encoding
-            _content_language = path_http_headers.content_language
-            _content_md5 = path_http_headers.content_md5
-            _content_type_parameter = path_http_headers.content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        _content = body
 
-        request = build_update_request(
+        request = build_download_request(
             url=self._config.url,
-            action=action,
-            mode=mode,
-            request_id_parameter=request_id_parameter,
             timeout=timeout,
-            max_records=max_records,
-            continuation=continuation,
-            force_flag=force_flag,
-            position=position,
-            retain_uncommitted_data=retain_uncommitted_data,
-            close=close,
-            content_length=content_length,
-            content_md5=_content_md5,
+            range=range,
+            range_get_content_md5=range_get_content_md5,
             lease_id=_lease_id,
-            cache_control=_cache_control,
-            content_type_parameter=_content_type_parameter,
-            content_disposition=_content_disposition,
-            content_encoding=_content_encoding,
-            content_language=_content_language,
-            properties=properties,
-            owner=owner,
-            group=group,
-            permissions=permissions,
-            acl=acl,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            content_type=content_type,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
             version=self._config.version,
-            content=_content,
-            template_url=self.update.metadata["url"],
+            template_url=self.download.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=True, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 202]:
+        if response.status_code not in [200, 206]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
-        deserialized = None
         response_headers = {}
         if response.status_code == 200:
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
             response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
             response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
             response_headers["Content-Disposition"] = self._deserialize(
                 "str", response.headers.get("Content-Disposition")
             )
-            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
             response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
-            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
-            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
-            response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
-            response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
             response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
             response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-content-md5")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-file-attributes"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-attributes")
+            )
+            response_headers["x-ms-file-creation-time"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-creation-time")
+            )
+            response_headers["x-ms-file-last-write-time"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-last-write-time")
+            )
+            response_headers["x-ms-file-change-time"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-change-time")
+            )
+            response_headers["x-ms-file-permission-key"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-permission-key")
+            )
+            response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
+            response_headers["x-ms-file-parent-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-parent-id")
+            )
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
 
-            deserialized = self._deserialize("SetAccessControlRecursiveResponse", pipeline_response)
+            deserialized = response.stream_download(self._client._pipeline)
 
-        if response.status_code == 202:
-            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        if response.status_code == 206:
+            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
+            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+            response_headers["Content-Disposition"] = self._deserialize(
+                "str", response.headers.get("Content-Disposition")
+            )
+            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
             response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
             response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
+            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+            response_headers["x-ms-copy-completion-time"] = self._deserialize(
+                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+            )
+            response_headers["x-ms-copy-status-description"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-status-description")
+            )
+            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+            response_headers["x-ms-copy-progress"] = self._deserialize(
+                "str", response.headers.get("x-ms-copy-progress")
+            )
+            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+            response_headers["x-ms-content-md5"] = self._deserialize(
+                "bytearray", response.headers.get("x-ms-content-md5")
+            )
+            response_headers["x-ms-server-encrypted"] = self._deserialize(
+                "bool", response.headers.get("x-ms-server-encrypted")
+            )
+            response_headers["x-ms-file-attributes"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-attributes")
+            )
+            response_headers["x-ms-file-creation-time"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-creation-time")
+            )
+            response_headers["x-ms-file-last-write-time"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-last-write-time")
+            )
+            response_headers["x-ms-file-change-time"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-change-time")
+            )
+            response_headers["x-ms-file-permission-key"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-permission-key")
+            )
+            response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
+            response_headers["x-ms-file-parent-id"] = self._deserialize(
+                "str", response.headers.get("x-ms-file-parent-id")
+            )
+            response_headers["x-ms-lease-duration"] = self._deserialize(
+                "str", response.headers.get("x-ms-lease-duration")
+            )
+            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+
+            deserialized = response.stream_download(self._client._pipeline)
 
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)  # type: ignore
 
-        return deserialized
+        return deserialized  # type: ignore
 
-    update.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    download.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def lease(  # pylint: disable=inconsistent-return-statements
+    def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        x_ms_lease_action: Union[str, "_models.PathLeaseAction"],
-        request_id_parameter: Optional[str] = None,
+        sharesnapshot: Optional[str] = None,
         timeout: Optional[int] = None,
-        x_ms_lease_break_period: Optional[int] = None,
-        proposed_lease_id: Optional[str] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Lease Path.
+        """Returns all user-defined metadata, standard HTTP properties, and system properties for the
+        file. It does not return the content of the file.
 
-        Create and manage a lease to restrict write and delete access to the path. This operation
-        supports conditional HTTP requests.  For more information, see `Specifying Conditional Headers
-        for Blob Service Operations
-        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
-
-        :param x_ms_lease_action: There are five lease actions: "acquire", "break", "change", "renew",
-         and "release". Use "acquire" and specify the "x-ms-proposed-lease-id" and "x-ms-lease-duration"
-         to acquire a new lease. Use "break" to break an existing lease. When a lease is broken, the
-         lease break period is allowed to elapse, during which time no lease operation except break and
-         release can be performed on the file. When a lease is successfully broken, the response
-         indicates the interval in seconds until a new lease can be acquired. Use "change" and specify
-         the current lease ID in "x-ms-lease-id" and the new lease ID in "x-ms-proposed-lease-id" to
-         change the lease ID of an active lease. Use "renew" and specify the "x-ms-lease-id" to renew an
-         existing lease. Use "release" and specify the "x-ms-lease-id" to release a lease. Known values
-         are: "acquire", "break", "change", "renew", and "release". Required.
-        :type x_ms_lease_action: str or ~azure.storage.filedatalake.models.PathLeaseAction
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param x_ms_lease_break_period: The lease break period duration is optional to break a lease,
-         and  specifies the break period of the lease in seconds.  The lease break  duration must be
-         between 0 and 60 seconds. Default value is None.
-        :type x_ms_lease_break_period: int
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The Blob service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Default value is None.
-        :type proposed_lease_id: str
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = kwargs.pop("params", {}) or {}
 
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
         _lease_id = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_lease_request(
+        request = build_get_properties_request(
             url=self._config.url,
-            x_ms_lease_action=x_ms_lease_action,
-            request_id_parameter=request_id_parameter,
+            sharesnapshot=sharesnapshot,
             timeout=timeout,
-            x_ms_lease_break_period=x_ms_lease_break_period,
             lease_id=_lease_id,
-            proposed_lease_id=proposed_lease_id,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            x_ms_lease_duration=self._config.x_ms_lease_duration,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
             version=self._config.version,
-            template_url=self.lease.metadata["url"],
+            template_url=self.get_properties.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 201, 202]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        if response.status_code == 200:
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-
-        if response.status_code == 201:
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-
-        if response.status_code == 202:
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["x-ms-lease-time"] = self._deserialize("str", response.headers.get("x-ms-lease-time"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
+        response_headers["x-ms-type"] = self._deserialize("str", response.headers.get("x-ms-type"))
+        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
+        response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
+        response_headers["Content-Disposition"] = self._deserialize("str", response.headers.get("Content-Disposition"))
+        response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-completion-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+        )
+        response_headers["x-ms-copy-status-description"] = self._deserialize(
+            "str", response.headers.get("x-ms-copy-status-description")
+        )
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-progress"] = self._deserialize("str", response.headers.get("x-ms-copy-progress"))
+        response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
+        response_headers["x-ms-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-server-encrypted")
+        )
+        response_headers["x-ms-file-attributes"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-attributes")
+        )
+        response_headers["x-ms-file-creation-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-creation-time")
+        )
+        response_headers["x-ms-file-last-write-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-last-write-time")
+        )
+        response_headers["x-ms-file-change-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-change-time")
+        )
+        response_headers["x-ms-file-permission-key"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-permission-key")
+        )
+        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
+        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
+        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
+        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
+        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    lease.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    get_properties.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def read(
+    def delete(  # pylint: disable=inconsistent-return-statements
         self,
-        request_id_parameter: Optional[str] = None,
         timeout: Optional[int] = None,
-        range: Optional[str] = None,
-        x_ms_range_get_content_md5: Optional[bool] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
-        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
-    ) -> Iterator[bytes]:
-        """Read File.
-
-        Read the contents of a file.  For read operations, range requests are supported. This operation
-        supports conditional HTTP requests.  For more information, see `Specifying Conditional Headers
-        for Blob Service Operations
-        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+    ) -> None:
+        """removes the file from the storage account.
 
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param range: The HTTP Range request header specifies one or more byte ranges of the resource
-         to be retrieved. Default value is None.
-        :type range: str
-        :param x_ms_range_get_content_md5: Optional. When this header is set to "true" and specified
-         together with the Range header, the service returns the MD5 hash for the range, as long as the
-         range is less than or equal to 4MB in size. If this header is specified without the Range
-         header, the service returns status code 400 (Bad Request). If this header is set to true when
-         the range exceeds 4 MB in size, the service returns status code 400 (Bad Request). Default
-         value is None.
-        :type x_ms_range_get_content_md5: bool
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: Iterator of the response bytes or the result of cls(response)
-        :rtype: Iterator[bytes]
+        :return: None or the result of cls(response)
+        :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = kwargs.pop("params", {}) or {}
 
-        cls = kwargs.pop("cls", None)  # type: ClsType[Iterator[bytes]]
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
         _lease_id = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        if cpk_info is not None:
-            _encryption_algorithm = cpk_info.encryption_algorithm
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
 
-        request = build_read_request(
+        request = build_delete_request(
             url=self._config.url,
-            request_id_parameter=request_id_parameter,
             timeout=timeout,
-            range=range,
             lease_id=_lease_id,
-            x_ms_range_get_content_md5=x_ms_range_get_content_md5,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
             version=self._config.version,
-            template_url=self.read.metadata["url"],
+            template_url=self.delete.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
-            request, stream=True, **kwargs
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200, 206]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        if response.status_code == 200:
-            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
-            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
-            response_headers["Content-Disposition"] = self._deserialize(
-                "str", response.headers.get("Content-Disposition")
-            )
-            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
-            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
-            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
-            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["x-ms-resource-type"] = self._deserialize(
-                "str", response.headers.get("x-ms-resource-type")
-            )
-            response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
-            response_headers["x-ms-lease-duration"] = self._deserialize(
-                "str", response.headers.get("x-ms-lease-duration")
-            )
-            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
-            response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-                "bool", response.headers.get("x-ms-request-server-encrypted")
-            )
-            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
-                "str", response.headers.get("x-ms-encryption-key-sha256")
-            )
-
-            deserialized = response.stream_download(self._client._pipeline)
-
-        if response.status_code == 206:
-            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
-            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
-            response_headers["Content-Disposition"] = self._deserialize(
-                "str", response.headers.get("Content-Disposition")
-            )
-            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
-            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
-            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
-            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-            response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
-            response_headers["x-ms-content-md5"] = self._deserialize("str", response.headers.get("x-ms-content-md5"))
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["x-ms-resource-type"] = self._deserialize(
-                "str", response.headers.get("x-ms-resource-type")
-            )
-            response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
-            response_headers["x-ms-lease-duration"] = self._deserialize(
-                "str", response.headers.get("x-ms-lease-duration")
-            )
-            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
-            response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-                "bool", response.headers.get("x-ms-request-server-encrypted")
-            )
-            response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
-                "str", response.headers.get("x-ms-encryption-key-sha256")
-            )
-
-            deserialized = response.stream_download(self._client._pipeline)
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    read.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    delete.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def get_properties(  # pylint: disable=inconsistent-return-statements
+    def set_http_headers(  # pylint: disable=inconsistent-return-statements
         self,
-        request_id_parameter: Optional[str] = None,
         timeout: Optional[int] = None,
-        action: Optional[Union[str, "_models.PathGetPropertiesAction"]] = None,
-        upn: Optional[bool] = None,
+        file_content_length: Optional[int] = None,
+        file_permission: str = "inherit",
+        file_permission_key: Optional[str] = None,
+        file_attributes: str = "none",
+        file_creation_time: str = "now",
+        file_last_write_time: str = "now",
+        file_change_time: Optional[str] = None,
+        file_http_headers: Optional[_models.FileHTTPHeaders] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Get Properties | Get Status | Get Access Control List.
+        """Sets HTTP headers on the file.
 
-        Get Properties returns all system and user defined properties for a path. Get Status returns
-        all system defined properties for a path. Get Access Control List returns the access control
-        list for a path. This operation supports conditional HTTP requests.  For more information, see
-        `Specifying Conditional Headers for Blob Service Operations
-        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
-
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param action: Optional. If the value is "getStatus" only the system defined properties for the
-         path are returned. If the value is "getAccessControl" the access control list is returned in
-         the response headers (Hierarchical Namespace must be enabled for the account), otherwise the
-         properties are returned. Known values are: "getAccessControl" and "getStatus". Default value is
-         None.
-        :type action: str or ~azure.storage.filedatalake.models.PathGetPropertiesAction
-        :param upn: Optional. Valid only when Hierarchical Namespace is enabled for the account. If
-         "true", the user identity values returned in the x-ms-owner, x-ms-group, and x-ms-acl response
-         headers will be transformed from Azure Active Directory Object IDs to User Principal Names.  If
-         "false", the values will be returned as Azure Active Directory Object IDs. The default value is
-         false. Note that group and application Object IDs are not translated because they do not have
-         unique friendly names. Default value is None.
-        :type upn: bool
+        :param file_content_length: Resizes a file to the specified size. If the specified byte value
+         is less than the current size of the file, then all ranges above the specified byte value are
+         cleared. Default value is None.
+        :type file_content_length: int
+        :param file_permission: If specified the permission (security descriptor) shall be set for the
+         directory/file. This header can be used if Permission size is <= 8KB, else
+         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
+         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
+         x-ms-file-permission-key should be specified. Default value is "inherit".
+        :type file_permission: str
+        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
+         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
+         is None.
+        :type file_permission_key: str
+        :param file_attributes: If specified, the provided file attributes shall be set. Default value:
+         Archive for file and Directory for directory. None can also be specified as default.
+         Default value is "none".
+        :type file_attributes: str
+        :param file_creation_time: Creation time for the file/directory. Default value: Now. Default
+         value is "now".
+        :type file_creation_time: str
+        :param file_last_write_time: Last write time for the file/directory. Default value: Now.
+         Default value is "now".
+        :type file_last_write_time: str
+        :param file_change_time: Change time for the file/directory. Default value: Now. Default value
+         is None.
+        :type file_change_time: str
+        :param file_http_headers: Parameter group. Default value is None.
+        :type file_http_headers: ~azure.storage.fileshare.models.FileHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = kwargs.pop("params", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
+        _file_content_type = None
+        _file_content_encoding = None
+        _file_content_language = None
+        _file_cache_control = None
+        _file_content_md5 = None
+        _file_content_disposition = None
         _lease_id = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
+        if file_http_headers is not None:
+            _file_cache_control = file_http_headers.file_cache_control
+            _file_content_disposition = file_http_headers.file_content_disposition
+            _file_content_encoding = file_http_headers.file_content_encoding
+            _file_content_language = file_http_headers.file_content_language
+            _file_content_md5 = file_http_headers.file_content_md5
+            _file_content_type = file_http_headers.file_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_get_properties_request(
+        request = build_set_http_headers_request(
             url=self._config.url,
-            request_id_parameter=request_id_parameter,
             timeout=timeout,
-            action=action,
-            upn=upn,
+            file_content_length=file_content_length,
+            file_content_type=_file_content_type,
+            file_content_encoding=_file_content_encoding,
+            file_content_language=_file_content_language,
+            file_cache_control=_file_cache_control,
+            file_content_md5=_file_content_md5,
+            file_content_disposition=_file_content_disposition,
+            file_permission=file_permission,
+            file_permission_key=file_permission_key,
+            file_attributes=file_attributes,
+            file_creation_time=file_creation_time,
+            file_last_write_time=file_last_write_time,
+            file_change_time=file_change_time,
             lease_id=_lease_id,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
             version=self._config.version,
-            template_url=self.get_properties.metadata["url"],
+            template_url=self.set_http_headers.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
-        response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
-        response_headers["Content-Disposition"] = self._deserialize("str", response.headers.get("Content-Disposition"))
-        response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
-        response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
-        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-        response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
-        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-        response_headers["Content-MD5"] = self._deserialize("str", response.headers.get("Content-MD5"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["x-ms-resource-type"] = self._deserialize("str", response.headers.get("x-ms-resource-type"))
-        response_headers["x-ms-properties"] = self._deserialize("str", response.headers.get("x-ms-properties"))
-        response_headers["x-ms-owner"] = self._deserialize("str", response.headers.get("x-ms-owner"))
-        response_headers["x-ms-group"] = self._deserialize("str", response.headers.get("x-ms-group"))
-        response_headers["x-ms-permissions"] = self._deserialize("str", response.headers.get("x-ms-permissions"))
-        response_headers["x-ms-acl"] = self._deserialize("str", response.headers.get("x-ms-acl"))
-        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
-        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-file-permission-key"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-permission-key")
+        )
+        response_headers["x-ms-file-attributes"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-attributes")
+        )
+        response_headers["x-ms-file-creation-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-creation-time")
+        )
+        response_headers["x-ms-file-last-write-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-last-write-time")
+        )
+        response_headers["x-ms-file-change-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-change-time")
+        )
+        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
+        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    set_http_headers.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
+    def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
-        request_id_parameter: Optional[str] = None,
         timeout: Optional[int] = None,
-        recursive: Optional[bool] = None,
-        continuation: Optional[str] = None,
+        metadata: Optional[Dict[str, str]] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Delete File | Delete Directory.
-
-        Delete the file or directory. This operation supports conditional HTTP requests.  For more
-        information, see `Specifying Conditional Headers for Blob Service Operations
-        <https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations>`_.
+        """Updates user-defined metadata for the specified file.
 
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param recursive: Required. Default value is None.
-        :type recursive: bool
-        :param continuation: Optional.  When deleting a directory, the number of paths that are deleted
-         with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a
-         continuation token is returned in this response header.  When a continuation token is returned
-         in the response, it must be specified in a subsequent invocation of the delete operation to
-         continue deleting the directory. Default value is None.
-        :type continuation: str
+        :param metadata: A name-value pair to associate with a file storage object. Default value is
+         None.
+        :type metadata: dict[str, str]
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = kwargs.pop("params", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
         _lease_id = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_delete_request(
+        request = build_set_metadata_request(
             url=self._config.url,
-            request_id_parameter=request_id_parameter,
             timeout=timeout,
-            recursive=recursive,
-            continuation=continuation,
+            metadata=metadata,
             lease_id=_lease_id,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
             version=self._config.version,
-            template_url=self.delete.metadata["url"],
+            template_url=self.set_metadata.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
-        response_headers["x-ms-deletion-id"] = self._deserialize("str", response.headers.get("x-ms-deletion-id"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    set_metadata.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def set_access_control(  # pylint: disable=inconsistent-return-statements
+    def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
-        owner: Optional[str] = None,
-        group: Optional[str] = None,
-        permissions: Optional[str] = None,
-        acl: Optional[str] = None,
+        duration: Optional[int] = None,
+        proposed_lease_id: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Set the owner, group, permissions, or access control list for a path.
+        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
+        operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param owner: Optional. The owner of the blob or directory. Default value is None.
-        :type owner: str
-        :param group: Optional. The owning group of the blob or directory. Default value is None.
-        :type group: str
-        :param permissions: Optional and only valid if Hierarchical Namespace is enabled for the
-         account. Sets POSIX access permissions for the file owner, the file owning group, and others.
-         Each class may be granted read, write, or execute permission.  The sticky bit is also
-         supported.  Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
-         Default value is None.
-        :type permissions: str
-        :param acl: Sets POSIX access control rights on files and directories. The value is a
-         comma-separated list of access control entries. Each access control entry (ACE) consists of a
-         scope, a type, a user or group identifier, and permissions in the format
-         "[scope:][type]:[id]:[permissions]". Default value is None.
-        :type acl: str
+        :param duration: Specifies the duration of the lease, in seconds, or negative one (-1) for a
+         lease that never expires. A non-infinite lease can be between 15 and 60 seconds. A lease
+         duration cannot be changed using renew or change. Default value is None.
+        :type duration: int
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Default value is None.
+        :type proposed_lease_id: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
-        :keyword action: action. Default value is "setAccessControl". Note that overriding this default
-         value may result in unsupported behavior.
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword action: Describes what lease action to take. Default value is "acquire". Note that
+         overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        action = kwargs.pop("action", _params.pop("action", "setAccessControl"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+        action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _lease_id = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        request = build_acquire_lease_request(
+            url=self._config.url,
+            timeout=timeout,
+            duration=duration,
+            proposed_lease_id=proposed_lease_id,
+            request_id_parameter=request_id_parameter,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
+            action=action,
+            version=self._config.version,
+            template_url=self.acquire_lease.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [201]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
 
-        request = build_set_access_control_request(
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    acquire_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+
+    @distributed_trace
+    def release_lease(  # pylint: disable=inconsistent-return-statements
+        self, lease_id: str, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    ) -> None:
+        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
+        operations.
+
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword action: Describes what lease action to take. Default value is "release". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+        action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
+
+        request = build_release_lease_request(
             url=self._config.url,
+            lease_id=lease_id,
             timeout=timeout,
-            lease_id=_lease_id,
-            owner=owner,
-            group=group,
-            permissions=permissions,
-            acl=acl,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
             action=action,
             version=self._config.version,
-            template_url=self.set_access_control.metadata["url"],
+            template_url=self.release_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_access_control.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    release_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def set_access_control_recursive(
+    def change_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        mode: Union[str, "_models.PathSetAccessControlRecursiveMode"],
+        lease_id: str,
         timeout: Optional[int] = None,
-        continuation: Optional[str] = None,
-        force_flag: Optional[bool] = None,
-        max_records: Optional[int] = None,
-        acl: Optional[str] = None,
+        proposed_lease_id: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
-    ) -> _models.SetAccessControlRecursiveResponse:
-        """Set the access control list for a path and sub-paths.
+    ) -> None:
+        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
+        operations.
 
-        :param mode: Mode "set" sets POSIX access control rights on files and directories, "modify"
-         modifies one or more POSIX access control rights  that pre-exist on files and directories,
-         "remove" removes one or more POSIX access control rights  that were present earlier on files
-         and directories. Known values are: "set", "modify", and "remove". Required.
-        :type mode: str or ~azure.storage.filedatalake.models.PathSetAccessControlRecursiveMode
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param continuation: Optional.  When deleting a directory, the number of paths that are deleted
-         with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a
-         continuation token is returned in this response header.  When a continuation token is returned
-         in the response, it must be specified in a subsequent invocation of the delete operation to
-         continue deleting the directory. Default value is None.
-        :type continuation: str
-        :param force_flag: Optional. Valid for "SetAccessControlRecursive" operation. If set to false,
-         the operation will terminate quickly on encountering user errors (4XX). If true, the operation
-         will ignore user errors and proceed with the operation on other sub-entities of the directory.
-         Continuation token will only be returned when forceFlag is true in case of user errors. If not
-         set the default value is false for this. Default value is None.
-        :type force_flag: bool
-        :param max_records: Optional. It specifies the maximum number of files or directories on which
-         the acl change will be applied. If omitted or greater than 2,000, the request will process up
-         to 2,000 items. Default value is None.
-        :type max_records: int
-        :param acl: Sets POSIX access control rights on files and directories. The value is a
-         comma-separated list of access control entries. Each access control entry (ACE) consists of a
-         scope, a type, a user or group identifier, and permissions in the format
-         "[scope:][type]:[id]:[permissions]". Default value is None.
-        :type acl: str
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Default value is None.
+        :type proposed_lease_id: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword action: action. Default value is "setAccessControlRecursive". Note that overriding
-         this default value may result in unsupported behavior.
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword action: Describes what lease action to take. Default value is "change". Note that
+         overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: SetAccessControlRecursiveResponse or the result of cls(response)
-        :rtype: ~azure.storage.filedatalake.models.SetAccessControlRecursiveResponse
+        :return: None or the result of cls(response)
+        :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        action = kwargs.pop("action", _params.pop("action", "setAccessControlRecursive"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[_models.SetAccessControlRecursiveResponse]
+        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+        action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        request = build_set_access_control_recursive_request(
+        request = build_change_lease_request(
             url=self._config.url,
-            mode=mode,
+            lease_id=lease_id,
             timeout=timeout,
-            continuation=continuation,
-            force_flag=force_flag,
-            max_records=max_records,
-            acl=acl,
+            proposed_lease_id=proposed_lease_id,
             request_id_parameter=request_id_parameter,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
             action=action,
             version=self._config.version,
-            template_url=self.set_access_control_recursive.metadata["url"],
+            template_url=self.change_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
-        response_headers["x-ms-continuation"] = self._deserialize("str", response.headers.get("x-ms-continuation"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-
-        deserialized = self._deserialize("SetAccessControlRecursiveResponse", pipeline_response)
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    set_access_control_recursive.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    change_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def flush_data(  # pylint: disable=inconsistent-return-statements
+    def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
-        position: Optional[int] = None,
-        retain_uncommitted_data: Optional[bool] = None,
-        close: Optional[bool] = None,
-        content_length: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
-        cpk_info: Optional[_models.CpkInfo] = None,
         **kwargs: Any
     ) -> None:
-        """Set the owner, group, permissions, or access control list for a path.
+        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
+        operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param position: This parameter allows the caller to upload data in parallel and control the
-         order in which it is appended to the file.  It is required when uploading data to be appended
-         to the file and when flushing previously uploaded data to the file.  The value must be the
-         position where the data is to be appended.  Uploaded data is not immediately flushed, or
-         written, to the file.  To flush, the previously uploaded data must be contiguous, the position
-         parameter must be specified and equal to the length of the file after all data has been
-         written, and there must not be a request entity body included with the request. Default value
-         is None.
-        :type position: int
-        :param retain_uncommitted_data: Valid only for flush operations.  If "true", uncommitted data
-         is retained after the flush operation completes; otherwise, the uncommitted data is deleted
-         after the flush operation.  The default is false.  Data at offsets less than the specified
-         position are written to the file when flush succeeds, but this optional parameter allows data
-         after the flush position to be retained for a future flush operation. Default value is None.
-        :type retain_uncommitted_data: bool
-        :param close: Azure Storage Events allow applications to receive notifications when files
-         change. When Azure Storage Events are enabled, a file changed event is raised. This event has a
-         property indicating whether this is the final change to distinguish the difference between an
-         intermediate flush to a file stream and the final close of a file stream. The close query
-         parameter is valid only when the action is "flush" and change notifications are enabled. If the
-         value of close is "true" and the flush operation completes successfully, the service raises a
-         file change notification with a property indicating that this is the final update (the file
-         stream has been closed). If "false" a change notification is raised indicating the file has
-         changed. The default is false. This query parameter is set to true by the Hadoop ABFS driver to
-         indicate that the file stream has been closed.". Default value is None.
-        :type close: bool
-        :param content_length: Required for "Append Data" and "Flush Data".  Must be 0 for "Flush
-         Data".  Must be the length of the request content in bytes for "Append Data". Default value is
-         None.
-        :type content_length: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param path_http_headers: Parameter group. Default value is None.
-        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param modified_access_conditions: Parameter group. Default value is None.
-        :type modified_access_conditions: ~azure.storage.filedatalake.models.ModifiedAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
-        :keyword action: action. Default value is "flush". Note that overriding this default value may
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
+        :paramtype comp: str
+        :keyword action: Describes what lease action to take. Default value is "break". Note that
+         overriding this default value may result in unsupported behavior.
         :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        action = kwargs.pop("action", _params.pop("action", "flush"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+        action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _content_md5 = None
         _lease_id = None
-        _cache_control = None
-        _content_type_parameter = None
-        _content_disposition = None
-        _content_encoding = None
-        _content_language = None
-        _if_match = None
-        _if_none_match = None
-        _if_modified_since = None
-        _if_unmodified_since = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        if path_http_headers is not None:
-            _cache_control = path_http_headers.cache_control
-            _content_disposition = path_http_headers.content_disposition
-            _content_encoding = path_http_headers.content_encoding
-            _content_language = path_http_headers.content_language
-            _content_md5 = path_http_headers.content_md5
-            _content_type_parameter = path_http_headers.content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if modified_access_conditions is not None:
-            _if_match = modified_access_conditions.if_match
-            _if_modified_since = modified_access_conditions.if_modified_since
-            _if_none_match = modified_access_conditions.if_none_match
-            _if_unmodified_since = modified_access_conditions.if_unmodified_since
-        if cpk_info is not None:
-            _encryption_algorithm = cpk_info.encryption_algorithm
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
 
-        request = build_flush_data_request(
+        request = build_break_lease_request(
             url=self._config.url,
             timeout=timeout,
-            position=position,
-            retain_uncommitted_data=retain_uncommitted_data,
-            close=close,
-            content_length=content_length,
-            content_md5=_content_md5,
             lease_id=_lease_id,
-            cache_control=_cache_control,
-            content_type_parameter=_content_type_parameter,
-            content_disposition=_content_disposition,
-            content_encoding=_content_encoding,
-            content_language=_content_language,
-            if_match=_if_match,
-            if_none_match=_if_none_match,
-            if_modified_since=_if_modified_since,
-            if_unmodified_since=_if_unmodified_since,
             request_id_parameter=request_id_parameter,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
             action=action,
             version=self._config.version,
-            template_url=self.flush_data.metadata["url"],
+            template_url=self.break_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
-        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
-            "str", response.headers.get("x-ms-encryption-key-sha256")
-        )
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    flush_data.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    break_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def append_data(  # pylint: disable=inconsistent-return-statements
+    def upload_range(  # pylint: disable=inconsistent-return-statements
         self,
-        body: IO,
-        position: Optional[int] = None,
+        range: str,
+        content_length: int,
         timeout: Optional[int] = None,
-        content_length: Optional[int] = None,
-        transactional_content_crc64: Optional[bytes] = None,
-        request_id_parameter: Optional[str] = None,
-        flush: Optional[bool] = None,
-        path_http_headers: Optional[_models.PathHTTPHeaders] = None,
+        file_range_write: Union[str, _models.FileRangeWriteType] = "update",
+        content_md5: Optional[bytes] = None,
+        file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        cpk_info: Optional[_models.CpkInfo] = None,
+        optionalbody: Optional[IO] = None,
         **kwargs: Any
     ) -> None:
-        """Append data to the file.
+        """Upload a range of bytes to a file.
 
-        :param body: Initial data. Required.
-        :type body: IO
-        :param position: This parameter allows the caller to upload data in parallel and control the
-         order in which it is appended to the file.  It is required when uploading data to be appended
-         to the file and when flushing previously uploaded data to the file.  The value must be the
-         position where the data is to be appended.  Uploaded data is not immediately flushed, or
-         written, to the file.  To flush, the previously uploaded data must be contiguous, the position
-         parameter must be specified and equal to the length of the file after all data has been
-         written, and there must not be a request entity body included with the request. Default value
-         is None.
-        :type position: int
+        :param range: Specifies the range of bytes to be written. Both the start and end of the range
+         must be specified. For an update operation, the range can be up to 4 MB in size. For a clear
+         operation, the range can be up to the value of the file's full size. The File service accepts
+         only a single byte range for the Range and 'x-ms-range' headers, and the byte range must be
+         specified in the following format: bytes=startByte-endByte. Required.
+        :type range: str
+        :param content_length: Specifies the number of bytes being transmitted in the request body.
+         When the x-ms-write header is set to clear, the value of this header must be set to zero.
+         Required.
+        :type content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param content_length: Required for "Append Data" and "Flush Data".  Must be 0 for "Flush
-         Data".  Must be the length of the request content in bytes for "Append Data". Default value is
-         None.
-        :type content_length: int
-        :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
-         validated by the service. Default value is None.
-        :type transactional_content_crc64: bytes
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :param flush: If file should be flushed after the append. Default value is None.
-        :type flush: bool
-        :param path_http_headers: Parameter group. Default value is None.
-        :type path_http_headers: ~azure.storage.filedatalake.models.PathHTTPHeaders
+        :param file_range_write: Specify one of the following options: - Update: Writes the bytes
+         specified by the request body into the specified range. The Range and Content-Length headers
+         must match to perform the update. - Clear: Clears the specified range and releases the space
+         used in storage for that range. To clear a range, set the Content-Length header to zero, and
+         set the Range header to a value that indicates the range to clear, up to maximum file size.
+         Known values are: "update" and "clear". Default value is "update".
+        :type file_range_write: str or ~azure.storage.fileshare.models.FileRangeWriteType
+        :param content_md5: An MD5 hash of the content. This hash is used to verify the integrity of
+         the data during transport. When the Content-MD5 header is specified, the File service compares
+         the hash of the content that has arrived with the header value that was sent. If the two hashes
+         do not match, the operation will fail with error code 400 (Bad Request). Default value is None.
+        :type content_md5: bytes
+        :param file_last_written_mode: If the file last write time should be preserved or overwritten.
+         Known values are: "Now" and "Preserve". Default value is None.
+        :type file_last_written_mode: str or ~azure.storage.fileshare.models.FileLastWrittenMode
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.filedatalake.models.LeaseAccessConditions
-        :param cpk_info: Parameter group. Default value is None.
-        :type cpk_info: ~azure.storage.filedatalake.models.CpkInfo
-        :keyword action: action. Default value is "append". Note that overriding this default value may
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :param optionalbody: Initial data. Default value is None.
+        :type optionalbody: IO
+        :keyword comp: comp. Default value is "range". Note that overriding this default value may
          result in unsupported behavior.
-        :paramtype action: str
+        :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        action = kwargs.pop("action", _params.pop("action", "append"))  # type: str
-        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/json"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
+        content_type: str = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _transactional_content_hash = None
         _lease_id = None
-        _encryption_key = None
-        _encryption_key_sha256 = None
-        _encryption_algorithm = None
-        if path_http_headers is not None:
-            _transactional_content_hash = path_http_headers.transactional_content_hash
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        if cpk_info is not None:
-            _encryption_algorithm = cpk_info.encryption_algorithm
-            _encryption_key = cpk_info.encryption_key
-            _encryption_key_sha256 = cpk_info.encryption_key_sha256
-        _content = body
+        _content = optionalbody
 
-        request = build_append_data_request(
+        request = build_upload_range_request(
             url=self._config.url,
-            position=position,
-            timeout=timeout,
+            range=range,
             content_length=content_length,
-            transactional_content_hash=_transactional_content_hash,
-            transactional_content_crc64=transactional_content_crc64,
+            timeout=timeout,
+            file_range_write=file_range_write,
+            content_md5=content_md5,
             lease_id=_lease_id,
-            request_id_parameter=request_id_parameter,
-            encryption_key=_encryption_key,
-            encryption_key_sha256=_encryption_key_sha256,
-            encryption_algorithm=_encryption_algorithm,
-            flush=flush,
-            action=action,
+            file_last_written_mode=file_last_written_mode,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
             content_type=content_type,
             version=self._config.version,
             content=_content,
-            template_url=self.append_data.metadata["url"],
+            template_url=self.upload_range.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-file-last-write-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-last-write-time")
+        )
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    upload_range.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+
+    @distributed_trace
+    def upload_range_from_url(  # pylint: disable=inconsistent-return-statements
+        self,
+        range: str,
+        copy_source: str,
+        content_length: int,
+        timeout: Optional[int] = None,
+        source_range: Optional[str] = None,
+        source_content_crc64: Optional[bytes] = None,
+        copy_source_authorization: Optional[str] = None,
+        file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """Upload a range of bytes to a file where the contents are read from a URL.
+
+        :param range: Writes data to the specified byte range in the file. Required.
+        :type range: str
+        :param copy_source: Specifies the URL of the source file or blob, up to 2 KB in length. To copy
+         a file to another file within the same storage account, you may use Shared Key to authenticate
+         the source file. If you are copying a file from another storage account, or if you are copying
+         a blob from the same storage account or another storage account, then you must authenticate the
+         source file or blob using a shared access signature. If the source is a public blob, no
+         authentication is required to perform the copy operation. A file in a share snapshot can also
+         be specified as a copy source. Required.
+        :type copy_source: str
+        :param content_length: Specifies the number of bytes being transmitted in the request body.
+         When the x-ms-write header is set to clear, the value of this header must be set to zero.
+         Required.
+        :type content_length: int
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param source_range: Bytes of source data in the specified range. Default value is None.
+        :type source_range: str
+        :param source_content_crc64: Specify the crc64 calculated for the range of bytes that must be
+         read from the copy source. Default value is None.
+        :type source_content_crc64: bytes
+        :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
+         OAuth access token to copy source. Default value is None.
+        :type copy_source_authorization: str
+        :param file_last_written_mode: If the file last write time should be preserved or overwritten.
+         Known values are: "Now" and "Preserve". Default value is None.
+        :type file_last_written_mode: str or ~azure.storage.fileshare.models.FileLastWrittenMode
+        :param source_modified_access_conditions: Parameter group. Default value is None.
+        :type source_modified_access_conditions:
+         ~azure.storage.fileshare.models.SourceModifiedAccessConditions
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword comp: comp. Default value is "range". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
+
+        _source_if_match_crc64 = None
+        _source_if_none_match_crc64 = None
+        _lease_id = None
+        if source_modified_access_conditions is not None:
+            _source_if_match_crc64 = source_modified_access_conditions.source_if_match_crc64
+            _source_if_none_match_crc64 = source_modified_access_conditions.source_if_none_match_crc64
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+
+        request = build_upload_range_from_url_request(
+            url=self._config.url,
+            range=range,
+            copy_source=copy_source,
+            content_length=content_length,
+            timeout=timeout,
+            source_range=source_range,
+            source_content_crc64=source_content_crc64,
+            source_if_match_crc64=_source_if_match_crc64,
+            source_if_none_match_crc64=_source_if_none_match_crc64,
+            lease_id=_lease_id,
+            copy_source_authorization=copy_source_authorization,
+            file_last_written_mode=file_last_written_mode,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            allow_source_trailing_dot=self._config.allow_source_trailing_dot,
+            comp=comp,
+            file_range_write_from_url=self._config.file_range_write_from_url,
+            version=self._config.version,
+            template_url=self.upload_range_from_url.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [201]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-content-crc64"] = self._deserialize(
             "bytearray", response.headers.get("x-ms-content-crc64")
         )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
         response_headers["x-ms-request-server-encrypted"] = self._deserialize(
             "bool", response.headers.get("x-ms-request-server-encrypted")
         )
-        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
-            "str", response.headers.get("x-ms-encryption-key-sha256")
+        response_headers["x-ms-file-last-write-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-last-write-time")
         )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    append_data.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    upload_range_from_url.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def set_expiry(  # pylint: disable=inconsistent-return-statements
+    def get_range_list(
         self,
-        expiry_options: Union[str, "_models.PathExpiryOptions"],
+        sharesnapshot: Optional[str] = None,
+        prevsharesnapshot: Optional[str] = None,
         timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        expires_on: Optional[str] = None,
+        range: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """Sets the time a blob will expire and be deleted.
+    ) -> _models.ShareFileRangeList:
+        """Returns the list of valid ranges for a file.
 
-        :param expiry_options: Required. Indicates mode of the expiry time. Known values are:
-         "NeverExpire", "RelativeToCreation", "RelativeToNow", and "Absolute". Required.
-        :type expiry_options: str or ~azure.storage.filedatalake.models.PathExpiryOptions
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
+        :param prevsharesnapshot: The previous snapshot parameter is an opaque DateTime value that,
+         when present, specifies the previous snapshot. Default value is None.
+        :type prevsharesnapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+        :param range: Specifies the range of bytes over which to list ranges, inclusively. Default
          value is None.
-        :type request_id_parameter: str
-        :param expires_on: The time to set the blob to expiry. Default value is None.
-        :type expires_on: str
-        :keyword comp: comp. Default value is "expiry". Note that overriding this default value may
+        :type range: str
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword comp: comp. Default value is "rangelist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: ShareFileRangeList or the result of cls(response)
+        :rtype: ~azure.storage.fileshare.models.ShareFileRangeList
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop("comp", _params.pop("comp", "expiry"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["rangelist"] = kwargs.pop("comp", _params.pop("comp", "rangelist"))
+        cls: ClsType[_models.ShareFileRangeList] = kwargs.pop("cls", None)
+
+        _lease_id = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
 
-        request = build_set_expiry_request(
+        request = build_get_range_list_request(
             url=self._config.url,
-            expiry_options=expiry_options,
+            sharesnapshot=sharesnapshot,
+            prevsharesnapshot=prevsharesnapshot,
             timeout=timeout,
-            request_id_parameter=request_id_parameter,
-            expires_on=expires_on,
+            range=range,
+            lease_id=_lease_id,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
             comp=comp,
             version=self._config.version,
-            template_url=self.set_expiry.metadata["url"],
+            template_url=self.get_range_list.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["x-ms-content-length"] = self._deserialize("int", response.headers.get("x-ms-content-length"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        deserialized = self._deserialize("ShareFileRangeList", pipeline_response)
+
+        if cls:
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
+
+    get_range_list.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+
+    @distributed_trace
+    def start_copy(  # pylint: disable=inconsistent-return-statements
+        self,
+        copy_source: str,
+        timeout: Optional[int] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        file_permission: str = "inherit",
+        file_permission_key: Optional[str] = None,
+        copy_file_smb_info: Optional[_models.CopyFileSmbInfo] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        **kwargs: Any
+    ) -> None:
+        """Copies a blob or file to a destination file within the storage account.
+
+        :param copy_source: Specifies the URL of the source file or blob, up to 2 KB in length. To copy
+         a file to another file within the same storage account, you may use Shared Key to authenticate
+         the source file. If you are copying a file from another storage account, or if you are copying
+         a blob from the same storage account or another storage account, then you must authenticate the
+         source file or blob using a shared access signature. If the source is a public blob, no
+         authentication is required to perform the copy operation. A file in a share snapshot can also
+         be specified as a copy source. Required.
+        :type copy_source: str
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param metadata: A name-value pair to associate with a file storage object. Default value is
+         None.
+        :type metadata: dict[str, str]
+        :param file_permission: If specified the permission (security descriptor) shall be set for the
+         directory/file. This header can be used if Permission size is <= 8KB, else
+         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
+         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
+         x-ms-file-permission-key should be specified. Default value is "inherit".
+        :type file_permission: str
+        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
+         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
+         is None.
+        :type file_permission_key: str
+        :param copy_file_smb_info: Parameter group. Default value is None.
+        :type copy_file_smb_info: ~azure.storage.fileshare.models.CopyFileSmbInfo
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = kwargs.pop("params", {}) or {}
+
+        cls: ClsType[None] = kwargs.pop("cls", None)
+
+        _file_permission_copy_mode = None
+        _ignore_read_only = None
+        _file_attributes = None
+        _file_creation_time = None
+        _file_last_write_time = None
+        _file_change_time = None
+        _set_archive_attribute = None
+        _lease_id = None
+        if copy_file_smb_info is not None:
+            _file_attributes = copy_file_smb_info.file_attributes
+            _file_change_time = copy_file_smb_info.file_change_time
+            _file_creation_time = copy_file_smb_info.file_creation_time
+            _file_last_write_time = copy_file_smb_info.file_last_write_time
+            _file_permission_copy_mode = copy_file_smb_info.file_permission_copy_mode
+            _ignore_read_only = copy_file_smb_info.ignore_read_only
+            _set_archive_attribute = copy_file_smb_info.set_archive_attribute
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+
+        request = build_start_copy_request(
+            url=self._config.url,
+            copy_source=copy_source,
+            timeout=timeout,
+            metadata=metadata,
+            file_permission=file_permission,
+            file_permission_key=file_permission_key,
+            file_permission_copy_mode=_file_permission_copy_mode,
+            ignore_read_only=_ignore_read_only,
+            file_attributes=_file_attributes,
+            file_creation_time=_file_creation_time,
+            file_last_write_time=_file_last_write_time,
+            file_change_time=_file_change_time,
+            set_archive_attribute=_set_archive_attribute,
+            lease_id=_lease_id,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            allow_source_trailing_dot=self._config.allow_source_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            version=self._config.version,
+            template_url=self.start_copy.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
         )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [202]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_expiry.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    start_copy.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
 
     @distributed_trace
-    def undelete(  # pylint: disable=inconsistent-return-statements
+    def abort_copy(  # pylint: disable=inconsistent-return-statements
         self,
+        copy_id: str,
         timeout: Optional[int] = None,
-        undelete_source: Optional[str] = None,
-        request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Undelete a path that was previously soft deleted.
+        """Aborts a pending Copy File operation, and leaves a destination file with zero length and full
+        metadata.
 
+        :param copy_id: The copy identifier provided in the x-ms-copy-id header of the original Copy
+         File operation. Required.
+        :type copy_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
-         Timeouts for Blob Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param undelete_source: Only for hierarchical namespace enabled accounts. Optional. The path of
-         the soft deleted blob to undelete. Default value is None.
-        :type undelete_source: str
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword comp: comp. Default value is "copy". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
+        :keyword copy_action_abort_constant: Abort. Default value is "abort". Note that overriding this
+         default value may result in unsupported behavior.
+        :paramtype copy_action_abort_constant: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp: Literal["copy"] = kwargs.pop("comp", _params.pop("comp", "copy"))
+        copy_action_abort_constant: Literal["abort"] = kwargs.pop(
+            "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
+        )
+        cls: ClsType[None] = kwargs.pop("cls", None)
+
+        _lease_id = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+
+        request = build_abort_copy_request(
+            url=self._config.url,
+            copy_id=copy_id,
+            timeout=timeout,
+            lease_id=_lease_id,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
+            copy_action_abort_constant=copy_action_abort_constant,
+            version=self._config.version,
+            template_url=self.abort_copy.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [204]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    abort_copy.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+
+    @distributed_trace
+    def list_handles(
+        self,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
+        timeout: Optional[int] = None,
+        sharesnapshot: Optional[str] = None,
+        **kwargs: Any
+    ) -> _models.ListHandlesResponse:
+        """Lists handles for file.
+
+        :param marker: A string value that identifies the portion of the list to be returned with the
+         next list operation. The operation returns a marker value within the response body if the list
+         returned was not complete. The marker value may then be used in a subsequent call to request
+         the next set of list items. The marker value is opaque to the client. Default value is None.
+        :type marker: str
+        :param maxresults: Specifies the maximum number of entries to return. If the request does not
+         specify maxresults, or specifies a value greater than 5,000, the server will return up to 5,000
+         items. Default value is None.
+        :type maxresults: int
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
+        :keyword comp: comp. Default value is "listhandles". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: ListHandlesResponse or the result of cls(response)
+        :rtype: ~azure.storage.fileshare.models.ListHandlesResponse
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp: Literal["listhandles"] = kwargs.pop("comp", _params.pop("comp", "listhandles"))
+        cls: ClsType[_models.ListHandlesResponse] = kwargs.pop("cls", None)
+
+        request = build_list_handles_request(
+            url=self._config.url,
+            marker=marker,
+            maxresults=maxresults,
+            timeout=timeout,
+            sharesnapshot=sharesnapshot,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.list_handles.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+
+        deserialized = self._deserialize("ListHandlesResponse", pipeline_response)
+
+        if cls:
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
+
+    list_handles.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+
+    @distributed_trace
+    def force_close_handles(  # pylint: disable=inconsistent-return-statements
+        self,
+        handle_id: str,
+        timeout: Optional[int] = None,
+        marker: Optional[str] = None,
+        sharesnapshot: Optional[str] = None,
+        **kwargs: Any
+    ) -> None:
+        """Closes all handles open for given file.
+
+        :param handle_id: Specifies handle ID opened on the file or directory to be closed. Asterisk
+         (*) is a wildcard that specifies all handles. Required.
+        :type handle_id: str
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param marker: A string value that identifies the portion of the list to be returned with the
+         next list operation. The operation returns a marker value within the response body if the list
+         returned was not complete. The marker value may then be used in a subsequent call to request
+         the next set of list items. The marker value is opaque to the client. Default value is None.
+        :type marker: str
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
+        :keyword comp: comp. Default value is "forceclosehandles". Note that overriding this default
+         value may result in unsupported behavior.
+        :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp = kwargs.pop("comp", _params.pop("comp", "undelete"))  # type: str
-        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+        comp: Literal["forceclosehandles"] = kwargs.pop("comp", _params.pop("comp", "forceclosehandles"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        request = build_undelete_request(
+        request = build_force_close_handles_request(
             url=self._config.url,
+            handle_id=handle_id,
             timeout=timeout,
-            undelete_source=undelete_source,
-            request_id_parameter=request_id_parameter,
+            marker=marker,
+            sharesnapshot=sharesnapshot,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
             comp=comp,
             version=self._config.version,
-            template_url=self.undelete.metadata["url"],
+            template_url=self.force_close_handles.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)  # type: ignore
+        request.url = self._client.format_url(request.url)
 
-        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-marker"] = self._deserialize("str", response.headers.get("x-ms-marker"))
+        response_headers["x-ms-number-of-handles-closed"] = self._deserialize(
+            "int", response.headers.get("x-ms-number-of-handles-closed")
+        )
+        response_headers["x-ms-number-of-handles-failed"] = self._deserialize(
+            "int", response.headers.get("x-ms-number-of-handles-failed")
         )
+
+        if cls:
+            return cls(pipeline_response, None, response_headers)
+
+    force_close_handles.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+
+    @distributed_trace
+    def rename(  # pylint: disable=inconsistent-return-statements
+        self,
+        rename_source: str,
+        timeout: Optional[int] = None,
+        replace_if_exists: Optional[bool] = None,
+        ignore_read_only: Optional[bool] = None,
+        file_permission: str = "inherit",
+        file_permission_key: Optional[str] = None,
+        metadata: Optional[Dict[str, str]] = None,
+        source_lease_access_conditions: Optional[_models.SourceLeaseAccessConditions] = None,
+        destination_lease_access_conditions: Optional[_models.DestinationLeaseAccessConditions] = None,
+        copy_file_smb_info: Optional[_models.CopyFileSmbInfo] = None,
+        file_http_headers: Optional[_models.FileHTTPHeaders] = None,
+        **kwargs: Any
+    ) -> None:
+        """Renames a file.
+
+        :param rename_source: Required. Specifies the URI-style path of the source file, up to 2 KB in
+         length. Required.
+        :type rename_source: str
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :param replace_if_exists: Optional. A boolean value for if the destination file already exists,
+         whether this request will overwrite the file or not. If true, the rename will succeed and will
+         overwrite the destination file. If not provided or if false and the destination file does
+         exist, the request will not overwrite the destination file. If provided and the destination
+         file doesnt exist, the rename will succeed. Note: This value does not override the
+         x-ms-file-copy-ignore-read-only header value. Default value is None.
+        :type replace_if_exists: bool
+        :param ignore_read_only: Optional. A boolean value that specifies whether the ReadOnly
+         attribute on a preexisting destination file should be respected. If true, the rename will
+         succeed, otherwise, a previous file at the destination with the ReadOnly attribute set will
+         cause the rename to fail. Default value is None.
+        :type ignore_read_only: bool
+        :param file_permission: If specified the permission (security descriptor) shall be set for the
+         directory/file. This header can be used if Permission size is <= 8KB, else
+         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
+         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
+         x-ms-file-permission-key should be specified. Default value is "inherit".
+        :type file_permission: str
+        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
+         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
+         is None.
+        :type file_permission_key: str
+        :param metadata: A name-value pair to associate with a file storage object. Default value is
+         None.
+        :type metadata: dict[str, str]
+        :param source_lease_access_conditions: Parameter group. Default value is None.
+        :type source_lease_access_conditions:
+         ~azure.storage.fileshare.models.SourceLeaseAccessConditions
+        :param destination_lease_access_conditions: Parameter group. Default value is None.
+        :type destination_lease_access_conditions:
+         ~azure.storage.fileshare.models.DestinationLeaseAccessConditions
+        :param copy_file_smb_info: Parameter group. Default value is None.
+        :type copy_file_smb_info: ~azure.storage.fileshare.models.CopyFileSmbInfo
+        :param file_http_headers: Parameter group. Default value is None.
+        :type file_http_headers: ~azure.storage.fileshare.models.FileHTTPHeaders
+        :keyword comp: comp. Default value is "rename". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+        error_map = {
+            401: ClientAuthenticationError,
+            404: ResourceNotFoundError,
+            409: ResourceExistsError,
+            304: ResourceNotModifiedError,
+        }
+        error_map.update(kwargs.pop("error_map", {}) or {})
+
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+
+        comp: Literal["rename"] = kwargs.pop("comp", _params.pop("comp", "rename"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
+
+        _source_lease_id = None
+        _destination_lease_id = None
+        _file_attributes = None
+        _file_creation_time = None
+        _file_last_write_time = None
+        _file_change_time = None
+        _file_content_type = None
+        if source_lease_access_conditions is not None:
+            _source_lease_id = source_lease_access_conditions.source_lease_id
+        if destination_lease_access_conditions is not None:
+            _destination_lease_id = destination_lease_access_conditions.destination_lease_id
+        if copy_file_smb_info is not None:
+            _file_attributes = copy_file_smb_info.file_attributes
+            _file_change_time = copy_file_smb_info.file_change_time
+            _file_creation_time = copy_file_smb_info.file_creation_time
+            _file_last_write_time = copy_file_smb_info.file_last_write_time
+        if file_http_headers is not None:
+            _file_content_type = file_http_headers.file_content_type
+
+        request = build_rename_request(
+            url=self._config.url,
+            rename_source=rename_source,
+            timeout=timeout,
+            replace_if_exists=replace_if_exists,
+            ignore_read_only=ignore_read_only,
+            source_lease_id=_source_lease_id,
+            destination_lease_id=_destination_lease_id,
+            file_attributes=_file_attributes,
+            file_creation_time=_file_creation_time,
+            file_last_write_time=_file_last_write_time,
+            file_change_time=_file_change_time,
+            file_permission=file_permission,
+            file_permission_key=file_permission_key,
+            metadata=metadata,
+            file_content_type=_file_content_type,
+            allow_trailing_dot=self._config.allow_trailing_dot,
+            allow_source_trailing_dot=self._config.allow_source_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            comp=comp,
+            version=self._config.version,
+            template_url=self.rename.metadata["url"],
+            headers=_headers,
+            params=_params,
+        )
+        request = _convert_request(request)
+        request.url = self._client.format_url(request.url)
+
+        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+            request, stream=False, **kwargs
+        )
+
+        response = pipeline_response.http_response
+
+        if response.status_code not in [200]:
+            map_error(status_code=response.status_code, response=response, error_map=error_map)
+            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
+            raise HttpResponseError(response=response, model=error)
+
+        response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-resource-type"] = self._deserialize("str", response.headers.get("x-ms-resource-type"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
+        )
+        response_headers["x-ms-file-permission-key"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-permission-key")
+        )
+        response_headers["x-ms-file-attributes"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-attributes")
+        )
+        response_headers["x-ms-file-creation-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-creation-time")
+        )
+        response_headers["x-ms-file-last-write-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-last-write-time")
+        )
+        response_headers["x-ms-file-change-time"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-change-time")
+        )
+        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
+        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    undelete.metadata = {"url": "{url}/{filesystem}/{path}"}  # type: ignore
+    rename.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_list_paths_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_list_paths_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_path_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_path_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_quick_query_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_quick_query_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_serialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/response_handlers.py`

 * *Files 1% similar despite different names*

```diff
@@ -82,19 +82,21 @@
 def return_context_and_deserialized(response, deserialized, response_headers):  # pylint: disable=unused-argument
     return response.http_response.location_mode, deserialized
 
 
 def process_storage_error(storage_error):   # pylint:disable=too-many-statements
     raise_error = HttpResponseError
     serialized = False
-    if not storage_error.response:
+    if not storage_error.response or storage_error.response.status_code in [200, 204]:
         raise storage_error
     # If it is one of those three then it has been serialized prior by the generated layer.
     if isinstance(storage_error, (PartialBatchErrorException,
-                                  ClientAuthenticationError, ResourceNotFoundError, ResourceExistsError)):
+                                  ClientAuthenticationError,
+                                  ResourceNotFoundError,
+                                  ResourceExistsError)):
         serialized = True
     error_code = storage_error.response.headers.get('x-ms-error-code')
     error_message = storage_error.message
     additional_data = {}
     error_dict = {}
     try:
         error_body = ContentDecodePolicy.deserialize_from_http_generics(storage_error.response)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/shared_access_signature.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,16 @@
 
 from datetime import date
 
 from .parser import _str, _to_utc_datetime
 from .constants import X_MS_VERSION
 from . import sign_string, url_quote
 
-
+# cspell:ignoreRegExp rsc.
+# cspell:ignoreRegExp s..?id
 class QueryStringConstants(object):
     SIGNED_SIGNATURE = 'sig'
     SIGNED_PERMISSION = 'sp'
     SIGNED_START = 'st'
     SIGNED_EXPIRY = 'se'
     SIGNED_RESOURCE = 'sr'
     SIGNED_IDENTIFIER = 'si'
@@ -34,14 +35,16 @@
     SIGNED_SERVICES = 'ss'
     SIGNED_OID = 'skoid'
     SIGNED_TID = 'sktid'
     SIGNED_KEY_START = 'skt'
     SIGNED_KEY_EXPIRY = 'ske'
     SIGNED_KEY_SERVICE = 'sks'
     SIGNED_KEY_VERSION = 'skv'
+
+    # for blob only
     SIGNED_ENCRYPTION_SCOPE = 'ses'
 
     # for ADLS
     SIGNED_AUTHORIZED_OID = 'saoid'
     SIGNED_UNAUTHORIZED_OID = 'suoid'
     SIGNED_CORRELATION_ID = 'scid'
     SIGNED_DIRECTORY_DEPTH = 'sdd'
@@ -71,14 +74,15 @@
             QueryStringConstants.SIGNED_SERVICES,
             QueryStringConstants.SIGNED_OID,
             QueryStringConstants.SIGNED_TID,
             QueryStringConstants.SIGNED_KEY_START,
             QueryStringConstants.SIGNED_KEY_EXPIRY,
             QueryStringConstants.SIGNED_KEY_SERVICE,
             QueryStringConstants.SIGNED_KEY_VERSION,
+            # for blob only
             QueryStringConstants.SIGNED_ENCRYPTION_SCOPE,
             # for ADLS
             QueryStringConstants.SIGNED_AUTHORIZED_OID,
             QueryStringConstants.SIGNED_UNAUTHORIZED_OID,
             QueryStringConstants.SIGNED_CORRELATION_ID,
             QueryStringConstants.SIGNED_DIRECTORY_DEPTH,
         ]
@@ -164,14 +168,17 @@
     def __init__(self):
         self.query_dict = {}
 
     def _add_query(self, name, val):
         if val:
             self.query_dict[name] = _str(val) if val is not None else None
 
+    def add_encryption_scope(self, **kwargs):
+        self._add_query(QueryStringConstants.SIGNED_ENCRYPTION_SCOPE, kwargs.pop('encryption_scope', None))
+
     def add_base(self, permission, expiry, start, ip, protocol, x_ms_version):
         if isinstance(start, date):
             start = _to_utc_datetime(start)
 
         if isinstance(expiry, date):
             expiry = _to_utc_datetime(expiry)
 
@@ -188,17 +195,14 @@
     def add_id(self, policy_id):
         self._add_query(QueryStringConstants.SIGNED_IDENTIFIER, policy_id)
 
     def add_account(self, services, resource_types):
         self._add_query(QueryStringConstants.SIGNED_SERVICES, services)
         self._add_query(QueryStringConstants.SIGNED_RESOURCE_TYPES, resource_types)
 
-    def add_encryption_scope(self, **kwargs):
-        self._add_query(QueryStringConstants.SIGNED_ENCRYPTION_SCOPE, kwargs.pop('encryption_scope', None))
-
     def add_override_response_headers(self, cache_control,
                                       content_disposition,
                                       content_encoding,
                                       content_language,
                                       content_type):
         self._add_query(QueryStringConstants.SIGNED_CACHE_CONTROL, cache_control)
         self._add_query(QueryStringConstants.SIGNED_CONTENT_DISPOSITION, content_disposition)
@@ -223,8 +227,8 @@
              get_value_to_append(QueryStringConstants.SIGNED_VERSION) +
              get_value_to_append(QueryStringConstants.SIGNED_ENCRYPTION_SCOPE))
 
         self._add_query(QueryStringConstants.SIGNED_SIGNATURE,
                         sign_string(account_key, string_to_sign))
 
     def get_token(self):
-        return '&'.join(['{0}={1}'.format(n, url_quote(v)) for n, v in self.query_dict.items() if v is not None])
+        return '&'.join([f'{n}={url_quote(v)}' for n, v in self.query_dict.items() if v is not None])
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_upload_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_upload_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_directory_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_directory_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_file_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_file_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_lease_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_data_lake_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_download_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_download_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_file_system_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_file_system_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_list_paths_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/aio/_list_blobs_helper.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,53 +1,73 @@
+# pylint: disable=too-many-lines
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
-# pylint: disable=too-few-public-methods, too-many-instance-attributes
-# pylint: disable=super-init-not-called, too-many-lines
+
+from urllib.parse import unquote
+
+from azure.core.async_paging import AsyncPageIterator, AsyncItemPaged
 from azure.core.exceptions import HttpResponseError
-from azure.core.async_paging import AsyncPageIterator
 
-from .._deserialize import process_storage_error, get_deleted_path_properties_from_generated_code, \
-    return_headers_and_deserialized_path_list
+from .._deserialize import (
+    get_blob_properties_from_generated_code,
+    load_many_xml_nodes,
+    load_xml_int,
+    load_xml_string,
+)
 from .._generated.models import BlobItemInternal, BlobPrefix as GenBlobPrefix
-
+from .._models import BlobProperties
 from .._shared.models import DictMixin
-from .._shared.response_handlers import return_context_and_deserialized
-from .._generated.models import Path
-from .._models import PathProperties
+from .._shared.response_handlers import (
+    return_context_and_deserialized,
+    return_raw_deserialized,
+    process_storage_error,
+)
 
 
-class DeletedPathPropertiesPaged(AsyncPageIterator):
-    """An Iterable of deleted path properties.
+class BlobPropertiesPaged(AsyncPageIterator):
+    """An Iterable of Blob properties.
 
     :ivar str service_endpoint: The service URL.
-    :ivar str prefix: A path name prefix being used to filter the list.
+    :ivar str prefix: A blob name prefix being used to filter the list.
     :ivar str marker: The continuation token of the current page of results.
     :ivar int results_per_page: The maximum number of results retrieved per API call.
-    :ivar str continuation_token: The continuation token to retrieve the next page of results.
     :ivar str location_mode: The location mode being used to list results. The available
         options include "primary" and "secondary".
     :ivar current_page: The current page of listed results.
-    :vartype current_page: list(~azure.storage.filedatalake.DeletedPathProperties)
-    :ivar str container: The container that the paths are listed from.
+    :vartype current_page: list(~azure.storage.blob.models.BlobProperties)
+    :ivar str container: The container that the blobs are listed from.
     :ivar str delimiter: A delimiting character used for hierarchy listing.
 
     :param callable command: Function to retrieve the next page of items.
+    :param str container: The container that the blobs are listed from.
+    :param str prefix: Filters the results to return only blobs whose names
+        begin with the specified prefix.
+    :param int results_per_page: The maximum number of blobs to retrieve per
+        call.
+    :param str continuation_token: An opaque continuation token.
+    :param str delimiter:
+        Used to capture blobs whose names begin with the same substring up to
+        the appearance of the delimiter character. The delimiter may be a single
+        character or a string.
+    :param location_mode: Specifies the location the request should be sent to.
+        This mode only applies for RA-GRS accounts which allow secondary read access.
+        Options include 'primary' or 'secondary'.
     """
     def __init__(
             self, command,
             container=None,
             prefix=None,
             results_per_page=None,
             continuation_token=None,
             delimiter=None,
             location_mode=None):
-        super(DeletedPathPropertiesPaged, self).__init__(
+        super(BlobPropertiesPaged, self).__init__(
             get_next=self._get_next_cb,
             extract_data=self._extract_data_cb,
             continuation_token=continuation_token or ""
         )
         self._command = command
         self.service_endpoint = None
         self.prefix = prefix
@@ -59,119 +79,174 @@
         self.location_mode = location_mode
 
     async def _get_next_cb(self, continuation_token):
         try:
             return await self._command(
                 prefix=self.prefix,
                 marker=continuation_token or None,
-                max_results=self.results_per_page,
+                maxresults=self.results_per_page,
                 cls=return_context_and_deserialized,
                 use_location=self.location_mode)
         except HttpResponseError as error:
             process_storage_error(error)
 
     async def _extract_data_cb(self, get_next_return):
         self.location_mode, self._response = get_next_return
         self.service_endpoint = self._response.service_endpoint
         self.prefix = self._response.prefix
         self.marker = self._response.marker
         self.results_per_page = self._response.max_results
         self.container = self._response.container_name
-        self.current_page = self._response.segment.blob_prefixes  + self._response.segment.blob_items
-        self.current_page = [self._build_item(item) for item in self.current_page]
-        self.delimiter = self._response.delimiter
+        self.current_page = [self._build_item(item) for item in self._response.segment.blob_items]
 
         return self._response.next_marker or None, self.current_page
 
     def _build_item(self, item):
+        if isinstance(item, BlobProperties):
+            return item
         if isinstance(item, BlobItemInternal):
-            file_props = get_deleted_path_properties_from_generated_code(item)
-            file_props.file_system = self.container
-            return file_props
-        if isinstance(item, GenBlobPrefix):
-            return DirectoryPrefix(
-                container=self.container,
-                prefix=item.name,
-                results_per_page=self.results_per_page,
-                location_mode=self.location_mode)
+            blob = get_blob_properties_from_generated_code(item)  # pylint: disable=protected-access
+            blob.container = self.container
+            return blob
         return item
 
 
-class DirectoryPrefix(DictMixin):
-    """Directory prefix.
+class BlobNamesPaged(AsyncPageIterator):
+    """An Iterable of Blob names.
 
-    :ivar str name: Name of the deleted directory.
+    :ivar str service_endpoint: The service URL.
+    :ivar str prefix: A blob name prefix being used to filter the list.
+    :ivar str marker: The continuation token of the current page of results.
     :ivar int results_per_page: The maximum number of results retrieved per API call.
+    :ivar str continuation_token: The continuation token to retrieve the next page of results.
     :ivar str location_mode: The location mode being used to list results. The available
         options include "primary" and "secondary".
-    :ivar str file_system: The file system that the deleted paths are listed from.
+    :ivar current_page: The current page of listed results.
+    :vartype current_page: list(str)
+    :ivar str container: The container that the blobs are listed from.
     :ivar str delimiter: A delimiting character used for hierarchy listing.
-    """
-    def __init__(self, **kwargs):
-        self.name = kwargs.get('prefix')
-        self.results_per_page = kwargs.get('results_per_page')
-        self.file_system = kwargs.get('container')
-        self.delimiter = kwargs.get('delimiter')
-        self.location_mode = kwargs.get('location_mode')
-
-
-class PathPropertiesPaged(AsyncPageIterator):
-    """An Iterable of Path properties.
-
-    :ivar str path: Filters the results to return only paths under the specified path.
-    :ivar int results_per_page: The maximum number of results retrieved per API call.
-    :ivar str continuation_token: The continuation token to retrieve the next page of results.
-    :ivar list(~azure.storage.filedatalake.PathProperties) current_page: The current page of listed results.
 
     :param callable command: Function to retrieve the next page of items.
-    :param str path: Filters the results to return only paths under the specified path.
-    :param int max_results: The maximum number of psths to retrieve per
+    :param str container: The name of the container.
+    :param str prefix: Filters the results to return only blobs whose names
+        begin with the specified prefix.
+    :param int results_per_page: The maximum number of blobs to retrieve per
         call.
     :param str continuation_token: An opaque continuation token.
+    :param location_mode: Specifies the location the request should be sent to.
+        This mode only applies for RA-GRS accounts which allow secondary read access.
+        Options include 'primary' or 'secondary'.
     """
-
     def __init__(
             self, command,
-            recursive,
-            path=None,
-            max_results=None,
+            container=None,
+            prefix=None,
+            results_per_page=None,
             continuation_token=None,
-            upn=None):
-        super(PathPropertiesPaged, self).__init__(
+            location_mode=None):
+        super(BlobNamesPaged, self).__init__(
             get_next=self._get_next_cb,
             extract_data=self._extract_data_cb,
             continuation_token=continuation_token or ""
         )
         self._command = command
-        self.recursive = recursive
-        self.results_per_page = max_results
-        self.path = path
-        self.upn = upn
+        self.service_endpoint = None
+        self.prefix = prefix
+        self.marker = None
+        self.results_per_page = results_per_page
+        self.container = container
         self.current_page = None
-        self.path_list = None
+        self.location_mode = location_mode
 
     async def _get_next_cb(self, continuation_token):
         try:
             return await self._command(
-                self.recursive,
-                continuation=continuation_token or None,
-                path=self.path,
-                max_results=self.results_per_page,
-                upn=self.upn,
-                cls=return_headers_and_deserialized_path_list)
+                prefix=self.prefix,
+                marker=continuation_token or None,
+                maxresults=self.results_per_page,
+                cls=return_raw_deserialized,
+                use_location=self.location_mode)
         except HttpResponseError as error:
             process_storage_error(error)
 
     async def _extract_data_cb(self, get_next_return):
-        self.path_list, self._response = get_next_return
-        self.current_page = [self._build_item(item) for item in self.path_list]
+        self.location_mode, self._response = get_next_return
+        self.service_endpoint = self._response.get('ServiceEndpoint')
+        self.prefix = load_xml_string(self._response, 'Prefix')
+        self.marker = load_xml_string(self._response, 'Marker')
+        self.results_per_page = load_xml_int(self._response, 'MaxResults')
+        self.container = self._response.get('ContainerName')
 
-        return self._response['continuation'] or None, self.current_page
+        blobs = load_many_xml_nodes(self._response, 'Blob', wrapper='Blobs')
+        self.current_page = [load_xml_string(blob, 'Name') for blob in blobs]
 
-    @staticmethod
-    def _build_item(item):
-        if isinstance(item, PathProperties):
-            return item
-        if isinstance(item, Path):
-            path = PathProperties._from_generated(item)  # pylint: disable=protected-access
-            return path
+        next_marker = load_xml_string(self._response, 'NextMarker')
+        return next_marker or None, self.current_page
+
+
+class BlobPrefix(AsyncItemPaged, DictMixin):
+    """An Iterable of Blob properties.
+
+    Returned from walk_blobs when a delimiter is used.
+    Can be thought of as a virtual blob directory.
+
+    :ivar str name: The prefix, or "directory name" of the blob.
+    :ivar str prefix: A blob name prefix being used to filter the list.
+    :ivar int results_per_page: The maximum number of results retrieved per API call.
+    :ivar str marker: The continuation token of the current page of results.
+    :ivar str location_mode: The location mode being used to list results. The available
+        options include "primary" and "secondary".
+    :ivar current_page: The current page of listed results.
+    :vartype current_page: list(~azure.storage.blob.models.BlobProperties)
+    :ivar str container: The container that the blobs are listed from.
+    :ivar str delimiter: A delimiting character used for hierarchy listing.
+    :param callable command: Function to retrieve the next page of items.
+    :param str prefix: Filters the results to return only blobs whose names
+        begin with the specified prefix.
+    :param int results_per_page: The maximum number of blobs to retrieve per
+        call.
+    :param str marker: An opaque continuation token.
+    :param str delimiter:
+        Used to capture blobs whose names begin with the same substring up to
+        the appearance of the delimiter character. The delimiter may be a single
+        character or a string.
+    :param location_mode: Specifies the location the request should be sent to.
+        This mode only applies for RA-GRS accounts which allow secondary read access.
+        Options include 'primary' or 'secondary'.
+    """
+    def __init__(self, *args, **kwargs):
+        super(BlobPrefix, self).__init__(*args, page_iterator_class=BlobPrefixPaged, **kwargs)
+        self.name = kwargs.get('prefix')
+        self.prefix = kwargs.get('prefix')
+        self.results_per_page = kwargs.get('results_per_page')
+        self.container = kwargs.get('container')
+        self.delimiter = kwargs.get('delimiter')
+        self.location_mode = kwargs.get('location_mode')
+
+
+class BlobPrefixPaged(BlobPropertiesPaged):
+    def __init__(self, *args, **kwargs):
+        super(BlobPrefixPaged, self).__init__(*args, **kwargs)
+        self.name = self.prefix
+
+    async def _extract_data_cb(self, get_next_return):
+        continuation_token, _ = await super(BlobPrefixPaged, self)._extract_data_cb(get_next_return)
+        self.current_page = self._response.segment.blob_prefixes + self._response.segment.blob_items
+        self.current_page = [self._build_item(item) for item in self.current_page]
+        self.delimiter = self._response.delimiter
+
+        return continuation_token, self.current_page
+
+    def _build_item(self, item):
+        item = super(BlobPrefixPaged, self)._build_item(item)
+        if isinstance(item, GenBlobPrefix):
+            if item.name.encoded:
+                name = unquote(item.name.content)
+            else:
+                name = item.name.content
+            return BlobPrefix(
+                self._command,
+                container=self.container,
+                prefix=name,
+                results_per_page=self.results_per_page,
+                location_mode=self.location_mode)
         return item
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_path_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_path_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_upload_helper.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/aio/_upload_helper.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_directory_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_directory_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_download.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_download.py`

 * *Files 17% similar despite different names*

```diff
@@ -4,106 +4,69 @@
 # license information.
 # --------------------------------------------------------------------------
 
 import sys
 import threading
 import warnings
 from io import BytesIO
+from typing import Iterator
 
-from azure.core.exceptions import HttpResponseError
+from azure.core.exceptions import HttpResponseError, ResourceModifiedError
 from azure.core.tracing.common import with_current_context
-from ._shared.encryption import decrypt_blob
 from ._shared.request_handlers import validate_and_format_range_headers
 from ._shared.response_handlers import process_storage_error, parse_length_from_content_range
 
 
-def process_range_and_offset(start_range, end_range, length, encryption):
-    start_offset, end_offset = 0, 0
-    if encryption.get("key") is not None or encryption.get("resolver") is not None:
-        if start_range is not None:
-            # Align the start of the range along a 16 byte block
-            start_offset = start_range % 16
-            start_range -= start_offset
-
-            # Include an extra 16 bytes for the IV if necessary
-            # Because of the previous offsetting, start_range will always
-            # be a multiple of 16.
-            if start_range > 0:
-                start_offset += 16
-                start_range -= 16
-
-        if length is not None:
-            # Align the end of the range along a 16 byte block
-            end_offset = 15 - (end_range % 16)
-            end_range += end_offset
-
-    return (start_range, end_range), (start_offset, end_offset)
-
-
-def process_content(data, start_offset, end_offset, encryption):
+def process_content(data):
     if data is None:
         raise ValueError("Response cannot be None.")
+
     try:
-        content = b"".join(list(data))
+        return b"".join(list(data))
     except Exception as error:
         raise HttpResponseError(message="Download stream interrupted.", response=data.response, error=error)
-    if content and encryption.get("key") is not None or encryption.get("resolver") is not None:
-        try:
-            return decrypt_blob(
-                encryption.get("required"),
-                encryption.get("key"),
-                encryption.get("resolver"),
-                content,
-                start_offset,
-                end_offset,
-                data.response.headers,
-            )
-        except Exception as error:
-            raise HttpResponseError(message="Decryption failed.", response=data.response, error=error)
-    return content
 
 
 class _ChunkDownloader(object):  # pylint: disable=too-many-instance-attributes
     def __init__(
         self,
         client=None,
         total_size=None,
         chunk_size=None,
         current_progress=None,
         start_range=None,
         end_range=None,
         stream=None,
         parallel=None,
         validate_content=None,
-        encryption_options=None,
+        progress_hook=None,
+        etag=None,
         **kwargs
     ):
         self.client = client
-
+        self.etag = etag
         # Information on the download range/chunk size
         self.chunk_size = chunk_size
         self.total_size = total_size
         self.start_index = start_range
         self.end_index = end_range
 
         # The destination that we will write to
         self.stream = stream
         self.stream_lock = threading.Lock() if parallel else None
         self.progress_lock = threading.Lock() if parallel else None
+        self.progress_hook = progress_hook
 
         # For a parallel download, the stream is always seekable, so we note down the current position
         # in order to seek to the right place when out-of-order chunks come in
         self.stream_start = stream.tell() if parallel else None
 
         # Download progress so far
         self.progress_total = current_progress
 
-        # Encryption
-        self.encryption_options = encryption_options
-
         # Parameters for each get operation
         self.validate_content = validate_content
         self.request_options = kwargs
 
     def _calculate_range(self, chunk_start):
         if chunk_start + self.chunk_size > self.end_index:
             chunk_end = self.end_index
@@ -132,51 +95,55 @@
     def _update_progress(self, length):
         if self.progress_lock:
             with self.progress_lock:  # pylint: disable=not-context-manager
                 self.progress_total += length
         else:
             self.progress_total += length
 
+        if self.progress_hook:
+            self.progress_hook(self.progress_total, self.total_size)
+
     def _write_to_stream(self, chunk_data, chunk_start):
         if self.stream_lock:
             with self.stream_lock:  # pylint: disable=not-context-manager
                 self.stream.seek(self.stream_start + (chunk_start - self.start_index))
                 self.stream.write(chunk_data)
         else:
             self.stream.write(chunk_data)
 
     def _download_chunk(self, chunk_start, chunk_end):
-        download_range, offset = process_range_and_offset(
-            chunk_start, chunk_end, chunk_end, self.encryption_options
-        )
         range_header, range_validation = validate_and_format_range_headers(
-            download_range[0], download_range[1], check_content_md5=self.validate_content
+            chunk_start, chunk_end, check_content_md5=self.validate_content
         )
 
         try:
             _, response = self.client.download(
                 range=range_header,
                 range_get_content_md5=range_validation,
                 validate_content=self.validate_content,
                 data_stream_total=self.total_size,
                 download_stream_current=self.progress_total,
                 **self.request_options
             )
+            if response.properties.etag != self.etag:
+                raise ResourceModifiedError(message="The file has been modified while downloading.")
+
         except HttpResponseError as error:
             process_storage_error(error)
 
-        chunk_data = process_content(response, offset[0], offset[1], self.encryption_options)
+        chunk_data = process_content(response)
         return chunk_data
 
 
 class _ChunkIterator(object):
     """Async iterator for chunks in blob download stream."""
 
-    def __init__(self, size, content, downloader):
+    def __init__(self, size, content, downloader, chunk_size):
         self.size = size
+        self._chunk_size = chunk_size
         self._current_content = content
         self._iter_downloader = downloader
         self._iter_chunks = None
         self._complete = (size == 0)
 
     def __len__(self):
         return self.size
@@ -185,55 +152,70 @@
         return self
 
     def __next__(self):
         """Iterate through responses."""
         if self._complete:
             raise StopIteration("Download complete")
         if not self._iter_downloader:
-            # If no iterator was supplied, the download completed with
-            # the initial GET, so we just return that data
+            # cut the data obtained from initial GET into chunks
+            if len(self._current_content) > self._chunk_size:
+                return self._get_chunk_data()
             self._complete = True
             return self._current_content
 
         if not self._iter_chunks:
             self._iter_chunks = self._iter_downloader.get_chunk_offsets()
-        else:
+
+        # initial GET result still has more than _chunk_size bytes of data
+        if len(self._current_content) >= self._chunk_size:
+            return self._get_chunk_data()
+
+        try:
             chunk = next(self._iter_chunks)
-            self._current_content = self._iter_downloader.yield_chunk(chunk)
+            self._current_content += self._iter_downloader.yield_chunk(chunk)
+        except StopIteration as e:
+            self._complete = True
+            if self._current_content:
+                return self._current_content
+            raise e
 
-        return self._current_content
+        return self._get_chunk_data()
 
     next = __next__  # Python 2 compatibility.
 
+    def _get_chunk_data(self):
+        chunk_data = self._current_content[: self._chunk_size]
+        self._current_content = self._current_content[self._chunk_size:]
+        return chunk_data
+
 
 class StorageStreamDownloader(object):  # pylint: disable=too-many-instance-attributes
     """A streaming object to download from Azure Storage.
 
     :ivar str name:
         The name of the file being downloaded.
     :ivar: str path:
         The full path of the file.
     :ivar str share:
         The name of the share where the file is.
     :ivar ~azure.storage.fileshare.FileProperties properties:
         The properties of the file being downloaded. If only a range of the data is being
         downloaded, this will be reflected in the properties.
     :ivar int size:
-        The size of the total data in the stream. This will be the byte range if speficied,
+        The size of the total data in the stream. This will be the byte range if specified,
         otherwise the total size of the file.
     """
 
     def __init__(
         self,
         client=None,
         config=None,
         start_range=None,
         end_range=None,
         validate_content=None,
-        encryption_options=None,
         max_concurrency=1,
         name=None,
         path=None,
         share=None,
         encoding=None,
         **kwargs
     ):
@@ -246,37 +228,36 @@
         self._client = client
         self._config = config
         self._start_range = start_range
         self._end_range = end_range
         self._max_concurrency = max_concurrency
         self._encoding = encoding
         self._validate_content = validate_content
-        self._encryption_options = encryption_options or {}
+        self._progress_hook = kwargs.pop('progress_hook', None)
         self._request_options = kwargs
         self._location_mode = None
         self._download_complete = False
         self._current_content = None
         self._file_size = None
         self._response = None
+        self._etag = None
 
         # The service only provides transactional MD5s for chunks under 4MB.
         # If validate_content is on, get only self.MAX_CHUNK_GET_SIZE for the first
         # chunk so a transactional MD5 can be retrieved.
         self._first_get_size = (
             self._config.max_single_get_size if not self._validate_content else self._config.max_chunk_get_size
         )
         initial_request_start = self._start_range if self._start_range is not None else 0
         if self._end_range is not None and self._end_range - self._start_range < self._first_get_size:
             initial_request_end = self._end_range
         else:
             initial_request_end = initial_request_start + self._first_get_size - 1
 
-        self._initial_range, self._initial_offset = process_range_and_offset(
-            initial_request_start, initial_request_end, self._end_range, self._encryption_options
-        )
+        self._initial_range = (initial_request_start, initial_request_end)
 
         self._response = self._initial_request()
         self.properties = self._response.properties
         self.properties.name = self.name
         self.properties.path = self.path
         self.properties.share = self.share
 
@@ -295,20 +276,15 @@
         # of the stored MD5
         # TODO: Set to the stored MD5 when the service returns this
         self.properties.content_md5 = None
 
         if self.size == 0:
             self._current_content = b""
         else:
-            self._current_content = process_content(
-                self._response,
-                self._initial_offset[0],
-                self._initial_offset[1],
-                self._encryption_options
-            )
+            self._current_content = process_content(self._response)
 
     def __len__(self):
         return self.size
 
     def _initial_request(self):
         range_header, range_validation = validate_and_format_range_headers(
             self._initial_range[0],
@@ -331,24 +307,27 @@
             # Check the location we read from to ensure we use the same one
             # for subsequent requests.
             self._location_mode = location_mode
 
             # Parse the total file size and adjust the download size if ranges
             # were specified
             self._file_size = parse_length_from_content_range(response.properties.content_range)
+            if self._file_size is None:
+                raise ValueError("Required Content-Range response header is missing or malformed.")
+
             if self._end_range is not None:
                 # Use the end range index unless it is over the end of the file
                 self.size = min(self._file_size, self._end_range - self._start_range + 1)
             elif self._start_range is not None:
                 self.size = self._file_size - self._start_range
             else:
                 self.size = self._file_size
 
         except HttpResponseError as error:
-            if self._start_range is None and error.response.status_code == 416:
+            if self._start_range is None and error.response and error.response.status_code == 416:
                 # Get range will fail on an empty file. If the user did not
                 # request a range, do a regular get request in order to get
                 # any properties.
                 try:
                     _, response = self._client.download(
                         validate_content=self._validate_content,
                         data_stream_total=0,
@@ -364,17 +343,23 @@
             else:
                 process_storage_error(error)
 
         # If the file is small, the download is complete at this point.
         # If file size is large, download the rest of the file in chunks.
         if response.properties.size == self.size:
             self._download_complete = True
+        self._etag = response.properties.etag
         return response
 
     def chunks(self):
+        # type: () -> Iterator[bytes]
+        """Iterate over chunks in the download stream.
+
+        :rtype: Iterator[bytes]
+        """
         if self.size == 0 or self._download_complete:
             iter_downloader = None
         else:
             data_end = self._file_size
             if self._end_range is not None:
                 # Use the end range index unless it is over the end of the file
                 data_end = min(self._file_size, self._end_range + 1)
@@ -384,57 +369,63 @@
                 chunk_size=self._config.max_chunk_get_size,
                 current_progress=self._first_get_size,
                 start_range=self._initial_range[1] + 1,  # start where the first download ended
                 end_range=data_end,
                 stream=None,
                 parallel=False,
                 validate_content=self._validate_content,
-                encryption_options=self._encryption_options,
                 use_location=self._location_mode,
+                etag=self._etag,
                 **self._request_options
             )
         return _ChunkIterator(
             size=self.size,
             content=self._current_content,
-            downloader=iter_downloader)
+            downloader=iter_downloader,
+            chunk_size=self._config.max_chunk_get_size)
 
     def readall(self):
+        # type: () -> bytes
         """Download the contents of this file.
 
         This operation is blocking until all data is downloaded.
-        :rtype: bytes or str
+        :rtype: bytes
         """
         stream = BytesIO()
         self.readinto(stream)
         data = stream.getvalue()
         if self._encoding:
             return data.decode(self._encoding)
         return data
 
     def content_as_bytes(self, max_concurrency=1):
-        """Download the contents of this file.
+        """DEPRECATED: Download the contents of this file.
 
         This operation is blocking until all data is downloaded.
 
+        This method is deprecated, use func:`readall` instead.
+
         :keyword int max_concurrency:
             The number of parallel connections with which to download.
         :rtype: bytes
         """
         warnings.warn(
             "content_as_bytes is deprecated, use readall instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
         return self.readall()
 
     def content_as_text(self, max_concurrency=1, encoding="UTF-8"):
-        """Download the contents of this file, and decode as text.
+        """DEPRECATED: Download the contents of this file, and decode as text.
 
         This operation is blocking until all data is downloaded.
 
+        This method is deprecated, use func:`readall` instead.
+
         :keyword int max_concurrency:
             The number of parallel connections with which to download.
         :param str encoding:
             Test encoding to decode the downloaded bytes. Default is UTF-8.
         :rtype: str
         """
         warnings.warn(
@@ -465,14 +456,17 @@
             try:
                 stream.seek(stream.tell())
             except (NotImplementedError, AttributeError):
                 raise ValueError(error_message)
 
         # Write the content to the user stream
         stream.write(self._current_content)
+        if self._progress_hook:
+            self._progress_hook(len(self._current_content), self.size)
+
         if self._download_complete:
             return self.size
 
         data_end = self._file_size
         if self._end_range is not None:
             # Use the length unless it is over the end of the file
             data_end = min(self._file_size, self._end_range + 1)
@@ -483,32 +477,35 @@
             chunk_size=self._config.max_chunk_get_size,
             current_progress=self._first_get_size,
             start_range=self._initial_range[1] + 1,  # Start where the first download ended
             end_range=data_end,
             stream=stream,
             parallel=parallel,
             validate_content=self._validate_content,
-            encryption_options=self._encryption_options,
             use_location=self._location_mode,
+            progress_hook=self._progress_hook,
+            etag=self._etag,
             **self._request_options
         )
         if parallel:
             import concurrent.futures
-            executor = concurrent.futures.ThreadPoolExecutor(self._max_concurrency)
-            list(executor.map(
-                    with_current_context(downloader.process_chunk),
-                    downloader.get_chunk_offsets()
-                ))
+            with concurrent.futures.ThreadPoolExecutor(self._max_concurrency) as executor:
+                list(executor.map(
+                        with_current_context(downloader.process_chunk),
+                        downloader.get_chunk_offsets()
+                    ))
         else:
             for chunk in downloader.get_chunk_offsets():
                 downloader.process_chunk(chunk)
         return self.size
 
     def download_to_stream(self, stream, max_concurrency=1):
-        """Download the contents of this file to a stream.
+        """DEPRECATED: Download the contents of this file to a stream.
+
+        This method is deprecated, use func:`readinto` instead.
 
         :param stream:
             The stream to download to. This can be an open file-handle,
             or any writable stream. The stream must be seekable if the download
             uses more than one parallel connection.
         :returns: The properties of the downloaded file.
         :rtype: Any
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_file_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_file_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_azure_file_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_azure_file_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_azure_file_storage_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_azure_file_storage_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_configuration_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/_configuration_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_directory_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_file_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_file_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_share_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/aio/operations_async/_share_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_azure_file_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_azure_file_storage_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_directory_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_directory_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_file_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_file_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_share_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_generated/operations/_share_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_lease.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_serialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_share_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/response_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_directory_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_directory_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_download_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_download_async.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,49 +1,34 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
-
+# pylint: disable=invalid-overridden-method
 import asyncio
 import sys
+import warnings
 from io import BytesIO
 from itertools import islice
-import warnings
+from typing import AsyncIterator
 
-from azure.core.exceptions import HttpResponseError
-from .._shared.encryption import decrypt_blob
+from azure.core.exceptions import HttpResponseError, ResourceModifiedError
+from .._download import _ChunkDownloader
 from .._shared.request_handlers import validate_and_format_range_headers
 from .._shared.response_handlers import process_storage_error, parse_length_from_content_range
-from .._download import process_range_and_offset, _ChunkDownloader
 
 
-async def process_content(data, start_offset, end_offset, encryption):
+async def process_content(data):
     if data is None:
         raise ValueError("Response cannot be None.")
+
     try:
-        content = data.response.body()
+        return data.response.body()
     except Exception as error:
         raise HttpResponseError(message="Download stream interrupted.", response=data.response, error=error)
-    if encryption.get('key') is not None or encryption.get('resolver') is not None:
-        try:
-            return decrypt_blob(
-                encryption.get('required'),
-                encryption.get('key'),
-                encryption.get('resolver'),
-                content,
-                start_offset,
-                end_offset,
-                data.response.headers)
-        except Exception as error:
-            raise HttpResponseError(
-                message="Decryption failed.",
-                response=data.response,
-                error=error)
-    return content
 
 
 class _AsyncChunkDownloader(_ChunkDownloader):
     def __init__(self, **kwargs):
         super(_AsyncChunkDownloader, self).__init__(**kwargs)
         self.stream_lock = asyncio.Lock() if kwargs.get('parallel') else None
         self.progress_lock = asyncio.Lock() if kwargs.get('parallel') else None
@@ -63,52 +48,55 @@
     async def _update_progress(self, length):
         if self.progress_lock:
             async with self.progress_lock:  # pylint: disable=not-async-context-manager
                 self.progress_total += length
         else:
             self.progress_total += length
 
+        if self.progress_hook:
+            await self.progress_hook(self.progress_total, self.total_size)
+
     async def _write_to_stream(self, chunk_data, chunk_start):
         if self.stream_lock:
             async with self.stream_lock:  # pylint: disable=not-async-context-manager
                 self.stream.seek(self.stream_start + (chunk_start - self.start_index))
                 self.stream.write(chunk_data)
         else:
             self.stream.write(chunk_data)
 
     async def _download_chunk(self, chunk_start, chunk_end):
-        download_range, offset = process_range_and_offset(
-            chunk_start, chunk_end, chunk_end, self.encryption_options
-        )
         range_header, range_validation = validate_and_format_range_headers(
-            download_range[0],
-            download_range[1],
+            chunk_start,
+            chunk_end,
             check_content_md5=self.validate_content
         )
         try:
             _, response = await self.client.download(
                 range=range_header,
                 range_get_content_md5=range_validation,
                 validate_content=self.validate_content,
                 data_stream_total=self.total_size,
                 download_stream_current=self.progress_total,
                 **self.request_options
             )
+            if response.properties.etag != self.etag:
+                raise ResourceModifiedError(message="The file has been modified while downloading.")
         except HttpResponseError as error:
             process_storage_error(error)
 
-        chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)
+        chunk_data = await process_content(response)
         return chunk_data
 
 
 class _AsyncChunkIterator(object):
-    """Async iterator for chunks in file download stream."""
+    """Async iterator for chunks in blob download stream."""
 
-    def __init__(self, size, content, downloader):
+    def __init__(self, size, content, downloader, chunk_size):
         self.size = size
+        self._chunk_size = chunk_size
         self._current_content = content
         self._iter_downloader = downloader
         self._iter_chunks = None
         self._complete = (size == 0)
 
     def __len__(self):
         return self.size
@@ -120,29 +108,43 @@
         return self
 
     async def __anext__(self):
         """Iterate through responses."""
         if self._complete:
             raise StopAsyncIteration("Download complete")
         if not self._iter_downloader:
-            # If no iterator was supplied, the download completed with
-            # the initial GET, so we just return that data
+            # cut the data obtained from initial GET into chunks
+            if len(self._current_content) > self._chunk_size:
+                return self._get_chunk_data()
             self._complete = True
             return self._current_content
 
         if not self._iter_chunks:
             self._iter_chunks = self._iter_downloader.get_chunk_offsets()
-        else:
-            try:
-                chunk = next(self._iter_chunks)
-            except StopIteration:
-                raise StopAsyncIteration("Download complete")
-            self._current_content = await self._iter_downloader.yield_chunk(chunk)
 
-        return self._current_content
+        # initial GET result still has more than _chunk_size bytes of data
+        if len(self._current_content) >= self._chunk_size:
+            return self._get_chunk_data()
+
+        try:
+            chunk = next(self._iter_chunks)
+            self._current_content += await self._iter_downloader.yield_chunk(chunk)
+        except StopIteration:
+            self._complete = True
+            # it's likely that there some data left in self._current_content
+            if self._current_content:
+                return self._current_content
+            raise StopAsyncIteration("Download complete")
+
+        return self._get_chunk_data()
+
+    def _get_chunk_data(self):
+        chunk_data = self._current_content[: self._chunk_size]
+        self._current_content = self._current_content[self._chunk_size:]
+        return chunk_data
 
 
 class StorageStreamDownloader(object):  # pylint: disable=too-many-instance-attributes
     """A streaming object to download from Azure Storage.
 
     :ivar str name:
         The name of the file being downloaded.
@@ -150,26 +152,25 @@
         The full path of the file.
     :ivar str share:
         The name of the share where the file is.
     :ivar ~azure.storage.fileshare.FileProperties properties:
         The properties of the file being downloaded. If only a range of the data is being
         downloaded, this will be reflected in the properties.
     :ivar int size:
-        The size of the total data in the stream. This will be the byte range if speficied,
+        The size of the total data in the stream. This will be the byte range if specified,
         otherwise the total size of the file.
     """
 
     def __init__(
             self,
             client=None,
             config=None,
             start_range=None,
             end_range=None,
             validate_content=None,
-            encryption_options=None,
             max_concurrency=1,
             name=None,
             path=None,
             share=None,
             encoding=None,
             **kwargs
     ):
@@ -182,36 +183,35 @@
         self._client = client
         self._config = config
         self._start_range = start_range
         self._end_range = end_range
         self._max_concurrency = max_concurrency
         self._encoding = encoding
         self._validate_content = validate_content
-        self._encryption_options = encryption_options or {}
+        self._progress_hook = kwargs.pop('progress_hook', None)
         self._request_options = kwargs
         self._location_mode = None
         self._download_complete = False
         self._current_content = None
         self._file_size = None
         self._response = None
+        self._etag = None
 
         # The service only provides transactional MD5s for chunks under 4MB.
         # If validate_content is on, get only self.MAX_CHUNK_GET_SIZE for the first
         # chunk so a transactional MD5 can be retrieved.
         self._first_get_size = self._config.max_single_get_size if not self._validate_content \
             else self._config.max_chunk_get_size
         initial_request_start = self._start_range if self._start_range is not None else 0
         if self._end_range is not None and self._end_range - self._start_range < self._first_get_size:
             initial_request_end = self._end_range
         else:
             initial_request_end = initial_request_start + self._first_get_size - 1
 
-        self._initial_range, self._initial_offset = process_range_and_offset(
-            initial_request_start, initial_request_end, self._end_range, self._encryption_options
-        )
+        self._initial_range = (initial_request_start, initial_request_end)
 
     def __len__(self):
         return self.size
 
     async def _setup(self):
         self._response = await self._initial_request()
         self.properties = self._response.properties
@@ -234,20 +234,15 @@
         # of the stored MD5
         # TODO: Set to the stored MD5 when the service returns this
         self.properties.content_md5 = None
 
         if self.size == 0:
             self._current_content = b""
         else:
-            self._current_content = await process_content(
-                self._response,
-                self._initial_offset[0],
-                self._initial_offset[1],
-                self._encryption_options
-            )
+            self._current_content = await process_content(self._response)
 
     async def _initial_request(self):
         range_header, range_validation = validate_and_format_range_headers(
             self._initial_range[0],
             self._initial_range[1],
             start_range_required=False,
             end_range_required=False,
@@ -265,24 +260,27 @@
             # Check the location we read from to ensure we use the same one
             # for subsequent requests.
             self._location_mode = location_mode
 
             # Parse the total file size and adjust the download size if ranges
             # were specified
             self._file_size = parse_length_from_content_range(response.properties.content_range)
+            if self._file_size is None:
+                raise ValueError("Required Content-Range response header is missing or malformed.")
+
             if self._end_range is not None:
                 # Use the length unless it is over the end of the file
                 self.size = min(self._file_size, self._end_range - self._start_range + 1)
             elif self._start_range is not None:
                 self.size = self._file_size - self._start_range
             else:
                 self.size = self._file_size
 
         except HttpResponseError as error:
-            if self._start_range is None and error.response.status_code == 416:
+            if self._start_range is None and error.response and error.response.status_code == 416:
                 # Get range will fail on an empty file. If the user did not
                 # request a range, do a regular get request in order to get
                 # any properties.
                 try:
                     _, response = await self._client.download(
                         validate_content=self._validate_content,
                         data_stream_total=0,
@@ -297,20 +295,22 @@
             else:
                 process_storage_error(error)
 
         # If the file is small, the download is complete at this point.
         # If file size is large, download the rest of the file in chunks.
         if response.properties.size == self.size:
             self._download_complete = True
+        self._etag = response.properties.etag
         return response
 
     def chunks(self):
+        # type: () -> AsyncIterator[bytes]
         """Iterate over chunks in the download stream.
 
-        :rtype: Iterable[bytes]
+        :rtype: AsyncIterator[bytes]
         """
         if self.size == 0 or self._download_complete:
             iter_downloader = None
         else:
             data_end = self._file_size
             if self._end_range is not None:
                 # Use the length unless it is over the end of the file
@@ -321,56 +321,63 @@
                 chunk_size=self._config.max_chunk_get_size,
                 current_progress=self._first_get_size,
                 start_range=self._initial_range[1] + 1,  # Start where the first download ended
                 end_range=data_end,
                 stream=None,
                 parallel=False,
                 validate_content=self._validate_content,
-                encryption_options=self._encryption_options,
                 use_location=self._location_mode,
+                etag=self._etag,
                 **self._request_options)
         return _AsyncChunkIterator(
             size=self.size,
             content=self._current_content,
-            downloader=iter_downloader)
+            downloader=iter_downloader,
+            chunk_size=self._config.max_chunk_get_size
+        )
 
     async def readall(self):
+        # type: () -> bytes
         """Download the contents of this file.
 
         This operation is blocking until all data is downloaded.
-        :rtype: bytes or str
+        :rtype: bytes
         """
         stream = BytesIO()
         await self.readinto(stream)
         data = stream.getvalue()
         if self._encoding:
             return data.decode(self._encoding)
         return data
 
     async def content_as_bytes(self, max_concurrency=1):
-        """Download the contents of this file.
+        """DEPRECATED: Download the contents of this file.
 
         This operation is blocking until all data is downloaded.
 
+        This method is deprecated, use func:`readall` instead.
+
         :keyword int max_concurrency:
             The number of parallel connections with which to download.
         :rtype: bytes
         """
         warnings.warn(
             "content_as_bytes is deprecated, use readall instead",
             DeprecationWarning
         )
         self._max_concurrency = max_concurrency
         return await self.readall()
 
     async def content_as_text(self, max_concurrency=1, encoding="UTF-8"):
-        """Download the contents of this file, and decode as text.
+        """DEPRECATED: Download the contents of this file, and decode as text.
 
         This operation is blocking until all data is downloaded.
 
+        This method is deprecated, use func:`readall` instead.
+
         :keyword int max_concurrency:
             The number of parallel connections with which to download.
         :param str encoding:
             Test encoding to decode the downloaded bytes. Default is UTF-8.
         :rtype: str
         """
         warnings.warn(
@@ -401,14 +408,17 @@
             try:
                 stream.seek(stream.tell())
             except (NotImplementedError, AttributeError):
                 raise ValueError(error_message)
 
         # Write the content to the user stream
         stream.write(self._current_content)
+        if self._progress_hook:
+            await self._progress_hook(len(self._current_content), self.size)
+
         if self._download_complete:
             return self.size
 
         data_end = self._file_size
         if self._end_range is not None:
             # Use the length unless it is over the end of the file
             data_end = min(self._file_size, self._end_range + 1)
@@ -419,16 +429,17 @@
             chunk_size=self._config.max_chunk_get_size,
             current_progress=self._first_get_size,
             start_range=self._initial_range[1] + 1,  # start where the first download ended
             end_range=data_end,
             stream=stream,
             parallel=parallel,
             validate_content=self._validate_content,
-            encryption_options=self._encryption_options,
             use_location=self._location_mode,
+            progress_hook=self._progress_hook,
+            etag=self._etag,
             **self._request_options)
 
         dl_tasks = downloader.get_chunk_offsets()
         running_futures = [
             asyncio.ensure_future(downloader.process_chunk(d))
             for d in islice(dl_tasks, 0, self._max_concurrency)
         ]
@@ -447,14 +458,16 @@
             # Wait for the remaining downloads to finish
             await asyncio.wait(running_futures)
         return self.size
 
     async def download_to_stream(self, stream, max_concurrency=1):
         """Download the contents of this file to a stream.
 
+        This method is deprecated, use func:`readinto` instead.
+
         :param stream:
             The stream to download to. This can be an open file-handle,
             or any writable stream. The stream must be seekable if the download
             uses more than one parallel connection.
         :returns: The properties of the downloaded file.
         :rtype: Any
         """
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_file_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_file_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_lease_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2019_07_07/aio/_share_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_directory_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_directory_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_file_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_file_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_azure_file_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_azure_file_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_serialization.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_serialization.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_vendor.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_vendor.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_azure_file_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_azure_file_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/aio/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_directory_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_directory_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_file_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_file_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_share_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/operations/_share_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_azure_file_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_azure_file_storage_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/models/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_directory_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_directory_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_file_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_share_operations.py`

 * *Files 22% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 import sys
-from typing import Any, Callable, Dict, IO, Iterator, Optional, TypeVar, Union
+from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union, overload
 
 from azure.core.exceptions import (
     ClientAuthenticationError,
     HttpResponseError,
     ResourceExistsError,
     ResourceNotFoundError,
     ResourceNotModifiedError,
@@ -37,1180 +37,812 @@
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 
 
 def build_create_request(
     url: str,
     *,
-    file_content_length: int,
     timeout: Optional[int] = None,
-    file_content_type: Optional[str] = None,
-    file_content_encoding: Optional[str] = None,
-    file_content_language: Optional[str] = None,
-    file_cache_control: Optional[str] = None,
-    file_content_md5: Optional[bytes] = None,
-    file_content_disposition: Optional[str] = None,
     metadata: Optional[Dict[str, str]] = None,
-    file_permission: str = "inherit",
-    file_permission_key: Optional[str] = None,
-    file_attributes: str = "none",
-    file_creation_time: str = "now",
-    file_last_write_time: str = "now",
-    file_change_time: Optional[str] = None,
-    lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    quota: Optional[int] = None,
+    access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
+    enabled_protocols: Optional[str] = None,
+    root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    file_type_constant: Literal["file"] = kwargs.pop("file_type_constant", _headers.pop("x-ms-type", "file"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    _headers["x-ms-content-length"] = _SERIALIZER.header("file_content_length", file_content_length, "int")
-    _headers["x-ms-type"] = _SERIALIZER.header("file_type_constant", file_type_constant, "str")
-    if file_content_type is not None:
-        _headers["x-ms-content-type"] = _SERIALIZER.header("file_content_type", file_content_type, "str")
-    if file_content_encoding is not None:
-        _headers["x-ms-content-encoding"] = _SERIALIZER.header("file_content_encoding", file_content_encoding, "str")
-    if file_content_language is not None:
-        _headers["x-ms-content-language"] = _SERIALIZER.header("file_content_language", file_content_language, "str")
-    if file_cache_control is not None:
-        _headers["x-ms-cache-control"] = _SERIALIZER.header("file_cache_control", file_cache_control, "str")
-    if file_content_md5 is not None:
-        _headers["x-ms-content-md5"] = _SERIALIZER.header("file_content_md5", file_content_md5, "bytearray")
-    if file_content_disposition is not None:
-        _headers["x-ms-content-disposition"] = _SERIALIZER.header(
-            "file_content_disposition", file_content_disposition, "str"
-        )
     if metadata is not None:
         _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    if file_permission is not None:
-        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
-    if file_permission_key is not None:
-        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
-    _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
-    if file_creation_time is not None:
-        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
-    if file_last_write_time is not None:
-        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
-    if file_change_time is not None:
-        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_download_request(
-    url: str,
-    *,
-    timeout: Optional[int] = None,
-    range: Optional[str] = None,
-    range_get_content_md5: Optional[bool] = None,
-    lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
+    if quota is not None:
+        _headers["x-ms-share-quota"] = _SERIALIZER.header("quota", quota, "int", minimum=1)
+    if access_tier is not None:
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("access_tier", access_tier, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if range is not None:
-        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
-    if range_get_content_md5 is not None:
-        _headers["x-ms-range-get-content-md5"] = _SERIALIZER.header(
-            "range_get_content_md5", range_get_content_md5, "bool"
-        )
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if enabled_protocols is not None:
+        _headers["x-ms-enabled-protocols"] = _SERIALIZER.header("enabled_protocols", enabled_protocols, "str")
+    if root_squash is not None:
+        _headers["x-ms-root-squash"] = _SERIALIZER.header("root_squash", root_squash, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_get_properties_request(
     url: str,
     *,
     sharesnapshot: Optional[str] = None,
     timeout: Optional[int] = None,
     lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if sharesnapshot is not None:
         _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="HEAD", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
 def build_delete_request(
     url: str,
     *,
+    sharesnapshot: Optional[str] = None,
     timeout: Optional[int] = None,
+    delete_snapshots: Optional[Union[str, _models.DeleteSnapshotsOptionType]] = None,
     lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if delete_snapshots is not None:
+        _headers["x-ms-delete-snapshots"] = _SERIALIZER.header("delete_snapshots", delete_snapshots, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_http_headers_request(
+def build_acquire_lease_request(
     url: str,
     *,
     timeout: Optional[int] = None,
-    file_content_length: Optional[int] = None,
-    file_content_type: Optional[str] = None,
-    file_content_encoding: Optional[str] = None,
-    file_content_language: Optional[str] = None,
-    file_cache_control: Optional[str] = None,
-    file_content_md5: Optional[bytes] = None,
-    file_content_disposition: Optional[str] = None,
-    file_permission: str = "inherit",
-    file_permission_key: Optional[str] = None,
-    file_attributes: str = "none",
-    file_creation_time: str = "now",
-    file_last_write_time: str = "now",
-    file_change_time: Optional[str] = None,
-    lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    duration: Optional[int] = None,
+    proposed_lease_id: Optional[str] = None,
+    sharesnapshot: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
+    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+    action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    if duration is not None:
+        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
+    if proposed_lease_id is not None:
+        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if file_content_length is not None:
-        _headers["x-ms-content-length"] = _SERIALIZER.header("file_content_length", file_content_length, "int")
-    if file_content_type is not None:
-        _headers["x-ms-content-type"] = _SERIALIZER.header("file_content_type", file_content_type, "str")
-    if file_content_encoding is not None:
-        _headers["x-ms-content-encoding"] = _SERIALIZER.header("file_content_encoding", file_content_encoding, "str")
-    if file_content_language is not None:
-        _headers["x-ms-content-language"] = _SERIALIZER.header("file_content_language", file_content_language, "str")
-    if file_cache_control is not None:
-        _headers["x-ms-cache-control"] = _SERIALIZER.header("file_cache_control", file_cache_control, "str")
-    if file_content_md5 is not None:
-        _headers["x-ms-content-md5"] = _SERIALIZER.header("file_content_md5", file_content_md5, "bytearray")
-    if file_content_disposition is not None:
-        _headers["x-ms-content-disposition"] = _SERIALIZER.header(
-            "file_content_disposition", file_content_disposition, "str"
-        )
-    if file_permission is not None:
-        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
-    if file_permission_key is not None:
-        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
-    _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
-    if file_creation_time is not None:
-        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
-    if file_last_write_time is not None:
-        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
-    if file_change_time is not None:
-        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_metadata_request(
+def build_release_lease_request(
     url: str,
     *,
+    lease_id: str,
     timeout: Optional[int] = None,
-    metadata: Optional[Dict[str, str]] = None,
-    lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    sharesnapshot: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
+    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+    action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
-    if metadata is not None:
-        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
+    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_acquire_lease_request(
+def build_change_lease_request(
     url: str,
     *,
+    lease_id: str,
     timeout: Optional[int] = None,
-    duration: Optional[int] = None,
     proposed_lease_id: Optional[str] = None,
+    sharesnapshot: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
+    action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
     _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    if duration is not None:
-        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
+    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     if proposed_lease_id is not None:
         _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_release_lease_request(
+def build_renew_lease_request(
     url: str,
     *,
     lease_id: str,
     timeout: Optional[int] = None,
+    sharesnapshot: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
+    action: Literal["renew"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
     _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
     _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_change_lease_request(
+def build_break_lease_request(
     url: str,
     *,
-    lease_id: str,
     timeout: Optional[int] = None,
-    proposed_lease_id: Optional[str] = None,
+    break_period: Optional[int] = None,
+    lease_id: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    sharesnapshot: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
     comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
+    action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if sharesnapshot is not None:
+        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
     _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if proposed_lease_id is not None:
-        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    if break_period is not None:
+        _headers["x-ms-lease-break-period"] = _SERIALIZER.header("break_period", break_period, "int")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_break_lease_request(
-    url: str,
-    *,
-    timeout: Optional[int] = None,
-    lease_id: Optional[str] = None,
-    request_id_parameter: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
-    **kwargs: Any
+def build_create_snapshot_request(
+    url: str, *, timeout: Optional[int] = None, metadata: Optional[Dict[str, str]] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["snapshot"] = kwargs.pop("comp", _params.pop("comp", "snapshot"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if metadata is not None:
+        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if request_id_parameter is not None:
-        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_upload_range_request(
+def build_create_permission_request(
     url: str,
     *,
-    range: str,
-    content_length: int,
     timeout: Optional[int] = None,
-    file_range_write: Union[str, _models.FileRangeWriteType] = "update",
-    content_md5: Optional[bytes] = None,
-    lease_id: Optional[str] = None,
-    file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
-    content: Optional[IO] = None,
-    allow_trailing_dot: Optional[bool] = None,
     file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
     content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
-    _headers["x-ms-write"] = _SERIALIZER.header("file_range_write", file_range_write, "str")
-    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
-    if content_md5 is not None:
-        _headers["Content-MD5"] = _SERIALIZER.header("content_md5", content_md5, "bytearray")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if file_last_written_mode is not None:
-        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header(
-            "file_last_written_mode", file_last_written_mode, "str"
-        )
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
     if file_request_intent is not None:
         _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     if content_type is not None:
         _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_upload_range_from_url_request(
+def build_get_permission_request(
     url: str,
     *,
-    range: str,
-    copy_source: str,
-    content_length: int,
+    file_permission_key: str,
     timeout: Optional[int] = None,
-    source_range: Optional[str] = None,
-    source_content_crc64: Optional[bytes] = None,
-    source_if_match_crc64: Optional[bytes] = None,
-    source_if_none_match_crc64: Optional[bytes] = None,
-    lease_id: Optional[str] = None,
-    copy_source_authorization: Optional[str] = None,
-    file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    allow_source_trailing_dot: Optional[bool] = None,
+    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
-    file_range_write_from_url: Literal["update"] = kwargs.pop(
-        "file_range_write_from_url", _headers.pop("x-ms-write", "update")
-    )
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
+    accept = _headers.pop("Accept", "application/json")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
-    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
-    if source_range is not None:
-        _headers["x-ms-source-range"] = _SERIALIZER.header("source_range", source_range, "str")
-    _headers["x-ms-write"] = _SERIALIZER.header("file_range_write_from_url", file_range_write_from_url, "str")
-    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
-    if source_content_crc64 is not None:
-        _headers["x-ms-source-content-crc64"] = _SERIALIZER.header(
-            "source_content_crc64", source_content_crc64, "bytearray"
-        )
-    if source_if_match_crc64 is not None:
-        _headers["x-ms-source-if-match-crc64"] = _SERIALIZER.header(
-            "source_if_match_crc64", source_if_match_crc64, "bytearray"
-        )
-    if source_if_none_match_crc64 is not None:
-        _headers["x-ms-source-if-none-match-crc64"] = _SERIALIZER.header(
-            "source_if_none_match_crc64", source_if_none_match_crc64, "bytearray"
-        )
+    _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if copy_source_authorization is not None:
-        _headers["x-ms-copy-source-authorization"] = _SERIALIZER.header(
-            "copy_source_authorization", copy_source_authorization, "str"
-        )
-    if file_last_written_mode is not None:
-        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header(
-            "file_last_written_mode", file_last_written_mode, "str"
-        )
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if allow_source_trailing_dot is not None:
-        _headers["x-ms-source-allow-trailing-dot"] = _SERIALIZER.header(
-            "allow_source_trailing_dot", allow_source_trailing_dot, "bool"
-        )
+    if file_request_intent is not None:
+        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_get_range_list_request(
+def build_set_properties_request(
     url: str,
     *,
-    sharesnapshot: Optional[str] = None,
-    prevsharesnapshot: Optional[str] = None,
     timeout: Optional[int] = None,
-    range: Optional[str] = None,
+    quota: Optional[int] = None,
+    access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
     lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["rangelist"] = kwargs.pop("comp", _params.pop("comp", "rangelist"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
-    if prevsharesnapshot is not None:
-        _params["prevsharesnapshot"] = _SERIALIZER.query("prevsharesnapshot", prevsharesnapshot, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if range is not None:
-        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if quota is not None:
+        _headers["x-ms-share-quota"] = _SERIALIZER.header("quota", quota, "int", minimum=1)
+    if access_tier is not None:
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("access_tier", access_tier, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if root_squash is not None:
+        _headers["x-ms-root-squash"] = _SERIALIZER.header("root_squash", root_squash, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_start_copy_request(
+def build_set_metadata_request(
     url: str,
     *,
-    copy_source: str,
     timeout: Optional[int] = None,
     metadata: Optional[Dict[str, str]] = None,
-    file_permission: str = "inherit",
-    file_permission_key: Optional[str] = None,
-    file_permission_copy_mode: Optional[Union[str, _models.PermissionCopyModeType]] = None,
-    ignore_read_only: Optional[bool] = None,
-    file_attributes: Optional[str] = None,
-    file_creation_time: Optional[str] = None,
-    file_last_write_time: Optional[str] = None,
-    file_change_time: Optional[str] = None,
-    set_archive_attribute: Optional[bool] = None,
     lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    allow_source_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if metadata is not None:
         _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
-    if file_permission is not None:
-        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
-    if file_permission_key is not None:
-        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
-    if file_permission_copy_mode is not None:
-        _headers["x-ms-file-permission-copy-mode"] = _SERIALIZER.header(
-            "file_permission_copy_mode", file_permission_copy_mode, "str"
-        )
-    if ignore_read_only is not None:
-        _headers["x-ms-file-copy-ignore-readonly"] = _SERIALIZER.header("ignore_read_only", ignore_read_only, "bool")
-    if file_attributes is not None:
-        _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
-    if file_creation_time is not None:
-        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
-    if file_last_write_time is not None:
-        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
-    if file_change_time is not None:
-        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
-    if set_archive_attribute is not None:
-        _headers["x-ms-file-copy-set-archive"] = _SERIALIZER.header(
-            "set_archive_attribute", set_archive_attribute, "bool"
-        )
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if allow_source_trailing_dot is not None:
-        _headers["x-ms-source-allow-trailing-dot"] = _SERIALIZER.header(
-            "allow_source_trailing_dot", allow_source_trailing_dot, "bool"
-        )
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_abort_copy_request(
-    url: str,
-    *,
-    copy_id: str,
-    timeout: Optional[int] = None,
-    lease_id: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
-    **kwargs: Any
+def build_get_access_policy_request(
+    url: str, *, timeout: Optional[int] = None, lease_id: Optional[str] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["copy"] = kwargs.pop("comp", _params.pop("comp", "copy"))
-    copy_action_abort_constant: Literal["abort"] = kwargs.pop(
-        "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
-    )
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["copyid"] = _SERIALIZER.query("copy_id", copy_id, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-copy-action"] = _SERIALIZER.header("copy_action_abort_constant", copy_action_abort_constant, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_list_handles_request(
-    url: str,
-    *,
-    marker: Optional[str] = None,
-    maxresults: Optional[int] = None,
-    timeout: Optional[int] = None,
-    sharesnapshot: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
-    **kwargs: Any
+def build_set_access_policy_request(
+    url: str, *, timeout: Optional[int] = None, lease_id: Optional[str] = None, content: Any = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["listhandles"] = kwargs.pop("comp", _params.pop("comp", "listhandles"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
+    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if marker is not None:
-        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
-    if maxresults is not None:
-        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
-def build_force_close_handles_request(
-    url: str,
-    *,
-    handle_id: str,
-    timeout: Optional[int] = None,
-    marker: Optional[str] = None,
-    sharesnapshot: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
-    **kwargs: Any
+def build_get_statistics_request(
+    url: str, *, timeout: Optional[int] = None, lease_id: Optional[str] = None, **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["forceclosehandles"] = kwargs.pop("comp", _params.pop("comp", "forceclosehandles"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["stats"] = kwargs.pop("comp", _params.pop("comp", "stats"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if marker is not None:
-        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
-    _headers["x-ms-handle-id"] = _SERIALIZER.header("handle_id", handle_id, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_rename_request(
+def build_restore_request(
     url: str,
     *,
-    rename_source: str,
     timeout: Optional[int] = None,
-    replace_if_exists: Optional[bool] = None,
-    ignore_read_only: Optional[bool] = None,
-    source_lease_id: Optional[str] = None,
-    destination_lease_id: Optional[str] = None,
-    file_attributes: Optional[str] = None,
-    file_creation_time: Optional[str] = None,
-    file_last_write_time: Optional[str] = None,
-    file_change_time: Optional[str] = None,
-    file_permission: str = "inherit",
-    file_permission_key: Optional[str] = None,
-    metadata: Optional[Dict[str, str]] = None,
-    file_content_type: Optional[str] = None,
-    allow_trailing_dot: Optional[bool] = None,
-    allow_source_trailing_dot: Optional[bool] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    request_id_parameter: Optional[str] = None,
+    deleted_share_name: Optional[str] = None,
+    deleted_share_version: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["rename"] = kwargs.pop("comp", _params.pop("comp", "rename"))
+    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+    comp: Literal["undelete"] = kwargs.pop("comp", _params.pop("comp", "undelete"))
     version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}/{directory}/{fileName}")
+    _url = kwargs.pop("template_url", "{url}/{shareName}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
     _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
 
     # Construct parameters
+    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    _headers["x-ms-file-rename-source"] = _SERIALIZER.header("rename_source", rename_source, "str")
-    if replace_if_exists is not None:
-        _headers["x-ms-file-rename-replace-if-exists"] = _SERIALIZER.header(
-            "replace_if_exists", replace_if_exists, "bool"
-        )
-    if ignore_read_only is not None:
-        _headers["x-ms-file-rename-ignore-readonly"] = _SERIALIZER.header("ignore_read_only", ignore_read_only, "bool")
-    if source_lease_id is not None:
-        _headers["x-ms-source-lease-id"] = _SERIALIZER.header("source_lease_id", source_lease_id, "str")
-    if destination_lease_id is not None:
-        _headers["x-ms-destination-lease-id"] = _SERIALIZER.header("destination_lease_id", destination_lease_id, "str")
-    if file_attributes is not None:
-        _headers["x-ms-file-attributes"] = _SERIALIZER.header("file_attributes", file_attributes, "str")
-    if file_creation_time is not None:
-        _headers["x-ms-file-creation-time"] = _SERIALIZER.header("file_creation_time", file_creation_time, "str")
-    if file_last_write_time is not None:
-        _headers["x-ms-file-last-write-time"] = _SERIALIZER.header("file_last_write_time", file_last_write_time, "str")
-    if file_change_time is not None:
-        _headers["x-ms-file-change-time"] = _SERIALIZER.header("file_change_time", file_change_time, "str")
-    if file_permission is not None:
-        _headers["x-ms-file-permission"] = _SERIALIZER.header("file_permission", file_permission, "str")
-    if file_permission_key is not None:
-        _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
-    if metadata is not None:
-        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    if file_content_type is not None:
-        _headers["x-ms-content-type"] = _SERIALIZER.header("file_content_type", file_content_type, "str")
-    if allow_trailing_dot is not None:
-        _headers["x-ms-allow-trailing-dot"] = _SERIALIZER.header("allow_trailing_dot", allow_trailing_dot, "bool")
-    if allow_source_trailing_dot is not None:
-        _headers["x-ms-source-allow-trailing-dot"] = _SERIALIZER.header(
-            "allow_source_trailing_dot", allow_source_trailing_dot, "bool"
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if deleted_share_name is not None:
+        _headers["x-ms-deleted-share-name"] = _SERIALIZER.header("deleted_share_name", deleted_share_name, "str")
+    if deleted_share_version is not None:
+        _headers["x-ms-deleted-share-version"] = _SERIALIZER.header(
+            "deleted_share_version", deleted_share_version, "str"
         )
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-class FileOperations:
+class ShareOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
         :class:`~azure.storage.fileshare.AzureFileStorage`'s
-        :attr:`file` attribute.
+        :attr:`share` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
         input_args = list(args)
         self._client = input_args.pop(0) if input_args else kwargs.pop("client")
         self._config = input_args.pop(0) if input_args else kwargs.pop("config")
         self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
         self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def create(  # pylint: disable=inconsistent-return-statements
         self,
-        file_content_length: int,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
-        file_permission: str = "inherit",
-        file_permission_key: Optional[str] = None,
-        file_attributes: str = "none",
-        file_creation_time: str = "now",
-        file_last_write_time: str = "now",
-        file_change_time: Optional[str] = None,
-        file_http_headers: Optional[_models.FileHTTPHeaders] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        quota: Optional[int] = None,
+        access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
+        enabled_protocols: Optional[str] = None,
+        root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
         **kwargs: Any
     ) -> None:
-        """Creates a new file or replaces a file. Note it only initializes the file with no content.
+        """Creates a new share under the specified account. If the share with the same name already
+        exists, the operation fails.
 
-        :param file_content_length: Specifies the maximum size for the file, up to 4 TB. Required.
-        :type file_content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: A name-value pair to associate with a file storage object. Default value is
          None.
         :type metadata: dict[str, str]
-        :param file_permission: If specified the permission (security descriptor) shall be set for the
-         directory/file. This header can be used if Permission size is <= 8KB, else
-         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
-         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
-         x-ms-file-permission-key should be specified. Default value is "inherit".
-        :type file_permission: str
-        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
-         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
-         is None.
-        :type file_permission_key: str
-        :param file_attributes: If specified, the provided file attributes shall be set. Default value:
-         Archive for file and Directory for directory. None can also be specified as default.
-         Default value is "none".
-        :type file_attributes: str
-        :param file_creation_time: Creation time for the file/directory. Default value: Now. Default
-         value is "now".
-        :type file_creation_time: str
-        :param file_last_write_time: Last write time for the file/directory. Default value: Now.
-         Default value is "now".
-        :type file_last_write_time: str
-        :param file_change_time: Change time for the file/directory. Default value: Now. Default value
-         is None.
-        :type file_change_time: str
-        :param file_http_headers: Parameter group. Default value is None.
-        :type file_http_headers: ~azure.storage.fileshare.models.FileHTTPHeaders
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword file_type_constant: Dummy constant parameter, file type can only be file. Default
-         value is "file". Note that overriding this default value may result in unsupported behavior.
-        :paramtype file_type_constant: str
+        :param quota: Specifies the maximum size of the share, in gigabytes. Default value is None.
+        :type quota: int
+        :param access_tier: Specifies the access tier of the share. Known values are:
+         "TransactionOptimized", "Hot", and "Cool". Default value is None.
+        :type access_tier: str or ~azure.storage.fileshare.models.ShareAccessTier
+        :param enabled_protocols: Protocols to enable on the share. Default value is None.
+        :type enabled_protocols: str
+        :param root_squash: Root squash to set on the share.  Only valid for NFS shares. Known values
+         are: "NoRootSquash", "RootSquash", and "AllSquash". Default value is None.
+        :type root_squash: str or ~azure.storage.fileshare.models.ShareRootSquash
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = kwargs.pop("params", {}) or {}
+        _headers = kwargs.pop("headers", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        file_type_constant: Literal["file"] = kwargs.pop("file_type_constant", _headers.pop("x-ms-type", "file"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _file_content_type = None
-        _file_content_encoding = None
-        _file_content_language = None
-        _file_cache_control = None
-        _file_content_md5 = None
-        _file_content_disposition = None
-        _lease_id = None
-        if file_http_headers is not None:
-            _file_cache_control = file_http_headers.file_cache_control
-            _file_content_disposition = file_http_headers.file_content_disposition
-            _file_content_encoding = file_http_headers.file_content_encoding
-            _file_content_language = file_http_headers.file_content_language
-            _file_content_md5 = file_http_headers.file_content_md5
-            _file_content_type = file_http_headers.file_content_type
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
         request = build_create_request(
             url=self._config.url,
-            file_content_length=file_content_length,
             timeout=timeout,
-            file_content_type=_file_content_type,
-            file_content_encoding=_file_content_encoding,
-            file_content_language=_file_content_language,
-            file_cache_control=_file_cache_control,
-            file_content_md5=_file_content_md5,
-            file_content_disposition=_file_content_disposition,
             metadata=metadata,
-            file_permission=file_permission,
-            file_permission_key=file_permission_key,
-            file_attributes=file_attributes,
-            file_creation_time=file_creation_time,
-            file_last_write_time=file_last_write_time,
-            file_change_time=file_change_time,
-            lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
-            file_type_constant=file_type_constant,
+            quota=quota,
+            access_tier=access_tier,
+            enabled_protocols=enabled_protocols,
+            root_squash=root_squash,
+            restype=restype,
             version=self._config.version,
             template_url=self.create.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
@@ -1228,297 +860,73 @@
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
-        response_headers["x-ms-file-permission-key"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-permission-key")
-        )
-        response_headers["x-ms-file-attributes"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-attributes")
-        )
-        response_headers["x-ms-file-creation-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-creation-time")
-        )
-        response_headers["x-ms-file-last-write-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-last-write-time")
-        )
-        response_headers["x-ms-file-change-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-change-time")
-        )
-        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
-        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    create.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
-
-    @distributed_trace
-    def download(
-        self,
-        timeout: Optional[int] = None,
-        range: Optional[str] = None,
-        range_get_content_md5: Optional[bool] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        **kwargs: Any
-    ) -> Iterator[bytes]:
-        """Reads or downloads a file from the system, including its metadata and properties.
-
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param range: Return file data only from the specified byte range. Default value is None.
-        :type range: str
-        :param range_get_content_md5: When this header is set to true and specified together with the
-         Range header, the service returns the MD5 hash for the range, as long as the range is less than
-         or equal to 4 MB in size. Default value is None.
-        :type range_get_content_md5: bool
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: Iterator of the response bytes or the result of cls(response)
-        :rtype: Iterator[bytes]
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = kwargs.pop("params", {}) or {}
-
-        cls: ClsType[Iterator[bytes]] = kwargs.pop("cls", None)
-
-        _lease_id = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
-        request = build_download_request(
-            url=self._config.url,
-            timeout=timeout,
-            range=range,
-            range_get_content_md5=range_get_content_md5,
-            lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
-            version=self._config.version,
-            template_url=self.download.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=True, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200, 206]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        if response.status_code == 200:
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
-            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
-            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
-            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
-            response_headers["Content-Disposition"] = self._deserialize(
-                "str", response.headers.get("Content-Disposition")
-            )
-            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["x-ms-copy-completion-time"] = self._deserialize(
-                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
-            )
-            response_headers["x-ms-copy-status-description"] = self._deserialize(
-                "str", response.headers.get("x-ms-copy-status-description")
-            )
-            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
-            response_headers["x-ms-copy-progress"] = self._deserialize(
-                "str", response.headers.get("x-ms-copy-progress")
-            )
-            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
-            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
-            response_headers["x-ms-content-md5"] = self._deserialize(
-                "bytearray", response.headers.get("x-ms-content-md5")
-            )
-            response_headers["x-ms-server-encrypted"] = self._deserialize(
-                "bool", response.headers.get("x-ms-server-encrypted")
-            )
-            response_headers["x-ms-file-attributes"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-attributes")
-            )
-            response_headers["x-ms-file-creation-time"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-creation-time")
-            )
-            response_headers["x-ms-file-last-write-time"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-last-write-time")
-            )
-            response_headers["x-ms-file-change-time"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-change-time")
-            )
-            response_headers["x-ms-file-permission-key"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-permission-key")
-            )
-            response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
-            response_headers["x-ms-file-parent-id"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-parent-id")
-            )
-            response_headers["x-ms-lease-duration"] = self._deserialize(
-                "str", response.headers.get("x-ms-lease-duration")
-            )
-            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
-
-            deserialized = response.stream_download(self._client._pipeline)
-
-        if response.status_code == 206:
-            response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-            response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
-            response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-            response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
-            response_headers["Content-Range"] = self._deserialize("str", response.headers.get("Content-Range"))
-            response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-            response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
-            response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
-            response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
-            response_headers["Content-Disposition"] = self._deserialize(
-                "str", response.headers.get("Content-Disposition")
-            )
-            response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
-            response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-            response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-            response_headers["Accept-Ranges"] = self._deserialize("str", response.headers.get("Accept-Ranges"))
-            response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-            response_headers["x-ms-copy-completion-time"] = self._deserialize(
-                "rfc-1123", response.headers.get("x-ms-copy-completion-time")
-            )
-            response_headers["x-ms-copy-status-description"] = self._deserialize(
-                "str", response.headers.get("x-ms-copy-status-description")
-            )
-            response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
-            response_headers["x-ms-copy-progress"] = self._deserialize(
-                "str", response.headers.get("x-ms-copy-progress")
-            )
-            response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
-            response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
-            response_headers["x-ms-content-md5"] = self._deserialize(
-                "bytearray", response.headers.get("x-ms-content-md5")
-            )
-            response_headers["x-ms-server-encrypted"] = self._deserialize(
-                "bool", response.headers.get("x-ms-server-encrypted")
-            )
-            response_headers["x-ms-file-attributes"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-attributes")
-            )
-            response_headers["x-ms-file-creation-time"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-creation-time")
-            )
-            response_headers["x-ms-file-last-write-time"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-last-write-time")
-            )
-            response_headers["x-ms-file-change-time"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-change-time")
-            )
-            response_headers["x-ms-file-permission-key"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-permission-key")
-            )
-            response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
-            response_headers["x-ms-file-parent-id"] = self._deserialize(
-                "str", response.headers.get("x-ms-file-parent-id")
-            )
-            response_headers["x-ms-lease-duration"] = self._deserialize(
-                "str", response.headers.get("x-ms-lease-duration")
-            )
-            response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-            response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
-
-            deserialized = response.stream_download(self._client._pipeline)
-
-        if cls:
-            return cls(pipeline_response, deserialized, response_headers)  # type: ignore
-
-        return deserialized  # type: ignore
-
-    download.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    create.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
     def get_properties(  # pylint: disable=inconsistent-return-statements
         self,
         sharesnapshot: Optional[str] = None,
         timeout: Optional[int] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Returns all user-defined metadata, standard HTTP properties, and system properties for the
-        file. It does not return the content of the file.
+        """Returns all user-defined metadata and system properties for the specified share or share
+        snapshot. The data returned does not include the share's list of files.
 
         :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
          specifies the share snapshot to query. Default value is None.
         :type sharesnapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = kwargs.pop("params", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_get_properties_request(
             url=self._config.url,
             sharesnapshot=sharesnapshot,
             timeout=timeout,
             lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            restype=restype,
             version=self._config.version,
             template_url=self.get_properties.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
@@ -1531,111 +939,114 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
-        response_headers["x-ms-type"] = self._deserialize("str", response.headers.get("x-ms-type"))
-        response_headers["Content-Length"] = self._deserialize("int", response.headers.get("Content-Length"))
-        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
-        response_headers["Content-Encoding"] = self._deserialize("str", response.headers.get("Content-Encoding"))
-        response_headers["Cache-Control"] = self._deserialize("str", response.headers.get("Cache-Control"))
-        response_headers["Content-Disposition"] = self._deserialize("str", response.headers.get("Content-Disposition"))
-        response_headers["Content-Language"] = self._deserialize("str", response.headers.get("Content-Language"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-copy-completion-time"] = self._deserialize(
-            "rfc-1123", response.headers.get("x-ms-copy-completion-time")
+        response_headers["x-ms-share-quota"] = self._deserialize("int", response.headers.get("x-ms-share-quota"))
+        response_headers["x-ms-share-provisioned-iops"] = self._deserialize(
+            "int", response.headers.get("x-ms-share-provisioned-iops")
         )
-        response_headers["x-ms-copy-status-description"] = self._deserialize(
-            "str", response.headers.get("x-ms-copy-status-description")
+        response_headers["x-ms-share-provisioned-ingress-mbps"] = self._deserialize(
+            "int", response.headers.get("x-ms-share-provisioned-ingress-mbps")
         )
-        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
-        response_headers["x-ms-copy-progress"] = self._deserialize("str", response.headers.get("x-ms-copy-progress"))
-        response_headers["x-ms-copy-source"] = self._deserialize("str", response.headers.get("x-ms-copy-source"))
-        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
-        response_headers["x-ms-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-server-encrypted")
-        )
-        response_headers["x-ms-file-attributes"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-attributes")
+        response_headers["x-ms-share-provisioned-egress-mbps"] = self._deserialize(
+            "int", response.headers.get("x-ms-share-provisioned-egress-mbps")
         )
-        response_headers["x-ms-file-creation-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-creation-time")
+        response_headers["x-ms-share-next-allowed-quota-downgrade-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-share-next-allowed-quota-downgrade-time")
         )
-        response_headers["x-ms-file-last-write-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-last-write-time")
+        response_headers["x-ms-share-provisioned-bandwidth-mibps"] = self._deserialize(
+            "int", response.headers.get("x-ms-share-provisioned-bandwidth-mibps")
         )
-        response_headers["x-ms-file-change-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-change-time")
-        )
-        response_headers["x-ms-file-permission-key"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-permission-key")
-        )
-        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
-        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
         response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
         response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
         response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
+        response_headers["x-ms-access-tier"] = self._deserialize("str", response.headers.get("x-ms-access-tier"))
+        response_headers["x-ms-access-tier-change-time"] = self._deserialize(
+            "rfc-1123", response.headers.get("x-ms-access-tier-change-time")
+        )
+        response_headers["x-ms-access-tier-transition-state"] = self._deserialize(
+            "str", response.headers.get("x-ms-access-tier-transition-state")
+        )
+        response_headers["x-ms-enabled-protocols"] = self._deserialize(
+            "str", response.headers.get("x-ms-enabled-protocols")
+        )
+        response_headers["x-ms-root-squash"] = self._deserialize("str", response.headers.get("x-ms-root-squash"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    get_properties.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    get_properties.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
     def delete(  # pylint: disable=inconsistent-return-statements
         self,
+        sharesnapshot: Optional[str] = None,
         timeout: Optional[int] = None,
+        delete_snapshots: Optional[Union[str, _models.DeleteSnapshotsOptionType]] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """removes the file from the storage account.
+        """Operation marks the specified share or share snapshot for deletion. The share or share snapshot
+        and any files contained within it are later deleted during garbage collection.
 
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param delete_snapshots: Specifies the option include to delete the base share and all of its
+         snapshots. Known values are: "include" and "include-leased". Default value is None.
+        :type delete_snapshots: str or ~azure.storage.fileshare.models.DeleteSnapshotsOptionType
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = kwargs.pop("params", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
         request = build_delete_request(
             url=self._config.url,
+            sharesnapshot=sharesnapshot,
             timeout=timeout,
+            delete_snapshots=delete_snapshots,
             lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            restype=restype,
             version=self._config.version,
             template_url=self.delete.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
@@ -1655,235 +1066,191 @@
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    delete.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def set_http_headers(  # pylint: disable=inconsistent-return-statements
+    def acquire_lease(  # pylint: disable=inconsistent-return-statements
         self,
         timeout: Optional[int] = None,
-        file_content_length: Optional[int] = None,
-        file_permission: str = "inherit",
-        file_permission_key: Optional[str] = None,
-        file_attributes: str = "none",
-        file_creation_time: str = "now",
-        file_last_write_time: str = "now",
-        file_change_time: Optional[str] = None,
-        file_http_headers: Optional[_models.FileHTTPHeaders] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        duration: Optional[int] = None,
+        proposed_lease_id: Optional[str] = None,
+        sharesnapshot: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
         **kwargs: Any
     ) -> None:
-        """Sets HTTP headers on the file.
+        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
+        for set and delete share operations.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param file_content_length: Resizes a file to the specified size. If the specified byte value
-         is less than the current size of the file, then all ranges above the specified byte value are
-         cleared. Default value is None.
-        :type file_content_length: int
-        :param file_permission: If specified the permission (security descriptor) shall be set for the
-         directory/file. This header can be used if Permission size is <= 8KB, else
-         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
-         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
-         x-ms-file-permission-key should be specified. Default value is "inherit".
-        :type file_permission: str
-        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
-         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
-         is None.
-        :type file_permission_key: str
-        :param file_attributes: If specified, the provided file attributes shall be set. Default value:
-         Archive for file and Directory for directory. None can also be specified as default.
-         Default value is "none".
-        :type file_attributes: str
-        :param file_creation_time: Creation time for the file/directory. Default value: Now. Default
-         value is "now".
-        :type file_creation_time: str
-        :param file_last_write_time: Last write time for the file/directory. Default value: Now.
-         Default value is "now".
-        :type file_last_write_time: str
-        :param file_change_time: Change time for the file/directory. Default value: Now. Default value
-         is None.
-        :type file_change_time: str
-        :param file_http_headers: Parameter group. Default value is None.
-        :type file_http_headers: ~azure.storage.fileshare.models.FileHTTPHeaders
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+        :param duration: Specifies the duration of the lease, in seconds, or negative one (-1) for a
+         lease that never expires. A non-infinite lease can be between 15 and 60 seconds. A lease
+         duration cannot be changed using renew or change. Default value is None.
+        :type duration: int
+        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
+         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
+         Constructor (String) for a list of valid GUID string formats. Default value is None.
+        :type proposed_lease_id: str
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
+        :keyword action: Describes what lease action to take. Default value is "acquire". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
+        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+        action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _file_content_type = None
-        _file_content_encoding = None
-        _file_content_language = None
-        _file_cache_control = None
-        _file_content_md5 = None
-        _file_content_disposition = None
-        _lease_id = None
-        if file_http_headers is not None:
-            _file_cache_control = file_http_headers.file_cache_control
-            _file_content_disposition = file_http_headers.file_content_disposition
-            _file_content_encoding = file_http_headers.file_content_encoding
-            _file_content_language = file_http_headers.file_content_language
-            _file_content_md5 = file_http_headers.file_content_md5
-            _file_content_type = file_http_headers.file_content_type
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
-        request = build_set_http_headers_request(
+        request = build_acquire_lease_request(
             url=self._config.url,
             timeout=timeout,
-            file_content_length=file_content_length,
-            file_content_type=_file_content_type,
-            file_content_encoding=_file_content_encoding,
-            file_content_language=_file_content_language,
-            file_cache_control=_file_cache_control,
-            file_content_md5=_file_content_md5,
-            file_content_disposition=_file_content_disposition,
-            file_permission=file_permission,
-            file_permission_key=file_permission_key,
-            file_attributes=file_attributes,
-            file_creation_time=file_creation_time,
-            file_last_write_time=file_last_write_time,
-            file_change_time=file_change_time,
-            lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            duration=duration,
+            proposed_lease_id=proposed_lease_id,
+            sharesnapshot=sharesnapshot,
+            request_id_parameter=request_id_parameter,
             comp=comp,
+            action=action,
+            restype=restype,
             version=self._config.version,
-            template_url=self.set_http_headers.metadata["url"],
+            template_url=self.acquire_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
-        response_headers["x-ms-file-permission-key"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-permission-key")
-        )
-        response_headers["x-ms-file-attributes"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-attributes")
-        )
-        response_headers["x-ms-file-creation-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-creation-time")
-        )
-        response_headers["x-ms-file-last-write-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-last-write-time")
-        )
-        response_headers["x-ms-file-change-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-change-time")
-        )
-        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
-        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_http_headers.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    acquire_lease.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def set_metadata(  # pylint: disable=inconsistent-return-statements
+    def release_lease(  # pylint: disable=inconsistent-return-statements
         self,
+        lease_id: str,
         timeout: Optional[int] = None,
-        metadata: Optional[Dict[str, str]] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        sharesnapshot: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
         **kwargs: Any
     ) -> None:
-        """Updates user-defined metadata for the specified file.
+        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
+        for set and delete share operations.
 
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param metadata: A name-value pair to associate with a file storage object. Default value is
-         None.
-        :type metadata: dict[str, str]
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
+        :keyword action: Describes what lease action to take. Default value is "release". Note that
+         overriding this default value may result in unsupported behavior.
+        :paramtype action: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
+        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
+        action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _lease_id = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
-        request = build_set_metadata_request(
+        request = build_release_lease_request(
             url=self._config.url,
+            lease_id=lease_id,
             timeout=timeout,
-            metadata=metadata,
-            lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            sharesnapshot=sharesnapshot,
+            request_id_parameter=request_id_parameter,
             comp=comp,
+            action=action,
+            restype=restype,
             version=self._config.version,
-            template_url=self.set_metadata.metadata["url"],
+            template_url=self.release_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
@@ -1895,61 +1262,67 @@
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_metadata.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    release_lease.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def acquire_lease(  # pylint: disable=inconsistent-return-statements
+    def change_lease(  # pylint: disable=inconsistent-return-statements
         self,
+        lease_id: str,
         timeout: Optional[int] = None,
-        duration: Optional[int] = None,
         proposed_lease_id: Optional[str] = None,
+        sharesnapshot: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
         **kwargs: Any
     ) -> None:
-        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
-        operations.
+        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
+        for set and delete share operations.
 
+        :param lease_id: Specifies the current lease ID on the resource. Required.
+        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param duration: Specifies the duration of the lease, in seconds, or negative one (-1) for a
-         lease that never expires. A non-infinite lease can be between 15 and 60 seconds. A lease
-         duration cannot be changed using renew or change. Default value is None.
-        :type duration: int
         :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
          400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
          Constructor (String) for a list of valid GUID string formats. Default value is None.
         :type proposed_lease_id: str
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "acquire". Note that
+        :keyword action: Describes what lease action to take. Default value is "change". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
@@ -1959,42 +1332,43 @@
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
         comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
+        action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        request = build_acquire_lease_request(
+        request = build_change_lease_request(
             url=self._config.url,
+            lease_id=lease_id,
             timeout=timeout,
-            duration=duration,
             proposed_lease_id=proposed_lease_id,
+            sharesnapshot=sharesnapshot,
             request_id_parameter=request_id_parameter,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
             comp=comp,
             action=action,
+            restype=restype,
             version=self._config.version,
-            template_url=self.acquire_lease.metadata["url"],
+            template_url=self.change_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
@@ -2005,40 +1379,51 @@
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    acquire_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    change_lease.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def release_lease(  # pylint: disable=inconsistent-return-statements
-        self, lease_id: str, timeout: Optional[int] = None, request_id_parameter: Optional[str] = None, **kwargs: Any
+    def renew_lease(  # pylint: disable=inconsistent-return-statements
+        self,
+        lease_id: str,
+        timeout: Optional[int] = None,
+        sharesnapshot: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
+        **kwargs: Any
     ) -> None:
-        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
-        operations.
+        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
+        for set and delete share operations.
 
         :param lease_id: Specifies the current lease ID on the resource. Required.
         :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "release". Note that
+        :keyword action: Describes what lease action to take. Default value is "renew". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
@@ -2048,28 +1433,29 @@
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
         comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
+        action: Literal["renew"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        request = build_release_lease_request(
+        request = build_renew_lease_request(
             url=self._config.url,
             lease_id=lease_id,
             timeout=timeout,
+            sharesnapshot=sharesnapshot,
             request_id_parameter=request_id_parameter,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
             comp=comp,
             action=action,
+            restype=restype,
             version=self._config.version,
-            template_url=self.release_lease.metadata["url"],
+            template_url=self.renew_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
@@ -2082,59 +1468,71 @@
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    release_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    renew_lease.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def change_lease(  # pylint: disable=inconsistent-return-statements
+    def break_lease(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id: str,
         timeout: Optional[int] = None,
-        proposed_lease_id: Optional[str] = None,
+        break_period: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
+        sharesnapshot: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
-        operations.
+        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
+        for set and delete share operations.
 
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Default value is None.
-        :type proposed_lease_id: str
+        :param break_period: For a break operation, proposed duration the lease should continue before
+         it is broken, in seconds, between 0 and 60. This break period is only used if it is shorter
+         than the time remaining on the lease. If longer, the time remaining on the lease is used. A new
+         lease will not be available before the break period has expired, but the lease may be held for
+         longer than the break period. If this header does not appear with a break operation, a
+         fixed-duration lease breaks after the remaining lease period elapses, and an infinite lease
+         breaks immediately. Default value is None.
+        :type break_period: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
+        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the share snapshot to query. Default value is None.
+        :type sharesnapshot: str
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
         :keyword comp: comp. Default value is "lease". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "change". Note that
+        :keyword action: Describes what lease action to take. Default value is "break". Note that
          overriding this default value may result in unsupported behavior.
         :paramtype action: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
@@ -2144,251 +1542,275 @@
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
         comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
+        action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        request = build_change_lease_request(
+        _lease_id = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+
+        request = build_break_lease_request(
             url=self._config.url,
-            lease_id=lease_id,
             timeout=timeout,
-            proposed_lease_id=proposed_lease_id,
+            break_period=break_period,
+            lease_id=_lease_id,
             request_id_parameter=request_id_parameter,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            sharesnapshot=sharesnapshot,
             comp=comp,
             action=action,
+            restype=restype,
             version=self._config.version,
-            template_url=self.change_lease.metadata["url"],
+            template_url=self.break_lease.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
         response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    break_lease.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def break_lease(  # pylint: disable=inconsistent-return-statements
-        self,
-        timeout: Optional[int] = None,
-        request_id_parameter: Optional[str] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        **kwargs: Any
+    def create_snapshot(  # pylint: disable=inconsistent-return-statements
+        self, timeout: Optional[int] = None, metadata: Optional[Dict[str, str]] = None, **kwargs: Any
     ) -> None:
-        """[Update] The Lease File operation establishes and manages a lock on a file for write and delete
-        operations.
+        """Creates a read-only snapshot of a share.
 
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+        :param metadata: A name-value pair to associate with a file storage object. Default value is
+         None.
+        :type metadata: dict[str, str]
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "snapshot". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "break". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype action: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["snapshot"] = kwargs.pop("comp", _params.pop("comp", "snapshot"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _lease_id = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
-        request = build_break_lease_request(
+        request = build_create_snapshot_request(
             url=self._config.url,
             timeout=timeout,
-            lease_id=_lease_id,
-            request_id_parameter=request_id_parameter,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            metadata=metadata,
+            restype=restype,
             comp=comp,
-            action=action,
             version=self._config.version,
-            template_url=self.break_lease.metadata["url"],
+            template_url=self.create_snapshot.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
+        response_headers["x-ms-snapshot"] = self._deserialize("str", response.headers.get("x-ms-snapshot"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    break_lease.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    create_snapshot.metadata = {"url": "{url}/{shareName}"}
 
-    @distributed_trace
-    def upload_range(  # pylint: disable=inconsistent-return-statements
+    @overload
+    def create_permission(  # pylint: disable=inconsistent-return-statements
         self,
-        range: str,
-        content_length: int,
+        share_permission: _models.SharePermission,
         timeout: Optional[int] = None,
-        file_range_write: Union[str, _models.FileRangeWriteType] = "update",
-        content_md5: Optional[bytes] = None,
-        file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        optionalbody: Optional[IO] = None,
+        *,
+        content_type: str = "application/json",
         **kwargs: Any
     ) -> None:
-        """Upload a range of bytes to a file.
+        """Create a permission (a security descriptor).
 
-        :param range: Specifies the range of bytes to be written. Both the start and end of the range
-         must be specified. For an update operation, the range can be up to 4 MB in size. For a clear
-         operation, the range can be up to the value of the file's full size. The File service accepts
-         only a single byte range for the Range and 'x-ms-range' headers, and the byte range must be
-         specified in the following format: bytes=startByte-endByte. Required.
-        :type range: str
-        :param content_length: Specifies the number of bytes being transmitted in the request body.
-         When the x-ms-write header is set to clear, the value of this header must be set to zero.
-         Required.
-        :type content_length: int
+        :param share_permission: A permission (a security descriptor) at the share level. Required.
+        :type share_permission: ~azure.storage.fileshare.models.SharePermission
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param file_range_write: Specify one of the following options: - Update: Writes the bytes
-         specified by the request body into the specified range. The Range and Content-Length headers
-         must match to perform the update. - Clear: Clears the specified range and releases the space
-         used in storage for that range. To clear a range, set the Content-Length header to zero, and
-         set the Range header to a value that indicates the range to clear, up to maximum file size.
-         Known values are: "update" and "clear". Default value is "update".
-        :type file_range_write: str or ~azure.storage.fileshare.models.FileRangeWriteType
-        :param content_md5: An MD5 hash of the content. This hash is used to verify the integrity of
-         the data during transport. When the Content-MD5 header is specified, the File service compares
-         the hash of the content that has arrived with the header value that was sent. If the two hashes
-         do not match, the operation will fail with error code 400 (Bad Request). Default value is None.
-        :type content_md5: bytes
-        :param file_last_written_mode: If the file last write time should be preserved or overwritten.
-         Known values are: "Now" and "Preserve". Default value is None.
-        :type file_last_written_mode: str or ~azure.storage.fileshare.models.FileLastWrittenMode
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :param optionalbody: Initial data. Default value is None.
-        :type optionalbody: IO
-        :keyword comp: comp. Default value is "range". Note that overriding this default value may
-         result in unsupported behavior.
+        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
+         Default value is "application/json".
+        :paramtype content_type: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
+         may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
+
+    @overload
+    def create_permission(  # pylint: disable=inconsistent-return-statements
+        self,
+        share_permission: IO,
+        timeout: Optional[int] = None,
+        *,
+        content_type: str = "application/json",
+        **kwargs: Any
+    ) -> None:
+        """Create a permission (a security descriptor).
+
+        :param share_permission: A permission (a security descriptor) at the share level. Required.
+        :type share_permission: IO
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
+         Default value is "application/json".
+        :paramtype content_type: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype comp: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
+
+    @distributed_trace
+    def create_permission(  # pylint: disable=inconsistent-return-statements
+        self, share_permission: Union[_models.SharePermission, IO], timeout: Optional[int] = None, **kwargs: Any
+    ) -> None:
+        """Create a permission (a security descriptor).
+
+        :param share_permission: A permission (a security descriptor) at the share level. Is either a
+         SharePermission type or a IO type. Required.
+        :type share_permission: ~azure.storage.fileshare.models.SharePermission or IO
+        :param timeout: The timeout parameter is expressed in seconds. For more information, see
+         :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
+         Timeouts for File Service Operations.</a>`. Default value is None.
+        :type timeout: int
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype comp: str
+        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
+         Default value is None.
+        :paramtype content_type: str
+        :keyword callable cls: A custom type or function that will be passed the direct response
+        :return: None or the result of cls(response)
+        :rtype: None
+        :raises ~azure.core.exceptions.HttpResponseError:
+        """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
-        content_type: str = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
+        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _lease_id = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-        _content = optionalbody
+        content_type = content_type or "application/json"
+        _json = None
+        _content = None
+        if isinstance(share_permission, (IO, bytes)):
+            _content = share_permission
+        else:
+            _json = self._serialize.body(share_permission, "SharePermission")
 
-        request = build_upload_range_request(
+        request = build_create_permission_request(
             url=self._config.url,
-            range=range,
-            content_length=content_length,
             timeout=timeout,
-            file_range_write=file_range_write,
-            content_md5=content_md5,
-            lease_id=_lease_id,
-            file_last_written_mode=file_last_written_mode,
-            allow_trailing_dot=self._config.allow_trailing_dot,
             file_request_intent=self._config.file_request_intent,
+            restype=restype,
             comp=comp,
             content_type=content_type,
             version=self._config.version,
+            json=_json,
             content=_content,
-            template_url=self.upload_range.metadata["url"],
+            template_url=self.create_permission.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
@@ -2399,238 +1821,173 @@
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
-        response_headers["x-ms-file-last-write-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-last-write-time")
+        response_headers["x-ms-file-permission-key"] = self._deserialize(
+            "str", response.headers.get("x-ms-file-permission-key")
         )
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    upload_range.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    create_permission.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def upload_range_from_url(  # pylint: disable=inconsistent-return-statements
-        self,
-        range: str,
-        copy_source: str,
-        content_length: int,
-        timeout: Optional[int] = None,
-        source_range: Optional[str] = None,
-        source_content_crc64: Optional[bytes] = None,
-        copy_source_authorization: Optional[str] = None,
-        file_last_written_mode: Optional[Union[str, _models.FileLastWrittenMode]] = None,
-        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        **kwargs: Any
-    ) -> None:
-        """Upload a range of bytes to a file where the contents are read from a URL.
+    def get_permission(
+        self, file_permission_key: str, timeout: Optional[int] = None, **kwargs: Any
+    ) -> _models.SharePermission:
+        """Returns the permission (security descriptor) for a given key.
 
-        :param range: Writes data to the specified byte range in the file. Required.
-        :type range: str
-        :param copy_source: Specifies the URL of the source file or blob, up to 2 KB in length. To copy
-         a file to another file within the same storage account, you may use Shared Key to authenticate
-         the source file. If you are copying a file from another storage account, or if you are copying
-         a blob from the same storage account or another storage account, then you must authenticate the
-         source file or blob using a shared access signature. If the source is a public blob, no
-         authentication is required to perform the copy operation. A file in a share snapshot can also
-         be specified as a copy source. Required.
-        :type copy_source: str
-        :param content_length: Specifies the number of bytes being transmitted in the request body.
-         When the x-ms-write header is set to clear, the value of this header must be set to zero.
-         Required.
-        :type content_length: int
+        :param file_permission_key: Key of the permission to be set for the directory/file. Required.
+        :type file_permission_key: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param source_range: Bytes of source data in the specified range. Default value is None.
-        :type source_range: str
-        :param source_content_crc64: Specify the crc64 calculated for the range of bytes that must be
-         read from the copy source. Default value is None.
-        :type source_content_crc64: bytes
-        :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
-         OAuth access token to copy source. Default value is None.
-        :type copy_source_authorization: str
-        :param file_last_written_mode: If the file last write time should be preserved or overwritten.
-         Known values are: "Now" and "Preserve". Default value is None.
-        :type file_last_written_mode: str or ~azure.storage.fileshare.models.FileLastWrittenMode
-        :param source_modified_access_conditions: Parameter group. Default value is None.
-        :type source_modified_access_conditions:
-         ~azure.storage.fileshare.models.SourceModifiedAccessConditions
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "range". Note that overriding this default value may
-         result in unsupported behavior.
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
+         may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: SharePermission or the result of cls(response)
+        :rtype: ~azure.storage.fileshare.models.SharePermission
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["range"] = kwargs.pop("comp", _params.pop("comp", "range"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        _source_if_match_crc64 = None
-        _source_if_none_match_crc64 = None
-        _lease_id = None
-        if source_modified_access_conditions is not None:
-            _source_if_match_crc64 = source_modified_access_conditions.source_if_match_crc64
-            _source_if_none_match_crc64 = source_modified_access_conditions.source_if_none_match_crc64
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
+        cls: ClsType[_models.SharePermission] = kwargs.pop("cls", None)
 
-        request = build_upload_range_from_url_request(
+        request = build_get_permission_request(
             url=self._config.url,
-            range=range,
-            copy_source=copy_source,
-            content_length=content_length,
+            file_permission_key=file_permission_key,
             timeout=timeout,
-            source_range=source_range,
-            source_content_crc64=source_content_crc64,
-            source_if_match_crc64=_source_if_match_crc64,
-            source_if_none_match_crc64=_source_if_none_match_crc64,
-            lease_id=_lease_id,
-            copy_source_authorization=copy_source_authorization,
-            file_last_written_mode=file_last_written_mode,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            allow_source_trailing_dot=self._config.allow_source_trailing_dot,
+            file_request_intent=self._config.file_request_intent,
+            restype=restype,
             comp=comp,
-            file_range_write_from_url=self._config.file_range_write_from_url,
             version=self._config.version,
-            template_url=self.upload_range_from_url.metadata["url"],
+            template_url=self.get_permission.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-content-crc64"] = self._deserialize(
-            "bytearray", response.headers.get("x-ms-content-crc64")
-        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
-        response_headers["x-ms-file-last-write-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-last-write-time")
-        )
+
+        deserialized = self._deserialize("SharePermission", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    upload_range_from_url.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+        return deserialized
+
+    get_permission.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def get_range_list(
+    def set_properties(  # pylint: disable=inconsistent-return-statements
         self,
-        sharesnapshot: Optional[str] = None,
-        prevsharesnapshot: Optional[str] = None,
         timeout: Optional[int] = None,
-        range: Optional[str] = None,
+        quota: Optional[int] = None,
+        access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
+        root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
-    ) -> _models.ShareFileRangeList:
-        """Returns the list of valid ranges for a file.
+    ) -> None:
+        """Sets properties for the specified share.
 
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
-        :param prevsharesnapshot: The previous snapshot parameter is an opaque DateTime value that,
-         when present, specifies the previous snapshot. Default value is None.
-        :type prevsharesnapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param range: Specifies the range of bytes over which to list ranges, inclusively. Default
-         value is None.
-        :type range: str
+        :param quota: Specifies the maximum size of the share, in gigabytes. Default value is None.
+        :type quota: int
+        :param access_tier: Specifies the access tier of the share. Known values are:
+         "TransactionOptimized", "Hot", and "Cool". Default value is None.
+        :type access_tier: str or ~azure.storage.fileshare.models.ShareAccessTier
+        :param root_squash: Root squash to set on the share.  Only valid for NFS shares. Known values
+         are: "NoRootSquash", "RootSquash", and "AllSquash". Default value is None.
+        :type root_squash: str or ~azure.storage.fileshare.models.ShareRootSquash
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "rangelist". Note that overriding this default value may
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ShareFileRangeList or the result of cls(response)
-        :rtype: ~azure.storage.fileshare.models.ShareFileRangeList
+        :return: None or the result of cls(response)
+        :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["rangelist"] = kwargs.pop("comp", _params.pop("comp", "rangelist"))
-        cls: ClsType[_models.ShareFileRangeList] = kwargs.pop("cls", None)
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
-        request = build_get_range_list_request(
+        request = build_set_properties_request(
             url=self._config.url,
-            sharesnapshot=sharesnapshot,
-            prevsharesnapshot=prevsharesnapshot,
             timeout=timeout,
-            range=range,
+            quota=quota,
+            access_tier=access_tier,
             lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            root_squash=root_squash,
+            restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_range_list.metadata["url"],
+            template_url=self.set_properties.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
@@ -2641,314 +1998,267 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["x-ms-content-length"] = self._deserialize("int", response.headers.get("x-ms-content-length"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize("ShareFileRangeList", pipeline_response)
-
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    get_range_list.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    set_properties.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def start_copy(  # pylint: disable=inconsistent-return-statements
+    def set_metadata(  # pylint: disable=inconsistent-return-statements
         self,
-        copy_source: str,
         timeout: Optional[int] = None,
         metadata: Optional[Dict[str, str]] = None,
-        file_permission: str = "inherit",
-        file_permission_key: Optional[str] = None,
-        copy_file_smb_info: Optional[_models.CopyFileSmbInfo] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Copies a blob or file to a destination file within the storage account.
+        """Sets one or more user-defined name-value pairs for the specified share.
 
-        :param copy_source: Specifies the URL of the source file or blob, up to 2 KB in length. To copy
-         a file to another file within the same storage account, you may use Shared Key to authenticate
-         the source file. If you are copying a file from another storage account, or if you are copying
-         a blob from the same storage account or another storage account, then you must authenticate the
-         source file or blob using a shared access signature. If the source is a public blob, no
-         authentication is required to perform the copy operation. A file in a share snapshot can also
-         be specified as a copy source. Required.
-        :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param metadata: A name-value pair to associate with a file storage object. Default value is
          None.
         :type metadata: dict[str, str]
-        :param file_permission: If specified the permission (security descriptor) shall be set for the
-         directory/file. This header can be used if Permission size is <= 8KB, else
-         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
-         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
-         x-ms-file-permission-key should be specified. Default value is "inherit".
-        :type file_permission: str
-        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
-         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
-         is None.
-        :type file_permission_key: str
-        :param copy_file_smb_info: Parameter group. Default value is None.
-        :type copy_file_smb_info: ~azure.storage.fileshare.models.CopyFileSmbInfo
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
+         result in unsupported behavior.
+        :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
-        _params = kwargs.pop("params", {}) or {}
+        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _file_permission_copy_mode = None
-        _ignore_read_only = None
-        _file_attributes = None
-        _file_creation_time = None
-        _file_last_write_time = None
-        _file_change_time = None
-        _set_archive_attribute = None
         _lease_id = None
-        if copy_file_smb_info is not None:
-            _file_attributes = copy_file_smb_info.file_attributes
-            _file_change_time = copy_file_smb_info.file_change_time
-            _file_creation_time = copy_file_smb_info.file_creation_time
-            _file_last_write_time = copy_file_smb_info.file_last_write_time
-            _file_permission_copy_mode = copy_file_smb_info.file_permission_copy_mode
-            _ignore_read_only = copy_file_smb_info.ignore_read_only
-            _set_archive_attribute = copy_file_smb_info.set_archive_attribute
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
-        request = build_start_copy_request(
+        request = build_set_metadata_request(
             url=self._config.url,
-            copy_source=copy_source,
             timeout=timeout,
             metadata=metadata,
-            file_permission=file_permission,
-            file_permission_key=file_permission_key,
-            file_permission_copy_mode=_file_permission_copy_mode,
-            ignore_read_only=_ignore_read_only,
-            file_attributes=_file_attributes,
-            file_creation_time=_file_creation_time,
-            file_last_write_time=_file_last_write_time,
-            file_change_time=_file_change_time,
-            set_archive_attribute=_set_archive_attribute,
             lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            allow_source_trailing_dot=self._config.allow_source_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            restype=restype,
+            comp=comp,
             version=self._config.version,
-            template_url=self.start_copy.metadata["url"],
+            template_url=self.set_metadata.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [202]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
-        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    start_copy.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    set_metadata.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def abort_copy(  # pylint: disable=inconsistent-return-statements
+    def get_access_policy(
         self,
-        copy_id: str,
         timeout: Optional[int] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """Aborts a pending Copy File operation, and leaves a destination file with zero length and full
-        metadata.
+    ) -> List[_models.SignedIdentifier]:
+        """Returns information about stored access policies specified on the share.
 
-        :param copy_id: The copy identifier provided in the x-ms-copy-id header of the original Copy
-         File operation. Required.
-        :type copy_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param lease_access_conditions: Parameter group. Default value is None.
         :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "copy". Note that overriding this default value may
-         result in unsupported behavior.
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
+         in unsupported behavior.
         :paramtype comp: str
-        :keyword copy_action_abort_constant: Abort. Default value is "abort". Note that overriding this
-         default value may result in unsupported behavior.
-        :paramtype copy_action_abort_constant: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: list of SignedIdentifier or the result of cls(response)
+        :rtype: list[~azure.storage.fileshare.models.SignedIdentifier]
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["copy"] = kwargs.pop("comp", _params.pop("comp", "copy"))
-        copy_action_abort_constant: Literal["abort"] = kwargs.pop(
-            "copy_action_abort_constant", _headers.pop("x-ms-copy-action", "abort")
-        )
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
+        cls: ClsType[List[_models.SignedIdentifier]] = kwargs.pop("cls", None)
 
         _lease_id = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
 
-        request = build_abort_copy_request(
+        request = build_get_access_policy_request(
             url=self._config.url,
-            copy_id=copy_id,
             timeout=timeout,
             lease_id=_lease_id,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            restype=restype,
             comp=comp,
-            copy_action_abort_constant=copy_action_abort_constant,
             version=self._config.version,
-            template_url=self.abort_copy.metadata["url"],
+            template_url=self.get_access_policy.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [204]:
+        if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
+        deserialized = self._deserialize("[SignedIdentifier]", pipeline_response)
+
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
 
-    abort_copy.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    get_access_policy.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def list_handles(
+    def set_access_policy(  # pylint: disable=inconsistent-return-statements
         self,
-        marker: Optional[str] = None,
-        maxresults: Optional[int] = None,
         timeout: Optional[int] = None,
-        sharesnapshot: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        share_acl: Optional[List[_models.SignedIdentifier]] = None,
         **kwargs: Any
-    ) -> _models.ListHandlesResponse:
-        """Lists handles for file.
+    ) -> None:
+        """Sets a stored access policy for use with shared access signatures.
 
-        :param marker: A string value that identifies the portion of the list to be returned with the
-         next list operation. The operation returns a marker value within the response body if the list
-         returned was not complete. The marker value may then be used in a subsequent call to request
-         the next set of list items. The marker value is opaque to the client. Default value is None.
-        :type marker: str
-        :param maxresults: Specifies the maximum number of entries to return. If the request does not
-         specify maxresults, or specifies a value greater than 5,000, the server will return up to 5,000
-         items. Default value is None.
-        :type maxresults: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
-        :keyword comp: comp. Default value is "listhandles". Note that overriding this default value
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :param share_acl: The ACL for the share. Default value is None.
+        :type share_acl: list[~azure.storage.fileshare.models.SignedIdentifier]
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
          may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
+         in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ListHandlesResponse or the result of cls(response)
-        :rtype: ~azure.storage.fileshare.models.ListHandlesResponse
+        :return: None or the result of cls(response)
+        :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["listhandles"] = kwargs.pop("comp", _params.pop("comp", "listhandles"))
-        cls: ClsType[_models.ListHandlesResponse] = kwargs.pop("cls", None)
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
+        content_type: str = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))
+        cls: ClsType[None] = kwargs.pop("cls", None)
 
-        request = build_list_handles_request(
+        _lease_id = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+        serialization_ctxt = {"xml": {"name": "SignedIdentifiers", "wrapped": True}}
+        if share_acl is not None:
+            _content = self._serialize.body(
+                share_acl, "[SignedIdentifier]", is_xml=True, serialization_ctxt=serialization_ctxt
+            )
+        else:
+            _content = None
+
+        request = build_set_access_policy_request(
             url=self._config.url,
-            marker=marker,
-            maxresults=maxresults,
             timeout=timeout,
-            sharesnapshot=sharesnapshot,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            lease_id=_lease_id,
+            restype=restype,
             comp=comp,
+            content_type=content_type,
             version=self._config.version,
-            template_url=self.list_handles.metadata["url"],
+            content=_content,
+            template_url=self.set_access_policy.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
@@ -2959,88 +2269,79 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["Content-Type"] = self._deserialize("str", response.headers.get("Content-Type"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize("ListHandlesResponse", pipeline_response)
-
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    list_handles.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    set_access_policy.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def force_close_handles(  # pylint: disable=inconsistent-return-statements
+    def get_statistics(
         self,
-        handle_id: str,
         timeout: Optional[int] = None,
-        marker: Optional[str] = None,
-        sharesnapshot: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """Closes all handles open for given file.
+    ) -> _models.ShareStats:
+        """Retrieves statistics related to the share.
 
-        :param handle_id: Specifies handle ID opened on the file or directory to be closed. Asterisk
-         (*) is a wildcard that specifies all handles. Required.
-        :type handle_id: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param marker: A string value that identifies the portion of the list to be returned with the
-         next list operation. The operation returns a marker value within the response body if the list
-         returned was not complete. The marker value may then be used in a subsequent call to request
-         the next set of list items. The marker value is opaque to the client. Default value is None.
-        :type marker: str
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
-        :keyword comp: comp. Default value is "forceclosehandles". Note that overriding this default
-         value may result in unsupported behavior.
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "stats". Note that overriding this default value may
+         result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: ShareStats or the result of cls(response)
+        :rtype: ~azure.storage.fileshare.models.ShareStats
         :raises ~azure.core.exceptions.HttpResponseError:
         """
         error_map = {
             401: ClientAuthenticationError,
             404: ResourceNotFoundError,
             409: ResourceExistsError,
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["forceclosehandles"] = kwargs.pop("comp", _params.pop("comp", "forceclosehandles"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["stats"] = kwargs.pop("comp", _params.pop("comp", "stats"))
+        cls: ClsType[_models.ShareStats] = kwargs.pop("cls", None)
 
-        request = build_force_close_handles_request(
+        _lease_id = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+
+        request = build_get_statistics_request(
             url=self._config.url,
-            handle_id=handle_id,
             timeout=timeout,
-            marker=marker,
-            sharesnapshot=sharesnapshot,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            lease_id=_lease_id,
+            restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.force_close_handles.metadata["url"],
+            template_url=self.get_statistics.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
@@ -3051,92 +2352,59 @@
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-marker"] = self._deserialize("str", response.headers.get("x-ms-marker"))
-        response_headers["x-ms-number-of-handles-closed"] = self._deserialize(
-            "int", response.headers.get("x-ms-number-of-handles-closed")
-        )
-        response_headers["x-ms-number-of-handles-failed"] = self._deserialize(
-            "int", response.headers.get("x-ms-number-of-handles-failed")
-        )
+
+        deserialized = self._deserialize("ShareStats", pipeline_response)
 
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
+
+        return deserialized
 
-    force_close_handles.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    get_statistics.metadata = {"url": "{url}/{shareName}"}
 
     @distributed_trace
-    def rename(  # pylint: disable=inconsistent-return-statements
+    def restore(  # pylint: disable=inconsistent-return-statements
         self,
-        rename_source: str,
         timeout: Optional[int] = None,
-        replace_if_exists: Optional[bool] = None,
-        ignore_read_only: Optional[bool] = None,
-        file_permission: str = "inherit",
-        file_permission_key: Optional[str] = None,
-        metadata: Optional[Dict[str, str]] = None,
-        source_lease_access_conditions: Optional[_models.SourceLeaseAccessConditions] = None,
-        destination_lease_access_conditions: Optional[_models.DestinationLeaseAccessConditions] = None,
-        copy_file_smb_info: Optional[_models.CopyFileSmbInfo] = None,
-        file_http_headers: Optional[_models.FileHTTPHeaders] = None,
+        request_id_parameter: Optional[str] = None,
+        deleted_share_name: Optional[str] = None,
+        deleted_share_version: Optional[str] = None,
         **kwargs: Any
     ) -> None:
-        """Renames a file.
+        """Restores a previously deleted Share.
 
-        :param rename_source: Required. Specifies the URI-style path of the source file, up to 2 KB in
-         length. Required.
-        :type rename_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
          href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
          Timeouts for File Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param replace_if_exists: Optional. A boolean value for if the destination file already exists,
-         whether this request will overwrite the file or not. If true, the rename will succeed and will
-         overwrite the destination file. If not provided or if false and the destination file does
-         exist, the request will not overwrite the destination file. If provided and the destination
-         file doesnt exist, the rename will succeed. Note: This value does not override the
-         x-ms-file-copy-ignore-read-only header value. Default value is None.
-        :type replace_if_exists: bool
-        :param ignore_read_only: Optional. A boolean value that specifies whether the ReadOnly
-         attribute on a preexisting destination file should be respected. If true, the rename will
-         succeed, otherwise, a previous file at the destination with the ReadOnly attribute set will
-         cause the rename to fail. Default value is None.
-        :type ignore_read_only: bool
-        :param file_permission: If specified the permission (security descriptor) shall be set for the
-         directory/file. This header can be used if Permission size is <= 8KB, else
-         x-ms-file-permission-key header shall be used. Default value: Inherit. If SDDL is specified as
-         input, it must have owner, group and dacl. Note: Only one of the x-ms-file-permission or
-         x-ms-file-permission-key should be specified. Default value is "inherit".
-        :type file_permission: str
-        :param file_permission_key: Key of the permission to be set for the directory/file. Note: Only
-         one of the x-ms-file-permission or x-ms-file-permission-key should be specified. Default value
-         is None.
-        :type file_permission_key: str
-        :param metadata: A name-value pair to associate with a file storage object. Default value is
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param deleted_share_name: Specifies the name of the previously-deleted share. Default value is
          None.
-        :type metadata: dict[str, str]
-        :param source_lease_access_conditions: Parameter group. Default value is None.
-        :type source_lease_access_conditions:
-         ~azure.storage.fileshare.models.SourceLeaseAccessConditions
-        :param destination_lease_access_conditions: Parameter group. Default value is None.
-        :type destination_lease_access_conditions:
-         ~azure.storage.fileshare.models.DestinationLeaseAccessConditions
-        :param copy_file_smb_info: Parameter group. Default value is None.
-        :type copy_file_smb_info: ~azure.storage.fileshare.models.CopyFileSmbInfo
-        :param file_http_headers: Parameter group. Default value is None.
-        :type file_http_headers: ~azure.storage.fileshare.models.FileHTTPHeaders
-        :keyword comp: comp. Default value is "rename". Note that overriding this default value may
+        :type deleted_share_name: str
+        :param deleted_share_version: Specifies the version of the previously-deleted share. Default
+         value is None.
+        :type deleted_share_version: str
+        :keyword restype: restype. Default value is "share". Note that overriding this default value
+         may result in unsupported behavior.
+        :paramtype restype: str
+        :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
@@ -3147,99 +2415,52 @@
             304: ResourceNotModifiedError,
         }
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["rename"] = kwargs.pop("comp", _params.pop("comp", "rename"))
+        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
+        comp: Literal["undelete"] = kwargs.pop("comp", _params.pop("comp", "undelete"))
         cls: ClsType[None] = kwargs.pop("cls", None)
 
-        _source_lease_id = None
-        _destination_lease_id = None
-        _file_attributes = None
-        _file_creation_time = None
-        _file_last_write_time = None
-        _file_change_time = None
-        _file_content_type = None
-        if source_lease_access_conditions is not None:
-            _source_lease_id = source_lease_access_conditions.source_lease_id
-        if destination_lease_access_conditions is not None:
-            _destination_lease_id = destination_lease_access_conditions.destination_lease_id
-        if copy_file_smb_info is not None:
-            _file_attributes = copy_file_smb_info.file_attributes
-            _file_change_time = copy_file_smb_info.file_change_time
-            _file_creation_time = copy_file_smb_info.file_creation_time
-            _file_last_write_time = copy_file_smb_info.file_last_write_time
-        if file_http_headers is not None:
-            _file_content_type = file_http_headers.file_content_type
-
-        request = build_rename_request(
+        request = build_restore_request(
             url=self._config.url,
-            rename_source=rename_source,
             timeout=timeout,
-            replace_if_exists=replace_if_exists,
-            ignore_read_only=ignore_read_only,
-            source_lease_id=_source_lease_id,
-            destination_lease_id=_destination_lease_id,
-            file_attributes=_file_attributes,
-            file_creation_time=_file_creation_time,
-            file_last_write_time=_file_last_write_time,
-            file_change_time=_file_change_time,
-            file_permission=file_permission,
-            file_permission_key=file_permission_key,
-            metadata=metadata,
-            file_content_type=_file_content_type,
-            allow_trailing_dot=self._config.allow_trailing_dot,
-            allow_source_trailing_dot=self._config.allow_source_trailing_dot,
-            file_request_intent=self._config.file_request_intent,
+            request_id_parameter=request_id_parameter,
+            deleted_share_name=deleted_share_name,
+            deleted_share_version=deleted_share_version,
+            restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.rename.metadata["url"],
+            template_url=self.restore.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
         request.url = self._client.format_url(request.url)
 
         pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
-            "bool", response.headers.get("x-ms-request-server-encrypted")
-        )
-        response_headers["x-ms-file-permission-key"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-permission-key")
-        )
-        response_headers["x-ms-file-attributes"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-attributes")
-        )
-        response_headers["x-ms-file-creation-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-creation-time")
-        )
-        response_headers["x-ms-file-last-write-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-last-write-time")
-        )
-        response_headers["x-ms-file-change-time"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-change-time")
-        )
-        response_headers["x-ms-file-id"] = self._deserialize("str", response.headers.get("x-ms-file-id"))
-        response_headers["x-ms-file-parent-id"] = self._deserialize("str", response.headers.get("x-ms-file-parent-id"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    rename.metadata = {"url": "{url}/{shareName}/{directory}/{fileName}"}
+    restore.metadata = {"url": "{url}/{shareName}"}
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_patch.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/operations/_share_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_page_blob_operations.py`

 * *Files 18% similar despite different names*

```diff
@@ -2,2465 +2,2229 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
-import sys
-from typing import Any, Callable, Dict, IO, List, Optional, TypeVar, Union, overload
+import datetime
+from typing import Any, Callable, Dict, IO, Optional, TypeVar, Union
 
 from azure.core.exceptions import (
     ClientAuthenticationError,
     HttpResponseError,
     ResourceExistsError,
     ResourceNotFoundError,
-    ResourceNotModifiedError,
     map_error,
 )
 from azure.core.pipeline import PipelineResponse
 from azure.core.pipeline.transport import HttpResponse
 from azure.core.rest import HttpRequest
 from azure.core.tracing.decorator import distributed_trace
 from azure.core.utils import case_insensitive_dict
 
 from .. import models as _models
 from .._serialization import Serializer
 from .._vendor import _convert_request, _format_url_section
 
-if sys.version_info >= (3, 8):
-    from typing import Literal  # pylint: disable=no-name-in-module, ungrouped-imports
-else:
-    from typing_extensions import Literal  # type: ignore  # pylint: disable=ungrouped-imports
 T = TypeVar("T")
 ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]
 
 _SERIALIZER = Serializer()
 _SERIALIZER.client_side_validation = False
 
 
 def build_create_request(
     url: str,
     *,
+    content_length: int,
+    blob_content_length: int,
     timeout: Optional[int] = None,
+    tier: Optional[Union[str, "_models.PremiumPageBlobAccessTier"]] = None,
+    blob_content_type: Optional[str] = None,
+    blob_content_encoding: Optional[str] = None,
+    blob_content_language: Optional[str] = None,
+    blob_content_md5: Optional[bytes] = None,
+    blob_cache_control: Optional[str] = None,
     metadata: Optional[Dict[str, str]] = None,
-    quota: Optional[int] = None,
-    access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
-    enabled_protocols: Optional[str] = None,
-    root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
+    lease_id: Optional[str] = None,
+    blob_content_disposition: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    blob_sequence_number: int = 0,
+    request_id_parameter: Optional[str] = None,
+    blob_tags_string: Optional[str] = None,
+    immutability_policy_expiry: Optional[datetime.datetime] = None,
+    immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+    legal_hold: Optional[bool] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "PageBlob"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
+    _headers["x-ms-blob-type"] = _SERIALIZER.header("blob_type", blob_type, "str")
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if tier is not None:
+        _headers["x-ms-access-tier"] = _SERIALIZER.header("tier", tier, "str")
+    if blob_content_type is not None:
+        _headers["x-ms-blob-content-type"] = _SERIALIZER.header("blob_content_type", blob_content_type, "str")
+    if blob_content_encoding is not None:
+        _headers["x-ms-blob-content-encoding"] = _SERIALIZER.header(
+            "blob_content_encoding", blob_content_encoding, "str"
+        )
+    if blob_content_language is not None:
+        _headers["x-ms-blob-content-language"] = _SERIALIZER.header(
+            "blob_content_language", blob_content_language, "str"
+        )
+    if blob_content_md5 is not None:
+        _headers["x-ms-blob-content-md5"] = _SERIALIZER.header("blob_content_md5", blob_content_md5, "bytearray")
+    if blob_cache_control is not None:
+        _headers["x-ms-blob-cache-control"] = _SERIALIZER.header("blob_cache_control", blob_cache_control, "str")
     if metadata is not None:
         _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    if quota is not None:
-        _headers["x-ms-share-quota"] = _SERIALIZER.header("quota", quota, "int", minimum=1)
-    if access_tier is not None:
-        _headers["x-ms-access-tier"] = _SERIALIZER.header("access_tier", access_tier, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if enabled_protocols is not None:
-        _headers["x-ms-enabled-protocols"] = _SERIALIZER.header("enabled_protocols", enabled_protocols, "str")
-    if root_squash is not None:
-        _headers["x-ms-root-squash"] = _SERIALIZER.header("root_squash", root_squash, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_get_properties_request(
-    url: str,
-    *,
-    sharesnapshot: Optional[str] = None,
-    timeout: Optional[int] = None,
-    lease_id: Optional[str] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_delete_request(
-    url: str,
-    *,
-    sharesnapshot: Optional[str] = None,
-    timeout: Optional[int] = None,
-    delete_snapshots: Optional[Union[str, _models.DeleteSnapshotsOptionType]] = None,
-    lease_id: Optional[str] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if delete_snapshots is not None:
-        _headers["x-ms-delete-snapshots"] = _SERIALIZER.header("delete_snapshots", delete_snapshots, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="DELETE", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_acquire_lease_request(
-    url: str,
-    *,
-    timeout: Optional[int] = None,
-    duration: Optional[int] = None,
-    proposed_lease_id: Optional[str] = None,
-    sharesnapshot: Optional[str] = None,
-    request_id_parameter: Optional[str] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
-
-    # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    if duration is not None:
-        _headers["x-ms-lease-duration"] = _SERIALIZER.header("duration", duration, "int")
-    if proposed_lease_id is not None:
-        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    if blob_content_disposition is not None:
+        _headers["x-ms-blob-content-disposition"] = _SERIALIZER.header(
+            "blob_content_disposition", blob_content_disposition, "str"
+        )
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if encryption_scope is not None:
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-blob-content-length"] = _SERIALIZER.header("blob_content_length", blob_content_length, "int")
+    if blob_sequence_number is not None:
+        _headers["x-ms-blob-sequence-number"] = _SERIALIZER.header("blob_sequence_number", blob_sequence_number, "int")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if blob_tags_string is not None:
+        _headers["x-ms-tags"] = _SERIALIZER.header("blob_tags_string", blob_tags_string, "str")
+    if immutability_policy_expiry is not None:
+        _headers["x-ms-immutability-policy-until-date"] = _SERIALIZER.header(
+            "immutability_policy_expiry", immutability_policy_expiry, "rfc-1123"
+        )
+    if immutability_policy_mode is not None:
+        _headers["x-ms-immutability-policy-mode"] = _SERIALIZER.header(
+            "immutability_policy_mode", immutability_policy_mode, "str"
+        )
+    if legal_hold is not None:
+        _headers["x-ms-legal-hold"] = _SERIALIZER.header("legal_hold", legal_hold, "bool")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_release_lease_request(
+def build_upload_pages_request(
     url: str,
     *,
-    lease_id: str,
+    content_length: int,
+    content: IO,
+    transactional_content_md5: Optional[bytes] = None,
+    transactional_content_crc64: Optional[bytes] = None,
     timeout: Optional[int] = None,
-    sharesnapshot: Optional[str] = None,
+    range: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    if_sequence_number_less_than_or_equal_to: Optional[int] = None,
+    if_sequence_number_less_than: Optional[int] = None,
+    if_sequence_number_equal_to: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+    page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "update"))  # type: str
+    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-page-write"] = _SERIALIZER.header("page_write", page_write, "str")
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if transactional_content_md5 is not None:
+        _headers["Content-MD5"] = _SERIALIZER.header(
+            "transactional_content_md5", transactional_content_md5, "bytearray"
+        )
+    if transactional_content_crc64 is not None:
+        _headers["x-ms-content-crc64"] = _SERIALIZER.header(
+            "transactional_content_crc64", transactional_content_crc64, "bytearray"
+        )
+    if range is not None:
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if encryption_scope is not None:
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
+    if if_sequence_number_less_than_or_equal_to is not None:
+        _headers["x-ms-if-sequence-number-le"] = _SERIALIZER.header(
+            "if_sequence_number_less_than_or_equal_to", if_sequence_number_less_than_or_equal_to, "int"
+        )
+    if if_sequence_number_less_than is not None:
+        _headers["x-ms-if-sequence-number-lt"] = _SERIALIZER.header(
+            "if_sequence_number_less_than", if_sequence_number_less_than, "int"
+        )
+    if if_sequence_number_equal_to is not None:
+        _headers["x-ms-if-sequence-number-eq"] = _SERIALIZER.header(
+            "if_sequence_number_equal_to", if_sequence_number_equal_to, "int"
+        )
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if content_type is not None:
+        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
 
 
-def build_change_lease_request(
+def build_clear_pages_request(
     url: str,
     *,
-    lease_id: str,
+    content_length: int,
     timeout: Optional[int] = None,
-    proposed_lease_id: Optional[str] = None,
-    sharesnapshot: Optional[str] = None,
+    range: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    if_sequence_number_less_than_or_equal_to: Optional[int] = None,
+    if_sequence_number_less_than: Optional[int] = None,
+    if_sequence_number_equal_to: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+    page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "clear"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if proposed_lease_id is not None:
-        _headers["x-ms-proposed-lease-id"] = _SERIALIZER.header("proposed_lease_id", proposed_lease_id, "str")
+    _headers["x-ms-page-write"] = _SERIALIZER.header("page_write", page_write, "str")
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    if range is not None:
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if encryption_scope is not None:
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
+    if if_sequence_number_less_than_or_equal_to is not None:
+        _headers["x-ms-if-sequence-number-le"] = _SERIALIZER.header(
+            "if_sequence_number_less_than_or_equal_to", if_sequence_number_less_than_or_equal_to, "int"
+        )
+    if if_sequence_number_less_than is not None:
+        _headers["x-ms-if-sequence-number-lt"] = _SERIALIZER.header(
+            "if_sequence_number_less_than", if_sequence_number_less_than, "int"
+        )
+    if if_sequence_number_equal_to is not None:
+        _headers["x-ms-if-sequence-number-eq"] = _SERIALIZER.header(
+            "if_sequence_number_equal_to", if_sequence_number_equal_to, "int"
+        )
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_renew_lease_request(
+def build_upload_pages_from_url_request(
     url: str,
     *,
-    lease_id: str,
+    source_url: str,
+    source_range: str,
+    content_length: int,
+    range: str,
+    source_content_md5: Optional[bytes] = None,
+    source_contentcrc64: Optional[bytes] = None,
     timeout: Optional[int] = None,
-    sharesnapshot: Optional[str] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    if_sequence_number_less_than_or_equal_to: Optional[int] = None,
+    if_sequence_number_less_than: Optional[int] = None,
+    if_sequence_number_equal_to: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    source_if_modified_since: Optional[datetime.datetime] = None,
+    source_if_unmodified_since: Optional[datetime.datetime] = None,
+    source_if_match: Optional[str] = None,
+    source_if_none_match: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
+    copy_source_authorization: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["renew"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+    page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "update"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    _headers["x-ms-page-write"] = _SERIALIZER.header("page_write", page_write, "str")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("source_url", source_url, "str")
+    _headers["x-ms-source-range"] = _SERIALIZER.header("source_range", source_range, "str")
+    if source_content_md5 is not None:
+        _headers["x-ms-source-content-md5"] = _SERIALIZER.header("source_content_md5", source_content_md5, "bytearray")
+    if source_contentcrc64 is not None:
+        _headers["x-ms-source-content-crc64"] = _SERIALIZER.header(
+            "source_contentcrc64", source_contentcrc64, "bytearray"
+        )
+    _headers["Content-Length"] = _SERIALIZER.header("content_length", content_length, "int")
+    _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if encryption_scope is not None:
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if if_sequence_number_less_than_or_equal_to is not None:
+        _headers["x-ms-if-sequence-number-le"] = _SERIALIZER.header(
+            "if_sequence_number_less_than_or_equal_to", if_sequence_number_less_than_or_equal_to, "int"
+        )
+    if if_sequence_number_less_than is not None:
+        _headers["x-ms-if-sequence-number-lt"] = _SERIALIZER.header(
+            "if_sequence_number_less_than", if_sequence_number_less_than, "int"
+        )
+    if if_sequence_number_equal_to is not None:
+        _headers["x-ms-if-sequence-number-eq"] = _SERIALIZER.header(
+            "if_sequence_number_equal_to", if_sequence_number_equal_to, "int"
+        )
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    if source_if_modified_since is not None:
+        _headers["x-ms-source-if-modified-since"] = _SERIALIZER.header(
+            "source_if_modified_since", source_if_modified_since, "rfc-1123"
+        )
+    if source_if_unmodified_since is not None:
+        _headers["x-ms-source-if-unmodified-since"] = _SERIALIZER.header(
+            "source_if_unmodified_since", source_if_unmodified_since, "rfc-1123"
+        )
+    if source_if_match is not None:
+        _headers["x-ms-source-if-match"] = _SERIALIZER.header("source_if_match", source_if_match, "str")
+    if source_if_none_match is not None:
+        _headers["x-ms-source-if-none-match"] = _SERIALIZER.header("source_if_none_match", source_if_none_match, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
+    if copy_source_authorization is not None:
+        _headers["x-ms-copy-source-authorization"] = _SERIALIZER.header(
+            "copy_source_authorization", copy_source_authorization, "str"
+        )
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_break_lease_request(
+def build_get_page_ranges_request(
     url: str,
     *,
+    snapshot: Optional[str] = None,
     timeout: Optional[int] = None,
-    break_period: Optional[int] = None,
+    range: Optional[str] = None,
     lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
-    sharesnapshot: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-    action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "pagelist"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
+    if snapshot is not None:
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-    if sharesnapshot is not None:
-        _params["sharesnapshot"] = _SERIALIZER.query("sharesnapshot", sharesnapshot, "str")
+    if marker is not None:
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
+    if maxresults is not None:
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
 
     # Construct headers
-    _headers["x-ms-lease-action"] = _SERIALIZER.header("action", action, "str")
-    if break_period is not None:
-        _headers["x-ms-lease-break-period"] = _SERIALIZER.header("break_period", break_period, "int")
+    if range is not None:
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_create_snapshot_request(
-    url: str, *, timeout: Optional[int] = None, metadata: Optional[Dict[str, str]] = None, **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["snapshot"] = kwargs.pop("comp", _params.pop("comp", "snapshot"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    if metadata is not None:
-        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_create_permission_request(
+def build_get_page_ranges_diff_request(
     url: str,
     *,
+    snapshot: Optional[str] = None,
     timeout: Optional[int] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
+    prevsnapshot: Optional[str] = None,
+    prev_snapshot_url: Optional[str] = None,
+    range: Optional[str] = None,
+    lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
+    marker: Optional[str] = None,
+    maxresults: Optional[int] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
-    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "pagelist"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
+    if snapshot is not None:
+        _params["snapshot"] = _SERIALIZER.query("snapshot", snapshot, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
+    if prevsnapshot is not None:
+        _params["prevsnapshot"] = _SERIALIZER.query("prevsnapshot", prevsnapshot, "str")
+    if marker is not None:
+        _params["marker"] = _SERIALIZER.query("marker", marker, "str")
+    if maxresults is not None:
+        _params["maxresults"] = _SERIALIZER.query("maxresults", maxresults, "int", minimum=1)
 
     # Construct headers
+    if prev_snapshot_url is not None:
+        _headers["x-ms-previous-snapshot-url"] = _SERIALIZER.header("prev_snapshot_url", prev_snapshot_url, "str")
+    if range is not None:
+        _headers["x-ms-range"] = _SERIALIZER.header("range", range, "str")
+    if lease_id is not None:
+        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
-    if content_type is not None:
-        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_get_permission_request(
-    url: str,
-    *,
-    file_permission_key: str,
-    timeout: Optional[int] = None,
-    file_request_intent: Optional[Union[str, _models.ShareTokenIntent]] = None,
-    **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/json")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-file-permission-key"] = _SERIALIZER.header("file_permission_key", file_permission_key, "str")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if file_request_intent is not None:
-        _headers["x-ms-file-request-intent"] = _SERIALIZER.header("file_request_intent", file_request_intent, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_properties_request(
+def build_resize_request(
     url: str,
     *,
+    blob_content_length: int,
     timeout: Optional[int] = None,
-    quota: Optional[int] = None,
-    access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
     lease_id: Optional[str] = None,
-    root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
+    encryption_key: Optional[str] = None,
+    encryption_key_sha256: Optional[str] = None,
+    encryption_algorithm: Optional[Union[str, "_models.EncryptionAlgorithmType"]] = None,
+    encryption_scope: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if quota is not None:
-        _headers["x-ms-share-quota"] = _SERIALIZER.header("quota", quota, "int", minimum=1)
-    if access_tier is not None:
-        _headers["x-ms-access-tier"] = _SERIALIZER.header("access_tier", access_tier, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if root_squash is not None:
-        _headers["x-ms-root-squash"] = _SERIALIZER.header("root_squash", root_squash, "str")
+    if encryption_key is not None:
+        _headers["x-ms-encryption-key"] = _SERIALIZER.header("encryption_key", encryption_key, "str")
+    if encryption_key_sha256 is not None:
+        _headers["x-ms-encryption-key-sha256"] = _SERIALIZER.header(
+            "encryption_key_sha256", encryption_key_sha256, "str"
+        )
+    if encryption_algorithm is not None:
+        _headers["x-ms-encryption-algorithm"] = _SERIALIZER.header("encryption_algorithm", encryption_algorithm, "str")
+    if encryption_scope is not None:
+        _headers["x-ms-encryption-scope"] = _SERIALIZER.header("encryption_scope", encryption_scope, "str")
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-blob-content-length"] = _SERIALIZER.header("blob_content_length", blob_content_length, "int")
+    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_set_metadata_request(
+def build_update_sequence_number_request(
     url: str,
     *,
+    sequence_number_action: Union[str, "_models.SequenceNumberActionType"],
     timeout: Optional[int] = None,
-    metadata: Optional[Dict[str, str]] = None,
     lease_id: Optional[str] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
+    blob_sequence_number: int = 0,
+    request_id_parameter: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
-    if metadata is not None:
-        _headers["x-ms-meta"] = _SERIALIZER.header("metadata", metadata, "{str}")
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if lease_id is not None:
         _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_get_access_policy_request(
-    url: str, *, timeout: Optional[int] = None, lease_id: Optional[str] = None, **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-sequence-number-action"] = _SERIALIZER.header(
+        "sequence_number_action", sequence_number_action, "str"
+    )
+    if blob_sequence_number is not None:
+        _headers["x-ms-blob-sequence-number"] = _SERIALIZER.header("blob_sequence_number", blob_sequence_number, "int")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
-
-
-def build_set_access_policy_request(
-    url: str, *, timeout: Optional[int] = None, lease_id: Optional[str] = None, content: Any = None, **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
-    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
-    if content_type is not None:
-        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
-    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
-
-    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, content=content, **kwargs)
-
-
-def build_get_statistics_request(
-    url: str, *, timeout: Optional[int] = None, lease_id: Optional[str] = None, **kwargs: Any
-) -> HttpRequest:
-    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["stats"] = kwargs.pop("comp", _params.pop("comp", "stats"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
-    accept = _headers.pop("Accept", "application/xml")
-
-    # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
-    path_format_arguments = {
-        "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
-    }
-
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
-
-    # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
-    _params["comp"] = _SERIALIZER.query("comp", comp, "str")
-    if timeout is not None:
-        _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
-
-    # Construct headers
-    _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
-    if lease_id is not None:
-        _headers["x-ms-lease-id"] = _SERIALIZER.header("lease_id", lease_id, "str")
+    if request_id_parameter is not None:
+        _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
-    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)
+    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-def build_restore_request(
+def build_copy_incremental_request(
     url: str,
     *,
+    copy_source: str,
     timeout: Optional[int] = None,
+    if_modified_since: Optional[datetime.datetime] = None,
+    if_unmodified_since: Optional[datetime.datetime] = None,
+    if_match: Optional[str] = None,
+    if_none_match: Optional[str] = None,
+    if_tags: Optional[str] = None,
     request_id_parameter: Optional[str] = None,
-    deleted_share_name: Optional[str] = None,
-    deleted_share_version: Optional[str] = None,
     **kwargs: Any
 ) -> HttpRequest:
     _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
     _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-    restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-    comp: Literal["undelete"] = kwargs.pop("comp", _params.pop("comp", "undelete"))
-    version: Literal["2022-11-02"] = kwargs.pop("version", _headers.pop("x-ms-version", "2022-11-02"))
+    comp = kwargs.pop("comp", _params.pop("comp", "incrementalcopy"))  # type: str
+    version = kwargs.pop("version", _headers.pop("x-ms-version", "2021-12-02"))  # type: str
     accept = _headers.pop("Accept", "application/xml")
 
     # Construct URL
-    _url = kwargs.pop("template_url", "{url}/{shareName}")
+    _url = kwargs.pop("template_url", "{url}/{containerName}/{blob}")
     path_format_arguments = {
         "url": _SERIALIZER.url("url", url, "str", skip_quote=True),
     }
 
-    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore
+    _url = _format_url_section(_url, **path_format_arguments)
 
     # Construct parameters
-    _params["restype"] = _SERIALIZER.query("restype", restype, "str")
     _params["comp"] = _SERIALIZER.query("comp", comp, "str")
     if timeout is not None:
         _params["timeout"] = _SERIALIZER.query("timeout", timeout, "int", minimum=0)
 
     # Construct headers
+    if if_modified_since is not None:
+        _headers["If-Modified-Since"] = _SERIALIZER.header("if_modified_since", if_modified_since, "rfc-1123")
+    if if_unmodified_since is not None:
+        _headers["If-Unmodified-Since"] = _SERIALIZER.header("if_unmodified_since", if_unmodified_since, "rfc-1123")
+    if if_match is not None:
+        _headers["If-Match"] = _SERIALIZER.header("if_match", if_match, "str")
+    if if_none_match is not None:
+        _headers["If-None-Match"] = _SERIALIZER.header("if_none_match", if_none_match, "str")
+    if if_tags is not None:
+        _headers["x-ms-if-tags"] = _SERIALIZER.header("if_tags", if_tags, "str")
+    _headers["x-ms-copy-source"] = _SERIALIZER.header("copy_source", copy_source, "str")
     _headers["x-ms-version"] = _SERIALIZER.header("version", version, "str")
     if request_id_parameter is not None:
         _headers["x-ms-client-request-id"] = _SERIALIZER.header("request_id_parameter", request_id_parameter, "str")
-    if deleted_share_name is not None:
-        _headers["x-ms-deleted-share-name"] = _SERIALIZER.header("deleted_share_name", deleted_share_name, "str")
-    if deleted_share_version is not None:
-        _headers["x-ms-deleted-share-version"] = _SERIALIZER.header(
-            "deleted_share_version", deleted_share_version, "str"
-        )
     _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")
 
     return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)
 
 
-class ShareOperations:
+class PageBlobOperations:
     """
     .. warning::
         **DO NOT** instantiate this class directly.
 
         Instead, you should access the following operations through
-        :class:`~azure.storage.fileshare.AzureFileStorage`'s
-        :attr:`share` attribute.
+        :class:`~azure.storage.blob.AzureBlobStorage`'s
+        :attr:`page_blob` attribute.
     """
 
     models = _models
 
     def __init__(self, *args, **kwargs):
         input_args = list(args)
         self._client = input_args.pop(0) if input_args else kwargs.pop("client")
         self._config = input_args.pop(0) if input_args else kwargs.pop("config")
         self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
         self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")
 
     @distributed_trace
     def create(  # pylint: disable=inconsistent-return-statements
         self,
+        content_length: int,
+        blob_content_length: int,
         timeout: Optional[int] = None,
+        tier: Optional[Union[str, "_models.PremiumPageBlobAccessTier"]] = None,
         metadata: Optional[Dict[str, str]] = None,
-        quota: Optional[int] = None,
-        access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
-        enabled_protocols: Optional[str] = None,
-        root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
-        **kwargs: Any
-    ) -> None:
-        """Creates a new share under the specified account. If the share with the same name already
-        exists, the operation fails.
-
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param metadata: A name-value pair to associate with a file storage object. Default value is
-         None.
-        :type metadata: dict[str, str]
-        :param quota: Specifies the maximum size of the share, in gigabytes. Default value is None.
-        :type quota: int
-        :param access_tier: Specifies the access tier of the share. Known values are:
-         "TransactionOptimized", "Hot", and "Cool". Default value is None.
-        :type access_tier: str or ~azure.storage.fileshare.models.ShareAccessTier
-        :param enabled_protocols: Protocols to enable on the share. Default value is None.
-        :type enabled_protocols: str
-        :param root_squash: Root squash to set on the share.  Only valid for NFS shares. Known values
-         are: "NoRootSquash", "RootSquash", and "AllSquash". Default value is None.
-        :type root_squash: str or ~azure.storage.fileshare.models.ShareRootSquash
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        request = build_create_request(
-            url=self._config.url,
-            timeout=timeout,
-            metadata=metadata,
-            quota=quota,
-            access_tier=access_tier,
-            enabled_protocols=enabled_protocols,
-            root_squash=root_squash,
-            restype=restype,
-            version=self._config.version,
-            template_url=self.create.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [201]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    create.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def get_properties(  # pylint: disable=inconsistent-return-statements
-        self,
-        sharesnapshot: Optional[str] = None,
-        timeout: Optional[int] = None,
+        blob_sequence_number: int = 0,
+        request_id_parameter: Optional[str] = None,
+        blob_tags_string: Optional[str] = None,
+        immutability_policy_expiry: Optional[datetime.datetime] = None,
+        immutability_policy_mode: Optional[Union[str, "_models.BlobImmutabilityPolicyMode"]] = None,
+        legal_hold: Optional[bool] = None,
+        blob_http_headers: Optional[_models.BlobHTTPHeaders] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Returns all user-defined metadata and system properties for the specified share or share
-        snapshot. The data returned does not include the share's list of files.
+        """The Create operation creates a new page blob.
 
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param blob_content_length: This header specifies the maximum size for the page blob, up to 1
+         TB. The page blob size must be aligned to a 512-byte boundary. Required.
+        :type blob_content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param tier: Optional. Indicates the tier to be set on the page blob. Known values are: "P4",
+         "P6", "P10", "P15", "P20", "P30", "P40", "P50", "P60", "P70", and "P80". Default value is None.
+        :type tier: str or ~azure.storage.blob.models.PremiumPageBlobAccessTier
+        :param metadata: Optional. Specifies a user-defined name-value pair associated with the blob.
+         If no name-value pairs are specified, the operation will copy the metadata from the source blob
+         or file to the destination blob. If one or more name-value pairs are specified, the destination
+         blob is created with the specified metadata, and metadata is not copied from the source blob or
+         file. Note that beginning with version 2009-09-19, metadata names must adhere to the naming
+         rules for C# identifiers. See Naming and Referencing Containers, Blobs, and Metadata for more
+         information. Default value is None.
+        :type metadata: dict[str, str]
+        :param blob_sequence_number: Set for page blobs only. The sequence number is a user-controlled
+         value that you can use to track requests. The value of the sequence number must be between 0
+         and 2^63 - 1. Default value is 0.
+        :type blob_sequence_number: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param blob_tags_string: Optional.  Used to set blob tags in various blob operations. Default
+         value is None.
+        :type blob_tags_string: str
+        :param immutability_policy_expiry: Specifies the date time when the blobs immutability policy
+         is set to expire. Default value is None.
+        :type immutability_policy_expiry: ~datetime.datetime
+        :param immutability_policy_mode: Specifies the immutability policy mode to set on the blob.
+         Known values are: "Mutable", "Unlocked", and "Locked". Default value is None.
+        :type immutability_policy_mode: str or ~azure.storage.blob.models.BlobImmutabilityPolicyMode
+        :param legal_hold: Specified if a legal hold should be set on the blob. Default value is None.
+        :type legal_hold: bool
+        :param blob_http_headers: Parameter group. Default value is None.
+        :type blob_http_headers: ~azure.storage.blob.models.BlobHTTPHeaders
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.blob.models.CpkInfo
+        :param cpk_scope_info: Parameter group. Default value is None.
+        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword blob_type: Specifies the type of blob to create: block blob, page blob, or append
+         blob. Default value is "PageBlob". Note that overriding this default value may result in
+         unsupported behavior.
+        :paramtype blob_type: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
+        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _params = kwargs.pop("params", {}) or {}
 
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        blob_type = kwargs.pop("blob_type", _headers.pop("x-ms-blob-type", "PageBlob"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
+        _blob_content_type = None
+        _blob_content_encoding = None
+        _blob_content_language = None
+        _blob_content_md5 = None
+        _blob_cache_control = None
         _lease_id = None
+        _blob_content_disposition = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        _encryption_scope = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
+        if blob_http_headers is not None:
+            _blob_cache_control = blob_http_headers.blob_cache_control
+            _blob_content_disposition = blob_http_headers.blob_content_disposition
+            _blob_content_encoding = blob_http_headers.blob_content_encoding
+            _blob_content_language = blob_http_headers.blob_content_language
+            _blob_content_md5 = blob_http_headers.blob_content_md5
+            _blob_content_type = blob_http_headers.blob_content_type
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
+        if cpk_scope_info is not None:
+            _encryption_scope = cpk_scope_info.encryption_scope
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_get_properties_request(
+        request = build_create_request(
             url=self._config.url,
-            sharesnapshot=sharesnapshot,
+            content_length=content_length,
+            blob_content_length=blob_content_length,
             timeout=timeout,
+            tier=tier,
+            blob_content_type=_blob_content_type,
+            blob_content_encoding=_blob_content_encoding,
+            blob_content_language=_blob_content_language,
+            blob_content_md5=_blob_content_md5,
+            blob_cache_control=_blob_cache_control,
+            metadata=metadata,
             lease_id=_lease_id,
-            restype=restype,
+            blob_content_disposition=_blob_content_disposition,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            encryption_scope=_encryption_scope,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
+            blob_sequence_number=blob_sequence_number,
+            request_id_parameter=request_id_parameter,
+            blob_tags_string=blob_tags_string,
+            immutability_policy_expiry=immutability_policy_expiry,
+            immutability_policy_mode=immutability_policy_mode,
+            legal_hold=legal_hold,
+            blob_type=blob_type,
             version=self._config.version,
-            template_url=self.get_properties.metadata["url"],
+            template_url=self.create.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["x-ms-meta"] = self._deserialize("{str}", response.headers.get("x-ms-meta"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
+        response_headers["x-ms-version-id"] = self._deserialize("str", response.headers.get("x-ms-version-id"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-share-quota"] = self._deserialize("int", response.headers.get("x-ms-share-quota"))
-        response_headers["x-ms-share-provisioned-iops"] = self._deserialize(
-            "int", response.headers.get("x-ms-share-provisioned-iops")
-        )
-        response_headers["x-ms-share-provisioned-ingress-mbps"] = self._deserialize(
-            "int", response.headers.get("x-ms-share-provisioned-ingress-mbps")
-        )
-        response_headers["x-ms-share-provisioned-egress-mbps"] = self._deserialize(
-            "int", response.headers.get("x-ms-share-provisioned-egress-mbps")
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
         )
-        response_headers["x-ms-share-next-allowed-quota-downgrade-time"] = self._deserialize(
-            "rfc-1123", response.headers.get("x-ms-share-next-allowed-quota-downgrade-time")
-        )
-        response_headers["x-ms-share-provisioned-bandwidth-mibps"] = self._deserialize(
-            "int", response.headers.get("x-ms-share-provisioned-bandwidth-mibps")
-        )
-        response_headers["x-ms-lease-duration"] = self._deserialize("str", response.headers.get("x-ms-lease-duration"))
-        response_headers["x-ms-lease-state"] = self._deserialize("str", response.headers.get("x-ms-lease-state"))
-        response_headers["x-ms-lease-status"] = self._deserialize("str", response.headers.get("x-ms-lease-status"))
-        response_headers["x-ms-access-tier"] = self._deserialize("str", response.headers.get("x-ms-access-tier"))
-        response_headers["x-ms-access-tier-change-time"] = self._deserialize(
-            "rfc-1123", response.headers.get("x-ms-access-tier-change-time")
-        )
-        response_headers["x-ms-access-tier-transition-state"] = self._deserialize(
-            "str", response.headers.get("x-ms-access-tier-transition-state")
-        )
-        response_headers["x-ms-enabled-protocols"] = self._deserialize(
-            "str", response.headers.get("x-ms-enabled-protocols")
-        )
-        response_headers["x-ms-root-squash"] = self._deserialize("str", response.headers.get("x-ms-root-squash"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    get_properties.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def delete(  # pylint: disable=inconsistent-return-statements
-        self,
-        sharesnapshot: Optional[str] = None,
-        timeout: Optional[int] = None,
-        delete_snapshots: Optional[Union[str, _models.DeleteSnapshotsOptionType]] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        **kwargs: Any
-    ) -> None:
-        """Operation marks the specified share or share snapshot for deletion. The share or share snapshot
-        and any files contained within it are later deleted during garbage collection.
-
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param delete_snapshots: Specifies the option include to delete the base share and all of its
-         snapshots. Known values are: "include" and "include-leased". Default value is None.
-        :type delete_snapshots: str or ~azure.storage.fileshare.models.DeleteSnapshotsOptionType
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        _lease_id = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
-        request = build_delete_request(
-            url=self._config.url,
-            sharesnapshot=sharesnapshot,
-            timeout=timeout,
-            delete_snapshots=delete_snapshots,
-            lease_id=_lease_id,
-            restype=restype,
-            version=self._config.version,
-            template_url=self.delete.metadata["url"],
-            headers=_headers,
-            params=_params,
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
         )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
         )
 
-        response = pipeline_response.http_response
-
-        if response.status_code not in [202]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    delete.metadata = {"url": "{url}/{shareName}"}
+    create.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def acquire_lease(  # pylint: disable=inconsistent-return-statements
+    def upload_pages(  # pylint: disable=inconsistent-return-statements
         self,
+        content_length: int,
+        body: IO,
+        transactional_content_md5: Optional[bytes] = None,
+        transactional_content_crc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
-        duration: Optional[int] = None,
-        proposed_lease_id: Optional[str] = None,
-        sharesnapshot: Optional[str] = None,
+        range: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        sequence_number_access_conditions: Optional[_models.SequenceNumberAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
-        for set and delete share operations.
+        """The Upload Pages operation writes a range of pages to a page blob.
 
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param body: Initial data. Required.
+        :type body: IO
+        :param transactional_content_md5: Specify the transactional md5 for the body, to be validated
+         by the service. Default value is None.
+        :type transactional_content_md5: bytes
+        :param transactional_content_crc64: Specify the transactional crc64 for the body, to be
+         validated by the service. Default value is None.
+        :type transactional_content_crc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param duration: Specifies the duration of the lease, in seconds, or negative one (-1) for a
-         lease that never expires. A non-infinite lease can be between 15 and 60 seconds. A lease
-         duration cannot be changed using renew or change. Default value is None.
-        :type duration: int
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Default value is None.
-        :type proposed_lease_id: str
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
+        :param range: Return only the bytes of the blob in the specified range. Default value is None.
+        :type range: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.blob.models.CpkInfo
+        :param cpk_scope_info: Parameter group. Default value is None.
+        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
+        :param sequence_number_access_conditions: Parameter group. Default value is None.
+        :type sequence_number_access_conditions:
+         ~azure.storage.blob.models.SequenceNumberAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "page". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "acquire". Note that
+        :keyword page_write: Required. You may specify one of the following options:
+
+
+         * Update: Writes the bytes specified by the request body into the specified range. The Range
+         and Content-Length headers must match to perform the update.
+         * Clear: Clears the specified range and releases the space used in storage for that range. To
+         clear a range, set the Content-Length header to zero, and the Range header to a value that
+         indicates the range to clear, up to maximum blob size. Default value is "update". Note that
          overriding this default value may result in unsupported behavior.
-        :paramtype action: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
+        :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["acquire"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "acquire"))
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+        page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "update"))  # type: str
+        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", "application/octet-stream"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        _lease_id = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        _encryption_scope = None
+        _if_sequence_number_less_than_or_equal_to = None
+        _if_sequence_number_less_than = None
+        _if_sequence_number_equal_to = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
+        if cpk_scope_info is not None:
+            _encryption_scope = cpk_scope_info.encryption_scope
+        if sequence_number_access_conditions is not None:
+            _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
+            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
+            _if_sequence_number_less_than_or_equal_to = (
+                sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
+            )
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        _content = body
 
-        request = build_acquire_lease_request(
+        request = build_upload_pages_request(
             url=self._config.url,
+            content_length=content_length,
+            transactional_content_md5=transactional_content_md5,
+            transactional_content_crc64=transactional_content_crc64,
             timeout=timeout,
-            duration=duration,
-            proposed_lease_id=proposed_lease_id,
-            sharesnapshot=sharesnapshot,
+            range=range,
+            lease_id=_lease_id,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            encryption_scope=_encryption_scope,
+            if_sequence_number_less_than_or_equal_to=_if_sequence_number_less_than_or_equal_to,
+            if_sequence_number_less_than=_if_sequence_number_less_than,
+            if_sequence_number_equal_to=_if_sequence_number_equal_to,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             comp=comp,
-            action=action,
-            restype=restype,
+            page_write=page_write,
+            content_type=content_type,
             version=self._config.version,
-            template_url=self.acquire_lease.metadata["url"],
+            content=_content,
+            template_url=self.upload_pages.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
         )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    acquire_lease.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def release_lease(  # pylint: disable=inconsistent-return-statements
-        self,
-        lease_id: str,
-        timeout: Optional[int] = None,
-        sharesnapshot: Optional[str] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
-    ) -> None:
-        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
-        for set and delete share operations.
-
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "release". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype action: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["release"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "release"))
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        request = build_release_lease_request(
-            url=self._config.url,
-            lease_id=lease_id,
-            timeout=timeout,
-            sharesnapshot=sharesnapshot,
-            request_id_parameter=request_id_parameter,
-            comp=comp,
-            action=action,
-            restype=restype,
-            version=self._config.version,
-            template_url=self.release_lease.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
         )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    release_lease.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def change_lease(  # pylint: disable=inconsistent-return-statements
-        self,
-        lease_id: str,
-        timeout: Optional[int] = None,
-        proposed_lease_id: Optional[str] = None,
-        sharesnapshot: Optional[str] = None,
-        request_id_parameter: Optional[str] = None,
-        **kwargs: Any
-    ) -> None:
-        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
-        for set and delete share operations.
-
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param proposed_lease_id: Proposed lease ID, in a GUID string format. The File service returns
-         400 (Invalid request) if the proposed lease ID is not in the correct format. See Guid
-         Constructor (String) for a list of valid GUID string formats. Default value is None.
-        :type proposed_lease_id: str
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
-        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
-         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
-         value is None.
-        :type request_id_parameter: str
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "change". Note that
-         overriding this default value may result in unsupported behavior.
-        :paramtype action: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["change"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "change"))
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        request = build_change_lease_request(
-            url=self._config.url,
-            lease_id=lease_id,
-            timeout=timeout,
-            proposed_lease_id=proposed_lease_id,
-            sharesnapshot=sharesnapshot,
-            request_id_parameter=request_id_parameter,
-            comp=comp,
-            action=action,
-            restype=restype,
-            version=self._config.version,
-            template_url=self.change_lease.metadata["url"],
-            headers=_headers,
-            params=_params,
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
         )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
         )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
         )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    change_lease.metadata = {"url": "{url}/{shareName}"}
+    upload_pages.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def renew_lease(  # pylint: disable=inconsistent-return-statements
+    def clear_pages(  # pylint: disable=inconsistent-return-statements
         self,
-        lease_id: str,
+        content_length: int,
         timeout: Optional[int] = None,
-        sharesnapshot: Optional[str] = None,
+        range: Optional[str] = None,
         request_id_parameter: Optional[str] = None,
+        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        sequence_number_access_conditions: Optional[_models.SequenceNumberAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
-        for set and delete share operations.
+        """The Clear Pages operation clears a set of pages from a page blob.
 
-        :param lease_id: Specifies the current lease ID on the resource. Required.
-        :type lease_id: str
+        :param content_length: The length of the request. Required.
+        :type content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
+        :param range: Return only the bytes of the blob in the specified range. Default value is None.
+        :type range: str
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+        :param lease_access_conditions: Parameter group. Default value is None.
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.blob.models.CpkInfo
+        :param cpk_scope_info: Parameter group. Default value is None.
+        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
+        :param sequence_number_access_conditions: Parameter group. Default value is None.
+        :type sequence_number_access_conditions:
+         ~azure.storage.blob.models.SequenceNumberAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "page". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "renew". Note that
+        :keyword page_write: Required. You may specify one of the following options:
+
+
+         * Update: Writes the bytes specified by the request body into the specified range. The Range
+         and Content-Length headers must match to perform the update.
+         * Clear: Clears the specified range and releases the space used in storage for that range. To
+         clear a range, set the Content-Length header to zero, and the Range header to a value that
+         indicates the range to clear, up to maximum blob size. Default value is "clear". Note that
          overriding this default value may result in unsupported behavior.
-        :paramtype action: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
+        :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["renew"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "renew"))
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+        page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "clear"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
-        request = build_renew_lease_request(
+        _lease_id = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        _encryption_scope = None
+        _if_sequence_number_less_than_or_equal_to = None
+        _if_sequence_number_less_than = None
+        _if_sequence_number_equal_to = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
+        if lease_access_conditions is not None:
+            _lease_id = lease_access_conditions.lease_id
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
+        if cpk_scope_info is not None:
+            _encryption_scope = cpk_scope_info.encryption_scope
+        if sequence_number_access_conditions is not None:
+            _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
+            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
+            _if_sequence_number_less_than_or_equal_to = (
+                sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
+            )
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+
+        request = build_clear_pages_request(
             url=self._config.url,
-            lease_id=lease_id,
+            content_length=content_length,
             timeout=timeout,
-            sharesnapshot=sharesnapshot,
+            range=range,
+            lease_id=_lease_id,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            encryption_scope=_encryption_scope,
+            if_sequence_number_less_than_or_equal_to=_if_sequence_number_less_than_or_equal_to,
+            if_sequence_number_less_than=_if_sequence_number_less_than,
+            if_sequence_number_equal_to=_if_sequence_number_equal_to,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
             comp=comp,
-            action=action,
-            restype=restype,
+            page_write=page_write,
             version=self._config.version,
-            template_url=self.renew_lease.metadata["url"],
+            template_url=self.clear_pages.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [200]:
+        if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
+        )
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    renew_lease.metadata = {"url": "{url}/{shareName}"}
+    clear_pages.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def break_lease(  # pylint: disable=inconsistent-return-statements
+    def upload_pages_from_url(  # pylint: disable=inconsistent-return-statements
         self,
+        source_url: str,
+        source_range: str,
+        content_length: int,
+        range: str,
+        source_content_md5: Optional[bytes] = None,
+        source_contentcrc64: Optional[bytes] = None,
         timeout: Optional[int] = None,
-        break_period: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        sharesnapshot: Optional[str] = None,
+        copy_source_authorization: Optional[str] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        sequence_number_access_conditions: Optional[_models.SequenceNumberAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
+        source_modified_access_conditions: Optional[_models.SourceModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """The Lease Share operation establishes and manages a lock on a share, or the specified snapshot
-        for set and delete share operations.
+        """The Upload Pages operation writes a range of pages to a page blob where the contents are read
+        from a URL.
 
+        :param source_url: Specify a URL to the copy source. Required.
+        :type source_url: str
+        :param source_range: Bytes of source data in the specified range. The length of this range
+         should match the ContentLength header and x-ms-range/Range destination range header. Required.
+        :type source_range: str
+        :param content_length: The length of the request. Required.
+        :type content_length: int
+        :param range: The range of bytes to which the source range would be written. The range should
+         be 512 aligned and range-end is required. Required.
+        :type range: str
+        :param source_content_md5: Specify the md5 calculated for the range of bytes that must be read
+         from the copy source. Default value is None.
+        :type source_content_md5: bytes
+        :param source_contentcrc64: Specify the crc64 calculated for the range of bytes that must be
+         read from the copy source. Default value is None.
+        :type source_contentcrc64: bytes
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param break_period: For a break operation, proposed duration the lease should continue before
-         it is broken, in seconds, between 0 and 60. This break period is only used if it is shorter
-         than the time remaining on the lease. If longer, the time remaining on the lease is used. A new
-         lease will not be available before the break period has expired, but the lease may be held for
-         longer than the break period. If this header does not appear with a break operation, a
-         fixed-duration lease breaks after the remaining lease period elapses, and an infinite lease
-         breaks immediately. Default value is None.
-        :type break_period: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param sharesnapshot: The snapshot parameter is an opaque DateTime value that, when present,
-         specifies the share snapshot to query. Default value is None.
-        :type sharesnapshot: str
+        :param copy_source_authorization: Only Bearer type is supported. Credentials should be a valid
+         OAuth access token to copy source. Default value is None.
+        :type copy_source_authorization: str
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.blob.models.CpkInfo
+        :param cpk_scope_info: Parameter group. Default value is None.
+        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword comp: comp. Default value is "lease". Note that overriding this default value may
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param sequence_number_access_conditions: Parameter group. Default value is None.
+        :type sequence_number_access_conditions:
+         ~azure.storage.blob.models.SequenceNumberAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :param source_modified_access_conditions: Parameter group. Default value is None.
+        :type source_modified_access_conditions:
+         ~azure.storage.blob.models.SourceModifiedAccessConditions
+        :keyword comp: comp. Default value is "page". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
-        :keyword action: Describes what lease action to take. Default value is "break". Note that
+        :keyword page_write: Required. You may specify one of the following options:
+
+
+         * Update: Writes the bytes specified by the request body into the specified range. The Range
+         and Content-Length headers must match to perform the update.
+         * Clear: Clears the specified range and releases the space used in storage for that range. To
+         clear a range, set the Content-Length header to zero, and the Range header to a value that
+         indicates the range to clear, up to maximum blob size. Default value is "update". Note that
          overriding this default value may result in unsupported behavior.
-        :paramtype action: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
+        :paramtype page_write: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        comp: Literal["lease"] = kwargs.pop("comp", _params.pop("comp", "lease"))
-        action: Literal["break"] = kwargs.pop("action", _headers.pop("x-ms-lease-action", "break"))
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
+        comp = kwargs.pop("comp", _params.pop("comp", "page"))  # type: str
+        page_write = kwargs.pop("page_write", _headers.pop("x-ms-page-write", "update"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        _encryption_scope = None
         _lease_id = None
+        _if_sequence_number_less_than_or_equal_to = None
+        _if_sequence_number_less_than = None
+        _if_sequence_number_equal_to = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
+        _source_if_modified_since = None
+        _source_if_unmodified_since = None
+        _source_if_match = None
+        _source_if_none_match = None
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
+        if cpk_scope_info is not None:
+            _encryption_scope = cpk_scope_info.encryption_scope
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if sequence_number_access_conditions is not None:
+            _if_sequence_number_equal_to = sequence_number_access_conditions.if_sequence_number_equal_to
+            _if_sequence_number_less_than = sequence_number_access_conditions.if_sequence_number_less_than
+            _if_sequence_number_less_than_or_equal_to = (
+                sequence_number_access_conditions.if_sequence_number_less_than_or_equal_to
+            )
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
+        if source_modified_access_conditions is not None:
+            _source_if_match = source_modified_access_conditions.source_if_match
+            _source_if_modified_since = source_modified_access_conditions.source_if_modified_since
+            _source_if_none_match = source_modified_access_conditions.source_if_none_match
+            _source_if_unmodified_since = source_modified_access_conditions.source_if_unmodified_since
 
-        request = build_break_lease_request(
+        request = build_upload_pages_from_url_request(
             url=self._config.url,
+            source_url=source_url,
+            source_range=source_range,
+            content_length=content_length,
+            range=range,
+            source_content_md5=source_content_md5,
+            source_contentcrc64=source_contentcrc64,
             timeout=timeout,
-            break_period=break_period,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            encryption_scope=_encryption_scope,
             lease_id=_lease_id,
+            if_sequence_number_less_than_or_equal_to=_if_sequence_number_less_than_or_equal_to,
+            if_sequence_number_less_than=_if_sequence_number_less_than,
+            if_sequence_number_equal_to=_if_sequence_number_equal_to,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
+            source_if_modified_since=_source_if_modified_since,
+            source_if_unmodified_since=_source_if_unmodified_since,
+            source_if_match=_source_if_match,
+            source_if_none_match=_source_if_none_match,
             request_id_parameter=request_id_parameter,
-            sharesnapshot=sharesnapshot,
-            comp=comp,
-            action=action,
-            restype=restype,
-            version=self._config.version,
-            template_url=self.break_lease.metadata["url"],
-            headers=_headers,
-            params=_params,
-        )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
-        )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [202]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-lease-time"] = self._deserialize("int", response.headers.get("x-ms-lease-time"))
-        response_headers["x-ms-lease-id"] = self._deserialize("str", response.headers.get("x-ms-lease-id"))
-        response_headers["x-ms-client-request-id"] = self._deserialize(
-            "str", response.headers.get("x-ms-client-request-id")
-        )
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    break_lease.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def create_snapshot(  # pylint: disable=inconsistent-return-statements
-        self, timeout: Optional[int] = None, metadata: Optional[Dict[str, str]] = None, **kwargs: Any
-    ) -> None:
-        """Creates a read-only snapshot of a share.
-
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param metadata: A name-value pair to associate with a file storage object. Default value is
-         None.
-        :type metadata: dict[str, str]
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "snapshot". Note that overriding this default value may
-         result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["snapshot"] = kwargs.pop("comp", _params.pop("comp", "snapshot"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        request = build_create_snapshot_request(
-            url=self._config.url,
-            timeout=timeout,
-            metadata=metadata,
-            restype=restype,
+            copy_source_authorization=copy_source_authorization,
             comp=comp,
+            page_write=page_write,
             version=self._config.version,
-            template_url=self.create_snapshot.metadata["url"],
+            template_url=self.upload_pages_from_url.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [201]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["x-ms-snapshot"] = self._deserialize("str", response.headers.get("x-ms-snapshot"))
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    create_snapshot.metadata = {"url": "{url}/{shareName}"}
-
-    @overload
-    def create_permission(  # pylint: disable=inconsistent-return-statements
-        self,
-        share_permission: _models.SharePermission,
-        timeout: Optional[int] = None,
-        *,
-        content_type: str = "application/json",
-        **kwargs: Any
-    ) -> None:
-        """Create a permission (a security descriptor).
-
-        :param share_permission: A permission (a security descriptor) at the share level. Required.
-        :type share_permission: ~azure.storage.fileshare.models.SharePermission
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
-         Default value is "application/json".
-        :paramtype content_type: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-
-    @overload
-    def create_permission(  # pylint: disable=inconsistent-return-statements
-        self,
-        share_permission: IO,
-        timeout: Optional[int] = None,
-        *,
-        content_type: str = "application/json",
-        **kwargs: Any
-    ) -> None:
-        """Create a permission (a security descriptor).
-
-        :param share_permission: A permission (a security descriptor) at the share level. Required.
-        :type share_permission: IO
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
-         Default value is "application/json".
-        :paramtype content_type: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-
-    @distributed_trace
-    def create_permission(  # pylint: disable=inconsistent-return-statements
-        self, share_permission: Union[_models.SharePermission, IO], timeout: Optional[int] = None, **kwargs: Any
-    ) -> None:
-        """Create a permission (a security descriptor).
-
-        :param share_permission: A permission (a security descriptor) at the share level. Is either a
-         SharePermission type or a IO type. Required.
-        :type share_permission: ~azure.storage.fileshare.models.SharePermission or IO
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype comp: str
-        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
-         Default value is None.
-        :paramtype content_type: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
-        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
-        cls: ClsType[None] = kwargs.pop("cls", None)
-
-        content_type = content_type or "application/json"
-        _json = None
-        _content = None
-        if isinstance(share_permission, (IO, bytes)):
-            _content = share_permission
-        else:
-            _json = self._serialize.body(share_permission, "SharePermission")
-
-        request = build_create_permission_request(
-            url=self._config.url,
-            timeout=timeout,
-            file_request_intent=self._config.file_request_intent,
-            restype=restype,
-            comp=comp,
-            content_type=content_type,
-            version=self._config.version,
-            json=_json,
-            content=_content,
-            template_url=self.create_permission.metadata["url"],
-            headers=_headers,
-            params=_params,
+        response_headers["Content-MD5"] = self._deserialize("bytearray", response.headers.get("Content-MD5"))
+        response_headers["x-ms-content-crc64"] = self._deserialize(
+            "bytearray", response.headers.get("x-ms-content-crc64")
         )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
         )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [201]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-        response_headers["x-ms-file-permission-key"] = self._deserialize(
-            "str", response.headers.get("x-ms-file-permission-key")
+        response_headers["x-ms-request-server-encrypted"] = self._deserialize(
+            "bool", response.headers.get("x-ms-request-server-encrypted")
         )
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    create_permission.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def get_permission(
-        self, file_permission_key: str, timeout: Optional[int] = None, **kwargs: Any
-    ) -> _models.SharePermission:
-        """Returns the permission (security descriptor) for a given key.
-
-        :param file_permission_key: Key of the permission to be set for the directory/file. Required.
-        :type file_permission_key: str
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "filepermission". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: SharePermission or the result of cls(response)
-        :rtype: ~azure.storage.fileshare.models.SharePermission
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["filepermission"] = kwargs.pop("comp", _params.pop("comp", "filepermission"))
-        cls: ClsType[_models.SharePermission] = kwargs.pop("cls", None)
-
-        request = build_get_permission_request(
-            url=self._config.url,
-            file_permission_key=file_permission_key,
-            timeout=timeout,
-            file_request_intent=self._config.file_request_intent,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            template_url=self.get_permission.metadata["url"],
-            headers=_headers,
-            params=_params,
+        response_headers["x-ms-encryption-key-sha256"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-key-sha256")
         )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        response_headers["x-ms-encryption-scope"] = self._deserialize(
+            "str", response.headers.get("x-ms-encryption-scope")
         )
 
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        deserialized = self._deserialize("SharePermission", pipeline_response)
-
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    get_permission.metadata = {"url": "{url}/{shareName}"}
+    upload_pages_from_url.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def set_properties(  # pylint: disable=inconsistent-return-statements
+    def get_page_ranges(
         self,
+        snapshot: Optional[str] = None,
         timeout: Optional[int] = None,
-        quota: Optional[int] = None,
-        access_tier: Optional[Union[str, _models.ShareAccessTier]] = None,
-        root_squash: Optional[Union[str, _models.ShareRootSquash]] = None,
+        range: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """Sets properties for the specified share.
-
+    ) -> _models.PageList:
+        """The Get Page Ranges operation returns the list of valid page ranges for a page blob or snapshot
+        of a page blob.
+
+        :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
+         see :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
+         a Snapshot of a Blob.</a>`. Default value is None.
+        :type snapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param quota: Specifies the maximum size of the share, in gigabytes. Default value is None.
-        :type quota: int
-        :param access_tier: Specifies the access tier of the share. Known values are:
-         "TransactionOptimized", "Hot", and "Cool". Default value is None.
-        :type access_tier: str or ~azure.storage.fileshare.models.ShareAccessTier
-        :param root_squash: Root squash to set on the share.  Only valid for NFS shares. Known values
-         are: "NoRootSquash", "RootSquash", and "AllSquash". Default value is None.
-        :type root_squash: str or ~azure.storage.fileshare.models.ShareRootSquash
+        :param range: Return only the bytes of the blob in the specified range. Default value is None.
+        :type range: str
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param marker: A string value that identifies the portion of the list of containers to be
+         returned with the next listing operation. The operation returns the NextMarker value within the
+         response body if the listing operation did not return all containers remaining to be listed
+         with the current page. The NextMarker value can be used as the value for the marker parameter
+         in a subsequent call to request the next page of list items. The marker value is opaque to the
+         client. Default value is None.
+        :type marker: str
+        :param maxresults: Specifies the maximum number of containers to return. If the request does
+         not specify maxresults, or specifies a value greater than 5000, the server will return up to
+         5000 items. Note that if the listing operation crosses a partition boundary, then the service
+         will return a continuation token for retrieving the remainder of the results. For this reason,
+         it is possible that the service will return fewer results than specified by maxresults, or than
+         the default of 5000. Default value is None.
+        :type maxresults: int
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "pagelist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: PageList or the result of cls(response)
+        :rtype: ~azure.storage.blob.models.PageList
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["properties"] = kwargs.pop("comp", _params.pop("comp", "properties"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "pagelist"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.PageList]
 
         _lease_id = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_set_properties_request(
+        request = build_get_page_ranges_request(
             url=self._config.url,
+            snapshot=snapshot,
             timeout=timeout,
-            quota=quota,
-            access_tier=access_tier,
+            range=range,
             lease_id=_lease_id,
-            root_squash=root_squash,
-            restype=restype,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
+            request_id_parameter=request_id_parameter,
+            marker=marker,
+            maxresults=maxresults,
             comp=comp,
             version=self._config.version,
-            template_url=self.set_properties.metadata["url"],
+            template_url=self.get_page_ranges.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["x-ms-blob-content-length"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-content-length")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
+        deserialized = self._deserialize("PageList", pipeline_response)
+
         if cls:
-            return cls(pipeline_response, None, response_headers)
+            return cls(pipeline_response, deserialized, response_headers)
 
-    set_properties.metadata = {"url": "{url}/{shareName}"}
+        return deserialized
+
+    get_page_ranges.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def set_metadata(  # pylint: disable=inconsistent-return-statements
+    def get_page_ranges_diff(
         self,
+        snapshot: Optional[str] = None,
         timeout: Optional[int] = None,
-        metadata: Optional[Dict[str, str]] = None,
+        prevsnapshot: Optional[str] = None,
+        prev_snapshot_url: Optional[str] = None,
+        range: Optional[str] = None,
+        request_id_parameter: Optional[str] = None,
+        marker: Optional[str] = None,
+        maxresults: Optional[int] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> None:
-        """Sets one or more user-defined name-value pairs for the specified share.
-
+    ) -> _models.PageList:
+        """The Get Page Ranges Diff operation returns the list of valid page ranges for a page blob that
+        were changed between target blob and previous snapshot.
+
+        :param snapshot: The snapshot parameter is an opaque DateTime value that, when present,
+         specifies the blob snapshot to retrieve. For more information on working with blob snapshots,
+         see :code:`<a
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/creating-a-snapshot-of-a-blob">Creating
+         a Snapshot of a Blob.</a>`. Default value is None.
+        :type snapshot: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
-        :param metadata: A name-value pair to associate with a file storage object. Default value is
-         None.
-        :type metadata: dict[str, str]
+        :param prevsnapshot: Optional in version 2015-07-08 and newer. The prevsnapshot parameter is a
+         DateTime value that specifies that the response will contain only pages that were changed
+         between target blob and previous snapshot. Changed pages include both updated and cleared
+         pages. The target blob may be a snapshot, as long as the snapshot specified by prevsnapshot is
+         the older of the two. Note that incremental snapshots are currently supported only for blobs
+         created on or after January 1, 2016. Default value is None.
+        :type prevsnapshot: str
+        :param prev_snapshot_url: Optional. This header is only supported in service versions
+         2019-04-19 and after and specifies the URL of a previous snapshot of the target blob. The
+         response will only contain pages that were changed between the target blob and its previous
+         snapshot. Default value is None.
+        :type prev_snapshot_url: str
+        :param range: Return only the bytes of the blob in the specified range. Default value is None.
+        :type range: str
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
+        :param marker: A string value that identifies the portion of the list of containers to be
+         returned with the next listing operation. The operation returns the NextMarker value within the
+         response body if the listing operation did not return all containers remaining to be listed
+         with the current page. The NextMarker value can be used as the value for the marker parameter
+         in a subsequent call to request the next page of list items. The marker value is opaque to the
+         client. Default value is None.
+        :type marker: str
+        :param maxresults: Specifies the maximum number of containers to return. If the request does
+         not specify maxresults, or specifies a value greater than 5000, the server will return up to
+         5000 items. Note that if the listing operation crosses a partition boundary, then the service
+         will return a continuation token for retrieving the remainder of the results. For this reason,
+         it is possible that the service will return fewer results than specified by maxresults, or than
+         the default of 5000. Default value is None.
+        :type maxresults: int
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "metadata". Note that overriding this default value may
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "pagelist". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: None or the result of cls(response)
-        :rtype: None
+        :return: PageList or the result of cls(response)
+        :rtype: ~azure.storage.blob.models.PageList
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["metadata"] = kwargs.pop("comp", _params.pop("comp", "metadata"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "pagelist"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[_models.PageList]
 
         _lease_id = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_set_metadata_request(
+        request = build_get_page_ranges_diff_request(
             url=self._config.url,
+            snapshot=snapshot,
             timeout=timeout,
-            metadata=metadata,
+            prevsnapshot=prevsnapshot,
+            prev_snapshot_url=prev_snapshot_url,
+            range=range,
             lease_id=_lease_id,
-            restype=restype,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
+            request_id_parameter=request_id_parameter,
+            marker=marker,
+            maxresults=maxresults,
             comp=comp,
             version=self._config.version,
-            template_url=self.set_metadata.metadata["url"],
+            template_url=self.get_page_ranges_diff.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
-        response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
-        response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
-
-        if cls:
-            return cls(pipeline_response, None, response_headers)
-
-    set_metadata.metadata = {"url": "{url}/{shareName}"}
-
-    @distributed_trace
-    def get_access_policy(
-        self,
-        timeout: Optional[int] = None,
-        lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        **kwargs: Any
-    ) -> List[_models.SignedIdentifier]:
-        """Returns information about stored access policies specified on the share.
-
-        :param timeout: The timeout parameter is expressed in seconds. For more information, see
-         :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
-        :type timeout: int
-        :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
-         in unsupported behavior.
-        :paramtype comp: str
-        :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: list of SignedIdentifier or the result of cls(response)
-        :rtype: list[~azure.storage.fileshare.models.SignedIdentifier]
-        :raises ~azure.core.exceptions.HttpResponseError:
-        """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
-        error_map.update(kwargs.pop("error_map", {}) or {})
-
-        _headers = kwargs.pop("headers", {}) or {}
-        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
-
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
-        cls: ClsType[List[_models.SignedIdentifier]] = kwargs.pop("cls", None)
-
-        _lease_id = None
-        if lease_access_conditions is not None:
-            _lease_id = lease_access_conditions.lease_id
-
-        request = build_get_access_policy_request(
-            url=self._config.url,
-            timeout=timeout,
-            lease_id=_lease_id,
-            restype=restype,
-            comp=comp,
-            version=self._config.version,
-            template_url=self.get_access_policy.metadata["url"],
-            headers=_headers,
-            params=_params,
+        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
+        response_headers["x-ms-blob-content-length"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-content-length")
         )
-        request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
-
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
-            request, stream=False, **kwargs
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
         )
-
-        response = pipeline_response.http_response
-
-        if response.status_code not in [200]:
-            map_error(status_code=response.status_code, response=response, error_map=error_map)
-            error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
-            raise HttpResponseError(response=response, model=error)
-
-        response_headers = {}
-        response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
-        response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize("[SignedIdentifier]", pipeline_response)
+        deserialized = self._deserialize("PageList", pipeline_response)
 
         if cls:
             return cls(pipeline_response, deserialized, response_headers)
 
         return deserialized
 
-    get_access_policy.metadata = {"url": "{url}/{shareName}"}
+    get_page_ranges_diff.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def set_access_policy(  # pylint: disable=inconsistent-return-statements
+    def resize(  # pylint: disable=inconsistent-return-statements
         self,
+        blob_content_length: int,
         timeout: Optional[int] = None,
+        request_id_parameter: Optional[str] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
-        share_acl: Optional[List[_models.SignedIdentifier]] = None,
+        cpk_info: Optional[_models.CpkInfo] = None,
+        cpk_scope_info: Optional[_models.CpkScopeInfo] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Sets a stored access policy for use with shared access signatures.
+        """Resize the Blob.
 
+        :param blob_content_length: This header specifies the maximum size for the page blob, up to 1
+         TB. The page blob size must be aligned to a 512-byte boundary. Required.
+        :type blob_content_length: int
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :param share_acl: The ACL for the share. Default value is None.
-        :type share_acl: list[~azure.storage.fileshare.models.SignedIdentifier]
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "acl". Note that overriding this default value may result
-         in unsupported behavior.
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param cpk_info: Parameter group. Default value is None.
+        :type cpk_info: ~azure.storage.blob.models.CpkInfo
+        :param cpk_scope_info: Parameter group. Default value is None.
+        :type cpk_scope_info: ~azure.storage.blob.models.CpkScopeInfo
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
+         result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
-        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
+        _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["acl"] = kwargs.pop("comp", _params.pop("comp", "acl"))
-        content_type: str = kwargs.pop("content_type", _headers.pop("Content-Type", "application/xml"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
+        _encryption_key = None
+        _encryption_key_sha256 = None
+        _encryption_algorithm = None
+        _encryption_scope = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
-        serialization_ctxt = {"xml": {"name": "SignedIdentifiers", "wrapped": True}}
-        if share_acl is not None:
-            _content = self._serialize.body(
-                share_acl, "[SignedIdentifier]", is_xml=True, serialization_ctxt=serialization_ctxt
-            )
-        else:
-            _content = None
+        if cpk_info is not None:
+            _encryption_algorithm = cpk_info.encryption_algorithm
+            _encryption_key = cpk_info.encryption_key
+            _encryption_key_sha256 = cpk_info.encryption_key_sha256
+        if cpk_scope_info is not None:
+            _encryption_scope = cpk_scope_info.encryption_scope
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_set_access_policy_request(
+        request = build_resize_request(
             url=self._config.url,
+            blob_content_length=blob_content_length,
             timeout=timeout,
             lease_id=_lease_id,
-            restype=restype,
+            encryption_key=_encryption_key,
+            encryption_key_sha256=_encryption_key_sha256,
+            encryption_algorithm=_encryption_algorithm,
+            encryption_scope=_encryption_scope,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
+            request_id_parameter=request_id_parameter,
             comp=comp,
-            content_type=content_type,
             version=self._config.version,
-            content=_content,
-            template_url=self.set_access_policy.metadata["url"],
+            template_url=self.resize.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    set_access_policy.metadata = {"url": "{url}/{shareName}"}
+    resize.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def get_statistics(
+    def update_sequence_number(  # pylint: disable=inconsistent-return-statements
         self,
+        sequence_number_action: Union[str, "_models.SequenceNumberActionType"],
         timeout: Optional[int] = None,
+        blob_sequence_number: int = 0,
+        request_id_parameter: Optional[str] = None,
         lease_access_conditions: Optional[_models.LeaseAccessConditions] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
-    ) -> _models.ShareStats:
-        """Retrieves statistics related to the share.
+    ) -> None:
+        """Update the sequence number of the blob.
 
+        :param sequence_number_action: Required if the x-ms-blob-sequence-number header is set for the
+         request. This property applies to page blobs only. This property indicates how the service
+         should modify the blob's sequence number. Known values are: "max", "update", and "increment".
+         Required.
+        :type sequence_number_action: str or ~azure.storage.blob.models.SequenceNumberActionType
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
+        :param blob_sequence_number: Set for page blobs only. The sequence number is a user-controlled
+         value that you can use to track requests. The value of the sequence number must be between 0
+         and 2^63 - 1. Default value is 0.
+        :type blob_sequence_number: int
+        :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
+         limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
+         value is None.
+        :type request_id_parameter: str
         :param lease_access_conditions: Parameter group. Default value is None.
-        :type lease_access_conditions: ~azure.storage.fileshare.models.LeaseAccessConditions
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "stats". Note that overriding this default value may
+        :type lease_access_conditions: ~azure.storage.blob.models.LeaseAccessConditions
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "properties". Note that overriding this default value may
          result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
-        :return: ShareStats or the result of cls(response)
-        :rtype: ~azure.storage.fileshare.models.ShareStats
+        :return: None or the result of cls(response)
+        :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["stats"] = kwargs.pop("comp", _params.pop("comp", "stats"))
-        cls: ClsType[_models.ShareStats] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "properties"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
 
         _lease_id = None
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
         if lease_access_conditions is not None:
             _lease_id = lease_access_conditions.lease_id
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_get_statistics_request(
+        request = build_update_sequence_number_request(
             url=self._config.url,
+            sequence_number_action=sequence_number_action,
             timeout=timeout,
             lease_id=_lease_id,
-            restype=restype,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
+            blob_sequence_number=blob_sequence_number,
+            request_id_parameter=request_id_parameter,
             comp=comp,
             version=self._config.version,
-            template_url=self.get_statistics.metadata["url"],
+            template_url=self.update_sequence_number.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
         if response.status_code not in [200]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
+        response_headers["x-ms-blob-sequence-number"] = self._deserialize(
+            "int", response.headers.get("x-ms-blob-sequence-number")
+        )
+        response_headers["x-ms-client-request-id"] = self._deserialize(
+            "str", response.headers.get("x-ms-client-request-id")
+        )
         response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
 
-        deserialized = self._deserialize("ShareStats", pipeline_response)
-
         if cls:
-            return cls(pipeline_response, deserialized, response_headers)
-
-        return deserialized
+            return cls(pipeline_response, None, response_headers)
 
-    get_statistics.metadata = {"url": "{url}/{shareName}"}
+    update_sequence_number.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
 
     @distributed_trace
-    def restore(  # pylint: disable=inconsistent-return-statements
+    def copy_incremental(  # pylint: disable=inconsistent-return-statements
         self,
+        copy_source: str,
         timeout: Optional[int] = None,
         request_id_parameter: Optional[str] = None,
-        deleted_share_name: Optional[str] = None,
-        deleted_share_version: Optional[str] = None,
+        modified_access_conditions: Optional[_models.ModifiedAccessConditions] = None,
         **kwargs: Any
     ) -> None:
-        """Restores a previously deleted Share.
-
+        """The Copy Incremental operation copies a snapshot of the source page blob to a destination page
+        blob. The snapshot is copied such that only the differential changes between the previously
+        copied snapshot are transferred to the destination. The copied snapshots are complete copies of
+        the original snapshot and can be read or copied from as usual. This API is supported since REST
+        version 2016-05-31.
+
+        :param copy_source: Specifies the name of the source page blob snapshot. This value is a URL of
+         up to 2 KB in length that specifies a page blob snapshot. The value should be URL-encoded as it
+         would appear in a request URI. The source blob must either be public or must be authenticated
+         via a shared access signature. Required.
+        :type copy_source: str
         :param timeout: The timeout parameter is expressed in seconds. For more information, see
          :code:`<a
-         href="https://docs.microsoft.com/en-us/rest/api/storageservices/Setting-Timeouts-for-File-Service-Operations?redirectedfrom=MSDN">Setting
-         Timeouts for File Service Operations.</a>`. Default value is None.
+         href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/setting-timeouts-for-blob-service-operations">Setting
+         Timeouts for Blob Service Operations.</a>`. Default value is None.
         :type timeout: int
         :param request_id_parameter: Provides a client-generated, opaque value with a 1 KB character
          limit that is recorded in the analytics logs when storage analytics logging is enabled. Default
          value is None.
         :type request_id_parameter: str
-        :param deleted_share_name: Specifies the name of the previously-deleted share. Default value is
-         None.
-        :type deleted_share_name: str
-        :param deleted_share_version: Specifies the version of the previously-deleted share. Default
-         value is None.
-        :type deleted_share_version: str
-        :keyword restype: restype. Default value is "share". Note that overriding this default value
-         may result in unsupported behavior.
-        :paramtype restype: str
-        :keyword comp: comp. Default value is "undelete". Note that overriding this default value may
-         result in unsupported behavior.
+        :param modified_access_conditions: Parameter group. Default value is None.
+        :type modified_access_conditions: ~azure.storage.blob.models.ModifiedAccessConditions
+        :keyword comp: comp. Default value is "incrementalcopy". Note that overriding this default
+         value may result in unsupported behavior.
         :paramtype comp: str
         :keyword callable cls: A custom type or function that will be passed the direct response
         :return: None or the result of cls(response)
         :rtype: None
         :raises ~azure.core.exceptions.HttpResponseError:
         """
-        error_map = {
-            401: ClientAuthenticationError,
-            404: ResourceNotFoundError,
-            409: ResourceExistsError,
-            304: ResourceNotModifiedError,
-        }
+        error_map = {401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError}
         error_map.update(kwargs.pop("error_map", {}) or {})
 
         _headers = kwargs.pop("headers", {}) or {}
         _params = case_insensitive_dict(kwargs.pop("params", {}) or {})
 
-        restype: Literal["share"] = kwargs.pop("restype", _params.pop("restype", "share"))
-        comp: Literal["undelete"] = kwargs.pop("comp", _params.pop("comp", "undelete"))
-        cls: ClsType[None] = kwargs.pop("cls", None)
+        comp = kwargs.pop("comp", _params.pop("comp", "incrementalcopy"))  # type: str
+        cls = kwargs.pop("cls", None)  # type: ClsType[None]
+
+        _if_modified_since = None
+        _if_unmodified_since = None
+        _if_match = None
+        _if_none_match = None
+        _if_tags = None
+        if modified_access_conditions is not None:
+            _if_match = modified_access_conditions.if_match
+            _if_modified_since = modified_access_conditions.if_modified_since
+            _if_none_match = modified_access_conditions.if_none_match
+            _if_tags = modified_access_conditions.if_tags
+            _if_unmodified_since = modified_access_conditions.if_unmodified_since
 
-        request = build_restore_request(
+        request = build_copy_incremental_request(
             url=self._config.url,
+            copy_source=copy_source,
             timeout=timeout,
+            if_modified_since=_if_modified_since,
+            if_unmodified_since=_if_unmodified_since,
+            if_match=_if_match,
+            if_none_match=_if_none_match,
+            if_tags=_if_tags,
             request_id_parameter=request_id_parameter,
-            deleted_share_name=deleted_share_name,
-            deleted_share_version=deleted_share_version,
-            restype=restype,
             comp=comp,
             version=self._config.version,
-            template_url=self.restore.metadata["url"],
+            template_url=self.copy_incremental.metadata["url"],
             headers=_headers,
             params=_params,
         )
         request = _convert_request(request)
-        request.url = self._client.format_url(request.url)
+        request.url = self._client.format_url(request.url)  # type: ignore
 
-        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
+        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
             request, stream=False, **kwargs
         )
 
         response = pipeline_response.http_response
 
-        if response.status_code not in [201]:
+        if response.status_code not in [202]:
             map_error(status_code=response.status_code, response=response, error_map=error_map)
             error = self._deserialize.failsafe_deserialize(_models.StorageError, pipeline_response)
             raise HttpResponseError(response=response, model=error)
 
         response_headers = {}
         response_headers["ETag"] = self._deserialize("str", response.headers.get("ETag"))
         response_headers["Last-Modified"] = self._deserialize("rfc-1123", response.headers.get("Last-Modified"))
-        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-client-request-id"] = self._deserialize(
             "str", response.headers.get("x-ms-client-request-id")
         )
+        response_headers["x-ms-request-id"] = self._deserialize("str", response.headers.get("x-ms-request-id"))
         response_headers["x-ms-version"] = self._deserialize("str", response.headers.get("x-ms-version"))
         response_headers["Date"] = self._deserialize("rfc-1123", response.headers.get("Date"))
+        response_headers["x-ms-copy-id"] = self._deserialize("str", response.headers.get("x-ms-copy-id"))
+        response_headers["x-ms-copy-status"] = self._deserialize("str", response.headers.get("x-ms-copy-status"))
 
         if cls:
             return cls(pipeline_response, None, response_headers)
 
-    restore.metadata = {"url": "{url}/{shareName}"}
+    copy_incremental.metadata = {"url": "{url}/{containerName}/{blob}"}  # type: ignore
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_lease.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_lease.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_serialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_share_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/response_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_directory_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_directory_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_file_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_file_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_lease_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_lease_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/aio/_share_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -2,14 +2,20 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from ._azure_queue_storage import AzureQueueStorage
-__all__ = ['AzureQueueStorage']
+from ._azure_blob_storage import AzureBlobStorage
 
-# `._patch.py` is used for handwritten extensions to the generated code
-# Example: https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/customize_code/how-to-patch-sdk-code.md
-from ._patch import patch_sdk
-patch_sdk()
+try:
+    from ._patch import __all__ as _patch_all
+    from ._patch import *  # type: ignore # pylint: disable=unused-wildcard-import
+except ImportError:
+    _patch_all = []
+from ._patch import patch_sdk as _patch_sdk
+
+__all__ = ["AzureBlobStorage"]
+__all__.extend([p for p in _patch_all if p not in __all__])
+
+_patch_sdk()
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_azure_queue_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_azure_queue_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_configuration.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/_patch.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -24,8 +24,8 @@
 # IN THE SOFTWARE.
 #
 # --------------------------------------------------------------------------
 
 # This file is used for handwritten extensions to the generated code. Example:
 # https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/customize_code/how-to-patch-sdk-code.md
 def patch_sdk():
-    pass
+    pass
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/_vendor.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/filedatalake/v2021_08_06/_generated/_vendor.py`

 * *Files 20% similar despite different names*

```diff
@@ -3,25 +3,25 @@
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
 from azure.core.pipeline.transport import HttpRequest
 
+
 def _convert_request(request, files=None):
     data = request.content if not files else None
     request = HttpRequest(method=request.method, url=request.url, headers=request.headers, data=data)
     if files:
         request.set_formdata_body(files)
     return request
 
+
 def _format_url_section(template, **kwargs):
     components = template.split("/")
     while components:
         try:
             return template.format(**kwargs)
         except KeyError as key:
             formatted_components = template.split("/")
-            components = [
-                c for c in formatted_components if "{}".format(key.args[0]) not in c
-            ]
+            components = [c for c in formatted_components if "{}".format(key.args[0]) not in c]
             template = "/".join(components)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -2,14 +2,20 @@
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
 # Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
-from ._azure_queue_storage import AzureQueueStorage
-__all__ = ['AzureQueueStorage']
+from ._azure_blob_storage import AzureBlobStorage
 
-# `._patch.py` is used for handwritten extensions to the generated code
-# Example: https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/customize_code/how-to-patch-sdk-code.md
-from ._patch import patch_sdk
-patch_sdk()
+try:
+    from ._patch import __all__ as _patch_all
+    from ._patch import *  # type: ignore # pylint: disable=unused-wildcard-import
+except ImportError:
+    _patch_all = []
+from ._patch import patch_sdk as _patch_sdk
+
+__all__ = ["AzureBlobStorage"]
+__all__.extend([p for p in _patch_all if p not in __all__])
+
+_patch_sdk()
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_azure_queue_storage_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_configuration.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,58 +1,52 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
-# Licensed under the MIT License. See License.txt in the project root for license information.
+# Licensed under the MIT License. See License.txt in the project root for
+# license information.
+#
 # Code generated by Microsoft (R) AutoRest Code Generator.
-# Changes may cause incorrect behavior and will be lost if the code is regenerated.
+# Changes may cause incorrect behavior and will be lost if the code is
+# regenerated.
 # --------------------------------------------------------------------------
 
-from typing import Any
-
 from azure.core.configuration import Configuration
 from azure.core.pipeline import policies
 
-VERSION = "unknown"
+from .version import VERSION
 
-class AzureQueueStorageConfiguration(Configuration):  # pylint: disable=too-many-instance-attributes
-    """Configuration for AzureQueueStorage.
 
+class AzureQueueStorageConfiguration(Configuration):
+    """Configuration for AzureQueueStorage
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
-    :param url: The URL of the service account, queue or message that is the target of the desired
-     operation.
+    :param url: The URL of the service account, queue or message that is the
+     targe of the desired operation.
     :type url: str
-    :keyword version: Specifies the version of the operation to use for this request. Default value
-     is "2018-03-28". Note that overriding this default value may result in unsupported behavior.
-    :paramtype version: str
+    :ivar version: Specifies the version of the operation to use for this
+     request.
+    :type version: str
     """
 
-    def __init__(
-        self,
-        url: str,
-        **kwargs: Any
-    ) -> None:
-        super(AzureQueueStorageConfiguration, self).__init__(**kwargs)
-        version = kwargs.pop('version', "2018-03-28")  # type: str
+    def __init__(self, url, **kwargs):
 
         if url is None:
             raise ValueError("Parameter 'url' must not be None.")
 
-        self.url = url
-        self.version = version
-        kwargs.setdefault('sdk_moniker', 'azurequeuestorage/{}'.format(VERSION))
+        super(AzureQueueStorageConfiguration, self).__init__(**kwargs)
         self._configure(**kwargs)
 
-    def _configure(
-        self,
-        **kwargs: Any
-    ) -> None:
+        self.user_agent_policy.add_user_agent('azsdk-python-azurequeuestorage/{}'.format(VERSION))
+        self.generate_client_request_id = True
+
+        self.url = url
+        self.version = "2018-03-28"
+
+    def _configure(self, **kwargs):
         self.user_agent_policy = kwargs.get('user_agent_policy') or policies.UserAgentPolicy(**kwargs)
         self.headers_policy = kwargs.get('headers_policy') or policies.HeadersPolicy(**kwargs)
         self.proxy_policy = kwargs.get('proxy_policy') or policies.ProxyPolicy(**kwargs)
         self.logging_policy = kwargs.get('logging_policy') or policies.NetworkTraceLoggingPolicy(**kwargs)
-        self.http_logging_policy = kwargs.get('http_logging_policy') or policies.HttpLoggingPolicy(**kwargs)
-        self.retry_policy = kwargs.get('retry_policy') or policies.AsyncRetryPolicy(**kwargs)
+        self.retry_policy = kwargs.get('retry_policy') or policies.RetryPolicy(**kwargs)
         self.custom_hook_policy = kwargs.get('custom_hook_policy') or policies.CustomHookPolicy(**kwargs)
-        self.redirect_policy = kwargs.get('redirect_policy') or policies.AsyncRedirectPolicy(**kwargs)
-        self.authentication_policy = kwargs.get('authentication_policy')
+        self.redirect_policy = kwargs.get('redirect_policy') or policies.RedirectPolicy(**kwargs)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_configuration_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/_patch.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_generated/aio/_patch.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -24,8 +24,8 @@
 # IN THE SOFTWARE.
 #
 # --------------------------------------------------------------------------
 
 # This file is used for handwritten extensions to the generated code. Example:
 # https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/customize_code/how-to-patch-sdk-code.md
 def patch_sdk():
-    pass
+    pass
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,13 +1,16 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
-# Licensed under the MIT License. See License.txt in the project root for license information.
+# Licensed under the MIT License. See License.txt in the project root for
+# license information.
+#
 # Code generated by Microsoft (R) AutoRest Code Generator.
-# Changes may cause incorrect behavior and will be lost if the code is regenerated.
+# Changes may cause incorrect behavior and will be lost if the code is
+# regenerated.
 # --------------------------------------------------------------------------
 
 from ._service_operations import ServiceOperations
 from ._queue_operations import QueueOperations
 from ._messages_operations import MessagesOperations
 from ._message_id_operations import MessageIdOperations
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_message_id_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_message_id_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_messages_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_messages_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_queue_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_queue_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_message_id_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_message_id_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_messages_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_messages_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_queue_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_queue_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_service_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/aio/operations_async/_service_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_azure_queue_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_azure_queue_storage_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_message_id_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_message_id_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_messages_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_messages_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_queue_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_queue_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_message_encoding.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_message_encoding.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_queue_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_serialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_serialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/base_client.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,114 +2,114 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 import logging
 import uuid
 from typing import (  # pylint: disable=unused-import
-    Optional,
     Any,
+    Dict,
+    Optional,
     Tuple,
+    TYPE_CHECKING,
+    Union,
 )
 
 try:
     from urllib.parse import parse_qs, quote
 except ImportError:
     from urlparse import parse_qs  # type: ignore
     from urllib2 import quote  # type: ignore
 
-import six
-
 from azure.core.configuration import Configuration
-from azure.core.credentials import AzureSasCredential
+from azure.core.credentials import AzureSasCredential, AzureNamedKeyCredential
 from azure.core.exceptions import HttpResponseError
 from azure.core.pipeline import Pipeline
 from azure.core.pipeline.transport import RequestsTransport, HttpTransport
 from azure.core.pipeline.policies import (
-    RedirectPolicy,
+    AzureSasCredentialPolicy,
     ContentDecodePolicy,
-    BearerTokenCredentialPolicy,
-    ProxyPolicy,
     DistributedTracingPolicy,
     HttpLoggingPolicy,
+    ProxyPolicy,
+    RedirectPolicy,
     UserAgentPolicy,
-    AzureSasCredentialPolicy
 )
 
-from .constants import STORAGE_OAUTH_SCOPE, SERVICE_HOST_BASE, CONNECTION_TIMEOUT, READ_TIMEOUT
+from .constants import CONNECTION_TIMEOUT, READ_TIMEOUT, SERVICE_HOST_BASE
 from .models import LocationMode
 from .authentication import SharedKeyCredentialPolicy
 from .shared_access_signature import QueryStringConstants
 from .request_handlers import serialize_batch_body, _get_batch_request_delimiter
 from .policies import (
-    StorageHeadersPolicy,
+    ExponentialRetry,
+    QueueMessagePolicy,
+    StorageBearerTokenCredentialPolicy,
     StorageContentValidation,
+    StorageHeadersPolicy,
+    StorageHosts,
+    StorageLoggingPolicy,
     StorageRequestHook,
     StorageResponseHook,
-    StorageLoggingPolicy,
-    StorageHosts,
-    QueueMessagePolicy,
-    ExponentialRetry,
 )
 from .._version import VERSION
 from .response_handlers import process_storage_error, PartialBatchErrorException
 
+if TYPE_CHECKING:
+    from azure.core.credentials import TokenCredential
 
 _LOGGER = logging.getLogger(__name__)
 _SERVICE_PARAMS = {
     "blob": {"primary": "BLOBENDPOINT", "secondary": "BLOBSECONDARYENDPOINT"},
     "queue": {"primary": "QUEUEENDPOINT", "secondary": "QUEUESECONDARYENDPOINT"},
     "file": {"primary": "FILEENDPOINT", "secondary": "FILESECONDARYENDPOINT"},
     "dfs": {"primary": "BLOBENDPOINT", "secondary": "BLOBENDPOINT"},
 }
 
+
 class StorageAccountHostsMixin(object):  # pylint: disable=too-many-instance-attributes
     def __init__(
         self,
         parsed_url,  # type: Any
         service,  # type: str
-        credential=None,  # type: Optional[Any]
+        credential=None,  # type: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long
         **kwargs  # type: Any
     ):
         # type: (...) -> None
         self._location_mode = kwargs.get("_location_mode", LocationMode.PRIMARY)
         self._hosts = kwargs.get("_hosts")
         self.scheme = parsed_url.scheme
 
         if service not in ["blob", "queue", "file-share", "dfs"]:
-            raise ValueError("Invalid service: {}".format(service))
+            raise ValueError(f"Invalid service: {service}")
         service_name = service.split('-')[0]
-        account = parsed_url.netloc.split(".{}.core.".format(service_name))
+        account = parsed_url.netloc.split(f".{service_name}.core.")
 
         self.account_name = account[0] if len(account) > 1 else None
         if not self.account_name and parsed_url.netloc.startswith("localhost") \
                 or parsed_url.netloc.startswith("127.0.0.1"):
             self.account_name = parsed_url.path.strip("/")
 
         self.credential = _format_shared_key_credential(self.account_name, credential)
         if self.scheme.lower() != "https" and hasattr(self.credential, "get_token"):
             raise ValueError("Token credential is only supported with HTTPS.")
 
         secondary_hostname = None
         if hasattr(self.credential, "account_name"):
             self.account_name = self.credential.account_name
-            secondary_hostname = "{}-secondary.{}.{}".format(
-                self.credential.account_name, service_name, SERVICE_HOST_BASE)
+            secondary_hostname = f"{self.credential.account_name}-secondary.{service_name}.{SERVICE_HOST_BASE}"
 
         if not self._hosts:
             if len(account) > 1:
                 secondary_hostname = parsed_url.netloc.replace(account[0], account[0] + "-secondary")
             if kwargs.get("secondary_hostname"):
                 secondary_hostname = kwargs["secondary_hostname"]
             primary_hostname = (parsed_url.netloc + parsed_url.path).rstrip('/')
             self._hosts = {LocationMode.PRIMARY: primary_hostname, LocationMode.SECONDARY: secondary_hostname}
 
-        self.require_encryption = kwargs.get("require_encryption", False)
-        self.key_encryption_key = kwargs.get("key_encryption_key")
-        self.key_resolver_function = kwargs.get("key_resolver_function")
         self._config, self._pipeline = self._create_pipeline(self.credential, storage_sdk=service, **kwargs)
 
     def __enter__(self):
         self._client.__enter__()
         return self
 
     def __exit__(self, *args):
@@ -184,51 +184,51 @@
 
     @location_mode.setter
     def location_mode(self, value):
         if self._hosts.get(value):
             self._location_mode = value
             self._client._config.url = self.url  # pylint: disable=protected-access
         else:
-            raise ValueError("No host URL for location mode: {}".format(value))
+            raise ValueError(f"No host URL for location mode: {value}")
 
     @property
     def api_version(self):
         """The version of the Storage API used for requests.
 
         :type: str
         """
         return self._client._config.version  # pylint: disable=protected-access
 
     def _format_query_string(self, sas_token, credential, snapshot=None, share_snapshot=None):
         query_str = "?"
         if snapshot:
-            query_str += "snapshot={}&".format(self.snapshot)
+            query_str += f"snapshot={self.snapshot}&"
         if share_snapshot:
-            query_str += "sharesnapshot={}&".format(self.snapshot)
+            query_str += f"sharesnapshot={self.snapshot}&"
         if sas_token and isinstance(credential, AzureSasCredential):
             raise ValueError(
                 "You cannot use AzureSasCredential when the resource URI also contains a Shared Access Signature.")
-        if sas_token and not credential:
-            query_str += sas_token
-        elif is_credential_sastoken(credential):
+        if is_credential_sastoken(credential):
             query_str += credential.lstrip("?")
             credential = None
+        elif sas_token:
+            query_str += sas_token
         return query_str.rstrip("?&"), credential
 
     def _create_pipeline(self, credential, **kwargs):
         # type: (Any, **Any) -> Tuple[Configuration, Pipeline]
         self._credential_policy = None
         if hasattr(credential, "get_token"):
-            self._credential_policy = BearerTokenCredentialPolicy(credential, STORAGE_OAUTH_SCOPE)
+            self._credential_policy = StorageBearerTokenCredentialPolicy(credential)
         elif isinstance(credential, SharedKeyCredentialPolicy):
             self._credential_policy = credential
         elif isinstance(credential, AzureSasCredential):
             self._credential_policy = AzureSasCredentialPolicy(credential)
         elif credential is not None:
-            raise TypeError("Unsupported credential: {}".format(credential))
+            raise TypeError(f"Unsupported credential: {credential}")
 
         config = kwargs.get("_configuration") or create_configuration(**kwargs)
         if kwargs.get("_pipeline"):
             return config, kwargs["_pipeline"]
         config.transport = kwargs.get("transport")  # type: ignore
         kwargs.setdefault("connection_timeout", CONNECTION_TIMEOUT)
         kwargs.setdefault("read_timeout", READ_TIMEOUT)
@@ -263,21 +263,18 @@
         """Given a series of request, do a Storage batch call.
         """
         # Pop it here, so requests doesn't feel bad about additional kwarg
         raise_on_any_failure = kwargs.pop("raise_on_any_failure", True)
         batch_id = str(uuid.uuid1())
 
         request = self._client._client.post(  # pylint: disable=protected-access
-            url='{}://{}/{}?{}comp=batch{}{}'.format(
-                self.scheme,
-                self.primary_hostname,
-                kwargs.pop('path', ""),
-                kwargs.pop('restype', ""),
-                kwargs.pop('sas', ""),
-                kwargs.pop('timeout', "")
+            url=(
+                f'{self.scheme}://{self.primary_hostname}/'
+                f"{kwargs.pop('path', '')}?{kwargs.pop('restype', '')}"
+                f"comp=batch{kwargs.pop('sas', '')}{kwargs.pop('timeout', '')}"
             ),
             headers={
                 'x-ms-version': self.api_version,
                 "Content-Type": "multipart/mixed; boundary=" + _get_batch_request_delimiter(batch_id, False, False)
             }
         )
 
@@ -341,24 +338,26 @@
         pass
 
     def __exit__(self, *args):  # pylint: disable=arguments-differ
         pass
 
 
 def _format_shared_key_credential(account_name, credential):
-    if isinstance(credential, six.string_types):
+    if isinstance(credential, str):
         if not account_name:
             raise ValueError("Unable to determine account name for shared key credential.")
         credential = {"account_name": account_name, "account_key": credential}
     if isinstance(credential, dict):
         if "account_name" not in credential:
             raise ValueError("Shared key credential missing 'account_name")
         if "account_key" not in credential:
             raise ValueError("Shared key credential missing 'account_key")
         return SharedKeyCredentialPolicy(**credential)
+    if isinstance(credential, AzureNamedKeyCredential):
+        return SharedKeyCredentialPolicy(credential.named_key.name, credential.named_key.key)
     return credential
 
 
 def parse_connection_str(conn_str, credential, service):
     conn_str = conn_str.rstrip(";")
     conn_settings = [s.split("=", 1) for s in conn_str.split(";")]
     if any(len(tup) != 2 for tup in conn_settings):
@@ -376,45 +375,46 @@
         primary = conn_settings[endpoints["primary"]]
         if endpoints["secondary"] in conn_settings:
             secondary = conn_settings[endpoints["secondary"]]
     else:
         if endpoints["secondary"] in conn_settings:
             raise ValueError("Connection string specifies only secondary endpoint.")
         try:
-            primary = "{}://{}.{}.{}".format(
-                conn_settings["DEFAULTENDPOINTSPROTOCOL"],
-                conn_settings["ACCOUNTNAME"],
-                service,
-                conn_settings["ENDPOINTSUFFIX"],
+            primary =(
+                f"{conn_settings['DEFAULTENDPOINTSPROTOCOL']}://"
+                f"{conn_settings['ACCOUNTNAME']}.{service}.{conn_settings['ENDPOINTSUFFIX']}"
             )
-            secondary = "{}-secondary.{}.{}".format(
-                conn_settings["ACCOUNTNAME"], service, conn_settings["ENDPOINTSUFFIX"]
+            secondary = (
+                f"{conn_settings['ACCOUNTNAME']}-secondary."
+                f"{service}.{conn_settings['ENDPOINTSUFFIX']}"
             )
         except KeyError:
             pass
 
     if not primary:
         try:
-            primary = "https://{}.{}.{}".format(
-                conn_settings["ACCOUNTNAME"], service, conn_settings.get("ENDPOINTSUFFIX", SERVICE_HOST_BASE)
+            primary = (
+                f"https://{conn_settings['ACCOUNTNAME']}."
+                f"{service}.{conn_settings.get('ENDPOINTSUFFIX', SERVICE_HOST_BASE)}"
             )
         except KeyError:
             raise ValueError("Connection string missing required connection details.")
     if service == "dfs":
         primary = primary.replace(".blob.", ".dfs.")
-        secondary = secondary.replace(".blob.", ".dfs.")
+        if secondary:
+            secondary = secondary.replace(".blob.", ".dfs.")
     return primary, secondary, credential
 
 
 def create_configuration(**kwargs):
     # type: (**Any) -> Configuration
     config = Configuration(**kwargs)
     config.headers_policy = StorageHeadersPolicy(**kwargs)
     config.user_agent_policy = UserAgentPolicy(
-        sdk_moniker="storage-{}/{}".format(kwargs.pop('storage_sdk'), VERSION), **kwargs)
+        sdk_moniker=f"storage-{kwargs.pop('storage_sdk')}/{VERSION}", **kwargs)
     config.retry_policy = kwargs.get("retry_policy") or ExponentialRetry(**kwargs)
     config.logging_policy = StorageLoggingPolicy(**kwargs)
     config.proxy_policy = ProxyPolicy(**kwargs)
 
     # Storage settings
     config.max_single_put_size = kwargs.get("max_single_put_size", 64 * 1024 * 1024)
     config.copy_polling_interval = 15
@@ -438,25 +438,25 @@
     config.max_range_size = kwargs.get("max_range_size", 4 * 1024 * 1024)
     return config
 
 
 def parse_query(query_str):
     sas_values = QueryStringConstants.to_list()
     parsed_query = {k: v[0] for k, v in parse_qs(query_str).items()}
-    sas_params = ["{}={}".format(k, quote(v, safe='')) for k, v in parsed_query.items() if k in sas_values]
+    sas_params = [f"{k}={quote(v, safe='')}" for k, v in parsed_query.items() if k in sas_values]
     sas_token = None
     if sas_params:
         sas_token = "&".join(sas_params)
 
     snapshot = parsed_query.get("snapshot") or parsed_query.get("sharesnapshot")
     return snapshot, sas_token
 
 
 def is_credential_sastoken(credential):
-    if not credential or not isinstance(credential, six.string_types):
+    if not credential or not isinstance(credential, str):
         return False
 
     sas_values = QueryStringConstants.to_list()
     parsed_query = parse_qs(credential.lstrip("?"))
     if parsed_query and all([k in sas_values for k in parsed_query.keys()]):
         return True
     return False
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/encryption.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/encryption.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/models.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 # -------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=too-many-instance-attributes
-
 from enum import Enum
 
 from azure.core import CaseInsensitiveEnumMeta
 
 
 def get_enum_value(value):
     if value is None or value in ["None", ""]:
@@ -81,15 +80,17 @@
     CONTAINER_DISABLED = "ContainerDisabled"
     CONTAINER_NOT_FOUND = "ContainerNotFound"
     CONTENT_LENGTH_LARGER_THAN_TIER_LIMIT = "ContentLengthLargerThanTierLimit"
     COPY_ACROSS_ACCOUNTS_NOT_SUPPORTED = "CopyAcrossAccountsNotSupported"
     COPY_ID_MISMATCH = "CopyIdMismatch"
     FEATURE_VERSION_MISMATCH = "FeatureVersionMismatch"
     INCREMENTAL_COPY_BLOB_MISMATCH = "IncrementalCopyBlobMismatch"
-    INCREMENTAL_COPY_OF_ERALIER_VERSION_SNAPSHOT_NOT_ALLOWED = "IncrementalCopyOfEralierVersionSnapshotNotAllowed"
+    INCREMENTAL_COPY_OF_EARLIER_VERSION_SNAPSHOT_NOT_ALLOWED = "IncrementalCopyOfEarlierVersionSnapshotNotAllowed"
+    #: Deprecated: Please use INCREMENTAL_COPY_OF_EARLIER_VERSION_SNAPSHOT_NOT_ALLOWED instead.
+    INCREMENTAL_COPY_OF_ERALIER_VERSION_SNAPSHOT_NOT_ALLOWED = "IncrementalCopyOfEarlierVersionSnapshotNotAllowed"
     INCREMENTAL_COPY_SOURCE_MUST_BE_SNAPSHOT = "IncrementalCopySourceMustBeSnapshot"
     INFINITE_LEASE_DURATION_REQUIRED = "InfiniteLeaseDurationRequired"
     INVALID_BLOB_OR_BLOCK = "InvalidBlobOrBlock"
     INVALID_BLOB_TIER = "InvalidBlobTier"
     INVALID_BLOB_TYPE = "InvalidBlobType"
     INVALID_BLOCK_ID = "InvalidBlockId"
     INVALID_BLOCK_LIST = "InvalidBlockList"
@@ -117,15 +118,17 @@
     PENDING_COPY_OPERATION = "PendingCopyOperation"
     PREVIOUS_SNAPSHOT_CANNOT_BE_NEWER = "PreviousSnapshotCannotBeNewer"
     PREVIOUS_SNAPSHOT_NOT_FOUND = "PreviousSnapshotNotFound"
     PREVIOUS_SNAPSHOT_OPERATION_NOT_SUPPORTED = "PreviousSnapshotOperationNotSupported"
     SEQUENCE_NUMBER_CONDITION_NOT_MET = "SequenceNumberConditionNotMet"
     SEQUENCE_NUMBER_INCREMENT_TOO_LARGE = "SequenceNumberIncrementTooLarge"
     SNAPSHOT_COUNT_EXCEEDED = "SnapshotCountExceeded"
-    SNAPHOT_OPERATION_RATE_EXCEEDED = "SnaphotOperationRateExceeded"
+    SNAPSHOT_OPERATION_RATE_EXCEEDED = "SnapshotOperationRateExceeded"
+    #: Deprecated: Please use SNAPSHOT_OPERATION_RATE_EXCEEDED instead.
+    SNAPHOT_OPERATION_RATE_EXCEEDED = "SnapshotOperationRateExceeded"
     SNAPSHOTS_PRESENT = "SnapshotsPresent"
     SOURCE_CONDITION_NOT_MET = "SourceConditionNotMet"
     SYSTEM_IN_USE = "SystemInUse"
     TARGET_CONDITION_NOT_MET = "TargetConditionNotMet"
     UNAUTHORIZED_BLOB_OVERWRITE = "UnauthorizedBlobOverwrite"
     BLOB_BEING_REHYDRATED = "BlobBeingRehydrated"
     BLOB_ARCHIVED = "BlobArchived"
@@ -281,15 +284,15 @@
         To specify service, container, or object you need only to
         include the first letter of the word in the string. E.g. service and container,
         you would provide a string "sc".
 
         :param str string: Specify service, container, or object in
             in the string with the first letter of the word.
         :return: A ResourceTypes object
-        :rtype: ~azure.storage.queue.ResourceTypes
+        :rtype: ~azure.storage.blob.ResourceTypes
         """
         res_service = 's' in string
         res_container = 'c' in string
         res_object = 'o' in string
 
         parsed = cls(res_service, res_container, res_object)
         parsed._str = string  # pylint: disable = protected-access
@@ -379,15 +382,15 @@
         To specify read, write, delete, etc. permissions you need only to
         include the first letter of the word in the string. E.g. for read and write
         permissions you would provide a string "rw".
 
         :param str permission: Specify permissions in
             the string with the first letter of the word.
         :return: An AccountSasPermissions object
-        :rtype: ~azure.storage.queue.AccountSasPermissions
+        :rtype: ~azure.storage.blob.AccountSasPermissions
         """
         p_read = 'r' in permission
         p_write = 'w' in permission
         p_delete = 'd' in permission
         p_delete_previous_version = 'x' in permission
         p_permanent_delete = 'y' in permission
         p_list = 'l' in permission
@@ -435,15 +438,15 @@
         To specify blob, queue, or file you need only to
         include the first letter of the word in the string. E.g. for blob and queue
         you would provide a string "bq".
 
         :param str string: Specify blob, queue, or file in
             in the string with the first letter of the word.
         :return: A Services object
-        :rtype: ~azure.storage.queue.Services
+        :rtype: ~azure.storage.blob.Services
         """
         res_blob = 'b' in string
         res_queue = 'q' in string
         res_file = 'f' in string
 
         parsed = cls(res_blob, res_queue, res_file)
         parsed._str = string  # pylint: disable = protected-access
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/parser.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/parser.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/response_handlers.py`

 * *Files 3% similar despite different names*

```diff
@@ -63,15 +63,18 @@
         if key.startswith('x-ms-'):
             key = key[5:]
         normalized[key.lower().replace('-', '_')] = get_enum_value(value)
     return normalized
 
 
 def deserialize_metadata(response, obj, headers):  # pylint: disable=unused-argument
-    raw_metadata = {k: v for k, v in response.headers.items() if k.startswith("x-ms-meta-")}
+    try:
+        raw_metadata = {k: v for k, v in response.http_response.headers.items() if k.startswith("x-ms-meta-")}
+    except AttributeError:
+        raw_metadata = {k: v for k, v in response.headers.items() if k.startswith("x-ms-meta-")}
     return {k[10:]: v for k, v in raw_metadata.items()}
 
 
 def return_response_headers(response, deserialized, response_headers):  # pylint: disable=unused-argument
     return normalize_headers(response_headers)
 
 
@@ -79,24 +82,26 @@
     return normalize_headers(response_headers), deserialized
 
 
 def return_context_and_deserialized(response, deserialized, response_headers):  # pylint: disable=unused-argument
     return response.http_response.location_mode, deserialized
 
 
+def return_raw_deserialized(response, *_):
+    return response.http_response.location_mode, response.context[ContentDecodePolicy.CONTEXT_NAME]
+
+
 def process_storage_error(storage_error):   # pylint:disable=too-many-statements
     raise_error = HttpResponseError
     serialized = False
-    if not storage_error.response or storage_error.response.status_code in [200, 204]:
+    if not storage_error.response:
         raise storage_error
     # If it is one of those three then it has been serialized prior by the generated layer.
     if isinstance(storage_error, (PartialBatchErrorException,
-                                  ClientAuthenticationError,
-                                  ResourceNotFoundError,
-                                  ResourceExistsError)):
+                                  ClientAuthenticationError, ResourceNotFoundError, ResourceExistsError)):
         serialized = True
     error_code = storage_error.response.headers.get('x-ms-error-code')
     error_message = storage_error.message
     additional_data = {}
     error_dict = {}
     try:
         error_body = ContentDecodePolicy.deserialize_from_http_generics(storage_error.response)
@@ -158,19 +163,19 @@
                 raise_error = ResourceExistsError
     except ValueError:
         # Got an unknown error code
         pass
 
     # Error message should include all the error properties
     try:
-        error_message += "\nErrorCode:{}".format(error_code.value)
+        error_message += f"\nErrorCode:{error_code.value}"
     except AttributeError:
-        error_message += "\nErrorCode:{}".format(error_code)
+        error_message += f"\nErrorCode:{error_code}"
     for name, info in additional_data.items():
-        error_message += "\n{}:{}".format(name, info)
+        error_message += f"\n{name}:{info}"
 
     # No need to create an instance if it has already been serialized by the generated layer
     if serialized:
         storage_error.message = error_message
         error = storage_error
     else:
         error = raise_error(message=error_message, response=storage_error.response)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads.py`

 * *Files 6% similar despite different names*

```diff
@@ -28,19 +28,19 @@
 def _parallel_uploads(executor, uploader, pending, running):
     range_ids = []
     while True:
         # Wait for some download to finish before adding a new one
         done, running = futures.wait(running, return_when=futures.FIRST_COMPLETED)
         range_ids.extend([chunk.result() for chunk in done])
         try:
-            for _ in range(0, len(done)):
-                next_chunk = next(pending)
-                running.add(executor.submit(with_current_context(uploader), next_chunk))
+            next_chunk = next(pending)
         except StopIteration:
             break
+        else:
+            running.add(executor.submit(with_current_context(uploader), next_chunk))
 
     # Wait for the remaining uploads to finish
     done, _running = futures.wait(running)
     range_ids.extend([chunk.result() for chunk in done])
     return range_ids
 
 
@@ -49,15 +49,14 @@
         uploader_class=None,
         total_size=None,
         chunk_size=None,
         max_concurrency=None,
         stream=None,
         validate_content=None,
         encryption_options=None,
-        progress_hook=None,
         **kwargs):
 
     if encryption_options:
         encryptor, padder = get_blob_encryptor_and_padder(
             encryption_options.get('cek'),
             encryption_options.get('vector'),
             uploader_class is not PageBlobChunkUploader)
@@ -72,94 +71,79 @@
     uploader = uploader_class(
         service=service,
         total_size=total_size,
         chunk_size=chunk_size,
         stream=stream,
         parallel=parallel,
         validate_content=validate_content,
-        progress_hook=progress_hook,
         **kwargs)
     if parallel:
-        with futures.ThreadPoolExecutor(max_concurrency) as executor:
-            upload_tasks = uploader.get_chunk_streams()
-            running_futures = [
-                executor.submit(with_current_context(uploader.process_chunk), u)
-                for u in islice(upload_tasks, 0, max_concurrency)
-            ]
-            range_ids = _parallel_uploads(executor, uploader.process_chunk, upload_tasks, running_futures)
+        executor = futures.ThreadPoolExecutor(max_concurrency)
+        upload_tasks = uploader.get_chunk_streams()
+        running_futures = [
+            executor.submit(with_current_context(uploader.process_chunk), u)
+            for u in islice(upload_tasks, 0, max_concurrency)
+        ]
+        range_ids = _parallel_uploads(executor, uploader.process_chunk, upload_tasks, running_futures)
     else:
         range_ids = [uploader.process_chunk(result) for result in uploader.get_chunk_streams()]
     if any(range_ids):
         return [r[1] for r in sorted(range_ids, key=lambda r: r[0])]
     return uploader.response_headers
 
 
 def upload_substream_blocks(
         service=None,
         uploader_class=None,
         total_size=None,
         chunk_size=None,
         max_concurrency=None,
         stream=None,
-        progress_hook=None,
         **kwargs):
     parallel = max_concurrency > 1
     if parallel and 'modified_access_conditions' in kwargs:
         # Access conditions do not work with parallelism
         kwargs['modified_access_conditions'] = None
     uploader = uploader_class(
         service=service,
         total_size=total_size,
         chunk_size=chunk_size,
         stream=stream,
         parallel=parallel,
-        progress_hook=progress_hook,
         **kwargs)
 
     if parallel:
-        with futures.ThreadPoolExecutor(max_concurrency) as executor:
-            upload_tasks = uploader.get_substream_blocks()
-            running_futures = [
-                executor.submit(with_current_context(uploader.process_substream_block), u)
-                for u in islice(upload_tasks, 0, max_concurrency)
-            ]
-            range_ids = _parallel_uploads(executor, uploader.process_substream_block, upload_tasks, running_futures)
+        executor = futures.ThreadPoolExecutor(max_concurrency)
+        upload_tasks = uploader.get_substream_blocks()
+        running_futures = [
+            executor.submit(with_current_context(uploader.process_substream_block), u)
+            for u in islice(upload_tasks, 0, max_concurrency)
+        ]
+        range_ids = _parallel_uploads(executor, uploader.process_substream_block, upload_tasks, running_futures)
     else:
         range_ids = [uploader.process_substream_block(b) for b in uploader.get_substream_blocks()]
-    if any(range_ids):
-        return sorted(range_ids)
-    return []
+    return sorted(range_ids)
 
 
 class _ChunkUploader(object):  # pylint: disable=too-many-instance-attributes
 
-    def __init__(
-            self, service,
-            total_size,
-            chunk_size,
-            stream,
-            parallel,
-            encryptor=None,
-            padder=None,
-            progress_hook=None,
-            **kwargs):
+    def __init__(self, service, total_size, chunk_size, stream, parallel, encryptor=None, padder=None, **kwargs):
         self.service = service
         self.total_size = total_size
         self.chunk_size = chunk_size
         self.stream = stream
         self.parallel = parallel
 
         # Stream management
         self.stream_start = stream.tell() if parallel else None
         self.stream_lock = Lock() if parallel else None
 
         # Progress feedback
         self.progress_total = 0
         self.progress_lock = Lock() if parallel else None
-        self.progress_hook = progress_hook
 
         # Encryption
         self.encryptor = encryptor
         self.padder = padder
         self.response_headers = None
         self.etag = None
         self.last_modified = None
@@ -209,17 +193,14 @@
     def _update_progress(self, length):
         if self.progress_lock is not None:
             with self.progress_lock:
                 self.progress_total += length
         else:
             self.progress_total += length
 
-        if self.progress_hook:
-            self.progress_hook(self.progress_total, self.total_size)
-
     def _upload_chunk(self, chunk_offset, chunk_data):
         raise NotImplementedError("Must be implemented by child class.")
 
     def _upload_chunk_with_progress(self, chunk_offset, chunk_data):
         range_id = self._upload_chunk(chunk_offset, chunk_data)
         self._update_progress(len(chunk_data))
         return range_id
@@ -236,24 +217,24 @@
 
         blocks = int(ceil(blob_length / (self.chunk_size * 1.0)))
         last_block_size = self.chunk_size if blob_length % self.chunk_size == 0 else blob_length % self.chunk_size
 
         for i in range(blocks):
             index = i * self.chunk_size
             length = last_block_size if i == blocks - 1 else self.chunk_size
-            yield index, SubStream(self.stream, index, length, lock)
+            yield ('BlockId{}'.format("%05d" % i), SubStream(self.stream, index, length, lock))
 
     def process_substream_block(self, block_data):
         return self._upload_substream_block_with_progress(block_data[0], block_data[1])
 
-    def _upload_substream_block(self, index, block_stream):
+    def _upload_substream_block(self, block_id, block_stream):
         raise NotImplementedError("Must be implemented by child class.")
 
-    def _upload_substream_block_with_progress(self, index, block_stream):
-        range_id = self._upload_substream_block(index, block_stream)
+    def _upload_substream_block_with_progress(self, block_id, block_stream):
+        range_id = self._upload_substream_block(block_id, block_stream)
         self._update_progress(len(block_stream))
         return range_id
 
     def set_response_properties(self, resp):
         self.etag = resp.etag
         self.last_modified = resp.last_modified
 
@@ -275,17 +256,16 @@
             chunk_data,
             data_stream_total=self.total_size,
             upload_stream_current=self.progress_total,
             **self.request_options
         )
         return index, block_id
 
-    def _upload_substream_block(self, index, block_stream):
+    def _upload_substream_block(self, block_id, block_stream):
         try:
-            block_id = 'BlockId{}'.format("%05d" % (index/self.chunk_size))
             self.service.stage_block(
                 block_id,
                 len(block_stream),
                 block_stream,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
@@ -305,95 +285,57 @@
     def _upload_chunk(self, chunk_offset, chunk_data):
         # avoid uploading the empty pages
         if not self._is_chunk_empty(chunk_data):
             chunk_end = chunk_offset + len(chunk_data) - 1
             content_range = "bytes={0}-{1}".format(chunk_offset, chunk_end)
             computed_md5 = None
             self.response_headers = self.service.upload_pages(
-                body=chunk_data,
+                chunk_data,
                 content_length=len(chunk_data),
                 transactional_content_md5=computed_md5,
                 range=content_range,
                 cls=return_response_headers,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
             )
 
             if not self.parallel and self.request_options.get('modified_access_conditions'):
                 self.request_options['modified_access_conditions'].if_match = self.response_headers['etag']
 
-    def _upload_substream_block(self, index, block_stream):
-        pass
-
 
 class AppendBlobChunkUploader(_ChunkUploader):  # pylint: disable=abstract-method
 
     def __init__(self, *args, **kwargs):
         super(AppendBlobChunkUploader, self).__init__(*args, **kwargs)
         self.current_length = None
 
     def _upload_chunk(self, chunk_offset, chunk_data):
         if self.current_length is None:
             self.response_headers = self.service.append_block(
-                body=chunk_data,
+                chunk_data,
                 content_length=len(chunk_data),
                 cls=return_response_headers,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
             )
             self.current_length = int(self.response_headers["blob_append_offset"])
         else:
             self.request_options['append_position_access_conditions'].append_position = \
                 self.current_length + chunk_offset
             self.response_headers = self.service.append_block(
-                body=chunk_data,
+                chunk_data,
                 content_length=len(chunk_data),
                 cls=return_response_headers,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
             )
 
-    def _upload_substream_block(self, index, block_stream):
-        pass
-
-
-class DataLakeFileChunkUploader(_ChunkUploader):  # pylint: disable=abstract-method
-
-    def _upload_chunk(self, chunk_offset, chunk_data):
-        # avoid uploading the empty pages
-        self.response_headers = self.service.append_data(
-            body=chunk_data,
-            position=chunk_offset,
-            content_length=len(chunk_data),
-            cls=return_response_headers,
-            data_stream_total=self.total_size,
-            upload_stream_current=self.progress_total,
-            **self.request_options
-        )
-
-        if not self.parallel and self.request_options.get('modified_access_conditions'):
-            self.request_options['modified_access_conditions'].if_match = self.response_headers['etag']
-
-    def _upload_substream_block(self, index, block_stream):
-        try:
-            self.service.append_data(
-                body=block_stream,
-                position=index,
-                content_length=len(block_stream),
-                cls=return_response_headers,
-                data_stream_total=self.total_size,
-                upload_stream_current=self.progress_total,
-                **self.request_options
-            )
-        finally:
-            block_stream.close()
-
 
 class FileChunkUploader(_ChunkUploader):  # pylint: disable=abstract-method
 
     def _upload_chunk(self, chunk_offset, chunk_data):
         length = len(chunk_data)
         chunk_end = chunk_offset + length - 1
         response = self.service.upload_range(
@@ -402,18 +344,14 @@
             length,
             data_stream_total=self.total_size,
             upload_stream_current=self.progress_total,
             **self.request_options
         )
         return 'bytes={0}-{1}'.format(chunk_offset, chunk_end), response
 
-    # TODO: Implement this method.
-    def _upload_substream_block(self, index, block_stream):
-        pass
-
 
 class SubStream(IOBase):
 
     def __init__(self, wrapped_stream, stream_begin_index, length, lockObj):
         # Python 2.7: file-like objects created with open() typically support seek(), but are not
         # derivations of io.IOBase and thus do not implement seekable().
         # Python > 3.0: file-like objects created with open() are derived from io.IOBase.
@@ -490,21 +428,14 @@
                         absolute_position = self._stream_begin_index + self._position
                         self._wrapped_stream.seek(absolute_position, SEEK_SET)
                         # If we can't seek to the right location, our read will be corrupted so fail fast.
                         if self._wrapped_stream.tell() != absolute_position:
                             raise IOError("Stream failed to seek to the desired location.")
                         buffer_from_stream = self._wrapped_stream.read(current_max_buffer_size)
                 else:
-                    absolute_position = self._stream_begin_index + self._position
-                    # It's possible that there's connection problem during data transfer,
-                    # so when we retry we don't want to read from current position of wrapped stream,
-                    # instead we should seek to where we want to read from.
-                    if self._wrapped_stream.tell() != absolute_position:
-                        self._wrapped_stream.seek(absolute_position, SEEK_SET)
-
                     buffer_from_stream = self._wrapped_stream.read(current_max_buffer_size)
 
             if buffer_from_stream:
                 # update the buffer with new data from the wrapped stream
                 # we need to note down the start position and size of the buffer, in case seek is performed later
                 self._buffer = BytesIO(buffer_from_stream)
                 self._current_buffer_start = self._position
@@ -585,31 +516,29 @@
 
     def __iter__(self):
         return self.iterator
 
     def seekable(self):
         return False
 
-    def __next__(self):
+    def next(self):
         return next(self.iterator)
 
-    next = __next__  # Python 2 compatibility.
-
     def tell(self, *args, **kwargs):
         raise UnsupportedOperation("Data generator does not support tell.")
 
     def seek(self, *args, **kwargs):
         raise UnsupportedOperation("Data generator is unseekable.")
 
     def read(self, size):
         data = self.leftover
         count = len(self.leftover)
         try:
             while count < size:
-                chunk = self.__next__()
+                chunk = self.next()
                 if isinstance(chunk, six.text_type):
                     chunk = chunk.encode(self.encoding)
                 data += chunk
                 count += len(chunk)
         except StopIteration:
             pass
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/uploads_async.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,31 +2,46 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=no-self-use
 
 import asyncio
+import inspect
+import threading
 from asyncio import Lock
+from io import UnsupportedOperation
 from itertools import islice
-import threading
-
 from math import ceil
-
-import six
+from typing import AsyncGenerator, Union
 
 from . import encode_base64, url_quote
 from .request_handlers import get_length
 from .response_handlers import return_response_headers
-from .encryption import get_blob_encryptor_and_padder
 from .uploads import SubStream, IterStreamer  # pylint: disable=unused-import
 
 
-_LARGE_BLOB_UPLOAD_MAX_READ_BUFFER_SIZE = 4 * 1024 * 1024
-_ERROR_VALUE_SHOULD_BE_SEEKABLE_STREAM = '{0} should be a seekable file-like/io.IOBase type stream object.'
+async def _async_parallel_uploads(uploader, pending, running):
+    range_ids = []
+    while True:
+        # Wait for some download to finish before adding a new one
+        done, running = await asyncio.wait(running, return_when=asyncio.FIRST_COMPLETED)
+        range_ids.extend([chunk.result() for chunk in done])
+        try:
+            for _ in range(0, len(done)):
+                next_chunk = await pending.__anext__()
+                running.add(asyncio.ensure_future(uploader(next_chunk)))
+        except StopAsyncIteration:
+            break
+
+    # Wait for the remaining uploads to finish
+    if running:
+        done, _running = await asyncio.wait(running)
+        range_ids.extend([chunk.result() for chunk in done])
+    return range_ids
 
 
 async def _parallel_uploads(uploader, pending, running):
     range_ids = []
     while True:
         # Wait for some download to finish before adding a new one
         done, running = await asyncio.wait(running, return_when=asyncio.FIRST_COMPLETED)
@@ -48,26 +63,17 @@
 async def upload_data_chunks(
         service=None,
         uploader_class=None,
         total_size=None,
         chunk_size=None,
         max_concurrency=None,
         stream=None,
-        encryption_options=None,
         progress_hook=None,
         **kwargs):
 
-    if encryption_options:
-        encryptor, padder = get_blob_encryptor_and_padder(
-            encryption_options.get('cek'),
-            encryption_options.get('vector'),
-            uploader_class is not PageBlobChunkUploader)
-        kwargs['encryptor'] = encryptor
-        kwargs['padder'] = padder
-
     parallel = max_concurrency > 1
     if parallel and 'modified_access_conditions' in kwargs:
         # Access conditions do not work with parallelism
         kwargs['modified_access_conditions'] = None
 
     uploader = uploader_class(
         service=service,
@@ -76,22 +82,26 @@
         stream=stream,
         parallel=parallel,
         progress_hook=progress_hook,
         **kwargs)
 
     if parallel:
         upload_tasks = uploader.get_chunk_streams()
-        running_futures = [
-            asyncio.ensure_future(uploader.process_chunk(u))
-            for u in islice(upload_tasks, 0, max_concurrency)
-        ]
-        range_ids = await _parallel_uploads(uploader.process_chunk, upload_tasks, running_futures)
+        running_futures = []
+        for _ in range(max_concurrency):
+            try:
+                chunk = await upload_tasks.__anext__()
+                running_futures.append(asyncio.ensure_future(uploader.process_chunk(chunk)))
+            except StopAsyncIteration:
+                break
+
+        range_ids = await _async_parallel_uploads(uploader.process_chunk, upload_tasks, running_futures)
     else:
         range_ids = []
-        for chunk in uploader.get_chunk_streams():
+        async for chunk in uploader.get_chunk_streams():
             range_ids.append(await uploader.process_chunk(chunk))
 
     if any(range_ids):
         return [r[1] for r in sorted(range_ids, key=lambda r: r[0])]
     return uploader.response_headers
 
 
@@ -148,15 +158,14 @@
         self.service = service
         self.total_size = total_size
         self.chunk_size = chunk_size
         self.stream = stream
         self.parallel = parallel
 
         # Stream management
-        self.stream_start = stream.tell() if parallel else None
         self.stream_lock = threading.Lock() if parallel else None
 
         # Progress feedback
         self.progress_total = 0
         self.progress_lock = Lock() if parallel else None
         self.progress_hook = progress_hook
 
@@ -164,26 +173,28 @@
         self.encryptor = encryptor
         self.padder = padder
         self.response_headers = None
         self.etag = None
         self.last_modified = None
         self.request_options = kwargs
 
-    def get_chunk_streams(self):
+    async def get_chunk_streams(self):
         index = 0
         while True:
             data = b''
             read_size = self.chunk_size
 
             # Buffer until we either reach the end of the stream or get a whole chunk.
             while True:
                 if self.total_size:
                     read_size = min(self.chunk_size - len(data), self.total_size - (index + len(data)))
                 temp = self.stream.read(read_size)
-                if not isinstance(temp, six.binary_type):
+                if inspect.isawaitable(temp):
+                    temp = await temp
+                if not isinstance(temp, bytes):
                     raise TypeError('Blob data should be of type bytes.')
                 data += temp or b""
 
                 # We have read an empty string and so are at the end
                 # of the buffer or we have read a full chunk.
                 if temp == b'' or len(data) == self.chunk_size:
                     break
@@ -213,15 +224,15 @@
         if self.progress_lock is not None:
             async with self.progress_lock:
                 self.progress_total += length
         else:
             self.progress_total += length
 
         if self.progress_hook:
-            self.progress_hook(self.progress_total, self.total_size)
+            await self.progress_hook(self.progress_total, self.total_size)
 
     async def _upload_chunk(self, chunk_offset, chunk_data):
         raise NotImplementedError("Must be implemented by child class.")
 
     async def _upload_chunk_with_progress(self, chunk_offset, chunk_data):
         range_id = await self._upload_chunk(chunk_offset, chunk_data)
         await self._update_progress(len(chunk_data))
@@ -266,28 +277,28 @@
     def __init__(self, *args, **kwargs):
         kwargs.pop('modified_access_conditions', None)
         super(BlockBlobChunkUploader, self).__init__(*args, **kwargs)
         self.current_length = None
 
     async def _upload_chunk(self, chunk_offset, chunk_data):
         # TODO: This is incorrect, but works with recording.
-        index = '{0:032d}'.format(chunk_offset)
+        index = f'{chunk_offset:032d}'
         block_id = encode_base64(url_quote(encode_base64(index)))
         await self.service.stage_block(
             block_id,
             len(chunk_data),
             body=chunk_data,
             data_stream_total=self.total_size,
             upload_stream_current=self.progress_total,
             **self.request_options)
         return index, block_id
 
     async def _upload_substream_block(self, index, block_stream):
         try:
-            block_id = 'BlockId{}'.format("%05d" % (index/self.chunk_size))
+            block_id = f'BlockId{"%05d" % (index/self.chunk_size)}'
             await self.service.stage_block(
                 block_id,
                 len(block_stream),
                 block_stream,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options)
@@ -306,15 +317,15 @@
                 return False
         return True
 
     async def _upload_chunk(self, chunk_offset, chunk_data):
         # avoid uploading the empty pages
         if not self._is_chunk_empty(chunk_data):
             chunk_end = chunk_offset + len(chunk_data) - 1
-            content_range = 'bytes={0}-{1}'.format(chunk_offset, chunk_end)
+            content_range = f'bytes={chunk_offset}-{chunk_end}'
             computed_md5 = None
             self.response_headers = await self.service.upload_pages(
                 body=chunk_data,
                 content_length=len(chunk_data),
                 transactional_content_md5=computed_md5,
                 range=content_range,
                 cls=return_response_headers,
@@ -400,13 +411,51 @@
             chunk_data,
             chunk_offset,
             length,
             data_stream_total=self.total_size,
             upload_stream_current=self.progress_total,
             **self.request_options
         )
-        range_id = 'bytes={0}-{1}'.format(chunk_offset, chunk_end)
+        range_id = f'bytes={chunk_offset}-{chunk_end}'
         return range_id, response
 
     # TODO: Implement this method.
     async def _upload_substream_block(self, index, block_stream):
         pass
+
+
+class AsyncIterStreamer():
+    """
+    File-like streaming object for AsyncGenerators.
+    """
+    def __init__(self, generator: AsyncGenerator[Union[bytes, str], None], encoding: str = "UTF-8"):
+        self.iterator = generator.__aiter__()
+        self.leftover = b""
+        self.encoding = encoding
+
+    def seekable(self):
+        return False
+
+    def tell(self, *args, **kwargs):
+        raise UnsupportedOperation("Data generator does not support tell.")
+
+    def seek(self, *args, **kwargs):
+        raise UnsupportedOperation("Data generator is not seekable.")
+
+    async def read(self, size: int) -> bytes:
+        data = self.leftover
+        count = len(self.leftover)
+        try:
+            while count < size:
+                chunk = await self.iterator.__anext__()
+                if isinstance(chunk, str):
+                    chunk = chunk.encode(self.encoding)
+                data += chunk
+                count += len(chunk)
+        # This means count < size and what's leftover will be returned in this call.
+        except StopAsyncIteration:
+            self.leftover = b""
+
+        if count >= size:
+            self.leftover = data[size:]
+
+        return data[:size]
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2018_03_28/aio/_queue_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_deserialize.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_deserialize.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_azure_queue_storage.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_azure_queue_storage.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/_configuration.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_configuration_async.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 # Changes may cause incorrect behavior and will be lost if the code is
 # regenerated.
 # --------------------------------------------------------------------------
 
 from azure.core.configuration import Configuration
 from azure.core.pipeline import policies
 
-from .version import VERSION
+from ..version import VERSION
 
 
 class AzureQueueStorageConfiguration(Configuration):
     """Configuration for AzureQueueStorage
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
@@ -34,19 +34,20 @@
             raise ValueError("Parameter 'url' must not be None.")
 
         super(AzureQueueStorageConfiguration, self).__init__(**kwargs)
         self._configure(**kwargs)
 
         self.user_agent_policy.add_user_agent('azsdk-python-azurequeuestorage/{}'.format(VERSION))
         self.generate_client_request_id = True
+        self.accept_language = None
 
         self.url = url
         self.version = "2018-03-28"
 
     def _configure(self, **kwargs):
         self.user_agent_policy = kwargs.get('user_agent_policy') or policies.UserAgentPolicy(**kwargs)
         self.headers_policy = kwargs.get('headers_policy') or policies.HeadersPolicy(**kwargs)
         self.proxy_policy = kwargs.get('proxy_policy') or policies.ProxyPolicy(**kwargs)
         self.logging_policy = kwargs.get('logging_policy') or policies.NetworkTraceLoggingPolicy(**kwargs)
-        self.retry_policy = kwargs.get('retry_policy') or policies.RetryPolicy(**kwargs)
+        self.retry_policy = kwargs.get('retry_policy') or policies.AsyncRetryPolicy(**kwargs)
         self.custom_hook_policy = kwargs.get('custom_hook_policy') or policies.CustomHookPolicy(**kwargs)
-        self.redirect_policy = kwargs.get('redirect_policy') or policies.RedirectPolicy(**kwargs)
+        self.redirect_policy = kwargs.get('redirect_policy') or policies.AsyncRedirectPolicy(**kwargs)
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_azure_queue_storage_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_azure_queue_storage_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/_configuration_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_generated/_configuration.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,53 +1,55 @@
 # coding=utf-8
 # --------------------------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
-# Licensed under the MIT License. See License.txt in the project root for
-# license information.
-#
+# Licensed under the MIT License. See License.txt in the project root for license information.
 # Code generated by Microsoft (R) AutoRest Code Generator.
-# Changes may cause incorrect behavior and will be lost if the code is
-# regenerated.
+# Changes may cause incorrect behavior and will be lost if the code is regenerated.
 # --------------------------------------------------------------------------
 
+from typing import Any
+
 from azure.core.configuration import Configuration
 from azure.core.pipeline import policies
 
-from ..version import VERSION
+VERSION = "unknown"
+
 
+class AzureBlobStorageConfiguration(Configuration):  # pylint: disable=too-many-instance-attributes
+    """Configuration for AzureBlobStorage.
 
-class AzureQueueStorageConfiguration(Configuration):
-    """Configuration for AzureQueueStorage
     Note that all parameters used to create this instance are saved as instance
     attributes.
 
-    :param url: The URL of the service account, queue or message that is the
-     targe of the desired operation.
+    :param url: The URL of the service account, container, or blob that is the target of the
+     desired operation. Required.
     :type url: str
-    :ivar version: Specifies the version of the operation to use for this
-     request.
-    :type version: str
+    :keyword version: Specifies the version of the operation to use for this request. Default value
+     is "2021-12-02". Note that overriding this default value may result in unsupported behavior.
+    :paramtype version: str
     """
 
-    def __init__(self, url, **kwargs):
+    def __init__(self, url: str, **kwargs: Any) -> None:
+        super(AzureBlobStorageConfiguration, self).__init__(**kwargs)
+        version = kwargs.pop("version", "2021-12-02")  # type: str
 
         if url is None:
             raise ValueError("Parameter 'url' must not be None.")
 
-        super(AzureQueueStorageConfiguration, self).__init__(**kwargs)
-        self._configure(**kwargs)
-
-        self.user_agent_policy.add_user_agent('azsdk-python-azurequeuestorage/{}'.format(VERSION))
-        self.generate_client_request_id = True
-        self.accept_language = None
-
         self.url = url
-        self.version = "2018-03-28"
+        self.version = version
+        kwargs.setdefault("sdk_moniker", "azureblobstorage/{}".format(VERSION))
+        self._configure(**kwargs)
 
-    def _configure(self, **kwargs):
-        self.user_agent_policy = kwargs.get('user_agent_policy') or policies.UserAgentPolicy(**kwargs)
-        self.headers_policy = kwargs.get('headers_policy') or policies.HeadersPolicy(**kwargs)
-        self.proxy_policy = kwargs.get('proxy_policy') or policies.ProxyPolicy(**kwargs)
-        self.logging_policy = kwargs.get('logging_policy') or policies.NetworkTraceLoggingPolicy(**kwargs)
-        self.retry_policy = kwargs.get('retry_policy') or policies.AsyncRetryPolicy(**kwargs)
-        self.custom_hook_policy = kwargs.get('custom_hook_policy') or policies.CustomHookPolicy(**kwargs)
-        self.redirect_policy = kwargs.get('redirect_policy') or policies.AsyncRedirectPolicy(**kwargs)
+    def _configure(
+        self, **kwargs  # type: Any
+    ):
+        # type: (...) -> None
+        self.user_agent_policy = kwargs.get("user_agent_policy") or policies.UserAgentPolicy(**kwargs)
+        self.headers_policy = kwargs.get("headers_policy") or policies.HeadersPolicy(**kwargs)
+        self.proxy_policy = kwargs.get("proxy_policy") or policies.ProxyPolicy(**kwargs)
+        self.logging_policy = kwargs.get("logging_policy") or policies.NetworkTraceLoggingPolicy(**kwargs)
+        self.http_logging_policy = kwargs.get("http_logging_policy") or policies.HttpLoggingPolicy(**kwargs)
+        self.retry_policy = kwargs.get("retry_policy") or policies.RetryPolicy(**kwargs)
+        self.custom_hook_policy = kwargs.get("custom_hook_policy") or policies.CustomHookPolicy(**kwargs)
+        self.redirect_policy = kwargs.get("redirect_policy") or policies.RedirectPolicy(**kwargs)
+        self.authentication_policy = kwargs.get("authentication_policy")
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_message_id_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_message_id_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_messages_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_messages_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_queue_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_queue_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/aio/operations_async/_service_operations_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/__init__.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_azure_queue_storage_enums.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_azure_queue_storage_enums.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models_py3.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/models/_models_py3.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_message_id_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_message_id_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_messages_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_messages_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_queue_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_queue_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_service_operations.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_generated/operations/_service_operations.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_message_encoding.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_message_encoding.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_service_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_queue_service_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/__init__.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/fileshare/v2022_11_02/_shared/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,48 +9,46 @@
 import hmac
 
 try:
     from urllib.parse import quote, unquote
 except ImportError:
     from urllib2 import quote, unquote # type: ignore
 
-import six
-
 
 def url_quote(url):
     return quote(url)
 
 
 def url_unquote(url):
     return unquote(url)
 
 
 def encode_base64(data):
-    if isinstance(data, six.text_type):
+    if isinstance(data, str):
         data = data.encode('utf-8')
     encoded = base64.b64encode(data)
     return encoded.decode('utf-8')
 
 
 def decode_base64_to_bytes(data):
-    if isinstance(data, six.text_type):
+    if isinstance(data, str):
         data = data.encode('utf-8')
     return base64.b64decode(data)
 
 
 def decode_base64_to_text(data):
     decoded_bytes = decode_base64_to_bytes(data)
     return decoded_bytes.decode('utf-8')
 
 
 def sign_string(key, string_to_sign, key_is_base64=True):
     if key_is_base64:
         key = decode_base64_to_bytes(key)
     else:
-        if isinstance(key, six.text_type):
+        if isinstance(key, str):
             key = key.encode('utf-8')
-    if isinstance(string_to_sign, six.text_type):
+    if isinstance(string_to_sign, str):
         string_to_sign = string_to_sign.encode('utf-8')
     signed_hmac_sha256 = hmac.HMAC(key, string_to_sign, hashlib.sha256)
     digest = signed_hmac_sha256.digest()
     encoded_digest = encode_base64(digest)
     return encoded_digest
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/authentication.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/authentication.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/base_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/constants.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/constants.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/policies_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/request_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/request_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/response_handlers.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/response_handlers.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/blob/v2022_11_02/_shared/uploads.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,45 +2,42 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License. See License.txt in the project root for
 # license information.
 # --------------------------------------------------------------------------
 # pylint: disable=no-self-use
 
 from concurrent import futures
-from io import (BytesIO, IOBase, SEEK_CUR, SEEK_END, SEEK_SET, UnsupportedOperation)
-from threading import Lock
+from io import BytesIO, IOBase, SEEK_CUR, SEEK_END, SEEK_SET, UnsupportedOperation
 from itertools import islice
 from math import ceil
-
-import six
+from threading import Lock
 
 from azure.core.tracing.common import with_current_context
 
 from . import encode_base64, url_quote
 from .request_handlers import get_length
 from .response_handlers import return_response_headers
-from .encryption import get_blob_encryptor_and_padder
 
 
 _LARGE_BLOB_UPLOAD_MAX_READ_BUFFER_SIZE = 4 * 1024 * 1024
 _ERROR_VALUE_SHOULD_BE_SEEKABLE_STREAM = "{0} should be a seekable file-like/io.IOBase type stream object."
 
 
 def _parallel_uploads(executor, uploader, pending, running):
     range_ids = []
     while True:
         # Wait for some download to finish before adding a new one
         done, running = futures.wait(running, return_when=futures.FIRST_COMPLETED)
         range_ids.extend([chunk.result() for chunk in done])
         try:
-            next_chunk = next(pending)
+            for _ in range(0, len(done)):
+                next_chunk = next(pending)
+                running.add(executor.submit(with_current_context(uploader), next_chunk))
         except StopIteration:
             break
-        else:
-            running.add(executor.submit(with_current_context(uploader), next_chunk))
 
     # Wait for the remaining uploads to finish
     done, _running = futures.wait(running)
     range_ids.extend([chunk.result() for chunk in done])
     return range_ids
 
 
@@ -48,102 +45,108 @@
         service=None,
         uploader_class=None,
         total_size=None,
         chunk_size=None,
         max_concurrency=None,
         stream=None,
         validate_content=None,
-        encryption_options=None,
+        progress_hook=None,
         **kwargs):
 
-    if encryption_options:
-        encryptor, padder = get_blob_encryptor_and_padder(
-            encryption_options.get('cek'),
-            encryption_options.get('vector'),
-            uploader_class is not PageBlobChunkUploader)
-        kwargs['encryptor'] = encryptor
-        kwargs['padder'] = padder
-
     parallel = max_concurrency > 1
     if parallel and 'modified_access_conditions' in kwargs:
         # Access conditions do not work with parallelism
         kwargs['modified_access_conditions'] = None
 
     uploader = uploader_class(
         service=service,
         total_size=total_size,
         chunk_size=chunk_size,
         stream=stream,
         parallel=parallel,
         validate_content=validate_content,
+        progress_hook=progress_hook,
         **kwargs)
     if parallel:
-        executor = futures.ThreadPoolExecutor(max_concurrency)
-        upload_tasks = uploader.get_chunk_streams()
-        running_futures = [
-            executor.submit(with_current_context(uploader.process_chunk), u)
-            for u in islice(upload_tasks, 0, max_concurrency)
-        ]
-        range_ids = _parallel_uploads(executor, uploader.process_chunk, upload_tasks, running_futures)
+        with futures.ThreadPoolExecutor(max_concurrency) as executor:
+            upload_tasks = uploader.get_chunk_streams()
+            running_futures = [
+                executor.submit(with_current_context(uploader.process_chunk), u)
+                for u in islice(upload_tasks, 0, max_concurrency)
+            ]
+            range_ids = _parallel_uploads(executor, uploader.process_chunk, upload_tasks, running_futures)
     else:
         range_ids = [uploader.process_chunk(result) for result in uploader.get_chunk_streams()]
     if any(range_ids):
         return [r[1] for r in sorted(range_ids, key=lambda r: r[0])]
     return uploader.response_headers
 
 
 def upload_substream_blocks(
         service=None,
         uploader_class=None,
         total_size=None,
         chunk_size=None,
         max_concurrency=None,
         stream=None,
+        progress_hook=None,
         **kwargs):
     parallel = max_concurrency > 1
     if parallel and 'modified_access_conditions' in kwargs:
         # Access conditions do not work with parallelism
         kwargs['modified_access_conditions'] = None
     uploader = uploader_class(
         service=service,
         total_size=total_size,
         chunk_size=chunk_size,
         stream=stream,
         parallel=parallel,
+        progress_hook=progress_hook,
         **kwargs)
 
     if parallel:
-        executor = futures.ThreadPoolExecutor(max_concurrency)
-        upload_tasks = uploader.get_substream_blocks()
-        running_futures = [
-            executor.submit(with_current_context(uploader.process_substream_block), u)
-            for u in islice(upload_tasks, 0, max_concurrency)
-        ]
-        range_ids = _parallel_uploads(executor, uploader.process_substream_block, upload_tasks, running_futures)
+        with futures.ThreadPoolExecutor(max_concurrency) as executor:
+            upload_tasks = uploader.get_substream_blocks()
+            running_futures = [
+                executor.submit(with_current_context(uploader.process_substream_block), u)
+                for u in islice(upload_tasks, 0, max_concurrency)
+            ]
+            range_ids = _parallel_uploads(executor, uploader.process_substream_block, upload_tasks, running_futures)
     else:
         range_ids = [uploader.process_substream_block(b) for b in uploader.get_substream_blocks()]
-    return sorted(range_ids)
+    if any(range_ids):
+        return sorted(range_ids)
+    return []
 
 
 class _ChunkUploader(object):  # pylint: disable=too-many-instance-attributes
 
-    def __init__(self, service, total_size, chunk_size, stream, parallel, encryptor=None, padder=None, **kwargs):
+    def __init__(
+            self, service,
+            total_size,
+            chunk_size,
+            stream,
+            parallel,
+            encryptor=None,
+            padder=None,
+            progress_hook=None,
+            **kwargs):
         self.service = service
         self.total_size = total_size
         self.chunk_size = chunk_size
         self.stream = stream
         self.parallel = parallel
 
         # Stream management
-        self.stream_start = stream.tell() if parallel else None
         self.stream_lock = Lock() if parallel else None
 
         # Progress feedback
         self.progress_total = 0
         self.progress_lock = Lock() if parallel else None
+        self.progress_hook = progress_hook
 
         # Encryption
         self.encryptor = encryptor
         self.padder = padder
         self.response_headers = None
         self.etag = None
         self.last_modified = None
@@ -156,15 +159,15 @@
             read_size = self.chunk_size
 
             # Buffer until we either reach the end of the stream or get a whole chunk.
             while True:
                 if self.total_size:
                     read_size = min(self.chunk_size - len(data), self.total_size - (index + len(data)))
                 temp = self.stream.read(read_size)
-                if not isinstance(temp, six.binary_type):
+                if not isinstance(temp, bytes):
                     raise TypeError("Blob data should be of type bytes.")
                 data += temp or b""
 
                 # We have read an empty string and so are at the end
                 # of the buffer or we have read a full chunk.
                 if temp == b"" or len(data) == self.chunk_size:
                     break
@@ -193,14 +196,17 @@
     def _update_progress(self, length):
         if self.progress_lock is not None:
             with self.progress_lock:
                 self.progress_total += length
         else:
             self.progress_total += length
 
+        if self.progress_hook:
+            self.progress_hook(self.progress_total, self.total_size)
+
     def _upload_chunk(self, chunk_offset, chunk_data):
         raise NotImplementedError("Must be implemented by child class.")
 
     def _upload_chunk_with_progress(self, chunk_offset, chunk_data):
         range_id = self._upload_chunk(chunk_offset, chunk_data)
         self._update_progress(len(chunk_data))
         return range_id
@@ -217,24 +223,24 @@
 
         blocks = int(ceil(blob_length / (self.chunk_size * 1.0)))
         last_block_size = self.chunk_size if blob_length % self.chunk_size == 0 else blob_length % self.chunk_size
 
         for i in range(blocks):
             index = i * self.chunk_size
             length = last_block_size if i == blocks - 1 else self.chunk_size
-            yield ('BlockId{}'.format("%05d" % i), SubStream(self.stream, index, length, lock))
+            yield index, SubStream(self.stream, index, length, lock)
 
     def process_substream_block(self, block_data):
         return self._upload_substream_block_with_progress(block_data[0], block_data[1])
 
-    def _upload_substream_block(self, block_id, block_stream):
+    def _upload_substream_block(self, index, block_stream):
         raise NotImplementedError("Must be implemented by child class.")
 
-    def _upload_substream_block_with_progress(self, block_id, block_stream):
-        range_id = self._upload_substream_block(block_id, block_stream)
+    def _upload_substream_block_with_progress(self, index, block_stream):
+        range_id = self._upload_substream_block(index, block_stream)
         self._update_progress(len(block_stream))
         return range_id
 
     def set_response_properties(self, resp):
         self.etag = resp.etag
         self.last_modified = resp.last_modified
 
@@ -244,28 +250,29 @@
     def __init__(self, *args, **kwargs):
         kwargs.pop("modified_access_conditions", None)
         super(BlockBlobChunkUploader, self).__init__(*args, **kwargs)
         self.current_length = None
 
     def _upload_chunk(self, chunk_offset, chunk_data):
         # TODO: This is incorrect, but works with recording.
-        index = '{0:032d}'.format(chunk_offset)
+        index = f'{chunk_offset:032d}'
         block_id = encode_base64(url_quote(encode_base64(index)))
         self.service.stage_block(
             block_id,
             len(chunk_data),
             chunk_data,
             data_stream_total=self.total_size,
             upload_stream_current=self.progress_total,
             **self.request_options
         )
         return index, block_id
 
-    def _upload_substream_block(self, block_id, block_stream):
+    def _upload_substream_block(self, index, block_stream):
         try:
+            block_id = f'BlockId{"%05d" % (index/self.chunk_size)}'
             self.service.stage_block(
                 block_id,
                 len(block_stream),
                 block_stream,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
@@ -282,75 +289,117 @@
         # if reached the end without returning, then chunk_data is all 0's
         return not any(bytearray(chunk_data))
 
     def _upload_chunk(self, chunk_offset, chunk_data):
         # avoid uploading the empty pages
         if not self._is_chunk_empty(chunk_data):
             chunk_end = chunk_offset + len(chunk_data) - 1
-            content_range = "bytes={0}-{1}".format(chunk_offset, chunk_end)
+            content_range = f"bytes={chunk_offset}-{chunk_end}"
             computed_md5 = None
             self.response_headers = self.service.upload_pages(
-                chunk_data,
+                body=chunk_data,
                 content_length=len(chunk_data),
                 transactional_content_md5=computed_md5,
                 range=content_range,
                 cls=return_response_headers,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
             )
 
             if not self.parallel and self.request_options.get('modified_access_conditions'):
                 self.request_options['modified_access_conditions'].if_match = self.response_headers['etag']
 
+    def _upload_substream_block(self, index, block_stream):
+        pass
+
 
 class AppendBlobChunkUploader(_ChunkUploader):  # pylint: disable=abstract-method
 
     def __init__(self, *args, **kwargs):
         super(AppendBlobChunkUploader, self).__init__(*args, **kwargs)
         self.current_length = None
 
     def _upload_chunk(self, chunk_offset, chunk_data):
         if self.current_length is None:
             self.response_headers = self.service.append_block(
-                chunk_data,
+                body=chunk_data,
                 content_length=len(chunk_data),
                 cls=return_response_headers,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
             )
             self.current_length = int(self.response_headers["blob_append_offset"])
         else:
             self.request_options['append_position_access_conditions'].append_position = \
                 self.current_length + chunk_offset
             self.response_headers = self.service.append_block(
-                chunk_data,
+                body=chunk_data,
                 content_length=len(chunk_data),
                 cls=return_response_headers,
                 data_stream_total=self.total_size,
                 upload_stream_current=self.progress_total,
                 **self.request_options
             )
 
+    def _upload_substream_block(self, index, block_stream):
+        pass
+
+
+class DataLakeFileChunkUploader(_ChunkUploader):  # pylint: disable=abstract-method
+
+    def _upload_chunk(self, chunk_offset, chunk_data):
+        # avoid uploading the empty pages
+        self.response_headers = self.service.append_data(
+            body=chunk_data,
+            position=chunk_offset,
+            content_length=len(chunk_data),
+            cls=return_response_headers,
+            data_stream_total=self.total_size,
+            upload_stream_current=self.progress_total,
+            **self.request_options
+        )
+
+        if not self.parallel and self.request_options.get('modified_access_conditions'):
+            self.request_options['modified_access_conditions'].if_match = self.response_headers['etag']
+
+    def _upload_substream_block(self, index, block_stream):
+        try:
+            self.service.append_data(
+                body=block_stream,
+                position=index,
+                content_length=len(block_stream),
+                cls=return_response_headers,
+                data_stream_total=self.total_size,
+                upload_stream_current=self.progress_total,
+                **self.request_options
+            )
+        finally:
+            block_stream.close()
+
 
 class FileChunkUploader(_ChunkUploader):  # pylint: disable=abstract-method
 
     def _upload_chunk(self, chunk_offset, chunk_data):
         length = len(chunk_data)
         chunk_end = chunk_offset + length - 1
         response = self.service.upload_range(
             chunk_data,
             chunk_offset,
             length,
             data_stream_total=self.total_size,
             upload_stream_current=self.progress_total,
             **self.request_options
         )
-        return 'bytes={0}-{1}'.format(chunk_offset, chunk_end), response
+        return f'bytes={chunk_offset}-{chunk_end}', response
+
+    # TODO: Implement this method.
+    def _upload_substream_block(self, index, block_stream):
+        pass
 
 
 class SubStream(IOBase):
 
     def __init__(self, wrapped_stream, stream_begin_index, length, lockObj):
         # Python 2.7: file-like objects created with open() typically support seek(), but are not
         # derivations of io.IOBase and thus do not implement seekable().
@@ -428,14 +477,21 @@
                         absolute_position = self._stream_begin_index + self._position
                         self._wrapped_stream.seek(absolute_position, SEEK_SET)
                         # If we can't seek to the right location, our read will be corrupted so fail fast.
                         if self._wrapped_stream.tell() != absolute_position:
                             raise IOError("Stream failed to seek to the desired location.")
                         buffer_from_stream = self._wrapped_stream.read(current_max_buffer_size)
                 else:
+                    absolute_position = self._stream_begin_index + self._position
+                    # It's possible that there's connection problem during data transfer,
+                    # so when we retry we don't want to read from current position of wrapped stream,
+                    # instead we should seek to where we want to read from.
+                    if self._wrapped_stream.tell() != absolute_position:
+                        self._wrapped_stream.seek(absolute_position, SEEK_SET)
+
                     buffer_from_stream = self._wrapped_stream.read(current_max_buffer_size)
 
             if buffer_from_stream:
                 # update the buffer with new data from the wrapped stream
                 # we need to note down the start position and size of the buffer, in case seek is performed later
                 self._buffer = BytesIO(buffer_from_stream)
                 self._current_buffer_start = self._position
@@ -516,33 +572,36 @@
 
     def __iter__(self):
         return self.iterator
 
     def seekable(self):
         return False
 
-    def next(self):
+    def __next__(self):
         return next(self.iterator)
 
+    next = __next__  # Python 2 compatibility.
+
     def tell(self, *args, **kwargs):
         raise UnsupportedOperation("Data generator does not support tell.")
 
     def seek(self, *args, **kwargs):
-        raise UnsupportedOperation("Data generator is unseekable.")
+        raise UnsupportedOperation("Data generator is not seekable.")
 
     def read(self, size):
         data = self.leftover
         count = len(self.leftover)
         try:
             while count < size:
-                chunk = self.next()
-                if isinstance(chunk, six.text_type):
+                chunk = self.__next__()
+                if isinstance(chunk, str):
                     chunk = chunk.encode(self.encoding)
                 data += chunk
                 count += len(chunk)
+        # This means count < size and what's leftover will be returned in this call.
         except StopIteration:
-            pass
+            self.leftover = b""
 
-        if count > size:
+        if count >= size:
             self.leftover = data[size:]
 
         return data[:size]
```

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared/uploads_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared_access_signature.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/_shared_access_signature.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_models.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_models.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_service_client_async.py` & `azure-multiapi-storage-1.2.0/azure/multiapi/storagev2/queue/v2019_07_07/aio/_queue_service_client_async.py`

 * *Files identical despite different names*

### Comparing `azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/PKG-INFO` & `azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: azure-multiapi-storage
-Version: 1.1.0
+Version: 1.2.0
 Summary: Microsoft Azure Storage Client Library for Python with multi API version support.
 Home-page: https://github.com/Azure/azure-multiapi-storage-python
 Author: Microsoft Corporation
 Author-email: azpycli@microsoft.com
 License: MIT
 Classifier: Development Status :: 4 - Beta
 Classifier: Programming Language :: Python
@@ -35,14 +35,18 @@
 
 - The official Azure CosmosDB Table SDK is at https://github.com/Azure/azure-cosmosdb-python/tree/master/azure-cosmosdb-table.
 
 - **Please file issues at the appropriate repository above.**
 
 Change Log
 ----------
+1.2.0
+++++++
+* blob: Support v2022-11-02(12.16.0) and remove v2021-06-08
+
 1.1.0
 ++++++
 * fileshare: Support v2022-11-02(12.12.0b1) and remove v2021-06-08
 
 1.0.0
 ++++++
 * storageV1:
```

### Comparing `azure-multiapi-storage-1.1.0/azure_multiapi_storage.egg-info/SOURCES.txt` & `azure-multiapi-storage-1.2.0/azure_multiapi_storage.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -291,85 +291,14 @@
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_client_async.py
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_blob_service_client_async.py
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_container_client_async.py
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_download_async.py
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_lease_async.py
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_models.py
 azure/multiapi/storagev2/blob/v2019_07_07/aio/_upload_helpers.py
-azure/multiapi/storagev2/blob/v2021_06_08/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_blob_client.py
-azure/multiapi/storagev2/blob/v2021_06_08/_blob_service_client.py
-azure/multiapi/storagev2/blob/v2021_06_08/_container_client.py
-azure/multiapi/storagev2/blob/v2021_06_08/_deserialize.py
-azure/multiapi/storagev2/blob/v2021_06_08/_download.py
-azure/multiapi/storagev2/blob/v2021_06_08/_lease.py
-azure/multiapi/storagev2/blob/v2021_06_08/_list_blobs_helper.py
-azure/multiapi/storagev2/blob/v2021_06_08/_models.py
-azure/multiapi/storagev2/blob/v2021_06_08/_quick_query_helper.py
-azure/multiapi/storagev2/blob/v2021_06_08/_serialize.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared_access_signature.py
-azure/multiapi/storagev2/blob/v2021_06_08/_upload_helpers.py
-azure/multiapi/storagev2/blob/v2021_06_08/_version.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/_azure_blob_storage.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/_configuration.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/_patch.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/_vendor.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_azure_blob_storage.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_configuration.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/_patch.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_append_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_block_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_container_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_page_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/aio/operations/_service_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_azure_blob_storage_enums.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_models.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/models/_models_py3.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_append_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_block_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_container_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_page_blob_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_generated/operations/_service_operations.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/authentication.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/base_client.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/base_client_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/constants.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/encryption.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/models.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/parser.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/policies.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/policies_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/request_handlers.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/response_handlers.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/shared_access_signature.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/uploads.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/uploads_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/avro_io.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/avro_io_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/datafile.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/datafile_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/_shared/avro/schema.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/__init__.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_blob_client_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_blob_service_client_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_container_client_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_download_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_lease_async.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_list_blobs_helper.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_models.py
-azure/multiapi/storagev2/blob/v2021_06_08/aio/_upload_helpers.py
 azure/multiapi/storagev2/blob/v2021_08_06/__init__.py
 azure/multiapi/storagev2/blob/v2021_08_06/_blob_client.py
 azure/multiapi/storagev2/blob/v2021_08_06/_blob_service_client.py
 azure/multiapi/storagev2/blob/v2021_08_06/_container_client.py
 azure/multiapi/storagev2/blob/v2021_08_06/_deserialize.py
 azure/multiapi/storagev2/blob/v2021_08_06/_download.py
 azure/multiapi/storagev2/blob/v2021_08_06/_encryption.py
@@ -436,14 +365,88 @@
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_blob_service_client_async.py
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_container_client_async.py
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_download_async.py
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_lease_async.py
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_list_blobs_helper.py
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_models.py
 azure/multiapi/storagev2/blob/v2021_08_06/aio/_upload_helpers.py
+azure/multiapi/storagev2/blob/v2022_11_02/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_blob_client.py
+azure/multiapi/storagev2/blob/v2022_11_02/_blob_service_client.py
+azure/multiapi/storagev2/blob/v2022_11_02/_container_client.py
+azure/multiapi/storagev2/blob/v2022_11_02/_deserialize.py
+azure/multiapi/storagev2/blob/v2022_11_02/_download.py
+azure/multiapi/storagev2/blob/v2022_11_02/_encryption.py
+azure/multiapi/storagev2/blob/v2022_11_02/_lease.py
+azure/multiapi/storagev2/blob/v2022_11_02/_list_blobs_helper.py
+azure/multiapi/storagev2/blob/v2022_11_02/_models.py
+azure/multiapi/storagev2/blob/v2022_11_02/_quick_query_helper.py
+azure/multiapi/storagev2/blob/v2022_11_02/_serialize.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared_access_signature.py
+azure/multiapi/storagev2/blob/v2022_11_02/_upload_helpers.py
+azure/multiapi/storagev2/blob/v2022_11_02/_version.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/_azure_blob_storage.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/_configuration.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/_patch.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/_serialization.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/_vendor.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_azure_blob_storage.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_configuration.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/_patch.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_append_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_block_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_container_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_page_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_patch.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/aio/operations/_service_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_azure_blob_storage_enums.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_models_py3.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/models/_patch.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_append_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_block_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_container_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_page_blob_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_patch.py
+azure/multiapi/storagev2/blob/v2022_11_02/_generated/operations/_service_operations.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/authentication.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/base_client.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/base_client_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/constants.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/models.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/parser.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/policies.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/policies_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/request_handlers.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/response_handlers.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/shared_access_signature.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/uploads.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/uploads_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/avro_io.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/avro_io_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/datafile.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/datafile_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/_shared/avro/schema.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/__init__.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_blob_client_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_blob_service_client_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_container_client_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_download_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_lease_async.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_list_blobs_helper.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_models.py
+azure/multiapi/storagev2/blob/v2022_11_02/aio/_upload_helpers.py
 azure/multiapi/storagev2/filedatalake/__init__.py
 azure/multiapi/storagev2/filedatalake/v2019_07_07/__init__.py
 azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_directory_client.py
 azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_file_client.py
 azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_lease.py
 azure/multiapi/storagev2/filedatalake/v2019_07_07/_data_lake_service_client.py
 azure/multiapi/storagev2/filedatalake/v2019_07_07/_deserialize.py
```

### Comparing `azure-multiapi-storage-1.1.0/setup.py` & `azure-multiapi-storage-1.2.0/setup.py`

 * *Files 0% similar despite different names*

```diff
@@ -31,15 +31,15 @@
     except AttributeError:
         pass
 except ImportError:
     pass
 
 setup(
     name='azure-multiapi-storage',
-    version='1.1.0',
+    version='1.2.0',
     description='Microsoft Azure Storage Client Library for Python with multi API version support.',
     long_description=open('README.rst', 'r').read(),
     license='MIT',
     author='Microsoft Corporation',
     author_email='azpycli@microsoft.com',
     url='https://github.com/Azure/azure-multiapi-storage-python',
     classifiers=[
```

