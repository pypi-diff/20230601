# Comparing `tmp/optool-0.3.0-py3-none-any.whl.zip` & `tmp/optool-0.4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,39 +1,39 @@
-Zip file size: 50248 bytes, number of entries: 37
--rw-rw-rw-  2.0 unx        6 b- defN 23-May-26 08:49 optool/VERSION
--rw-r--r--  2.0 unx     5469 b- defN 23-May-26 08:49 optool/__init__.py
--rw-r--r--  2.0 unx      949 b- defN 23-May-26 08:49 optool/conversions.py
--rw-r--r--  2.0 unx     1094 b- defN 23-May-26 08:49 optool/languages.py
--rw-r--r--  2.0 unx     4095 b- defN 23-May-26 08:49 optool/logging.py
--rw-r--r--  2.0 unx     7758 b- defN 23-May-26 08:49 optool/math.py
--rw-r--r--  2.0 unx     1148 b- defN 23-May-26 08:49 optool/orthography.py
--rw-r--r--  2.0 unx     1814 b- defN 23-May-26 08:49 optool/parallel.py
--rw-rw-rw-  2.0 unx        0 b- defN 23-May-26 08:49 optool/py.typed
--rw-r--r--  2.0 unx    31001 b- defN 23-May-26 08:49 optool/uom.py
--rw-r--r--  2.0 unx      833 b- defN 23-May-26 08:49 optool/util.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-26 08:49 optool/fields/__init__.py
--rw-r--r--  2.0 unx     3914 b- defN 23-May-26 08:49 optool/fields/callables.py
--rw-r--r--  2.0 unx     4363 b- defN 23-May-26 08:49 optool/fields/containers.py
--rw-r--r--  2.0 unx     2122 b- defN 23-May-26 08:49 optool/fields/dataframe.py
--rw-r--r--  2.0 unx      829 b- defN 23-May-26 08:49 optool/fields/misc.py
--rw-r--r--  2.0 unx     6940 b- defN 23-May-26 08:49 optool/fields/numeric.py
--rw-r--r--  2.0 unx     5143 b- defN 23-May-26 08:49 optool/fields/quantities.py
--rw-r--r--  2.0 unx     6155 b- defN 23-May-26 08:49 optool/fields/series.py
--rw-r--r--  2.0 unx     2335 b- defN 23-May-26 08:49 optool/fields/symbolic.py
--rw-r--r--  2.0 unx     5848 b- defN 23-May-26 08:49 optool/fields/util.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-26 08:49 optool/optimization/__init__.py
--rw-r--r--  2.0 unx     4206 b- defN 23-May-26 08:49 optool/optimization/constraints.py
--rw-r--r--  2.0 unx     4535 b- defN 23-May-26 08:49 optool/optimization/helpers.py
--rw-r--r--  2.0 unx     8014 b- defN 23-May-26 08:49 optool/optimization/ode.py
--rw-r--r--  2.0 unx    21135 b- defN 23-May-26 08:49 optool/optimization/problem.py
--rw-r--r--  2.0 unx     7159 b- defN 23-May-26 08:49 optool/optimization/variables.py
--rw-r--r--  2.0 unx     2862 b- defN 23-May-26 08:49 optool/serialization/__init__.py
--rw-r--r--  2.0 unx     1317 b- defN 23-May-26 08:49 optool/serialization/datetime_objects.py
--rw-r--r--  2.0 unx      616 b- defN 23-May-26 08:49 optool/serialization/numpy_objects.py
--rw-r--r--  2.0 unx     2880 b- defN 23-May-26 08:49 optool/serialization/pandas_objects.py
--rw-r--r--  2.0 unx     1217 b- defN 23-May-26 08:49 optool/serialization/pint_objects.py
--rw-rw-rw-  2.0 unx     1081 b- defN 23-May-26 08:49 optool-0.3.0.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx     7771 b- defN 23-May-26 08:49 optool-0.3.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-26 08:49 optool-0.3.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 23-May-26 08:49 optool-0.3.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2989 b- defN 23-May-26 08:49 optool-0.3.0.dist-info/RECORD
-37 files, 157697 bytes uncompressed, 45508 bytes compressed:  71.1%
+Zip file size: 52251 bytes, number of entries: 37
+-rw-rw-rw-  2.0 unx        6 b- defN 23-Jun-01 12:43 optool/VERSION
+-rw-r--r--  2.0 unx     6712 b- defN 23-Jun-01 12:43 optool/__init__.py
+-rw-r--r--  2.0 unx      949 b- defN 23-Jun-01 12:43 optool/conversions.py
+-rw-r--r--  2.0 unx     1094 b- defN 23-Jun-01 12:43 optool/languages.py
+-rw-r--r--  2.0 unx     4095 b- defN 23-Jun-01 12:43 optool/logging.py
+-rw-r--r--  2.0 unx     7769 b- defN 23-Jun-01 12:43 optool/math.py
+-rw-r--r--  2.0 unx     1148 b- defN 23-Jun-01 12:43 optool/orthography.py
+-rw-r--r--  2.0 unx     1814 b- defN 23-Jun-01 12:43 optool/parallel.py
+-rw-rw-rw-  2.0 unx        0 b- defN 23-Jun-01 12:43 optool/py.typed
+-rw-r--r--  2.0 unx    32140 b- defN 23-Jun-01 12:43 optool/uom.py
+-rw-r--r--  2.0 unx      833 b- defN 23-Jun-01 12:43 optool/util.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-01 12:43 optool/fields/__init__.py
+-rw-r--r--  2.0 unx     4284 b- defN 23-Jun-01 12:43 optool/fields/callables.py
+-rw-r--r--  2.0 unx     4363 b- defN 23-Jun-01 12:43 optool/fields/containers.py
+-rw-r--r--  2.0 unx     2312 b- defN 23-Jun-01 12:43 optool/fields/dataframe.py
+-rw-r--r--  2.0 unx      829 b- defN 23-Jun-01 12:43 optool/fields/misc.py
+-rw-r--r--  2.0 unx     7737 b- defN 23-Jun-01 12:43 optool/fields/numeric.py
+-rw-r--r--  2.0 unx     5870 b- defN 23-Jun-01 12:43 optool/fields/quantities.py
+-rw-r--r--  2.0 unx     6249 b- defN 23-Jun-01 12:43 optool/fields/series.py
+-rw-r--r--  2.0 unx     2590 b- defN 23-Jun-01 12:43 optool/fields/symbolic.py
+-rw-r--r--  2.0 unx     8589 b- defN 23-Jun-01 12:43 optool/fields/util.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-01 12:43 optool/optimization/__init__.py
+-rw-r--r--  2.0 unx     4206 b- defN 23-Jun-01 12:43 optool/optimization/constraints.py
+-rw-r--r--  2.0 unx     4535 b- defN 23-Jun-01 12:43 optool/optimization/helpers.py
+-rw-r--r--  2.0 unx     8014 b- defN 23-Jun-01 12:43 optool/optimization/ode.py
+-rw-r--r--  2.0 unx    21144 b- defN 23-Jun-01 12:43 optool/optimization/problem.py
+-rw-r--r--  2.0 unx     7171 b- defN 23-Jun-01 12:43 optool/optimization/variables.py
+-rw-r--r--  2.0 unx     3091 b- defN 23-Jun-01 12:43 optool/serialization/__init__.py
+-rw-r--r--  2.0 unx     1317 b- defN 23-Jun-01 12:43 optool/serialization/datetime_objects.py
+-rw-r--r--  2.0 unx      686 b- defN 23-Jun-01 12:43 optool/serialization/numpy_objects.py
+-rw-r--r--  2.0 unx     2880 b- defN 23-Jun-01 12:43 optool/serialization/pandas_objects.py
+-rw-r--r--  2.0 unx     1453 b- defN 23-Jun-01 12:43 optool/serialization/pint_objects.py
+-rw-rw-rw-  2.0 unx     1081 b- defN 23-Jun-01 12:43 optool-0.4.0.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx     7568 b- defN 23-Jun-01 12:43 optool-0.4.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-01 12:43 optool-0.4.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 23-Jun-01 12:43 optool-0.4.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2989 b- defN 23-Jun-01 12:43 optool-0.4.0.dist-info/RECORD
+37 files, 165617 bytes uncompressed, 47511 bytes compressed:  71.3%
```

## zipnote {}

```diff
@@ -90,23 +90,23 @@
 
 Filename: optool/serialization/pandas_objects.py
 Comment: 
 
 Filename: optool/serialization/pint_objects.py
 Comment: 
 
-Filename: optool-0.3.0.dist-info/LICENSE.txt
+Filename: optool-0.4.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: optool-0.3.0.dist-info/METADATA
+Filename: optool-0.4.0.dist-info/METADATA
 Comment: 
 
-Filename: optool-0.3.0.dist-info/WHEEL
+Filename: optool-0.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: optool-0.3.0.dist-info/top_level.txt
+Filename: optool-0.4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: optool-0.3.0.dist-info/RECORD
+Filename: optool-0.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## optool/VERSION

```diff
@@ -1 +1 @@
-0.3.0
+0.4.0
```

## optool/__init__.py

```diff
@@ -35,17 +35,40 @@
 
 class ImplementationError(Exception):
     pass
 
 
 class BaseModel(pydantic.BaseModel):
     """
-    Change default behavior, see https://pydantic-docs.helpmanual.io/usage/model_config/#change-behaviour-globally.
+    Main base model used in this package.
+
+    Using this class as a superclass for all Pydantic models, their default behavior is adjusted in a very convenient
+    way. The default behavior is defined as follows:
+
+    - Model fields can be of arbitrary user types.
+    - The creation of new fields at runtime is forbidden.
+    - The validation on field assignment is enabled, not only on creation.
+    - All attributes starting with an underscore are private.
+    - Default values are also validated.
+    - Do not copy models on validation, simply keep them untouched.
+    - Allows to get the private field values as items of the `values` dictionary during validation.
+    - Customized JSON loader that can deserialize specified objects.
+    - Customized JSON encoder that can serialize specified objects.
+
+    Furthermore, comparing models for equality invokes a recursive comparison of the two dictionaries, which allows to
+    handle array-like elements.
+
+    See Also:
+        https://pydantic-docs.helpmanual.io/usage/model_config/#change-behaviour-globally.
     """
 
+    def __init_subclass__(cls, **kwargs):
+        super().__init_subclass__(**kwargs)
+        cls.__doc__ = ''  # Null out the representation docstring of every subclass
+
     # noinspection PyUnboundLocalVariable
     @no_type_check
     def __setattr__(self, name, value):
         offer_private_attrs: bool = getattr(self.__config__, 'offer_private_attrs_during_validation', False)
 
         if offer_private_attrs:
             private_values = {name: getattr(self, name) for name in self.__private_attributes__ if hasattr(self, name)}
@@ -142,9 +165,15 @@
         """
         Customized JSON encoder that can serialize specified objects.
         """
 
 
 validate_arguments = pydantic.validate_arguments(config=dict(arbitrary_types_allowed=True))
 """
-Decorator to validate the arguments passed to a function, but with 'arbitrary_types_allowed' set to True.
+Decorator to validate the arguments passed to a function.
+
+Returns:
+    :py:data:`~typing.Callable`:
+
+Note:
+    This is equal to :py:func:`pydantic.validate_arguments` but with ``arbitrary_types_allowed`` set to :py:data:`True`.
 """
```

## optool/math.py

```diff
@@ -94,25 +94,26 @@
         return isarray(value.magnitude)
     raise TypeError(f"Unsupported type {type(value)}")
 
 
 def isvector(value: Union[NUMERIC_TYPES, SYMBOLIC_TYPES],
              representation: Optional[VectorRepresentation] = None) -> bool:
     """
-    Return True if value is a (column or row) vector, and False otherwise.
+    Return :py:data:`True` if value is a (column or row) vector, and :py:data:`False` otherwise.
 
     Args:
-        value (Union[NUMERIC_TYPES, OPT_VARIABLE_TYPES]): The value to check
-        representation (VectorRepresentation): The representation of the vector
+        value: The value to check
+        representation: The representation of the vector
 
     Returns:
-        True if value has two dimensions and is either a row or a column vector, depending on the requested axis
+        :py:data:`True` if the value has two dimensions and is either a row or a column vector, depending on the
+        requested axis, or :py:data:`False` otherwise.
 
     See Also:
-        :py:meth:`iscolumn`, :py:meth:`isrow`, :py:class:`VectorRepresentation`
+        :py:func:`iscolumn`, :py:func:`isrow`, :py:class:`VectorRepresentation`
     """
     if not representation:
         return iscolumn(value) or isrow(value)
     return iscolumn(value) if representation is VectorRepresentation.COLUMN else isrow(value)
 
 
 def iscolumn(value: Union[NUMERIC_TYPES, SYMBOLIC_TYPES]) -> bool:
```

## optool/uom.py

```diff
@@ -1,22 +1,68 @@
 from typing import Optional
 
 import pint
 import pint_pandas
 
-UNITS = pint.get_application_registry()  # See for why this is a good idea https://stackoverflow.com/a/68089489
+UNITS = pint.get_application_registry()
+"""
+The application's :py:class:`pint.UnitRegistry`, retrieved via :py:func:`pint.get_application_registry`.
+
+See Also:
+    See https://stackoverflow.com/a/68089489 for why this is a good idea.
+"""
+
 UNITS.define('square_meter = meter**2 = m² = m2')
 UNITS.define('cubic_meter = meter**3 = m3')
 
 # Exchange rates as of May 10, 2022, 3:48 p.m., taken from https://finance.yahoo.com/currency-converter/
 UNITS.define('USD = [currency] = $ = usd')
 UNITS.define('CHF = USD / 0.9918 = _ = chf')
 UNITS.define('EUR = USD / 0.9484 = € = eur')
 
 Quantity = UNITS.Quantity  # Should use this registry, see https://github.com/hgrecco/pint/issues/1480
+"""Representation of a physical quantity with a value and associated unit."""
+Quantity.__doc__ = \
+    """
+    Representation of a physical quantity with a value and associated unit.
+
+    This class represents a physical quantity, consisting of a numerical value and an associated unit. It provides
+    functionality for performing mathematical operations and conversions between different units.
+
+    Note:
+        This class is a reference to :py:class:`pint.Quantity` that has :py:data:`.UNITS` as its
+        :py:class:`pint.UnitRegistry`.
+
+    Attributes:
+        magnitude: The numerical value of the quantity.
+        units: The unit associated with the quantity.
+
+    Examples::
+
+        # Creating a Quantity object:
+
+        >>> from optool.uom import Quantity, UNITS
+        >>> length = Quantity(5, UNITS.meter)
+        >>> print(length)
+        5 meter
+
+        # Performing arithmetic operations:
+
+        >>> width = Quantity(3, UNITS.meter)
+        >>> area = length * width
+        >>> print(area)
+        15 meter ** 2
+
+        # Converting between units:
+
+        >>> length = Quantity(1000, UNITS.millimeter)
+        >>> print(length.to(UNITS.meter))
+        1 meter
+    """
+
 pint_pandas.PintType.ureg = UNITS
 
 
 class PhysicalDimension:
     dimensionality: Optional[str] = None
 
 
@@ -175,16 +221,16 @@
     strict = False
     dimensionality = '[]'
 
 
 class ElectricalConductivity(PhysicalDimension):
     """
     A measure of a material's ability to conduct electric current. Electrical conductivity is also called specific
-    conductance and is the reciprocal of :py:class:`optool.fields.quantities.ElectricalResistivity`. In SI units, it
-    is usually measured in siemens per metre (S/m).
+    conductance and is the reciprocal of :py:class:`ElectricalResistivity`. In SI units, it is usually measured in
+    siemens per metre (S/m).
 
     See Also:
         `Wikipedia: Electrical resistivity and conductivity
         <https://en.wikipedia.org/wiki/Electrical_resistivity_and_conductivity>`_
     """
     strict = False
     dimensionality = '[conductance] / [length]'
@@ -227,16 +273,15 @@
     strict = False
     dimensionality = '[charge]'
 
 
 class ElectricConductance(PhysicalDimension):
     """
     A measure for the ease with which an electric current passes. Its reciprocal quantity is
-    :py:class:`optool.fields.quantities.ElectricalResistance`. The unit commonly used in the SI unit system is the
-    siemens (S).
+    :py:class:`ElectricalResistance`. The unit commonly used in the SI unit system is the siemens (S).
 
     See Also:
         `Wikipedia: Electrical resistance and conductance
         <https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance>`_
     """
     strict = False
     dimensionality = '[conductance]'
@@ -290,16 +335,15 @@
     strict = False
     dimensionality = '[electric_potential]'
 
 
 class ElectricResistance(PhysicalDimension):
     """
     A measure for the ease with which an electric current passes. Its reciprocal quantity is
-    :py:class:`optool.fields.quantities.ElectricConductance`. The unit commonly used in the SI unit system is the
-    ohm (Ω).
+    :py:class:`ElectricConductance`. The unit commonly used in the SI unit system is the ohm (Ω).
 
     See Also:
         `Wikipedia: Electrical resistance and conductance
         <https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance>`_
     """
     strict = False
     dimensionality = '[resistance]'
@@ -328,16 +372,16 @@
     """
     strict = False
     dimensionality = '[entropy]'
 
 
 class Fluidity(PhysicalDimension):
     """
-    The reciprocal of :py:class:`optool.fields.quantities.Viscosity`. In SI units, it is usually reciprocal poise
-    (1/P), sometimes called the rhe.
+    The reciprocal of :py:class:`Viscosity`. In SI units, it is usually reciprocal poise (1/P), sometimes called the
+    `rhe`.
 
     See Also:
         `Wikipedia: Fluidity <https://en.wikipedia.org/wiki/Fluidity>`_
     """
     strict = False
     dimensionality = '[fluidity]'
 
@@ -440,15 +484,15 @@
 
 class KinematicViscosity(PhysicalDimension):
     """
     A measure of a fluid's resistance to flow. It is defined as the ratio of the dynamic viscosity of a fluid to its
     density. In SI units, it is usually measured in square meters per second (m^2/s).
 
     See Also:
-        `Wikipedia: Viscosity <https://en.wikipedia.org/wiki/Viscosity#Kinematic_viscosity>`_
+        `Wikipedia: Kinematic Viscosity <https://en.wikipedia.org/wiki/Viscosity#Kinematic_viscosity>`_
     """
     strict = False
     dimensionality = '[kinematic_viscosity]'
 
 
 class Length(PhysicalDimension):
     """
@@ -500,15 +544,15 @@
 
 
 class MagneticFieldStrength(PhysicalDimension):
     """
     A measure of the intensity of a magnetic field. In SI units, it is usually measured in amperes per meter (A/m).
 
     See Also:
-        `Wikipedia: Magnetic field <https://en.wikipedia.org/wiki/Magnetic_field#The_H-field>`_
+        `Wikipedia: Magnetic field - The H-field <https://en.wikipedia.org/wiki/Magnetic_field#The_H-field>`_
     """
     strict = False
     dimensionality = '[magnetic_field_strength]'
 
 
 class MagneticFlux(PhysicalDimension):
     """
@@ -525,15 +569,15 @@
 class MagneticFluxDensity(PhysicalDimension):
     """
     A measure of the actual magnetic field within a material considered as a concentration of magnetic field lines,
     or flux, per unit cross-sectional area. It is also called the magnitude of the magnetic field. The unit commonly
     used in the SI unit system is the tesla (T).
 
     See Also:
-        `Wikipedia: Magnetic field <https://en.wikipedia.org/wiki/Magnetic_field#The_B-field>`_
+        `Wikipedia: Magnetic field - The B-field <https://en.wikipedia.org/wiki/Magnetic_field#The_B-field>`_
     """
     strict = False
     dimensionality = '[magnetic_field]'
 
 
 class MagneticPermeability(PhysicalDimension):
     """
@@ -728,17 +772,16 @@
     strict = False
     dimensionality = '[energy] / [mass] / [temperature]'
 
 
 class Speed(PhysicalDimension):
     """
     The magnitude of the change of an object's position over time or the magnitude of the change of the object's
-    position per unit of time. Speed is not the same as :py:class:`optool.fields.quantities.Velocity`, which is a
-    vector quantity that has both magnitude and direction. In SI units, it is usually measured in meters per second
-    (m/s).
+    position per unit of time. Speed is not the same as :py:class:`Velocity`, which is a vector quantity that has both
+    magnitude and direction. In SI units, it is usually measured in meters per second (m/s).
 
     See Also:
         `Wikipedia: Speed <https://en.wikipedia.org/wiki/Speed>`_
     """
     strict = False
     dimensionality = '[speed]'
 
@@ -805,17 +848,16 @@
     """
     strict = False
     dimensionality = '[temperature] / [power]'
 
 
 class ThermalResistivity(PhysicalDimension):
     """
-    The reciprocal of :py:class:`optool.fields.quantities.ThermalConductivity`. It is a measure of a material's
-    ability to resists the conductive flow of heat. TIn SI units, it is usually measured in kelvin-meters per watt
-    (m·K)/W).
+    The reciprocal of :py:class:`ThermalConductivity`. It is a measure of a material's ability to resists the conductive
+    flow of heat. TIn SI units, it is usually measured in kelvin-meters per watt (m·K)/W).
 
     See Also:
         `Wikipedia: Thermal conductivity <https://en.wikipedia.org/wiki/Thermal_conductivity>`_
     """
     strict = False
     dimensionality = '[length] * [temperature] / [power]'
 
@@ -842,31 +884,29 @@
     """
     strict = False
     dimensionality = '[time]'
 
 
 class Torque(PhysicalDimension):
     """
-    The rotational equivalent of linear :py:class:`optool.fields.quantities.Force`. In SI units, it is usually
-    measured in newton-meters (N·m).
+    The rotational equivalent of linear :py:class:`Force`. In SI units, it is usually measured in newton-meters (N·m).
 
     See Also:
         `Wikipedia: Torque <https://en.wikipedia.org/wiki/Torque>`_
     """
     strict = False
     dimensionality = '[torque]'
 
 
 class Velocity(PhysicalDimension):
     """
     The directional speed of an object in motion as an indication of its rate of change in position as observed from
     a particular frame of reference and as measured by a particular standard of time. It is a physical vector
     quantity. Hence, both magnitude and direction are needed to define it. The scalar absolute value (magnitude) of
-    velocity is :py:class:`optool.fields.quantities.Speed`. In SI units, it is usually measured in meters per second
-    (m/s).
+    velocity is :py:class:`Speed`. In SI units, it is usually measured in meters per second (m/s).
 
     See Also:
         `Wikipedia: Velocity <https://en.wikipedia.org/wiki/Velocity>`_
     """
     strict = False
     dimensionality = '[velocity]'
```

## optool/fields/callables.py

```diff
@@ -1,13 +1,15 @@
 from __future__ import annotations
 
 import inspect
 from typing import Any, Callable, Optional, Type, Union
 
-from optool.fields.util import check_only_one_specified, get_type_validator
+from pydantic.fields import ModelField
+
+from optool.fields.util import check_only_one_specified, get_type_validator, update_object_schema
 
 
 class CallableParameterError(ValueError):
 
     def __init__(self, *, spec: str, expected: Any, value: inspect.FullArgSpec) -> None:
         super().__init__(f"expected the {spec} {expected}, but got a value with argument specification {value}")
 
@@ -36,14 +38,21 @@
     def __get_validators__(cls):
         yield get_type_validator(Callable)
         yield cls.validate_number_of_parameters
         yield cls.validate_parameter_types
         yield cls.validate_return_type
 
     @classmethod
+    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
+        update_object_schema(field_schema,
+                             num_params=cls.num_params,
+                             param_types=cls.param_types,
+                             return_type=cls.return_type)
+
+    @classmethod
     def validate_number_of_parameters(cls, val: Callable) -> Callable:
         if cls.num_params is None:
             return val
 
         arg_spec = cls._check_can_verify_params("number of parameters", cls.num_params, val)
         if len(arg_spec.args) == cls.num_params:
             return val
```

## optool/fields/dataframe.py

```diff
@@ -1,23 +1,23 @@
-from typing import TYPE_CHECKING, Any, Type
+from typing import TYPE_CHECKING, Any, Optional, Type
 
 import pandas as pd
 from pandas import DatetimeIndex, Index, TimedeltaIndex
 from pydantic.fields import ModelField
 
-from optool.fields.util import get_type_validator
+from optool.fields.util import get_type_validator, update_object_schema
 
 
 class IndexTypeError(ValueError):
 
     def __init__(self, *, expected: Type[Index], value: pd.DataFrame) -> None:
         super().__init__(f"expected index type {expected}, but got a DataFrame with index type {type(value.index)}")
 
 
-class ConstrainedDataFrame(pd.DataFrame):
+class ConstrainedDataFrame:
     """
     Pydantic-compatible field type for :py:class:`pandas.DataFrame` objects, which allows to specify the index type.
 
     See Also:
         `Pydantic documentation: Custom Data Types <https://docs.pydantic.dev/usage/types/#custom-data-types>`_ and
         class :py:class:`pydantic.types.ConstrainedInt` or similar of :py:mod:`pydantic`
     """
@@ -27,14 +27,18 @@
 
     @classmethod
     def __get_validators__(cls):
         yield get_type_validator(pd.DataFrame) if cls.strict else cls.validate_dataframe
         yield cls.validate_index_type
 
     @classmethod
+    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
+        update_object_schema(field_schema, index_type=cls.index_type.__name__)
+
+    @classmethod
     def validate_dataframe(cls, val: Any, field: ModelField) -> pd.DataFrame:
         if isinstance(val, pd.DataFrame):
             return val
         if field.sub_fields:
             raise TypeError(f"A constrained DataFrame cannot by typed, but have sub-fields {field.sub_fields}")
 
         return pd.DataFrame(val)
```

## optool/fields/numeric.py

```diff
@@ -1,17 +1,19 @@
 from __future__ import annotations
 
 import itertools
 import numbers
-from typing import TYPE_CHECKING, Any, Generic, Iterable, Optional, Type, TypeVar, Union
+from typing import TYPE_CHECKING, Any, ClassVar, Generic, Iterable, Optional, Type, TypeVar, Union
 
 import numpy as np
+import pydantic
 from pydantic.fields import ModelField
 
-from optool.fields.util import WrongTypeError, check_only_one_specified, check_sub_fields_level, get_type_validator
+from optool.fields.util import (WrongTypeError, check_only_one_specified, check_sub_fields_level, get_subtype_validator,
+                                get_type_validator, update_object_schema)
 
 
 class ShapeError(ValueError):
 
     def __init__(self, *, expected: tuple[int, ...], value: np.ndarray) -> None:
         super().__init__(f"expected the shape {expected}, but got a value with shape {value.shape}")
 
@@ -25,47 +27,55 @@
 class ArrayWriteableError(ValueError):
 
     def __init__(self, *, expected: bool, value: np.ndarray) -> None:
         super().__init__(f"expected writeable is {expected}, "
                          f"but got a value with writeable flag set to {value.flags.writeable}")
 
 
-T = TypeVar("T", bound=np.generic)
+T = TypeVar("T", bound=np.generic)  # Allow storing everything in ndarray
 
 
-class ConstrainedNdArray(Generic[T], np.ndarray[Any, np.dtype[T]]):
+# Due to the generic class, Pydantic has to be tricked out such that the automatic creation of schemas is working.
+class ConstrainedNdArray(pydantic.BaseModel, Generic[T]):
     """
     Pydantic-compatible field type for :py:class:`numpy.ndarray` objects, which allows to specify the data-type.
 
     The approach is inspired by https://github.com/cheind/pydantic-numpy.
 
     See Also:
         `Pydantic documentation: Custom Data Types <https://docs.pydantic.dev/usage/types/#custom-data-types>`_ and
         class :py:class:`pydantic.types.ConstrainedInt` or similar of :py:mod:`pydantic`
     """
 
-    strict: bool = True
-    dimensions: Optional[int] = None
-    shape_spec: Optional[tuple[int, ...]] = None
-    writeable: bool = True
+    strict: ClassVar[bool] = True
+    strict_subtypes: ClassVar[bool] = True
+    dimensions: ClassVar[Optional[int]] = None
+    shape_spec: ClassVar[Optional[tuple[int, ...]]] = None
+    writeable: ClassVar[bool] = True
 
     @classmethod
     def __get_validators__(cls):
-        yield get_type_validator(np.ndarray, lambda x: x.dtype) if cls.strict else cls.validate_ndarray
+        if cls.strict:
+            yield get_type_validator(np.ndarray)
+        if cls.strict_subtypes:
+            yield get_subtype_validator(np.ndarray, lambda x: x.dtype)
+
+        if not cls.strict:
+            yield cls.validate_ndarray
         yield cls.validate_dimensions
         yield cls.validate_shape
         yield cls.validate_writeable
 
     @classmethod
-    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
-        if field and field.sub_fields:
-            type_with_potential_subtype = f"np.ndarray[{field.sub_fields[0]}]"
-        else:
-            type_with_potential_subtype = "np.ndarray"
-        field_schema.update({"type": type_with_potential_subtype})
+    def __modify_schema__(cls, field_schema: dict[str, Any], field: Optional[ModelField]):
+        update_object_schema(field_schema,
+                             dimensions=cls.dimensions,
+                             shape_spec=cls.shape_spec,
+                             writeable=cls.writeable,
+                             datatype=field.sub_fields[0].type_.__name__ if field and field.sub_fields else None)
 
     @classmethod
     def validate_ndarray(cls, val: Any, field: ModelField) -> np.ndarray:
         if not isinstance(val, Iterable):
             val = [val]  # otherwise, np.asarray returns something weird
 
         if field.sub_fields is not None:
@@ -112,15 +122,16 @@
                shape: Optional[tuple[int, ...]] = None,
                writeable: bool = True) -> Type[np.ndarray]:
     """
     Creates a Pydantic-compatible field type for :py:class:`numpy.ndarray` objects, which allows specifying constraints
     on the accepted values.
 
     Args:
-        strict: If ``True`` only values of type :py:class:`numpy.ndarray` are accepted. (Default: ``False``)
+        strict: If :py:data:`True` only values of type :py:class:`numpy.ndarray` are accepted. (Default:
+            :py:data:`False`)
         dimensions: The expected dimensions as in :py:func:`numpy.ndim`.
         shape: The shape expected. One shape dimension can be ``-1`` indicating that this dimension is arbitrary.
         writeable: Boolean flag indicating whether the :py:class:`numpy.ndarray` object is mutable or not.
 
     Returns:
         A new Pydantic-compatible field type.
 
@@ -130,60 +141,67 @@
     check_only_one_specified(dimensions, shape, "Cannot specify both dimensions and shape.")
     namespace = dict(strict=strict, dimensions=dimensions, shape_spec=shape, writeable=writeable)
     return type('ConstrainedNdArrayValue', (ConstrainedNdArray,), namespace)  # type: ignore
 
 
 if TYPE_CHECKING:
 
-    NdArrayLike = Type[Union[np.ndarray[Any, np.dtype[T]], numbers.Number, Iterable]]
-    Array = Type[Union[np.ndarray[Any, np.dtype[T]], numbers.Number, Iterable]]
-    ImmutableArray = Type[Union[np.ndarray[Any, np.dtype[T]], numbers.Number, Iterable]]
+    NdArrayLike = Union[np.ndarray[Any, np.dtype[T]], numbers.Number, Iterable]
+    Array = Union[np.ndarray[Any, np.dtype[T]], numbers.Number, Iterable]
+    ImmutableArray = Union[np.ndarray[Any, np.dtype[T]], numbers.Number, Iterable]
 
     StrictNdArray = np.ndarray[Any, np.dtype[T]]
     Row = np.ndarray[Any, np.dtype[T]]
     Column = np.ndarray[Any, np.dtype[T]]
     Matrix = np.ndarray[Any, np.dtype[T]]
 
 else:
 
     class NdArrayLike(ConstrainedNdArray[T]):
         strict = False
+        strict_subtypes = False
 
     class Array(ConstrainedNdArray[T]):
         """
         Pydantic-compatible field type for one-dimensional :py:class:`numpy.ndarray` objects.
         """
         strict = False
+        strict_subtypes = False
         dimensions = 1
 
     class ImmutableArray(Array[T]):
         """
         Pydantic-compatible field type for one-dimensional :py:class:`numpy.ndarray` objects, where the flag
-        ``writeable`` is set to False.
+        ``writeable`` is set to :py:data:`False`.
         """
         strict = False
+        strict_subtypes = False
         writeable = False
 
     class StrictNdArray(ConstrainedNdArray[T]):
         strict = True
+        strict_subtypes = True
 
     class Row(ConstrainedNdArray[T]):
         """
         Pydantic-compatible field type for two-dimensional :py:class:`numpy.ndarray` objects representing row vectors.
         """
         strict = True
+        strict_subtypes = False
         shape_spec = (1, -1)
 
     class Column(ConstrainedNdArray[T]):
         """
         Pydantic-compatible field type for two-dimensional :py:class:`numpy.ndarray` objects representing column
         vectors.
         """
         strict = True
+        strict_subtypes = False
         shape_spec = (-1, 1)
 
     class Matrix(ConstrainedNdArray[T]):
         """
         Pydantic-compatible field type for two-dimensional :py:class:`numpy.ndarray` objects representing matrices.
         """
         strict = True
+        strict_subtypes = False
         dimensions = 2
```

## optool/fields/quantities.py

```diff
@@ -1,23 +1,25 @@
 from __future__ import annotations
 
 from numbers import Number
-from typing import TYPE_CHECKING, Any, Generic, TypeVar
+from typing import TYPE_CHECKING, Any, ClassVar, Generic, Optional, TypeVar, Union
 
+import pydantic
 from pint import Unit
 from pydantic import ValidationError
 from pydantic.fields import ModelField
 
-from optool.fields.util import WrongTypeError, check_validation_is_passed_on_to_sub_types, get_type_validator
+from optool.fields.util import (WrongTypeError, check_validation_is_passed_on_to_sub_types, get_dimension,
+                                get_subfield_schema, get_subtype_validator, get_type_validator, update_object_schema)
 from optool.uom import UNITS, PhysicalDimension, Quantity
 
 
 class DimensionalityError(ValueError):
 
-    def __init__(self, *, expected: str, value: Quantity) -> None:
+    def __init__(self, *, expected: Optional[str], value: Quantity) -> None:
         super().__init__(f"expected the dimensionality {expected}, "
                          f"but got a value with dimensionality {value.dimensionality}")
 
 
 class UnsupportedMagnitudeConversion(ValueError):
 
     def __init__(self, *, value: Any) -> None:
@@ -29,96 +31,105 @@
     def __init__(self, *, unit: str) -> None:
         super().__init__(f"cannot parse the unit {unit}")
 
 
 D = TypeVar("D", bound=PhysicalDimension)
 
 
-class ConstrainedUnit(Unit, Generic[D]):
+# Due to the generic class, Pydantic has to be tricked out such that the automatic creation of schemas is working.
+class ConstrainedUnit(pydantic.BaseModel, Generic[D]):
     """
     Pydantic-compatible field type for :py:class:`pint.Unit` objects, which allows to specify the desired
     dimensionality.
 
     See Also:
         `Pydantic documentation: Custom Data Types <https://docs.pydantic.dev/usage/types/#custom-data-types>`_ and
         class :py:class:`pydantic.types.ConstrainedInt` or similar of :py:mod:`pydantic`
     """
-    strict: bool = True
+    strict: ClassVar[bool] = True
 
     @classmethod
     def __get_validators__(cls):
         yield get_type_validator(Unit) if cls.strict else cls.validate_unit
         yield cls.validate_dimensionality
 
     @classmethod
+    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
+        dimension = get_dimension(field, 0)
+        update_object_schema(field_schema, dimensionality=dimension.dimensionality if dimension else None)
+
+    @classmethod
     def validate_unit(cls, value: Any, field: ModelField) -> Unit:
         if isinstance(value, Unit):
             return value
 
         if isinstance(value, str):
             try:
                 return UNITS.parse_units(value)
             except Exception as e:
                 raise UnitParseError(unit=value) from e
 
         raise WrongTypeError(expected=(Unit, str), value=value)
 
     @classmethod
     def validate_dimensionality(cls, val: Unit, field: ModelField) -> Unit:
-        if not field.sub_fields or field.sub_fields[0].type_ == Any:
+        dimension = get_dimension(field, 0)
+        if dimension is None or val.dimensionality == UNITS.get_dimensionality(dimension.dimensionality):
             return val
+        raise DimensionalityError(expected=dimension.dimensionality, value=val)
 
-        dimension = field.sub_fields[0].type_
-        if not issubclass(dimension, PhysicalDimension):
-            raise TypeError(f"Unsupported {dimension}, should be a {PhysicalDimension.__name__!r} or 'typing.Any'.")
-        elif val.dimensionality != UNITS.get_dimensionality(dimension.dimensionality):
-            raise DimensionalityError(expected=dimension.dimensionality, value=val)
-        return val
 
+T = TypeVar("T")  # Allow storing everything as magnitude in Quantity
 
-T = TypeVar("T")  # Allow storing anything as magnitude in Quantity
 
-
-class ConstrainedQuantity(Quantity, Generic[D, T]):
+# Due to the generic class, Pydantic has to be tricked out such that the automatic creation of schemas is working.
+class ConstrainedQuantity(pydantic.BaseModel, Generic[D, T]):
     """
-    Pydantic-compatible field type for :py:class:`pint.Quantity` objects, which allows to specify the desired
+    Pydantic-compatible field type for :py:class:`optool.uom.Quantity` objects, which allows to specify the desired
     dimensionality.
 
     See Also:
         Class :py:class:`pydantic.types.ConstrainedInt` or similar of :py:mod:`pydantic`.
     """
 
-    strict: bool = True
-    strict_subtypes: bool = True
+    strict: ClassVar[bool] = True
+    strict_subtypes: ClassVar[bool] = True
 
     @classmethod
     def __get_validators__(cls):
-        subtype_provider = (lambda x: type(x.m)) if cls.strict_subtypes else None
-        yield get_type_validator(Quantity, subtype_provider) if cls.strict else cls.validate_quantity
+        if cls.strict:
+            yield get_type_validator(Quantity)
+        if cls.strict_subtypes:
+            yield get_subtype_validator(Quantity, lambda x: type(x.m))
+
+        if not cls.strict:
+            yield cls.validate_quantity
         yield cls.validate_dimensionality
         yield cls.validate_magnitude
 
     @classmethod
+    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
+        dimension = get_dimension(field, 0)
+        update_object_schema(field_schema,
+                             dimensionality=dimension.dimensionality if dimension else None,
+                             datatype=get_subfield_schema(field, 1))
+
+    @classmethod
     def validate_quantity(cls, val: Any, field: ModelField) -> Quantity:
         try:
             return Quantity(val)
         except Exception as e:
             raise WrongTypeError(expected=(Quantity, str, Number), value=val) from e
 
     @classmethod
     def validate_dimensionality(cls, val: Quantity, field: ModelField) -> Quantity:
-        if not field.sub_fields or field.sub_fields[0].type_ == Any:
+        dimension = get_dimension(field, 0)
+        if dimension is None or val.dimensionality == UNITS.get_dimensionality(dimension.dimensionality):
             return val
-
-        dimension = field.sub_fields[0].type_
-        if not issubclass(dimension, PhysicalDimension):
-            raise TypeError(f"Unsupported {dimension}, should be a {PhysicalDimension.__name__!r} or 'typing.Any'.")
-        elif not val.check(dimension.dimensionality):
-            raise DimensionalityError(expected=dimension.dimensionality, value=val)
-        return val
+        raise DimensionalityError(expected=dimension.dimensionality, value=val)
 
     @classmethod
     def validate_magnitude(cls, val: Quantity, field: ModelField) -> Quantity:
         if not field.sub_fields:
             return val
 
         magnitude_field = field.sub_fields[1]
@@ -127,28 +138,28 @@
         if error:
             raise ValidationError([error], cls)
 
         return Quantity(valid_value, val.u)
 
 
 if TYPE_CHECKING:
-    UnitLike = Unit
-    StrictUnit = Unit
+    UnitLike = Union[Unit, str, ConstrainedUnit[D]]
+    StrictUnit = Union[Unit, ConstrainedUnit[D]]
 
     QuantityLike = Quantity
     StrictQuantity = Quantity
 
 else:
 
-    class UnitLike(ConstrainedUnit[D]):
+    class UnitLike(ConstrainedUnit[D], Unit):
         strict = False
 
-    class StrictUnit(ConstrainedUnit[D]):
+    class StrictUnit(ConstrainedUnit[D], Unit):
         strict = True
 
-    class QuantityLike(ConstrainedQuantity[D, T]):
+    class QuantityLike(ConstrainedQuantity[D, T], Quantity):
         strict = False
         strict_subtypes = False
 
-    class StrictQuantity(ConstrainedQuantity[D, T]):
+    class StrictQuantity(ConstrainedQuantity[D, T], Quantity):
         strict = True
         strict_subtypes = False
```

## optool/fields/series.py

```diff
@@ -1,20 +1,22 @@
 from __future__ import annotations
 
 from numbers import Number
-from typing import TYPE_CHECKING, Any, Generic, Iterable, Sequence, Type, TypeVar, cast
+from typing import TYPE_CHECKING, Any, ClassVar, Generic, Iterable, Optional, Sequence, Type, TypeVar, cast
 
 import numpy as np
 import pandas as pd
+import pydantic
 from pandas import DatetimeIndex, Index, TimedeltaIndex
 from pint_pandas import PintArray
 from pydantic import ValidationError
 from pydantic.fields import ModelField
 
-from optool.fields.util import WrongTypeError, check_sub_fields_level, get_type_validator
+from optool.fields.util import (WrongTypeError, check_sub_fields_level, get_subfield_schema, get_type_validator,
+                                update_object_schema)
 from optool.uom import PhysicalDimension, Quantity
 
 
 class IndexTypeError(ValueError):
 
     def __init__(self, *, expected: Type[Index], value: pd.Series) -> None:
         super().__init__(f"expected index type {expected}, but got a series with index type {type(value.index)}")
@@ -29,36 +31,39 @@
 class ArrayWriteableError(ValueError):
 
     def __init__(self, *, expected: bool, value: np.ndarray) -> None:
         super().__init__(f"expected writeable is {expected}, "
                          f"but got a value with writeable flag set to {value.flags.writeable}")
 
 
-T = TypeVar("T")  # Allow storing anything as data-type in Series
+T = TypeVar("T")  # Allow storing everything as data-type in Series
 
 
-class ConstrainedSeries(pd.Series, Generic[T]):
+class ConstrainedSeries(pydantic.BaseModel, Generic[T]):
     """
     Pydantic-compatible field type for :py:class:`pandas.Series` objects, which allows to specify the data-type.
 
     See Also:
         `Pydantic documentation: Custom Data Types <https://docs.pydantic.dev/usage/types/#custom-data-types>`_ and
         class :py:class:`pydantic.types.ConstrainedInt` or similar of :py:mod:`pydantic`
     """
 
-    strict: bool = True
-    index_type: Type[Index] = pd.RangeIndex
+    strict: ClassVar[bool] = True
+    index_type: ClassVar[Type[Index]] = pd.RangeIndex
 
     @classmethod
     def __get_validators__(cls):
         yield get_type_validator(pd.Series) if cls.strict else cls.validate_series
         yield cls.validate_index_type
         yield cls.validate_dimensionality
         yield cls.validate_data_type
-        # yield cls.validate_writeable
+
+    @classmethod
+    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
+        update_object_schema(field_schema, index_type=cls.index_type.__name__, datatype=get_subfield_schema(field, 0))
 
     @classmethod
     def validate_series(cls, val: Any, field: ModelField) -> pd.Series:
         if isinstance(val, pd.Series):
             return val
         if not field.sub_fields:
             return pd.Series(val)
@@ -130,20 +135,14 @@
         data_type = field.sub_fields[0].type_
         if val.dtype == data_type:
             return val
 
         raise WrongTypeError(expected=data_type, value=val.dtype)
 
     @classmethod
-    def validate_writeable(cls, val: np.ndarray) -> np.ndarray:
-        if val.flags.writeable == cls.writeable:
-            return val
-        raise ArrayWriteableError(expected=cls.writeable, value=val)
-
-    @classmethod
     def _make_iterable_quantity(cls, val: Any):
         if isinstance(val, Quantity) and not isinstance(val.magnitude, Iterable):
             val = Quantity([val.m], val.u)
         return val
 
     @classmethod
     def _is_physical_dimension(cls, field: ModelField) -> bool:
```

## optool/fields/symbolic.py

```diff
@@ -1,16 +1,16 @@
 from __future__ import annotations
 
 import itertools
 from typing import TYPE_CHECKING, Optional
 
 import casadi
-import numpy as np
+from pydantic.fields import ModelField
 
-from optool.fields.util import get_type_validator
+from optool.fields.util import get_type_validator, update_object_schema
 
 
 class ShapeError(ValueError):
 
     def __init__(self, *, expected: tuple[int, ...], value: casadi.SX) -> None:
         super().__init__(f"expected the shape {expected}, "
                          f"but got a value with shape ('called size' in CasADi) {value.size()}")
@@ -29,27 +29,34 @@
 
     @classmethod
     def __get_validators__(cls):
         yield get_type_validator(casadi.SX)
         yield cls.validate_shape
 
     @classmethod
-    def validate_shape(cls, val: casadi.SX) -> np.ndarray:
+    def __modify_schema__(cls, field_schema, field: Optional[ModelField]):
+        update_object_schema(field_schema, shape=cls.shape)
+
+    @classmethod
+    def validate_shape(cls, val: casadi.SX, field: ModelField) -> casadi.SX:
         if cls.shape is None or all(cls._compare_dim(*dims) for dims in itertools.zip_longest(cls.shape, val.size())):
             return val
         raise ShapeError(expected=cls.shape, value=val)
 
     @classmethod
     def _compare_dim(cls, expected: Optional[int], actual: Optional[int]) -> bool:
         return actual == expected or expected == -1
 
 
 if TYPE_CHECKING:
 
-    CasadiScalar = CasadiRow = CasadiColumn = CasadiMatrix = casadi.SX
+    CasadiScalar = casadi.SX
+    CasadiRow = casadi.SX
+    CasadiColumn = casadi.SX
+    CasadiMatrix = casadi.SX
 
 else:
 
     class CasadiScalar(ConstrainedCasadiSymbol):
         """
         Pydantic-compatible field type for two-dimensional :py:class:`casadi.SX` objects representing scalars.
         """
```

## optool/fields/util.py

```diff
@@ -1,16 +1,19 @@
 from __future__ import annotations
 
 import re
-from typing import Any, Callable, Iterable, Optional, Type, TypeVar, Union
+from typing import Any, Callable, Dict, Iterable, Optional, Type, TypeVar, Union
 
+import numpy as np
+import pydantic
 from pydantic.fields import ModelField
 from pydantic.validators import find_validators
 
 from optool import BaseModel
+from optool.uom import PhysicalDimension
 
 TypeDefinition = Union[type, tuple[type, ...]]
 ValidationFunc = Callable[[Any], Any]
 
 T = TypeVar("T")
 
 
@@ -21,15 +24,15 @@
 
 
 class WrongSubTypeError(ValueError):
 
     def __init__(self, *, expected_type: TypeDefinition, expected_subtype: TypeDefinition,
                  actual_subtype: TypeDefinition, value: Any) -> None:
         super().__init__(f"expected sub-type {expected_subtype} of {expected_type}, "
-                         f"but got {actual_subtype} of {type(value)}")
+                         f"but got sub-type {actual_subtype} of {type(value)}")
 
 
 class ArbitrarySubTypeError(ValueError):
 
     def __init__(self, *, name: str, field: ModelField) -> None:
         sub_type = None if field.sub_fields is None else field.sub_fields[0].type_
         super().__init__(f"the sub-field of {name!r} has the type {field.type_} (with sub-type {sub_type}), "
@@ -40,21 +43,22 @@
 class _ConfigWithArbitraryTypesNotAllowed(BaseModel.Config):
     arbitrary_types_allowed = False
 
 
 def has_specific_type_validator(type_: Type[Any]) -> bool:
     """
     Determines if the type specified has one or more validators that are more specific than just the
-    ``arbitrary_type_validator`` that is used when ``arbitrary_types_allowed`` of Config is set to True.
+    `arbitrary_type_validator` that is used when `arbitrary_types_allowed` of Config is set to :py:data:`True`.
 
     Args:
-        type_: The type to analyze
+        type_: The type to analyze.
 
     Returns:
-        True if the type specified has a validator that is different from the arbitrary_type_validator, False otherwise.
+        :py:data:`True` if the type specified has a validator that is different from the `arbitrary_type_validator`,
+        :py:data:`False` otherwise.
     """
 
     try:
         next(find_validators(type_, _ConfigWithArbitraryTypesNotAllowed))
         return True
     except Exception as e:
         if re.match("no validator found for <.*?>, see `arbitrary_types_allowed` in Config", str(e)):
@@ -75,53 +79,126 @@
     if field.sub_fields is None:
         return
     if field.sub_fields[0].sub_fields:
         raise ValueError(f"Generic types more than one level deep are currently not supported. "
                          f"Got {field.sub_fields[0].type_} and {field.sub_fields[0].sub_fields[0].type_}.")
 
 
-def get_type_validator(expected: Type[T],
-                       subtype_provider: Optional[Callable[[T], type]] = None) -> Callable[[Any, ModelField], T]:
+def get_type_validator(expected_type: Type[T]) -> Callable[[Any], T]:
     """
     Creates a validation function that checks if the input argument is of the expected type.
 
     Args:
-        expected: The type the resulting validator will enforce.
-        subtype_provider: Callable to get the subtype of the provided value.
+        expected_type: The type the resulting validator will enforce.
 
     Returns:
         A new function that can be used to validate if an input value is an instance of the type specified.
     """
 
-    def validate_type(value: Any, field: ModelField) -> T:
-        if not isinstance(value, expected):
-            raise WrongTypeError(expected=expected, value=value)
+    def validate_type(value: Any) -> T:
+        if isinstance(value, expected_type):
+            return value
+        raise WrongTypeError(expected=expected_type, value=value)
+
+    return validate_type
+
+
+def get_subtype_validator(object_type: Type[T], subtype_provider: Callable[[T],
+                                                                           Type]) -> Callable[[Any, ModelField], T]:
+    """
+    Creates a validation function that checks if the subtype of the input argument is of the expected type.
+
+    Args:
+        object_type: The type the resulting validator will enforce.
+        subtype_provider: Callable to get the subtype of the provided value.
+
+    Returns:
+        A new function that can be used to validate if an input value is an instance of the type specified.
+    """
 
-        if field.sub_fields is not None and subtype_provider is not None:
+    def validate_subtype(value: Any, field: ModelField) -> T:
+        if field.sub_fields:
             expected_subtype = field.sub_fields[0].type_
             actual_subtype = subtype_provider(value)
             if expected_subtype != actual_subtype:
-                raise WrongSubTypeError(expected_type=expected,
+                if isinstance(actual_subtype, np.dtype):
+                    actual_subtype = actual_subtype.type
+                raise WrongSubTypeError(expected_type=object_type,
                                         expected_subtype=expected_subtype,
                                         actual_subtype=actual_subtype,
                                         value=value)
             check_sub_fields_level(field)
 
         return value
 
-    return validate_type
+    return validate_subtype
 
 
 def check_only_one_specified(first: Any, second: Any, message: str) -> None:
     first_present = first if isinstance(first, bool) else first is not None
     second_present = second if isinstance(second, bool) else second is not None
     if first_present and second_present:
         raise ValueError(message)
 
 
+def get_subfield_schema(field: Optional[ModelField], subfield_index: int) -> Optional[Dict[str, Any]]:
+    """
+    Creates a schema of the sub-field of the model field specified.
+
+    Args:
+        field: The model field.
+        subfield_index: The index of the sub-field of interest.
+
+    Returns:
+        The schema representing the sub-field of the model field if it is present, :py:data:`None` otherwise.
+    """
+    if field is None or field.sub_fields is None:
+        return None
+    subfield_schema = pydantic.schema_of(field.sub_fields[subfield_index].type_)
+    subfield_schema.pop('title', None)
+    return subfield_schema
+
+
+def get_dimension(field: Optional[ModelField], subfield_index: int) -> Optional[PhysicalDimension]:
+    """
+    Gets the physical dimension associated to the model field specified.
+
+    Args:
+        field: The model field.
+        subfield_index: The index of the sub-field of interest.
+
+    Returns:
+        The physical dimension associated to the model field if it is present, :py:data:`None` otherwise.
+    """
+    if field is None or field.sub_fields is None:
+        return None
+    dimension = field.sub_fields[subfield_index].type_
+    if dimension == Any:
+        return None
+    if issubclass(dimension, PhysicalDimension):
+        return dimension
+
+    raise TypeError(f"Unsupported {dimension}, should be a {PhysicalDimension.__name__!r} or 'typing.Any'.")
+
+
+def update_object_schema(field_schema: Dict[str, Any], **properties) -> None:
+    """
+    Updates the field schema with object properties, ignoring :py:data:`None` values.
+
+    Updates the dictionary with a key ``type`` set to ``object`` and a key ``property``, the value of which is a
+    dictionary containing all properties specified that are not :py:data:`None`.
+
+    Args:
+        field_schema: The field schema to update.
+        **properties: The properties
+
+    """
+    field_schema |= {"type": "object", "properties": {k: v for (k, v) in properties.items() if v is not None}}
+
+
 def validate(value: T,
              validators: Union[bool, ValidationFunc, Iterable[ValidationFunc]],
              msg_template: Optional[str] = None) -> T:
     """
     Validates a given value based on the validator function(s) specified.
 
     Args:
```

## optool/optimization/problem.py

```diff
@@ -34,15 +34,15 @@
     Finds the index at which the element with the specified name is located in the specified list of elements.
 
     Args:
         name: The name of the variable or constraint.
         elements: The list of elements to search.
 
     Returns:
-        The index at which the element is located, or `None` if the element is not present in the list.
+        The index at which the element is located, or :py:data:`None` if the element is not present in the list.
     """
 
     validate_each(elements, lambda x: hasattr(x, "name"), "Element is missing attribute 'name', see {value}.")
     index = [i for (i, element) in enumerate(elements) if name == element.name]
     if not index:
         return None
     if len(index) == 1:
```

## optool/optimization/variables.py

```diff
@@ -6,15 +6,15 @@
 import numpy as np
 from pint import Unit
 from pydantic import StrictBool, root_validator, validator
 
 from optool import BaseModel
 from optool.fields.misc import NonEmptyStr
 from optool.fields.numeric import ImmutableArray
-from optool.fields.quantities import QuantityLike
+from optool.fields.quantities import QuantityLike, UnitLike
 from optool.fields.util import validate
 from optool.logging import LOGGER
 from optool.math import SYMBOLIC_TYPES, has_offset, num_elements
 from optool.uom import UNITS, Quantity
 
 
 class OptimizationVariable(BaseModel, ABC):
@@ -28,16 +28,16 @@
 
     _frozen_nominal_values: StrictBool = False
     """Indicator flag to ensure that nominal values cannot be changed anymore. Shouldn't be set manually."""
 
     name: NonEmptyStr
     """The name of the decision variable."""
 
-    unit: Unit = None
-    """The physical unit_of_scaling_variable of the decision variable."""
+    unit: Optional[UnitLike] = None
+    """The physical unit of the decision variable."""
 
     initial_guess: QuantityLike[Any, ImmutableArray]
     """The initial values to provide to the solver."""
 
     lower_bounds: QuantityLike[Any, ImmutableArray]
     """The minimum values allowed for the decision variable."""
 
@@ -132,26 +132,26 @@
 
     def _freeze_nominal_values(self):
         if not self._frozen_nominal_values:
             LOGGER.debug("Freezing nominal values of variable named {}.", self.name)
             self._frozen_nominal_values = True
 
     @staticmethod
-    def casadi(name: str, n: int, unit: Optional[Unit] = None):
+    def casadi(name: str, n: int, unit: Optional[UnitLike] = None):
         return CasadiVariable(name, n, unit)
 
 
 class CasadiVariable(OptimizationVariable):
     """
     Representation of a decision variable using the modeling language CasADi.
     """
 
     _symbols: casadi.SX
 
-    def __init__(self, name: str, n: int, unit: Optional[Unit] = None):
+    def __init__(self, name: str, n: int, unit: Optional[UnitLike] = None):
         super().__init__(name=name,
                          unit=unit,
                          initial_guess=Quantity(np.zeros((n,)), unit),
                          lower_bounds=Quantity(np.full((n,), -math.inf), unit),
                          upper_bounds=Quantity(np.full((n,), math.inf), unit),
                          nominal_values=Quantity(np.ones((n,)), unit))
         self._symbols = casadi.SX.sym(self.name, n, 1)
```

## optool/serialization/__init__.py

```diff
@@ -43,14 +43,23 @@
 
 
 class SerializationAssistant:
     _serializers: Dict[str, Serializer] = {}
 
     @classmethod
     def register(cls, *serializers: Serializer) -> Dict[Union[Type[Any], str, ForwardRef], Callable]:
+        """
+        Registers the serializers specified.
+
+        Args:
+            *serializers: The serializers to register
+
+        Returns:
+            Dictionary mapping types to the corresponding JSON encoders.
+        """
         for serializer in serializers:
             obj_type = serializer.get_type()
             obj_type_name = serializer.get_type_name()
             LOGGER.debug("Registering serializer for {}.", obj_type)
             if obj_type_name in cls._serializers:
                 raise ValueError(f"There is already an entry in the registry for {obj_type_name}.")
             cls._serializers[obj_type_name] = serializer
```

## optool/serialization/numpy_objects.py

```diff
@@ -4,14 +4,17 @@
 
 import numpy as np
 
 from optool.serialization import AllowedSerializedDictKeys, Serializer
 
 
 class NumpyNdArraySerializer(Serializer[np.ndarray]):
+    """
+    Serializer for :py:class:`numpy.ndarray` objects.
+    """
 
     def serialize(self, obj: np.ndarray) -> Dict[AllowedSerializedDictKeys, Any]:
         return {"datatype": obj.dtype.name, "writeable": obj.flags.writeable, "values": obj.tolist()}
 
     def deserialize(self, raw: Dict[AllowedSerializedDictKeys, Any]) -> np.ndarray:
         value = np.asarray(raw["values"], dtype=raw["datatype"])
         value.setflags(write=raw['writeable'])
```

## optool/serialization/pint_objects.py

```diff
@@ -7,31 +7,40 @@
 from pint_pandas import PintArray
 
 from optool.serialization import AllowedSerializedDictKeys, Serializer
 from optool.uom import UNITS, Quantity
 
 
 class PintQuantitySerializer(Serializer[Quantity]):
+    """
+    Serializer for :py:class:`optool.uom.Quantity` objects.
+    """
 
     def serialize(self, obj: Quantity) -> Dict[AllowedSerializedDictKeys, Any]:
         return {'mag': obj.m, 'unit': obj.u}
 
     def deserialize(self, raw: Dict[AllowedSerializedDictKeys, Any]) -> Quantity:
         return Quantity(raw['mag'], raw['unit'])
 
 
 class PintUnitSerializer(Serializer[Unit]):
+    """
+    Serializer for :py:class:`pint.Unit` objects.
+    """
 
     def serialize(self, obj: Unit) -> Dict[AllowedSerializedDictKeys, Any]:
-        return dict(to_units_container(obj))
+        return dict(to_units_container(obj))  # type: ignore
 
     def deserialize(self, raw: Dict[AllowedSerializedDictKeys, Any]) -> Unit:
         return UNITS.Unit(UNITS.UnitsContainer(raw))
 
 
 class PintArraySerializer(Serializer[PintArray]):
+    """
+    Serializer for :py:class:`pint_pandas.PintArray` objects.
+    """
 
     def serialize(self, obj: PintArray) -> Dict[AllowedSerializedDictKeys, Any]:
         return {'mag': obj.quantity.m, 'unit': obj.quantity.u}
 
     def deserialize(self, raw: Dict[AllowedSerializedDictKeys, Any]) -> PintArray:
         return PintArray(raw['mag'], raw['unit'])
```

## Comparing `optool-0.3.0.dist-info/LICENSE.txt` & `optool-0.4.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `optool-0.3.0.dist-info/METADATA` & `optool-0.4.0.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 Metadata-Version: 2.1
 Name: optool
-Version: 0.3.0
+Version: 0.4.0
 Summary: Optimization tools
 Author: Andreas Ritter
 Author-email: anritter@idsc.mavt.ethz.ch
 License: MIT
 Project-URL: Source, https://gitlab.com/ocsept/optool
-Project-URL: Documentation, https://gitlab.com/ocsept/documentation
-Project-URL: API, https://ocsept.gitlab.io/optool
+Project-URL: Documentation, https://ocsept.gitlab.io/optool
+Project-URL: API, https://ocsept.gitlab.io/optool/api/modules.html
 Platform: any
 Classifier: Development Status :: 4 - Beta
 Classifier: Programming Language :: Python
 Requires-Python: >=3.9
 Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
 License-File: LICENSE.txt
 Requires-Dist: casadi
 Requires-Dist: humanize
 Requires-Dist: inflection
 Requires-Dist: loguru
 Requires-Dist: numpy
 Requires-Dist: pandas
-Requires-Dist: pint (~=0.20.1)
+Requires-Dist: pint
 Requires-Dist: pint-pandas
 Requires-Dist: pydantic
 Provides-Extra: testing
 Requires-Dist: setuptools ; extra == 'testing'
 Requires-Dist: pytest ; extra == 'testing'
 Requires-Dist: pytest-cov ; extra == 'testing'
 
 [![PyPI-Server](https://img.shields.io/pypi/v/optool.svg)](https://pypi.org/project/optool/)
-[![Built Status](https://gitlab.com/ocsept/optool/badges/master/pipeline.svg)](https://gitlab.com/ocsept/optool/)
-[![Coverage](https://gitlab.com/ocsept/optool/badges/master/coverage.svg)](https://gitlab.com/ocsept/optool/)
+[![Built Status](https://gitlab.com/ocsept/optool/badges/main/pipeline.svg)](https://gitlab.com/ocsept/optool/)
+[![Coverage](https://gitlab.com/ocsept/optool/badges/main/coverage.svg)](https://gitlab.com/ocsept/optool/)
 [![ReadTheDocs](https://readthedocs.org/projects/optool/badge/?version=latest)](https://ocsept.gitlab.io/optool)
 
 # OPTOOL - Optimization tools
 
 Generally usable utilities related to optimization problems.
 
 ## Installation
@@ -50,27 +50,28 @@
 The source code is structured in a number of packages and modules, each of which serves a different purpose.
 
 ### Packages
 
 - The package [fields](src/optool/fields) contains implementations for Pydantic-compatible field types.
 - The package [optimization](src/optool/optimization) provides a convenient interface to numerical solvers for
   optimization problems.
-- The package [serialization](src/optool/serialization) implements JSON-to-object converters and vice versa that can be
-  used by Pydantic.
+- The package [serialization](src/optool/serialization) implements JSON-to-object
+  converters and vice versa that
+  can be used by Pydantic.
 
 ### Modules
 
-- The module [conversions](src/optool/conversions.py) offers various convenient function for converting data.
-- The module [languages](src/optool/languages.py) offers tools for i18n and L10n.
-- The module [logging](src/optool/logging.py) implements logging features.
-- The module [math](src/optool/math.py) implements math operations.
-- The module [orthography](src/optool/orthography.py) contains utilities for converting text.
-- The module [parallel](src/optool/parallel.py) adds functionalities to run optimizations in parallel.
-- The module [uom](src/optool/uom.py) offers functionalities related to physical units of measurements.
-- The module [util](src/optool/util.py) provides general purpose classes.
+- The [conversions](src/optool/conversions.py) module offers various convenient function for converting data.
+- The [languages](src/optool/languages.py) module offers tools for i18n and L10n.
+- The [logging](src/optool/logging.py) module implements logging features.
+- The [math](src/optool/math.py) module implements math operations.
+- The [orthography](src/optool/orthography.py) module contains utilities for converting text.
+- The [parallel](src/optool/parallel.py) module adds functionalities to run optimizations in parallel.
+- The [uom](src/optool/uom.py) module offers functionalities related to physical units of measurements.
+- The [util](src/optool/util.py) module provides general purpose classes.
 
 ## Dependencies
 
 The following libraries are necessary to run the program code.
 
 - [casadi](https://web.casadi.org) allows to build efficient optimal control software with minimal effort.
 - [humanize](https://python-humanize.readthedocs.io/en/latest/) provides various common string-related utilities like
@@ -78,26 +79,26 @@
 - [inflection](https://inflection.readthedocs.io/en/latest/) provides functions for string transformation such as to
   singularize and pluralize English words, to transform strings from camel case to underscored string, etc.
 - [loguru](https://pypi.org/project/loguru/) intends to make Python logging less painful by adding a bunch of useful
   functionalities that solve caveats of the standard loggers.
 - [numpy](https://numpy.org) is the fundamental package for scientific computing with Python.
 - [pandas](https://pandas.pydata.org) provides fast, powerful, flexible and easy to use features for data analysis and
   manipulation.
-- [pint](https://pint.readthedocs.io/en/stable/) allows to define, operate and manipulate physical quantities. It allows
-  arithmetic operations between them and conversions from and to different units.
+- [pint](https://pint.readthedocs.io/en/stable/) allows to define, operate and manipulate physical quantities.
+  It allows arithmetic operations between them and conversions from and to different units.
 - [pint-pandas](https://pint.readthedocs.io/en/0.18/pint-pandas.html) provides an extension to Pandas, which allows
   Pandas to recognize the quantities and store them in Pandas data frames and series.
 - [pydantic](https://docs.pydantic.dev) provides extensive data validation features and serialization capabilities using
   Python type hints.
-- [pytz](https://pythonhosted.org/pytz/) allows accurate and cross-platform timezone calculations.
 
 ### Development dependencies
 
 The following additional libraries are necessary for development, which are however automatically installed when the
-corresponding [tox] commands are used. Hence, [tox] is the only Python package stringently necessary.
+corresponding [tox] commands are used.
+Hence, [tox] is the only Python package stringently necessary.
 
 - [autodoc-pydantic](https://pypi.org/project/autodoc-pydantic/) allows to integrate pydantic models in the Sphinx
   documentation.
 - [babel](https://babel.pocoo.org/en/latest/index.html) simplifies internationalizing and localizing
 - [docformatter](https://github.com/PyCQA/docformatter) formats the docstrings.
 - [flake8](https://pypi.org/project/flake8/) offers tools to enforce code style guides.
 - [isort](https://pypi.org/project/isort/) provides a command line utility, Python library and plugins for various
@@ -123,13 +124,12 @@
   button to sections of the documentation.
 - [sphinx-toggleprompt](https://pypi.org/project/sphinx-toggleprompt/) adds a python prompt toggle to each code cell of
   the Sphinx documentation.
 - [sphinx](https://pypi.org/project/Sphinx/) offers functionalities to easily create intelligent and beautiful
   documentation for Python projects.
 - [toml](https://pypi.org/project/toml/) provides features to parse and create Tom’s obvious, minimal language (TOML)
   files typically used for project configurations.
-- [tox] automates and standardizes testing in Python by offering a generic virtualenv management and test CLI. It allows
-  to run predefined test procedures on various environments on personal computers as well as on CI servers.
-- [types-pytz](https://pypi.org/project/types-pytz/) is the type stub package for the pytz package.
+- [tox] automates and standardizes testing in Python by offering a generic virtualenv management and test CLI.
+  It allows to run predefined test procedures on various environments on personal computers as well as on CI servers.
 - [yapf](https://pypi.org/project/yapf/) formats Python source code files.
 
 [tox]: https://tox.readthedocs.io/en/stable/
```

## Comparing `optool-0.3.0.dist-info/RECORD` & `optool-0.4.0.dist-info/RECORD`

 * *Files 13% similar despite different names*

```diff
@@ -1,37 +1,37 @@
-optool/VERSION,sha256=2RXMldbKj0euKXcT7UbU5cXZnd0p_Dxh4mO98wXytbA,6
-optool/__init__.py,sha256=NWssAsxFZGSHcfJ2bCZ4kj3mYySr_9Tl9Meu17o_XzI,5469
+optool/VERSION,sha256=QLjrQACpE6d5EJBTXykdPTaYdBYqie88nj1OiHobnnk,6
+optool/__init__.py,sha256=arfySE6uNjtDlfXqgdmlT71219M-Tf27rE-JRO3-_nY,6712
 optool/conversions.py,sha256=eUbpDZ4Ep1MB-o-QdMYHUiiz0QlzCaRp21wzVWfUvFU,949
 optool/languages.py,sha256=TLG-Ez5dqiyIy4JlHxy39WV9FgXPDcjFrghufIlZEsY,1094
 optool/logging.py,sha256=GidpPg6pZwcjsUOKMrC1YT-K6YZmZLY3RAB4wSgF4s0,4095
-optool/math.py,sha256=T3dS7zeDNBOh8IIDd85GTnBvZW_trsS0DyJiyacj4Ww,7758
+optool/math.py,sha256=s16qZHm5s3lo3XTcJIq50a5xIC8oFBx-qugoQ0TpyHI,7769
 optool/orthography.py,sha256=KjLnK8KWMW6_d29Nuu8aAmK9NdgH-vscP5UlFMyWyB0,1148
 optool/parallel.py,sha256=W1fXrDSSTL9-SJXO9yN1zYltyahsyObHBV4cvHRNUqo,1814
 optool/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-optool/uom.py,sha256=L5VrhdXebtYaTvDbp1EZXqYYS1lF1M6m0KW3nM8p30o,31001
+optool/uom.py,sha256=exYTwKnLURBG2g4TOTO7z48XemzvZ_js16zzSbVeGpo,32140
 optool/util.py,sha256=eKRxJ4Y6sYAzTdnJew-2V9Vfv36nWFRKA2ol2Q8ce7o,833
 optool/fields/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-optool/fields/callables.py,sha256=2mwcFPXTsYKsm50W-NzpPuR82R_Z0RNTDJPVat1UVSc,3914
+optool/fields/callables.py,sha256=8BpDvXRgrDCprQrpBV-8RDkjQs0kSb1FWBUVQcwN6Fs,4284
 optool/fields/containers.py,sha256=Bka5Yi1z0sURI29_n6cy3b8qHtT64en9EzjPiSJVHXY,4363
-optool/fields/dataframe.py,sha256=Wa4cMQaPDf9W13jYaan15uijPiAuxCv2-F-Fd5jA1Zk,2122
+optool/fields/dataframe.py,sha256=nGv281iFWtkLW2O1hQvcDd-4-nKxS8BsW2lDXfg7jKo,2312
 optool/fields/misc.py,sha256=61UDJlRyd_cDEYrCUhdGOHg8iZRV2_voUxYkHu8Q9wM,829
-optool/fields/numeric.py,sha256=ieibdvnKn1fdMG_LoKjv5F_leb2A-3ry7Wz44i1MP6k,6940
-optool/fields/quantities.py,sha256=gjPz-DXk7Q_QmNR0us4VekWuosbWbsCCA2HJ944qBI4,5143
-optool/fields/series.py,sha256=byV8kM64Klt-c6XVxv9wJJp1S-2KW2EI4Ig5AfPR-tc,6155
-optool/fields/symbolic.py,sha256=qLTVDYhQ1t8FFRlgqiVHiTqjo5-f-VERzTUHF13NpxY,2335
-optool/fields/util.py,sha256=JlD9FPCHPDBYXKKy3YSwwjjbdyAp66Csw4FqP1sMm8Y,5848
+optool/fields/numeric.py,sha256=psy6el7kkVETCWHRH6FPjTzn50laEQu6gcx0ZyeGaW4,7737
+optool/fields/quantities.py,sha256=YwnaSPl0ba9slSsZzSCEtXjV_MIyqwJ2fcYxRuCq_cU,5870
+optool/fields/series.py,sha256=q8FM2TEdW2dgJxld2JZ26sYwPlh45340sHrwFovzOGM,6249
+optool/fields/symbolic.py,sha256=tp7hu3kzyE5uAiVYVkvH9iJxu2UzZS94wqaTbnf2eWE,2590
+optool/fields/util.py,sha256=dQXgo2obNJClHWjZhRvBYfZgBCTOA55BIeKqUFuAQUA,8589
 optool/optimization/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 optool/optimization/constraints.py,sha256=jpjrBnTWsc6rYjrJ9Hm9UFIwuUNBmXg04Wvr-x3JdTw,4206
 optool/optimization/helpers.py,sha256=BS9gHdDxPlWStSD621oKQPWFrhJgfaSbCnRvbmaEjks,4535
 optool/optimization/ode.py,sha256=DmTG8PPNkRuGnKiGieMJ5_qziti1_Ug_UDYIwumlv6Y,8014
-optool/optimization/problem.py,sha256=uh_f-klvjd0Mn1M8mpoLwBuUR2qbzvnWKHtggDTML9U,21135
-optool/optimization/variables.py,sha256=fcIldRQcriB_k-XF15lfst95vD3eOHuXnV5aNCDV3wg,7159
-optool/serialization/__init__.py,sha256=K6VhGngQxaxGxkkOH0ZBrOKdF-sdZSQs5jpFAkmFCzs,2862
+optool/optimization/problem.py,sha256=CkLSpb9TkRSz4jKm8JBKZKn7nQeKYBDwy5XEJkUYi84,21144
+optool/optimization/variables.py,sha256=3_nVfjzQo-E3fOFkXE1wK21PK8EHJfVqFRNZ_NnF6ec,7171
+optool/serialization/__init__.py,sha256=WGAyPU2RGld0ftiCcxgAleNV2NyX9rLRcRQNWYANr44,3091
 optool/serialization/datetime_objects.py,sha256=YaCHFJLYhfbQJeJnchpo2eQPActARuMuYOGlNLW4tfs,1317
-optool/serialization/numpy_objects.py,sha256=ORn0PRNFDEospPZPfnRBftAvzFQ3sqT5F7PMX4yIHuQ,616
+optool/serialization/numpy_objects.py,sha256=DV5zK-sXgx0dCtukU6lackGudji82vdhkNpQMHxBhVA,686
 optool/serialization/pandas_objects.py,sha256=layoYfhGtMLJeHZL4nwaeR2kuBqFK-OP1JBFlDPe4_Y,2880
-optool/serialization/pint_objects.py,sha256=xr2vjpCoT1JT--yElo9CjXIqR-VHlsQQhBS1IukdDfk,1217
-optool-0.3.0.dist-info/LICENSE.txt,sha256=hrghB2ojre3BR1nxeXTWOsbhc7CzFIRaC2r1Ez1gV10,1081
-optool-0.3.0.dist-info/METADATA,sha256=sIKTG_EIvqcOr2uBlueuGnIcq38MfUuq85CBrrZIzuY,7771
-optool-0.3.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-optool-0.3.0.dist-info/top_level.txt,sha256=rBfjZiBTokmEUSgWAvNw23rTh-MvuILbz6o2LeWprko,7
-optool-0.3.0.dist-info/RECORD,,
+optool/serialization/pint_objects.py,sha256=7ocbd5Fhwox0UJf-0-wLEPHPlFOu1z2tvDGVfWhWphw,1453
+optool-0.4.0.dist-info/LICENSE.txt,sha256=hrghB2ojre3BR1nxeXTWOsbhc7CzFIRaC2r1Ez1gV10,1081
+optool-0.4.0.dist-info/METADATA,sha256=GHggC_tR7rqScMniLGTouvjnyGYPA1VUd1x325Dtwv0,7568
+optool-0.4.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+optool-0.4.0.dist-info/top_level.txt,sha256=rBfjZiBTokmEUSgWAvNw23rTh-MvuILbz6o2LeWprko,7
+optool-0.4.0.dist-info/RECORD,,
```

